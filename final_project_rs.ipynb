{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project\n",
    "## Robert Shaheen version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "December 02, 2018 19:46:31\n"
     ]
    }
   ],
   "source": [
    "#Last run date\n",
    "import datetime\n",
    "print (datetime.datetime.now().strftime(\"%B %d, %Y %H:%M:%S\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "create_directory = False\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "if not(os.path.isdir(IMAGES_PATH)) and (create_directory):\n",
    "    os.makedirs(IMAGES_PATH)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BK Import section\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import expon, reciprocal, uniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 288)\n",
      "(1460, 288)\n"
     ]
    }
   ],
   "source": [
    "#An alternate way to prepare data\n",
    "df_train = pd.read_csv('datasets/train.csv')\n",
    "df_test = pd.read_csv('datasets/train.csv')\n",
    "\n",
    "sale_price=df_train.pop('SalePrice')\n",
    "df_train.drop(['Id'], inplace=True, axis=1)\n",
    "df_test.drop(['Id'], inplace=True, axis=1)\n",
    "\n",
    "numerical_features_indices_tr = np.where(df_train.dtypes != np.object)[0]\n",
    "categorical_features_indices_tr = np.where(df_train.dtypes == np.object)[0]\n",
    "\n",
    "numerical_features_indices = np.where(df_train.dtypes != np.object)[0]\n",
    "categorical_features_indices = np.where(df_train.dtypes == np.object)[0]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        #('poly_features', PolynomialFeatures(degree=1, include_bias=False)), # Take much more time to run\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent')), \n",
    "        ('cat_Encoder', OneHotEncoder(handle_unknown='ignore')), \n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num', num_pipeline, numerical_features_indices),\n",
    "        ('cat1', cat_pipeline, categorical_features_indices),\n",
    "    ])\n",
    "\n",
    "df_prep = full_pipeline.fit_transform(df_train)\n",
    "print(df_prep.shape)\n",
    "\n",
    "df_test = full_pipeline.transform(df_test)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(df_prep, sale_price, random_state = 42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models with the same input data\n",
    "names = [\"Linear Regression\", \"SVR\",\"Ridge\",\"Lasso\",\"ElasticNet\",\"SGDRegressor\",\"KNeighbors Regressor\",\n",
    "         \"Decision Tree Regressor\", \"Random Forest Regressor\"]\n",
    "\n",
    "baseline_regressors = [\n",
    "    LinearRegression(), \n",
    "    SVR(kernel=\"linear\"),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    ElasticNet(random_state=42),\n",
    "    SGDRegressor(random_state=42),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    RandomForestRegressor(random_state=42)\n",
    "]\n",
    "\n",
    "# Create a dictionary for the regressor mapped to the rmse of baseline regressor\n",
    "base_rmse = {}\n",
    "# dict to store final models\n",
    "final_models = {}\n",
    "    \n",
    "tuned_regressors = [\n",
    "    LinearRegression(), \n",
    "    SVR(kernel=\"linear\"),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    ElasticNet(random_state=42),\n",
    "    SGDRegressor(random_state=42),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    RandomForestRegressor(random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regressor_RMSE(X_tr, X_ts, y_tr, y_ts,regressors):\n",
    "    for name, rgs in zip(names, regressors):\n",
    "        rgs.fit(X_tr, y_tr)\n",
    "        y_pred =rgs.predict(X_ts)\n",
    "        rmse = np.sqrt(mean_squared_error(y_ts, y_pred)) \n",
    "        base_rmse[name] = rmse\n",
    "        print('RMSE for {0} model is {1}'.format(name,  rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear Regression model is 29511.17445905894\n",
      "RMSE for SVR model is 82230.28697572199\n",
      "RMSE for Ridge model is 30081.345746646897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Lasso model is 28166.597817133625\n",
      "RMSE for ElasticNet model is 36274.987007837975\n",
      "RMSE for SGDRegressor model is 32052.21241784793\n",
      "RMSE for KNeighbors Regressor model is 38010.12204533282\n",
      "RMSE for Decision Tree Regressor model is 45286.728826158025\n",
      "RMSE for Random Forest Regressor model is 33190.903777621184\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print_regressor_RMSE(train_X, val_X, train_y, val_y,baseline_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the reults from the grid/random searchCV runs\n",
    "def print_scores(estimator, display_threshold=40000):\n",
    "    rbf_cvrs = estimator.cv_results_\n",
    "    for mean_score, params in zip(rbf_cvrs[\"mean_test_score\"], rbf_cvrs[\"params\"]):\n",
    "        if np.sqrt(-mean_score) < display_threshold:\n",
    "            print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate using validation data\n",
    "def validate_model(model_name, estimator, original_list=names, X=val_X, y=val_y):\n",
    "    print('The best parameters for {0} model are:\\n{1}\\n'.format(model_name, grid_search.best_params_))\n",
    "    final_models[model_name]=estimator.best_estimator_\n",
    "    y_pred = final_models[model_name].predict(X)\n",
    "    rmse= np.sqrt(mean_squared_error(y, y_pred))\n",
    "    print('The RMSE for model is: {0:.2f}'.format(rmse))\n",
    "    if model_name in original_list:\n",
    "        print('The overall improvement with tuned hyper parameters is {0:.2%}'\n",
    "              .format((base_rmse[model_name]-rmse)/base_rmse[model_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    3.3s finished\n",
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - Linear Regression\n",
    "param_grid = {\n",
    "    'fit_intercept': [True],\n",
    "}\n",
    "\n",
    "# oddly enough it seems that the best fit is the unchanged algorthim\n",
    "\n",
    "grid_search = GridSearchCV(LinearRegression(), param_grid, cv=10,scoring='neg_mean_squared_error',verbose=1,n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for Linear Regression model are:\n",
      "{'fit_intercept': True}\n",
      "\n",
      "The RMSE for model is: 29511.18\n",
      "The overall improvement with tuned hyper parameters is -0.00%\n"
     ]
    }
   ],
   "source": [
    "validate_model('Linear Regression', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:    3.1s finished\n",
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - SVR\n",
    "param_distribs = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [113564],\n",
    "    'gamma': [0.0007790692366582295],\n",
    "}\n",
    "\n",
    "# oddly enough it seems that the best fit is the unchanged algorthim\n",
    "\n",
    "rand_search = RandomizedSearchCV(SVR(), param_distributions=param_distribs, n_iter=1, cv=5, \n",
    "                                 scoring='neg_mean_squared_error', verbose=1, n_jobs=2, random_state=42)\n",
    "rand_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31013.627149321474 {'kernel': 'rbf', 'gamma': 0.0007790692366582295, 'C': 113564}\n"
     ]
    }
   ],
   "source": [
    "print_scores(rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for SVR model are:\n",
      "{'fit_intercept': True}\n",
      "\n",
      "The RMSE for model is: 32261.25\n",
      "The overall improvement with tuned hyper parameters is 60.77%\n"
     ]
    }
   ],
   "source": [
    "validate_model('SVR', rand_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - Ridge\n",
    "param_grid = {\n",
    "    'alpha': [1.0],\n",
    "    'fit_intercept': [True],\n",
    "    #'solver': ['cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'auto'],\n",
    "    'solver': ['auto'],\n",
    "}\n",
    "\n",
    "# oddly enough it seems that the best fit is the unchanged algorthim\n",
    "\n",
    "grid_search = GridSearchCV(Ridge(random_state=42), param_grid, cv=3,scoring='neg_mean_squared_error',verbose=1,n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35272.76116039517 {'alpha': 1.0, 'fit_intercept': True, 'solver': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for Ridge model are:\n",
      "{'alpha': 1.0, 'fit_intercept': True, 'solver': 'auto'}\n",
      "\n",
      "The RMSE for model is: 30081.35\n",
      "The overall improvement with tuned hyper parameters is 0.00%\n"
     ]
    }
   ],
   "source": [
    "validate_model('Ridge', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    6.6s finished\n",
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - Lasso\n",
    "param_grid = {\n",
    "    'alpha': [1.0],\n",
    "    'max_iter': [1000],\n",
    "}\n",
    "\n",
    "# oddly enough it seems that the best fit is the unchanged algorthim\n",
    "\n",
    "grid_search = GridSearchCV(Lasso(random_state=42), param_grid, cv=10,scoring='neg_mean_squared_error',verbose=1,n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37032.95471550481 {'alpha': 1.0, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for Lasso model are:\n",
      "{'alpha': 1.0, 'max_iter': 1000}\n",
      "\n",
      "The RMSE for model is: 28166.60\n",
      "The overall improvement with tuned hyper parameters is 0.00%\n"
     ]
    }
   ],
   "source": [
    "validate_model('Lasso', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - Elastic Net\n",
    "param_grid = {\n",
    "    'alpha': [0.1],\n",
    "    'l1_ratio': [0.775],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(ElasticNet(random_state=42), param_grid, cv=8,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33628.6959313338 {'alpha': 0.1, 'l1_ratio': 0.775}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for ElasticNet model are:\n",
      "{'alpha': 0.1, 'l1_ratio': 0.775}\n",
      "\n",
      "The RMSE for model is: 31138.20\n",
      "The overall improvement with tuned hyper parameters is 14.16%\n"
     ]
    }
   ],
   "source": [
    "validate_model('ElasticNet', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDRegressor optimization - no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 484 tasks      | elapsed:    5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 960 out of 960 | elapsed:   13.0s finished\n",
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - SGDRegressor\n",
    "param_grid = {\n",
    "    'eta0': np.linspace(0.001, 0.1, num=20),\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'max_iter': [50],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'power_t':[0.5],\n",
    "    'penalty': ['none']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SGDRegressor(random_state=42), param_grid, verbose=1, cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34954.45710065991 {'eta0': 0.01663157894736842, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 50, 'penalty': 'none', 'power_t': 0.5}\n",
      "34961.38728992931 {'eta0': 0.021842105263157895, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 50, 'penalty': 'none', 'power_t': 0.5}\n",
      "34967.959445105684 {'eta0': 0.03226315789473684, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 50, 'penalty': 'none', 'power_t': 0.5}\n",
      "34923.57392029842 {'eta0': 0.03747368421052632, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 50, 'penalty': 'none', 'power_t': 0.5}\n",
      "34947.950573622315 {'eta0': 0.04268421052631579, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 50, 'penalty': 'none', 'power_t': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search, display_threshold=35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for SGDRegressor model are:\n",
      "{'eta0': 0.03747368421052632, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 50, 'penalty': 'none', 'power_t': 0.5}\n",
      "\n",
      "The RMSE for model is: 31602.49\n",
      "The overall improvement with tuned hyper parameters is 1.40%\n"
     ]
    }
   ],
   "source": [
    "validate_model('SGDRegressor', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDRegressor Optimization - with regularization\n",
    "commented out because it runs 72000 fits with no performance increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #Hyper parameters optimization - SGDRegressor\n",
    "# param_grid = [\n",
    "#     {'eta0': np.linspace(0.001, 0.1, num=20),\n",
    "#     'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "#     'max_iter': [50],\n",
    "#     'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "#     'power_t':[0.5],\n",
    "#     'penalty': ['l2','l1','elasticnet'],\n",
    "#     'l1_ratio': np.linspace(0, 1, num=5),\n",
    "#     'alpha': np.linspace(0.0001, 0.1, num=5),\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# grid_search = GridSearchCV(SGDRegressor(random_state=42), param_grid, verbose=1, cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "# grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_model('SGDRegressor', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    8.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:   10.3s finished\n",
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - KNeighbors Regressor\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(3,8),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, verbose=1, cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35851.730793495444 {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "35437.67194871518 {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "39996.77996214185 {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "39970.572570900615 {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
      "35782.53637057415 {'algorithm': 'auto', 'n_neighbors': 4, 'p': 1, 'weights': 'uniform'}\n",
      "35334.809806304154 {'algorithm': 'auto', 'n_neighbors': 4, 'p': 1, 'weights': 'distance'}\n",
      "39138.54812932241 {'algorithm': 'auto', 'n_neighbors': 4, 'p': 2, 'weights': 'uniform'}\n",
      "39098.05664835088 {'algorithm': 'auto', 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n",
      "36047.41645732144 {'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
      "35580.81488372424 {'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "37852.31038590408 {'algorithm': 'auto', 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "37852.34914326504 {'algorithm': 'auto', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
      "35857.531848758386 {'algorithm': 'auto', 'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}\n",
      "35442.769827881064 {'algorithm': 'auto', 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
      "37365.49923825976 {'algorithm': 'auto', 'n_neighbors': 6, 'p': 2, 'weights': 'uniform'}\n",
      "37351.70655547077 {'algorithm': 'auto', 'n_neighbors': 6, 'p': 2, 'weights': 'distance'}\n",
      "36131.816204452 {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n",
      "35687.66882433845 {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "37433.22952490392 {'algorithm': 'auto', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "37372.86280871062 {'algorithm': 'auto', 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for KNeighbors Regressor model are:\n",
      "{'algorithm': 'auto', 'n_neighbors': 4, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "The RMSE for model is: 33949.72\n",
      "The overall improvement with tuned hyper parameters is 10.68%\n"
     ]
    }
   ],
   "source": [
    "validate_model('KNeighbors Regressor', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the most important features\n",
    "def most_important_features(model, rgr_name, numResults=288, sort=True):\n",
    "    important_features = []\n",
    "    df = pd.DataFrame(df_prep.toarray()) \n",
    "    for name, score in zip(df.columns, model.feature_importances_):\n",
    "        important_features.append((name, score))\n",
    "\n",
    "    if sort:\n",
    "        important_features.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    print('Top 10 features according to {}.\\n'.format(rgr_name))\n",
    "    print('Column # represents the column location in df_prep (with one_hot_encoding):\\n')\n",
    "    print('{:>12}{:>7}\\n'.format('Column #', 'Score'))\n",
    "\n",
    "    for name, score in important_features[0:numResults]:\n",
    "        print('{:>12}: {:>8}'.format(name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 590 tasks      | elapsed:   12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 720 out of 720 | elapsed:   16.2s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - Decision Tree Regressor\n",
    "param_grid = {\n",
    "    'max_depth': np.append(np.arange(1,30+1,2), None),\n",
    "    'min_samples_split': np.arange(2,30+1,2),\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_features': ['auto'],\n",
    "    #'max_leaf_nodes': np.append(np.arange(2,25), None),\n",
    "    'max_leaf_nodes': [None], # none is the best every time\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid, verbose=1, cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38415.557018841486 {'max_depth': 13, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 17, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 19, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 21, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 23, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 25, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 27, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': 29, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "38415.557018841486 {'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search, display_threshold=38416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for Decision Tree Regressor model are:\n",
      "{'max_depth': 13, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 22}\n",
      "\n",
      "The RMSE for model is: 34931.28\n",
      "The overall improvement with tuned hyper parameters is 22.87%\n"
     ]
    }
   ],
   "source": [
    "validate_model('Decision Tree Regressor', grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features according to Decision Tree Regressor.\n",
      "\n",
      "Column # represents the column location in df_prep (with one_hot_encoding):\n",
      "\n",
      "    Column #  Score\n",
      "\n",
      "           3: 0.685652492153181\n",
      "          15: 0.11322765628744695\n",
      "          11: 0.033788062958275966\n",
      "          13: 0.030759413326429414\n",
      "           8: 0.01806852160964238\n"
     ]
    }
   ],
   "source": [
    "# Print the most important features according to decision tree analysis\n",
    "most_important_features(final_models['Decision Tree Regressor'], 'Decision Tree Regressor', numResults=5, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Hyperparameters optimization - Random Forest Regressor\n",
    "# # Use RandomSearchCV\n",
    "# # 38min 58s run time with the following params:\n",
    "\n",
    "# param_dist = {\n",
    "#      'n_estimators': np.arange(1500,2000+1),\n",
    "#      'max_depth': np.arange(15,25+1),\n",
    "#      'max_features': np.arange(20,100+1),\n",
    "#      'min_samples_split': np.arange(5, 7+1), \n",
    "#      'min_samples_leaf': [2], \n",
    "# }\n",
    "\n",
    "# rand_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_distributions=param_dist, scoring='neg_mean_squared_error', \n",
    "#                                     n_iter=100, cv=3, verbose=1, random_state=42, n_jobs=2)\n",
    "# rand_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_scores(rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_model('Random Forest Regressor', rand_search)\n",
    "\n",
    "# # --- results ----\n",
    "# # The best parameters for Random Forest Regressor model are:\n",
    "# # {'n_estimators': 1762, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 100, 'max_depth': 18}\n",
    "\n",
    "# # The RMSE for Random Forest Regressor model is: 29175.04\n",
    "# # The overall improvement with tuned hyper parameters is 12.10%\n",
    "\n",
    "# # Labeled data mean = 178840, rmse/mean = 16.31%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:   53.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - Random Forest Regressor\n",
    "param_grid = {\n",
    "    'n_estimators': [2000],\n",
    "    'max_depth': [18],\n",
    "    'max_features': [120],\n",
    "    'min_samples_split': [5], \n",
    "    'min_samples_leaf': [2], \n",
    "    # 'max_leaf_nodes': np.arange(2, 100+1, 10) # does not help rmse_val\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, verbose=1, cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29053.836358164444 {'max_depth': 18, 'max_features': 120, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 2000}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for Random Forest Regressor model are:\n",
      "{'max_depth': 18, 'max_features': 120, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 2000}\n",
      "\n",
      "The RMSE for model is: 28853.04\n",
      "The overall improvement with tuned hyper parameters is 13.07%\n"
     ]
    }
   ],
   "source": [
    "validate_model('Random Forest Regressor', grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features according to Random Forest Regressor.\n",
      "\n",
      "Column # represents the column location in df_prep (with one_hot_encoding):\n",
      "\n",
      "    Column #  Score\n",
      "\n",
      "           3: 0.3009408618104748\n",
      "          15: 0.1356567961478179\n",
      "          25: 0.08838503393349043\n",
      "         170: 0.047836395154024755\n",
      "          11: 0.04457602342625789\n"
     ]
    }
   ],
   "source": [
    "most_important_features(final_models['Random Forest Regressor'], 'Random Forest Regressor', numResults=5, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- best results ----\n",
    "# The best parameters for Random Forest Regressor model are:\n",
    "# {'max_depth': 18, 'max_features': 120, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 2000}\n",
    "\n",
    "# The RMSE for Random Forest Regressor model is: 28853.04\n",
    "# The overall improvement with tuned hyper parameters is 13.07%\n",
    "\n",
    "# Labeled data mean = 178840, rmse/mean = 16.13%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    2.8s finished\n",
      "C:\\Users\\Rob\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - BaggingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'max_samples': [1.0],\n",
    "    'max_features': [1.0],\n",
    "    'n_estimators': [7],\n",
    "    'bootstrap': [True],\n",
    "#     'base_estimator': [final_models['Lasso'], final_models['Linear Regression'], final_models['ElasticNet'],\n",
    "#                       final_models['SVR'], final_models['Ridge'], final_models['SGDRegressor'], LinearRegression(),\n",
    "#                       Lasso(random_state=42)],\n",
    "    'base_estimator': [final_models['SVR']]\n",
    "}\n",
    "\n",
    "bag_rgr = BaggingRegressor(n_jobs=2, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bag_rgr, param_grid=param_grid, verbose=1, \n",
    "                           cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31363.471514839377 {'base_estimator': SVR(C=113564, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "  gamma=0.0007790692366582295, kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'bootstrap': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 7}\n"
     ]
    }
   ],
   "source": [
    "print_scores(grid_search, display_threshold=33200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for BaggingRegressor model are:\n",
      "{'base_estimator': SVR(C=113564, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "  gamma=0.0007790692366582295, kernel='rbf', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'bootstrap': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 7}\n",
      "\n",
      "The RMSE for model is: 32006.70\n"
     ]
    }
   ],
   "source": [
    "validate_model('BaggingRegressor', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Hyper parameters optimization - GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'max_samples': [1.0],\n",
    "    'max_features': [1.0],\n",
    "    'n_estimators': [7],\n",
    "    'bootstrap': [True],\n",
    "#     'base_estimator': [final_models['Lasso'], final_models['Linear Regression'], final_models['ElasticNet'],\n",
    "#                       final_models['SVR'], final_models['Ridge'], final_models['SGDRegressor'], LinearRegression(),\n",
    "#                       Lasso(random_state=42)],\n",
    "    'base_estimator': [final_models['SVR']]\n",
    "}\n",
    "\n",
    "bag_rgr = BaggingRegressor(n_jobs=2, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bag_rgr, param_grid=param_grid, verbose=1, \n",
    "                           cv=3,scoring='neg_mean_squared_error', n_jobs=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(grid_search, display_threshold=33200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model('GradientBoostingRegressor', grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
