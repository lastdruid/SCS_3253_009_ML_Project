{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('uoft_ai_class_1/final_project/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HeatingQC',\n",
       " 'Condition2',\n",
       " 'BsmtExposure',\n",
       " 'CentralAir',\n",
       " 'PavedDrive',\n",
       " 'ExterCond',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'Condition1',\n",
       " 'ExterQual',\n",
       " 'GarageQual',\n",
       " 'RoofMatl',\n",
       " 'PoolQC',\n",
       " 'SaleCondition',\n",
       " 'Exterior1st',\n",
       " 'LotConfig',\n",
       " 'BsmtFinType1',\n",
       " 'Electrical',\n",
       " 'FireplaceQu',\n",
       " 'Neighborhood',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'Functional',\n",
       " 'GarageFinish',\n",
       " 'LandSlope',\n",
       " 'Foundation',\n",
       " 'Alley',\n",
       " 'GarageType',\n",
       " 'Heating',\n",
       " 'BldgType',\n",
       " 'MasVnrType',\n",
       " 'Fence',\n",
       " 'Utilities',\n",
       " 'LotShape',\n",
       " 'BsmtCond',\n",
       " 'KitchenQual',\n",
       " 'BsmtFinType2',\n",
       " 'MSZoning',\n",
       " 'BsmtQual',\n",
       " 'Exterior2nd',\n",
       " 'Street',\n",
       " 'GarageCond',\n",
       " 'LandContour']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the non-numerical columns\n",
    "\n",
    "cols = df_train.columns\n",
    "num_cols = df_train._get_numeric_data().columns\n",
    "list(set(cols) - set(num_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a8806302b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(corrmat, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of sale prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladimir\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a882947908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sale price / year built chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.concat([df_train['SalePrice'], df_train['YearBuilt']], axis=1)\n",
    "p = data.plot.scatter(x='SalePrice', y='YearBuilt', xlim=(0,650000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.concat([df_train['SalePrice'], df_train['OverallQual']], axis=1)\n",
    "p = data.plot.scatter(x='SalePrice', y='OverallQual', xlim=(0,650000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('uoft_ai_class_1/final_project/train.csv')\n",
    "df_test = pd.read_csv('uoft_ai_class_1/final_project/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Convert categories to one-hot-encodings\n",
    "    df_train_one_hot = pd.get_dummies(df)\n",
    "    \n",
    "    # Scale the dataframe\n",
    "    x = df_train_one_hot.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_train_one_hot_2 = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    return df_train_one_hot_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)\n",
    "# maybe we should use log for the sale price?\n",
    "# df_train[\"SalePrice\"] = np.log1p(df_train[\"SalePrice\"])\n",
    "\n",
    "sale_price = df_train['SalePrice']\n",
    "df_train.drop(['Id', 'SalePrice'], inplace=True, axis=1)\n",
    "\n",
    "df_train = prep_df(df_train)\n",
    "df_test = prep_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(df_train, sale_price, random_state = 42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Neural Network with TensorBoard support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir='./uoft_ai_class_1/Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons used (64, 8)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 482us/step - loss: 39209727090.1681 - val_loss: 38415715285.9178\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 39208035719.6844 - val_loss: 38416462441.2055\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 39205292425.4408 - val_loss: 38410682255.7808\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 39201872493.7770 - val_loss: 38408652631.6712\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 39197534179.8971 - val_loss: 38404936128.8767\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39192441646.9846 - val_loss: 38402884032.8767\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39186605841.1252 - val_loss: 38393029589.9178\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 39180532172.1852 - val_loss: 38381394621.3699\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 39173097605.4889 - val_loss: 38376386391.6712\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 39164851953.5094 - val_loss: 38371018106.7397\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 39155954816.2196 - val_loss: 38363417389.5890\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 39146269975.2727 - val_loss: 38352578924.7123\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 39134415701.6261 - val_loss: 38343175490.6301\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 39123983930.8405 - val_loss: 38338467727.7808\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39111580842.3739 - val_loss: 38323054704.2192\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 39100755546.4563 - val_loss: 38307878322.8493\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 39086853996.4597 - val_loss: 38293007261.8082\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 39072688152.5900 - val_loss: 38279144742.5753\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39056718895.4237 - val_loss: 38258308222.2466\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 39043245809.5094 - val_loss: 38237919540.6027\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39024455672.9743 - val_loss: 38223458977.3151\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39005667240.1784 - val_loss: 38208045308.4931\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38992777068.4597 - val_loss: 38185598134.3562\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38964828549.9280 - val_loss: 38169616243.7260\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38951283502.9846 - val_loss: 38149804256.4384\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38930617668.9400 - val_loss: 38122783449.4247\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38907505679.8079 - val_loss: 38105155163.1781\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 38887508976.1921 - val_loss: 38089194229.4795\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38868416817.6192 - val_loss: 38066174260.6027\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38842657273.8525 - val_loss: 38038892123.1781\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38817791332.5557 - val_loss: 38017437415.4521\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38793764849.9485 - val_loss: 37988674125.1507\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 38768360818.6072 - val_loss: 37960654876.0548\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38740717596.1029 - val_loss: 37934848701.3699\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 38710479504.9057 - val_loss: 37906747392.0000\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38690688286.2985 - val_loss: 37882451434.9589\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38664537058.1406 - val_loss: 37858491406.0274\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38624081013.6810 - val_loss: 37826807836.0548\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 38604775424.0000 - val_loss: 37793551514.3014\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38562314566.6964 - val_loss: 37764852974.4658\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 38541878217.5506 - val_loss: 37731120085.9178\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38522728195.0738 - val_loss: 37698115668.1644\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38476995336.3431 - val_loss: 37662110649.8630\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38454704405.5163 - val_loss: 37627305843.7260\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38400339637.7907 - val_loss: 37586609053.8082\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38367081652.9125 - val_loss: 37555387967.1233\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38325076600.3156 - val_loss: 37520020690.4110\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38309869606.6415 - val_loss: 37478059078.1370\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38256635889.9485 - val_loss: 37441993489.5342\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38232040913.4546 - val_loss: 37402707771.6164\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38173511047.6844 - val_loss: 37358163827.7260\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38128065611.5266 - val_loss: 37317430229.9178\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38114007124.3087 - val_loss: 37284975910.5753\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38069470048.1647 - val_loss: 37238745284.3836\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38029660388.3362 - val_loss: 37193790506.0822\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37980699006.9022 - val_loss: 37162362823.8904\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 37925221869.5575 - val_loss: 37111852158.2466\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 37904038404.3911 - val_loss: 37063130210.1918\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 37885945978.9503 - val_loss: 37028029818.7397\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 37812745228.2950 - val_loss: 36979481557.9178\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 37742369217.6467 - val_loss: 36939991601.0959\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 37728351275.9108 - val_loss: 36909065426.4110\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 37690082428.7067 - val_loss: 36845763626.0822\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 37601904039.3002 - val_loss: 36796212714.9589\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 139us/step - loss: 37583522434.8542 - val_loss: 36724763493.6986\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37514319843.8971 - val_loss: 36679389324.2740\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 37476653505.6467 - val_loss: 36634060182.7945\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37437957406.2985 - val_loss: 36580794480.2192\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 37311710995.692 - 0s 142us/step - loss: 37359955195.1698 - val_loss: 36518482958.0274\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 37292305409.7564 - val_loss: 36470046523.6164\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37221978631.9039 - val_loss: 36419414661.2603\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 37201964465.8388 - val_loss: 36366537208.9863\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 37188630672.0274 - val_loss: 36316665996.2740\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 37075915040.0549 - val_loss: 36262832604.9315\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37033336164.5557 - val_loss: 36204298632.7671\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 36998047782.6415 - val_loss: 36141908669.3699\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 36936083782.6964 - val_loss: 36073594964.1644\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 36882170056.2333 - val_loss: 36017164652.7123\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 36812272378.2916 - val_loss: 35960055723.8356\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 36770324262.2024 - val_loss: 35896110206.2466\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 36675189635.2933 - val_loss: 35847263835.1781\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 36618767561.9897 - val_loss: 35789587778.6301\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 36595366537.8799 - val_loss: 35738504234.0822\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 36529728861.5300 - val_loss: 35671945496.5479\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 36467173632.4391 - val_loss: 35614405561.8630\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 36379576369.1801 - val_loss: 35553127774.6849\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 36345168595.6501 - val_loss: 35485283426.1918\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 36296482573.6124 - val_loss: 35398027179.8356\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 36159499817.2762 - val_loss: 35331398193.0959\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 36163668997.2693 - val_loss: 35277100887.6712\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 36106327470.3259 - val_loss: 35224893019.1781\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 35982861858.2504 - val_loss: 35154857142.3562\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 35940615092.4734 - val_loss: 35093970579.2877\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 35886988816.6861 - val_loss: 35008141873.0959\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 35880186628.8302 - val_loss: 34958585182.6849\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 35762360857.4683 - val_loss: 34882273167.7808\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 35734502503.6295 - val_loss: 34808224501.4795\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 35594426336.3842 - val_loss: 34741327591.4521\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 35484964235.1973 - val_loss: 34655383580.0548\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 35431647038.7924 - val_loss: 34587759377.5342\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 35401818976.1647 - val_loss: 34502584796.9315\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 35350395709.0360 - val_loss: 34424579001.8630\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 35223405555.7050 - val_loss: 34352567506.4110\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 35155723174.4220 - val_loss: 34278795460.3836\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 35036902833.8388 - val_loss: 34213535603.7260\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 35012418958.7101 - val_loss: 34130845415.4521\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 34916536643.1835 - val_loss: 34062506208.4384\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 34882847282.0583 - val_loss: 33983619520.8767\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 34754894150.6964 - val_loss: 33895998478.0274\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 34685064074.3190 - val_loss: 33813395932.9315\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 34555093311.6707 - val_loss: 33748893527.6712\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 34575924601.6329 - val_loss: 33659674427.6164\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 34461367327.6158 - val_loss: 33582354403.9452\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 34422173755.7187 - val_loss: 33500151976.3288\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 34249919082.2641 - val_loss: 33411581306.7397\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 34217267105.1527 - val_loss: 33322514908.9315\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 34167842977.5918 - val_loss: 33240020122.3014\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 34119379741.4202 - val_loss: 33146366344.7671\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 33972610745.3036 - val_loss: 33063995083.3973\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 33944003712.2196 - val_loss: 32986715570.8493\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 33911532373.6261 - val_loss: 32919219662.9041\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 33742348793.8525 - val_loss: 32841786522.3014\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 33524503652.1166 - val_loss: 32752878493.8082\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 33544288593.2350 - val_loss: 32668569936.6575\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 33487083425.1527 - val_loss: 32592763413.0411\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 33437393647.7530 - val_loss: 32491854974.2466\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 33376881957.3242 - val_loss: 32409007594.9589\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 33158095754.3190 - val_loss: 32321495040.0000\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 149us/step - loss: 33094553737.0017 - val_loss: 32234445361.0959\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 33012223283.3756 - val_loss: 32145135587.9452\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 33030711123.8696 - val_loss: 32046351850.9589\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 32862972504.6998 - val_loss: 31950006384.2192\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 32718654585.1938 - val_loss: 31850183946.5205\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 32648510184.7273 - val_loss: 31763540220.4931\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 32547849779.8148 - val_loss: 31661061386.5205\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 32568827496.5077 - val_loss: 31572676664.1096\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 32326228691.6501 - val_loss: 31476428800.0000\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 32301345921.9760 - val_loss: 31391622943.5616\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 32133918818.3602 - val_loss: 31287628842.0822\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 32029724756.3087 - val_loss: 31193659392.0000\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 31950929010.1681 - val_loss: 31102266522.3014\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 32013882004.4185 - val_loss: 31004175682.6301\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 31961341115.9382 - val_loss: 30908031873.7534\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 31794096489.8250 - val_loss: 30808658509.1507\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 31650783463.8491 - val_loss: 30733405787.1781\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 31532941796.7753 - val_loss: 30633858090.0822\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 31507994388.6381 - val_loss: 30531932749.1507\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 31248746503.0257 - val_loss: 30423003640.9863\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 31204708074.4837 - val_loss: 30322737180.0548\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 31232887728.9605 - val_loss: 30223586402.1918\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 31066365228.3499 - val_loss: 30116965614.4658\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 31059842843.6638 - val_loss: 30016050161.9726\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 30683056208.7959 - val_loss: 29918966489.4247\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 30784323724.5146 - val_loss: 29823201700.8219\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 30677811958.7787 - val_loss: 29725124467.7260\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 30431874011.1149 - val_loss: 29626692481.7534\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 30542186446.8199 - val_loss: 29523284613.2603\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 30238096730.0172 - val_loss: 29416398932.1644\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 30084157187.0738 - val_loss: 29312755683.9452\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 30229709899.5266 - val_loss: 29218032177.0959\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 29945664742.0926 - val_loss: 29108749269.9178\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 30027116150.5592 - val_loss: 29002504556.7123\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 30003009511.4100 - val_loss: 28893027089.5342\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 30035427208.5626 - val_loss: 28779009150.2466\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 29810801869.5026 - val_loss: 28665709413.6986\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 29667710772.2539 - val_loss: 28610639030.3562\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 29492883782.6964 - val_loss: 28497433726.2466\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 29414741963.3070 - val_loss: 28365463383.6712\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 29378833578.3739 - val_loss: 28257886881.3151\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 29256826704.3568 - val_loss: 28133389690.7397\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 29064382748.5420 - val_loss: 28018434945.7534\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 29081959812.1715 - val_loss: 27906154860.7123\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 28947162429.9142 - val_loss: 27799821971.2877\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 28581675591.1355 - val_loss: 27677287409.9726\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 28547768246.2298 - val_loss: 27587185369.4247\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 28655004336.5214 - val_loss: 27530211440.2192\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 28562339832.9743 - val_loss: 27415135105.7534\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 28094927589.2144 - val_loss: 27288555772.4931\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 28223352264.6724 - val_loss: 27145022085.2603\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 28057528836.3911 - val_loss: 27066067645.3699\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 28029428800.9880 - val_loss: 26927628035.5069\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 28046763550.7376 - val_loss: 26815356928.0000\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 27688067507.5952 - val_loss: 26714856265.6438\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 27728489301.6261 - val_loss: 26602929502.6849\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 27628311360.5489 - val_loss: 26494985426.4110\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 27378903001.3585 - val_loss: 26375088043.8356\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 27270177741.0635 - val_loss: 26262215862.3562\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 27208731435.4717 - val_loss: 26134832450.6301\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 26964751121.1252 - val_loss: 26030749050.7397\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 27017854898.7170 - val_loss: 25917132126.6849\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 26838018033.9485 - val_loss: 25799756000.4384\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 26640226209.1527 - val_loss: 25691822108.0548\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 26590336354.7993 - val_loss: 25584130328.5479\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26676201774.1063 - val_loss: 25459515812.8219\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 26313230139.2796 - val_loss: 25334338714.3014\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 26535074006.2847 - val_loss: 25213652318.6849\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 26168845795.0189 - val_loss: 25105632915.2877\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 26245198886.6415 - val_loss: 24992971369.2055\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 26164449097.3310 - val_loss: 24868959779.0685\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 25738259888.0823 - val_loss: 24755163051.8356\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 26064080990.8473 - val_loss: 24648996022.3562\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 25700979120.0823 - val_loss: 24542519913.2055\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 25692493616.7410 - val_loss: 24421692991.1233\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 25432728837.7084 - val_loss: 24302634222.4658\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 25195532670.9022 - val_loss: 24184026574.9041\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 25251746958.2710 - val_loss: 24057465028.3836\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 25070465368.2607 - val_loss: 23942402749.3699\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 24897678320.1921 - val_loss: 23816910819.9452\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 25075810372.5009 - val_loss: 23698405768.7671\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 24635897487.1492 - val_loss: 23584347739.1781\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 24609714699.4168 - val_loss: 23472370786.1918\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 24745798836.9125 - val_loss: 23356112531.2877\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 24524695938.4151 - val_loss: 23236096448.8767\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 24345318111.9451 - val_loss: 23109922170.7397\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 24280552021.1870 - val_loss: 22989484060.0548\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 24195385161.3310 - val_loss: 22870176333.1507\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 23711443541.1870 - val_loss: 22748336745.2055\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 23822886202.4014 - val_loss: 22640796124.9315\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 23756636528.8508 - val_loss: 22571934565.6986\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 23712044116.3088 - val_loss: 22415882983.4521\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 23518646704.0823 - val_loss: 22319404508.9315\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 23418935910.7513 - val_loss: 22185292056.5479\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 23301561451.1424 - val_loss: 22032637517.1507\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 23319490918.3122 - val_loss: 21895037769.6438\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 23142607712.1647 - val_loss: 21764693286.5753\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 23057962435.4031 - val_loss: 21643104536.5479\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 22551565903.9177 - val_loss: 21505971999.5616\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 22668076451.7873 - val_loss: 21435692410.7397\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 22508773725.5300 - val_loss: 21340465194.0822\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 22299280705.4271 - val_loss: 21184806743.6712\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 22326231075.1286 - val_loss: 21074369606.1370\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 22534913315.5678 - val_loss: 20966139427.0685\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 21931182065.9485 - val_loss: 20846124424.7671\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 22026439204.0069 - val_loss: 20727357215.5616\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 21941215077.4340 - val_loss: 20582770154.9589\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 21980356052.9674 - val_loss: 20485982376.3288\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 21819146348.8988 - val_loss: 20379912500.6027\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 21753268220.4871 - val_loss: 20228295441.5342\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 21740405575.5746 - val_loss: 20135977647.3425\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 21530905327.7530 - val_loss: 20016587565.5890\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 21052994574.0515 - val_loss: 19864796749.1507\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 21269514001.1252 - val_loss: 19754240729.4247\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 21308717226.3739 - val_loss: 19653953101.1507\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 21348429637.8182 - val_loss: 19564218410.0822\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 20795988040.0137 - val_loss: 19425223974.5753\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 20553330825.0017 - val_loss: 19302671612.4931\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 20475052158.4631 - val_loss: 19174220659.7260\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 20340991241.2213 - val_loss: 19047969848.1096\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 20662517220.7753 - val_loss: 18929360531.2877\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 20125290506.5386 - val_loss: 18808745464.9863\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 19846255370.240 - 0s 145us/step - loss: 20560757238.3396 - val_loss: 18677338841.4247\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 19850290829.3928 - val_loss: 18561016144.6575\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 19811596827.2247 - val_loss: 18453787774.2466\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 20064559732.8027 - val_loss: 18335307453.3699\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 19767203736.3705 - val_loss: 18212000347.1781\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 19551260301.3928 - val_loss: 18094540463.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 19263785293.7221 - val_loss: 17986305627.1781\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 19291101612.5695 - val_loss: 17860913460.6027\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 19038674272.1647 - val_loss: 17736259541.9178\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 19362230489.7976 - val_loss: 17607607267.9452\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 18933188106.0995 - val_loss: 17501830200.1096\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 19147601718.0103 - val_loss: 17396335644.0548\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 18920498868.9125 - val_loss: 17266088062.2466\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 18689780793.9623 - val_loss: 17148020721.9726\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 18733937870.3808 - val_loss: 17025737349.2603\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 18902691749.5437 - val_loss: 16901653335.6712\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 18179547808.7136 - val_loss: 16794651507.7260\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 18237639558.8062 - val_loss: 16687911515.1781\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 18158511866.2916 - val_loss: 16558353113.4247\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 17943951781.5437 - val_loss: 16441900551.0137\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 17632962331.6638 - val_loss: 16346269499.6164\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 18010340196.5557 - val_loss: 16219428218.7397\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 17420735164.8165 - val_loss: 16110928264.7671\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 17573545471.1218 - val_loss: 15995817016.1096\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 17533399184.0274 - val_loss: 15865140083.7260\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 17727176630.2298 - val_loss: 15740215408.2192\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 17170554353.0703 - val_loss: 15639247114.5205\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 16976087013.6535 - val_loss: 15523367837.8082\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 16958100478.2436 - val_loss: 15403177086.2466\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 16926146171.8285 - val_loss: 15279742723.5068\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 16829273230.2710 - val_loss: 15175336749.5890\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 16856830607.1492 - val_loss: 15072660325.6986\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 17102226518.0652 - val_loss: 14965304291.9452\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 16675539277.7221 - val_loss: 14841961359.7808\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 16555883848.4528 - val_loss: 14721229445.2603\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 16276725888.2196 - val_loss: 14621313066.0822\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 15951743543.3276 - val_loss: 14510284940.2740\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 16116754328.3705 - val_loss: 14415368977.5342\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 16486725220.9949 - val_loss: 14292132793.8630\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 15915437708.5146 - val_loss: 14178061466.3014\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 16097870124.3499 - val_loss: 14080688422.5753\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 15793207116.8439 - val_loss: 13959423565.1507\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 15650625780.1441 - val_loss: 13842036651.8356\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 15602216997.7633 - val_loss: 13740116416.8767\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 15560645812.9125 - val_loss: 13632023537.9726\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 15812485896.3431 - val_loss: 13519626548.6027\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 15696220771.2384 - val_loss: 13415259416.5479\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 15400074618.5111 - val_loss: 13319745423.7808\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 15420012902.3122 - val_loss: 13227582071.2329\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 15029886287.4786 - val_loss: 13119636522.0822\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 15265866876.7067 - val_loss: 13001137208.1096\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 14721298352.9605 - val_loss: 12888898616.1096\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 14503698453.0772 - val_loss: 12772591735.2329\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 14937839454.4082 - val_loss: 12666800618.9589\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 14874140087.9863 - val_loss: 12572644562.4110\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 14730511948.4048 - val_loss: 12481953511.4521\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 14303108204.0206 - val_loss: 12379848991.5616\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 14538689465.7427 - val_loss: 12289717458.4110\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 14550508904.0686 - val_loss: 12167476764.0548\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 14283558901.0223 - val_loss: 12078698706.4110\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 14043744995.4580 - val_loss: 11982445729.3151\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 13862390420.4185 - val_loss: 11884258703.7808\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 13561635146.2093 - val_loss: 11788541629.3699\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 13608585775.4237 - val_loss: 11682687438.9041\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 13826072918.5043 - val_loss: 11588164853.4795\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 13436635731.4305 - val_loss: 11486856563.7260\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 13331049297.2350 - val_loss: 11386737741.1507\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 13226087683.9520 - val_loss: 11291479271.4521\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 13429201976.2058 - val_loss: 11191318457.8630\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 13564903169.3173 - val_loss: 11096160192.8767\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 148us/step - loss: 13691388581.9828 - val_loss: 11015345215.1233\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 13133880613.3242 - val_loss: 10912825708.7123\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 13033962221.9966 - val_loss: 10815235008.8767\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 13411916229.1595 - val_loss: 10720760242.8493\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 13697308591.2041 - val_loss: 10636419478.7945\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 135us/step - loss: 13449668734.4631 - val_loss: 10550610179.5068\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 13175252686.3808 - val_loss: 10460912064.8767\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 12676465258.2642 - val_loss: 10375506929.9726\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 12515580741.8182 - val_loss: 10274160654.0274\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 12197371371.8010 - val_loss: 10193896426.9589\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12910443559.5197 - val_loss: 10100755484.0548\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12674460491.0875 - val_loss: 10012392440.9863\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 12127337956.7753 - val_loss: 9929598520.1096\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 12093941033.7153 - val_loss: 9844116963.9452\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 12430413637.8182 - val_loss: 9757062080.8767\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 12502613590.9434 - val_loss: 9675151815.8904\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 12214766332.9262 - val_loss: 9602540803.5068\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12308023956.4185 - val_loss: 9522967692.2740\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 12313791725.1184 - val_loss: 9446864440.1096\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12018503917.1184 - val_loss: 9366954348.7123\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 12163639905.4820 - val_loss: 9285190698.0822\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 12208740342.3396 - val_loss: 9212184639.1233\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 11603211869.9691 - val_loss: 9123082380.2740\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11973992066.8542 - val_loss: 9055542608.6575\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 11588746389.2967 - val_loss: 8982215848.3288\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 12346238061.7770 - val_loss: 8902048585.6438\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 12140197199.4786 - val_loss: 8830680190.2466\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 11527734326.4494 - val_loss: 8744419580.4932\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 11624414494.2985 - val_loss: 8676286590.2466\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 11705424739.6775 - val_loss: 8605221130.5205\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 11578417351.3551 - val_loss: 8547158577.0959\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 11330111913.0566 - val_loss: 8479056398.0274\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 11613323538.0034 - val_loss: 8407966306.1918\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10930751515.6638 - val_loss: 8346224149.0411\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11541583230.0240 - val_loss: 8283256249.8630\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 11170560574.3533 - val_loss: 8214717250.6301\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 11780926090.7581 - val_loss: 8154941194.5205\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 11407583741.3654 - val_loss: 8084054352.6575\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 11062957902.6003 - val_loss: 8029421091.0685\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 11629146032.9605 - val_loss: 7975735071.5616\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 11120835378.4974 - val_loss: 7897928942.4658\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 11090605612.7890 - val_loss: 7842651914.5205\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10895864447.3413 - val_loss: 7787201669.2603\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10760346827.7461 - val_loss: 7734141994.0822\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 11056981554.0583 - val_loss: 7695791047.8904\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10657371005.1458 - val_loss: 7647986582.7945\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 10748919298.6346 - val_loss: 7597566414.9041\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10790358016.0000 - val_loss: 7546468085.4795\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11005909929.0566 - val_loss: 7489277797.6986\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10929096719.8079 - val_loss: 7435300821.9178\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10348077315.9520 - val_loss: 7384285618.8493\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10943111457.8113 - val_loss: 7341911425.7534\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10527907039.0669 - val_loss: 7302662193.0959\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 11100552144.5763 - val_loss: 7252449455.3425\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10523043282.3328 - val_loss: 7213548715.8356\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10704619523.5129 - val_loss: 7178659454.2466\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10176938426.1818 - val_loss: 7130233856.0000\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10119771664.6861 - val_loss: 7088049713.0959\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10359280304.9605 - val_loss: 7050507137.7534\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10656033881.5780 - val_loss: 7007576558.4658\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10406853422.5455 - val_loss: 6966514025.2055\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10745316764.7616 - val_loss: 6931033249.3151\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10335761775.0943 - val_loss: 6888745577.2055\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10781446337.6467 - val_loss: 6856340977.9726\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 144us/step - loss: 10241491209.2213 - val_loss: 6824975121.5342\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10210046580.8027 - val_loss: 6795685807.3425\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10228347597.5026 - val_loss: 6771513347.5068\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10645616418.6895 - val_loss: 6744217424.6575\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10107777733.5986 - val_loss: 6710558709.4795\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10901463969.1527 - val_loss: 6687456003.5068\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9854035755.4717 - val_loss: 6654691692.7123\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10687163790.7101 - val_loss: 6627797009.5342\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10516014547.2110 - val_loss: 6604846542.9041\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10247282105.7427 - val_loss: 6577241137.0959\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10258636546.6346 - val_loss: 6555361595.6164\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 135us/step - loss: 10410555327.0120 - val_loss: 6531399097.8630\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10207247287.9863 - val_loss: 6513733190.1370\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 10567860524.3499 - val_loss: 6489937576.3288\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10491631823.2590 - val_loss: 6469968198.1370\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10081955932.6518 - val_loss: 6450357037.5890\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10501644049.1252 - val_loss: 6428532620.2740\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9791903276.7890 - val_loss: 6408128771.5068\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9985805798.5317 - val_loss: 6386257106.4110\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10482681432.6998 - val_loss: 6373755956.6027\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10542692190.4082 - val_loss: 6353687625.6438\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10529370684.5969 - val_loss: 6334414935.6712\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10377539842.1955 - val_loss: 6322380484.3836\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10342261072.3568 - val_loss: 6312201124.8219\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10258496310.0103 - val_loss: 6296352746.9589\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10097597988.8851 - val_loss: 6277765253.2603\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11097996424.1235 - val_loss: 6270318164.1644\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10345422992.0274 - val_loss: 6253663344.2192\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10635201117.9691 - val_loss: 6245517666.1918\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10223384695.4374 - val_loss: 6236082561.7534\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10336418951.2453 - val_loss: 6229942212.3836\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10437891154.5523 - val_loss: 6224661195.3973\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10006264276.0892 - val_loss: 6211274780.0548\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10244888958.9022 - val_loss: 6191573339.1781\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10740805231.5334 - val_loss: 6187384467.2877\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9702574701.7770 - val_loss: 6174124028.4932\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10167759534.7650 - val_loss: 6164473578.9589\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10173917398.2847 - val_loss: 6158868886.7945\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 10608597802.666 - 0s 147us/step - loss: 10206235373.9966 - val_loss: 6147672842.5205\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10339695611.6089 - val_loss: 6140085539.0685\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10204269039.3139 - val_loss: 6127023721.2055\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10273972104.5626 - val_loss: 6122671177.6438\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10605106846.9571 - val_loss: 6117378749.3699\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10321615517.2007 - val_loss: 6112571339.3973\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10471329647.9726 - val_loss: 6102449239.6712\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10503998355.1012 - val_loss: 6097332911.3425\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9725435045.1046 - val_loss: 6093062740.1644\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10059515386.7307 - val_loss: 6085915434.0822\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10203208603.8834 - val_loss: 6080172049.5342\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10056977899.8010 - val_loss: 6073913582.4658\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10177876951.6021 - val_loss: 6065455910.5753\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10300350711.2178 - val_loss: 6061269959.8904\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10104252967.5197 - val_loss: 6060988317.8082\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10251398283.6364 - val_loss: 6051763978.5205\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10047469448.5626 - val_loss: 6046236864.8767\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10110183861.3516 - val_loss: 6050023185.5342\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10158288677.3242 - val_loss: 6041970365.3699\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9934704119.2178 - val_loss: 6035832151.6712\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10098471464.3979 - val_loss: 6029135212.7123\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10683652762.5660 - val_loss: 6024515440.2192\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10049385975.2178 - val_loss: 6025681183.5616\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10613223782.3122 - val_loss: 6020375762.4110\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10156108925.5849 - val_loss: 6021399425.7534\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9996517272.3705 - val_loss: 6014218061.1507\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 143us/step - loss: 9473095337.4957 - val_loss: 6008338740.6027\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9739416979.1012 - val_loss: 6010487001.4247\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10110898565.9280 - val_loss: 6005306206.6849\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10199346727.5197 - val_loss: 6007419616.4384\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10182793768.3979 - val_loss: 6003006779.6164\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10354785447.7393 - val_loss: 6007254983.8904\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10243981167.9726 - val_loss: 6007856538.3014\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 9858057338.9503 - val_loss: 6007270999.6712\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9963207166.2436 - val_loss: 6008121421.1507\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10659540598.5592 - val_loss: 6011055086.4658\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10004117256.3431 - val_loss: 6007769235.2877\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10371011551.5060 - val_loss: 6006824349.8082\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9903223247.6981 - val_loss: 6003511850.0822\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9627047201.8113 - val_loss: 6000843362.1918\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9751065897.7153 - val_loss: 5996076259.9452\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10356705557.5163 - val_loss: 5997138021.6986\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10069888810.5935 - val_loss: 5998692246.7945\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10441883958.8885 - val_loss: 6001961952.4384\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10373433791.8902 - val_loss: 5998325128.7671\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10106993296.9057 - val_loss: 5996482798.4658\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 9965530046.1338 - val_loss: 5990719403.8356\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9849148722.4974 - val_loss: 5988014041.4247\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10219296208.5763 - val_loss: 5988136588.2740\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10217042991.4237 - val_loss: 5990134044.0548\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10003210009.9074 - val_loss: 5986930386.4110\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10282188095.6707 - val_loss: 5993409507.9452\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9953162090.7033 - val_loss: 5983610704.6575\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10504973803.8010 - val_loss: 5983352035.9452\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10184101085.3105 - val_loss: 5981662618.3014\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10426188922.9503 - val_loss: 5979220136.3288\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10388390863.6981 - val_loss: 5983427001.8630\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 10257366229.4065 - val_loss: 5978982750.6849\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10110447800.4254 - val_loss: 5980198670.0274\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10013980900.3362 - val_loss: 5978647601.0959\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9869604229.9280 - val_loss: 5977693597.8082\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10137220169.7702 - val_loss: 5976640799.5616\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9769953094.6964 - val_loss: 5971271967.5616\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10624063849.8250 - val_loss: 5969903307.3973\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10244210236.5969 - val_loss: 5967585753.4247\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10364748890.4563 - val_loss: 5969701060.3836\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10162849625.1389 - val_loss: 5971873167.7808\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9938004222.6827 - val_loss: 5969749328.6575\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10289570284.6792 - val_loss: 5964179463.0137\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10181915848.2333 - val_loss: 5964470236.9315\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10901730590.2985 - val_loss: 5969319985.0959\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10665219256.4254 - val_loss: 5974062094.0274\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 9671485673.6055 - val_loss: 5969624604.0548\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10298102544.2470 - val_loss: 5971393848.1096\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9906467278.3808 - val_loss: 5970640839.8904\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10132736483.8971 - val_loss: 5969286785.7534\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10137621567.2316 - val_loss: 5964583571.2877\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10249825394.1681 - val_loss: 5962167103.1233\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9944234134.1750 - val_loss: 5962315600.6575\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10592886842.8405 - val_loss: 5964168472.5479\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10091891577.6329 - val_loss: 5967289701.6986\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9943158398.4631 - val_loss: 5961163050.0822\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10285260163.2933 - val_loss: 5960569831.4521\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9751674799.2041 - val_loss: 5966188067.0685\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10274635884.8988 - val_loss: 5961915809.3151\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9495531306.5935 - val_loss: 5965580133.6986\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10585978629.7084 - val_loss: 5964529130.9589\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10516553722.7307 - val_loss: 5962693884.4932\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9662875524.1715 - val_loss: 5962214610.4110\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9946943795.3756 - val_loss: 5957283657.6438\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 9956278053.7633 - val_loss: 5955387051.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10058262483.2110 - val_loss: 5951262337.7534\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10602659544.9194 - val_loss: 5959910652.4932\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10166432565.1321 - val_loss: 5961257275.6164\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10065808136.3431 - val_loss: 5958874953.6438\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10358117163.4717 - val_loss: 5958918487.6712\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9991720036.1166 - val_loss: 5954455117.1507\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10225265305.6878 - val_loss: 5953769275.6164\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9939094903.8765 - val_loss: 5949158494.6849\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 9994915394.7444 - val_loss: 5949262402.6301\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10830380091.7187 - val_loss: 5952815805.3699\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9787828233.6604 - val_loss: 5949386254.0274\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9939993011.5952 - val_loss: 5948290945.7534\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9938020237.8319 - val_loss: 5943278830.4658\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9875720334.7101 - val_loss: 5946481807.7808\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 10136388769.5918 - val_loss: 5945951288.1096\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10327249074.7170 - val_loss: 5943444704.4384\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10462859313.1801 - val_loss: 5942625532.4932\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10168771706.9503 - val_loss: 5939367992.1096\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9846497408.2196 - val_loss: 5936784755.7260\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10072510811.7736 - val_loss: 5938230833.0959\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10295297119.7256 - val_loss: 5934108928.0000\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10520487121.0154 - val_loss: 5942088921.4247\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10298172081.3997 - val_loss: 5944678449.0959\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10216353042.0034 - val_loss: 5951006656.8767\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10360336811.6913 - val_loss: 5942558818.1918\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9752839566.7101 - val_loss: 5949477646.0274\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10271131479.3825 - val_loss: 5952624436.6027\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9895241732.3911 - val_loss: 5953694670.9041\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10433839859.2659 - val_loss: 5953673338.7397\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9804240826.6209 - val_loss: 5951401493.0411\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10271957587.4305 - val_loss: 5954118729.6438\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9877526029.1732 - val_loss: 5951529377.3151\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10082196105.8799 - val_loss: 5953261981.8082\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10623655867.4991 - val_loss: 5956992771.5068\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10020857010.2779 - val_loss: 5958523423.5616\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10700303295.0120 - val_loss: 5960922217.2055\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9675315228.9811 - val_loss: 5961005816.9863\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10423638043.2247 - val_loss: 5960655345.9726\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9883146773.9554 - val_loss: 5956898465.3151\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10486569951.5060 - val_loss: 5957830957.5890\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10044011649.9760 - val_loss: 5957799199.5616\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10268089250.9091 - val_loss: 5961071587.9452\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9958587098.6758 - val_loss: 5955192218.3014\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9897264449.4271 - val_loss: 5957061912.5479\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10481879043.5129 - val_loss: 5962238418.4110\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10404707036.4322 - val_loss: 5965128598.7945\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9599830200.4254 - val_loss: 5963740219.6164\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10480385524.5832 - val_loss: 5961560183.2329\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10220738036.5832 - val_loss: 5962161804.2740\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10139573146.1269 - val_loss: 5962453553.0959\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10763605545.2762 - val_loss: 5967984324.3836\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10499757214.0789 - val_loss: 5968487585.3151\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9899272112.0823 - val_loss: 5971827487.5616\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10026244278.2298 - val_loss: 5968682559.1233\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10775079258.0172 - val_loss: 5968653108.6027\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9375251269.8182 - val_loss: 5968695460.8219\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9588392047.5334 - val_loss: 5969353433.4247\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9493286231.3825 - val_loss: 5964445155.9452\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10189142887.1904 - val_loss: 5963411298.1918\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10137723020.5146 - val_loss: 5966110404.3836\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10059895798.3396 - val_loss: 5967203804.9315\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10233344509.3654 - val_loss: 5966935036.4932\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10196878131.3756 - val_loss: 5964941073.5342\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10384615377.4545 - val_loss: 5968636847.3425\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 151us/step - loss: 10202900613.4889 - val_loss: 5968363309.5890\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9958044750.1612 - val_loss: 5968471180.2740\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10363175409.0703 - val_loss: 5967912718.0274\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10168657921.7564 - val_loss: 5967601814.7945\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9506435222.1750 - val_loss: 5964649338.7397\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10613230116.8851 - val_loss: 5968882098.8493\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9712998099.6501 - val_loss: 5966506236.4932\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10129632045.2281 - val_loss: 5963371316.6027\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10017251545.7976 - val_loss: 5970491539.2877\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9788392729.9074 - val_loss: 5975763470.0274\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10539625507.1286 - val_loss: 5978061266.4110\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10787937891.2384 - val_loss: 5977117808.2192\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10135365430.0103 - val_loss: 5979617118.6849\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10026804742.1475 - val_loss: 5976613740.7123\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10554460663.2178 - val_loss: 5973286663.0137\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10397562663.9588 - val_loss: 5975397390.0274\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10225338655.1767 - val_loss: 5973231623.0137\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10554608277.2967 - val_loss: 5971839179.3973\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9720689915.1698 - val_loss: 5968593085.3699\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9521367897.1389 - val_loss: 5966559495.0137\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10538701560.5352 - val_loss: 5964886601.6438\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10087241703.4100 - val_loss: 5961274634.5205\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9827870569.8250 - val_loss: 5957471004.0548\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10098337941.2967 - val_loss: 5957521127.4521\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10283800509.2556 - val_loss: 5958348333.5890\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10357062650.7307 - val_loss: 5958720350.6849\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10158754538.4837 - val_loss: 5960214717.3699\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10550445204.4185 - val_loss: 5960889498.3014\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10340663568.2470 - val_loss: 5962660688.6575\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10127896415.2864 - val_loss: 5964468238.0274\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10021877121.5369 - val_loss: 5961150793.6438\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10237778614.6690 - val_loss: 5960257006.4658\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10097537756.4322 - val_loss: 5956041657.8630\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10479186882.5249 - val_loss: 5956452492.2740\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10976811027.3208 - val_loss: 5958913925.2603\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10225011971.9520 - val_loss: 5963217997.1507\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10147667342.7101 - val_loss: 5957424261.2603\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9947467862.0652 - val_loss: 5957366727.8904\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10357034978.1407 - val_loss: 5959116544.0000\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9440716601.5232 - val_loss: 5953917278.6849\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9986763399.2453 - val_loss: 5950088486.5753\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10144558821.2144 - val_loss: 5952466940.4932\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9704793881.0292 - val_loss: 5956896406.7945\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9996890377.2213 - val_loss: 5956624903.0137\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9815172006.4220 - val_loss: 5955070218.5205\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10162125687.8765 - val_loss: 5949428174.9041\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10489255272.9468 - val_loss: 5950207214.4658\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10000179533.7221 - val_loss: 5947765570.6301\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10325374908.3774 - val_loss: 5951716201.2055\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10437013076.3087 - val_loss: 5952918808.5479\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10602983928.0961 - val_loss: 5952956226.6301\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10198192744.9468 - val_loss: 5952445159.4521\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10259348884.8576 - val_loss: 5953160777.6438\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10258814222.4906 - val_loss: 5954833232.6575\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9632498507.0875 - val_loss: 5949082992.2192\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9968652073.7153 - val_loss: 5949656274.4110\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10306555041.5918 - val_loss: 5948690730.0822\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10282412753.8937 - val_loss: 5946855406.4658\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9819170217.9348 - val_loss: 5943730088.3288\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10077442801.5094 - val_loss: 5943986316.2740\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10110563238.4220 - val_loss: 5941900957.8082\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10480063531.0326 - val_loss: 5942225043.2877\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9390726576.0823 - val_loss: 5939446784.0000\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10350008067.0738 - val_loss: 5936064687.3425\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9765575201.3722 - val_loss: 5937169583.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10115934801.6741 - val_loss: 5938454871.6712\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9913981024.6038 - val_loss: 5939895513.4247\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10200672096.1647 - val_loss: 5939716685.1507\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10111750506.7033 - val_loss: 5939686010.7397\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9914507987.6501 - val_loss: 5937949724.0548\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10401304602.3465 - val_loss: 5937646332.4932\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9938485087.7256 - val_loss: 5936762417.0959\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10695439428.5009 - val_loss: 5936836025.8630\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10145991102.5729 - val_loss: 5935828455.4521\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10150300788.8027 - val_loss: 5935806453.4795\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9917752138.2093 - val_loss: 5934189182.2466\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10444709749.2419 - val_loss: 5936211869.8082\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9387154238.7925 - val_loss: 5933000546.1918\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10481306025.0566 - val_loss: 5935311857.9726\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10883413901.8319 - val_loss: 5940347462.1370\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10510361494.6141 - val_loss: 5944182419.2877\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10416736610.7993 - val_loss: 5948390624.4384\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10248352174.3259 - val_loss: 5950992938.0822\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9475102521.5232 - val_loss: 5946981425.0959\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10140768370.1681 - val_loss: 5947275271.0137\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9560590964.8027 - val_loss: 5944801111.6712\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10317255941.7084 - val_loss: 5945402620.4932\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10736133810.2779 - val_loss: 5952897595.6164\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10479936964.2813 - val_loss: 5955785654.3562\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10010383630.4906 - val_loss: 5955176746.0822\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10374716802.4151 - val_loss: 5951243179.8356\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10408673174.6141 - val_loss: 5957545191.4521\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10690306288.6312 - val_loss: 5955804026.7397\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10020063597.3379 - val_loss: 5957609037.1507\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10445743486.9022 - val_loss: 5959997748.6027\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10285491695.3139 - val_loss: 5957270731.3973\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10289470026.6484 - val_loss: 5955177450.9589\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9773572914.4974 - val_loss: 5955651198.2466\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10410615501.5026 - val_loss: 5956470612.1644\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9829592641.8662 - val_loss: 5959995946.0822\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9523597485.8868 - val_loss: 5959434832.6575\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9970749170.8268 - val_loss: 5955553911.2329\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10184571710.7925 - val_loss: 5953532240.6575\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9916358611.2110 - val_loss: 5951605335.6712\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9783114935.5472 - val_loss: 5948827314.8493\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10138490721.9211 - val_loss: 5952116560.6575\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10199280733.0909 - val_loss: 5953781079.6712\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10077526059.9108 - val_loss: 5951163504.2192\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10391675665.1252 - val_loss: 5954208782.0274\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10193588791.3276 - val_loss: 5954448240.2192\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10786093851.6638 - val_loss: 5958770477.5890\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9689863721.2762 - val_loss: 5958385327.3425\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10514275656.4528 - val_loss: 5957910552.5479\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10424650303.2316 - val_loss: 5958028501.9178\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10430202179.1835 - val_loss: 5957793315.0685\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10273263381.5163 - val_loss: 5958090857.2055\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10458655886.2710 - val_loss: 5957756966.5753\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10080701524.3087 - val_loss: 5953443962.7397\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10210421719.1630 - val_loss: 5954842641.5342\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10347595055.4237 - val_loss: 5957181660.9315\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9859570236.5969 - val_loss: 5954079905.3151\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10082436169.7702 - val_loss: 5954511156.6027\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10219042188.9537 - val_loss: 5953261192.7671\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10197313492.0892 - val_loss: 5952365399.6712\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10619673079.2178 - val_loss: 5956742480.6575\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10136434551.8765 - val_loss: 5955312780.2740\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10114774841.5232 - val_loss: 5959605837.1507\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10039832294.5317 - val_loss: 5956107986.4110\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10252755411.2110 - val_loss: 5960266955.3973\n",
      "Epoch 707/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 161us/step - loss: 9651880851.1012 - val_loss: 5960071799.2329\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10758115166.4082 - val_loss: 5959391435.3973\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10196876114.9914 - val_loss: 5955212982.3562\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10729939579.8285 - val_loss: 5960053514.5205\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10524195264.7684 - val_loss: 5960371382.3562\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10450290962.0034 - val_loss: 5959215587.9452\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10410012289.0978 - val_loss: 5959176584.7671\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10246604567.2727 - val_loss: 5961652946.4110\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10064907874.3602 - val_loss: 5959026042.7397\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9981695786.5935 - val_loss: 5958094013.3699\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9880116584.0686 - val_loss: 5957221614.4658\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10243349244.0480 - val_loss: 5959416516.3836\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10131337893.9828 - val_loss: 5961963516.4932\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10089268873.8799 - val_loss: 5960123195.6164\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9798799216.8508 - val_loss: 5961796085.4795\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9854776106.5935 - val_loss: 5960078336.0000\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10231857505.0429 - val_loss: 5956402986.0822\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10316447268.8851 - val_loss: 5957410703.7808\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10072176120.0961 - val_loss: 5959892308.1644\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10479166170.6758 - val_loss: 5961082943.1233\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9702882574.4906 - val_loss: 5959201301.0411\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10382898344.6175 - val_loss: 5960580397.5890\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10122093125.3791 - val_loss: 5959384449.7534\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10155148170.3190 - val_loss: 5958058958.9041\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9843538271.2864 - val_loss: 5956326235.1781\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10270133898.7581 - val_loss: 5954053141.0411\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9204461271.1630 - val_loss: 5951823377.5342\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9895560738.2504 - val_loss: 5950473766.5753\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10278923481.7976 - val_loss: 5949856732.9315\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10444181481.1664 - val_loss: 5950561048.5479\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9804184006.9160 - val_loss: 5946464732.9315\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9901192595.9794 - val_loss: 5945460322.1918\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10164849137.0703 - val_loss: 5941310681.4247\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10016448649.8799 - val_loss: 5941559913.2055\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10498461912.0412 - val_loss: 5942483996.0548\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10309538299.6089 - val_loss: 5941831346.8493\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10080549466.4563 - val_loss: 5943905714.8493\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10115315459.0738 - val_loss: 5943717186.6301\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10025211503.5334 - val_loss: 5941824585.6438\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10094271180.6244 - val_loss: 5942421454.9041\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10268470338.7444 - val_loss: 5942414946.1918\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10013120865.0429 - val_loss: 5938708234.5205\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10363271252.3087 - val_loss: 5937474076.0548\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9892112706.3053 - val_loss: 5942180527.3425\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9667775284.2539 - val_loss: 5940030730.5205\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9647588196.1166 - val_loss: 5942957308.4932\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10005948089.3036 - val_loss: 5939880921.4247\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10046971902.2436 - val_loss: 5942278059.8356\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9919194005.7358 - val_loss: 5941436019.7260\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9828731220.7479 - val_loss: 5944064522.5205\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9887232288.0549 - val_loss: 5944807283.7260\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10335867175.9588 - val_loss: 5944318888.3288\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10336849832.1784 - val_loss: 5946018191.7808\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10352275884.5695 - val_loss: 5948976720.6575\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9844645822.1338 - val_loss: 5948596630.7945\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10504538657.3722 - val_loss: 5945031900.9315\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10193601372.6518 - val_loss: 5945656007.8904\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10267043876.8851 - val_loss: 5945034264.5479\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10377177940.7479 - val_loss: 5949104348.9315\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9977598410.4288 - val_loss: 5950627541.9178\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9555708279.8765 - val_loss: 5951205456.6575\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9905158365.3105 - val_loss: 5949836049.5342\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9879017549.2830 - val_loss: 5950872155.1781\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10539444550.6964 - val_loss: 5946933812.6027\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10109488977.2350 - val_loss: 5944307112.3288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10061569247.0669 - val_loss: 5944524544.0000\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10589590678.1750 - val_loss: 5946318230.7945\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10170176611.2384 - val_loss: 5949113417.6438\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10501939978.0995 - val_loss: 5950645037.5890\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10120874623.3413 - val_loss: 5949763247.3425\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10135168015.8079 - val_loss: 5954088756.6027\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9886486996.0892 - val_loss: 5953938410.9589\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10297462940.3225 - val_loss: 5955057397.4795\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9798687673.7427 - val_loss: 5949673738.5205\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9864589315.5129 - val_loss: 5949512416.4384\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9973440813.2281 - val_loss: 5948193465.8630\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10189771106.7993 - val_loss: 5951057541.2603\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9974757014.1750 - val_loss: 5950728206.0274\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9789841957.7633 - val_loss: 5945574049.3151\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10012180149.7907 - val_loss: 5946399091.7260\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 9938335684.2813 - val_loss: 5949709157.6986\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10092753059.3482 - val_loss: 5952247068.0548\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9611541194.8679 - val_loss: 5949091496.3288\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10475066404.8851 - val_loss: 5950854179.0685\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9807927700.8576 - val_loss: 5953473774.4658\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9775934853.9280 - val_loss: 5949738029.5890\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9627339357.9691 - val_loss: 5948229049.8630\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9781976410.0172 - val_loss: 5946187116.7123\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10267483627.8010 - val_loss: 5951369258.0822\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9811329876.3087 - val_loss: 5949725268.1644\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9891823941.8182 - val_loss: 5948822608.6575\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10487514507.1973 - val_loss: 5951783985.0959\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10211440644.3911 - val_loss: 5954976789.0411\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9830243693.3379 - val_loss: 5955468789.4795\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9818779312.5214 - val_loss: 5957580807.0137\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9691284745.2213 - val_loss: 5955554500.3836\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10558655640.8096 - val_loss: 5956607740.4932\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9974126228.4185 - val_loss: 5952780217.8630\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10285687070.2985 - val_loss: 5955416972.2740\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10507609673.3310 - val_loss: 5953897780.6027\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10568122954.6484 - val_loss: 5956606751.5616\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10233175540.5832 - val_loss: 5957243199.1233\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10482675677.7496 - val_loss: 5960199778.1918\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10446573350.2024 - val_loss: 5958961881.4247\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10552794586.2367 - val_loss: 5962900767.5616\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10332169224.7822 - val_loss: 5967511583.5616\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10055804747.0875 - val_loss: 5962902745.4247\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10093178335.5060 - val_loss: 5963095478.3562\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10523608107.0326 - val_loss: 5963360915.2877\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 10559840651.1973 - val_loss: 5964934080.8767\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 9905486491.4443 - val_loss: 5966308387.0685\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10562335975.8491 - val_loss: 5970490129.5342\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 10424699719.5746 - val_loss: 5972453298.8493\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 9870583133.5300 - val_loss: 5976017218.6301\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 10060191054.6003 - val_loss: 5976885248.0000\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 10393277159.8491 - val_loss: 5975205442.6301\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 10432345585.0703 - val_loss: 5974018868.6027\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 10150024127.0120 - val_loss: 5968234643.2877\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 10166708823.8216 - val_loss: 5970841031.8904\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 9838462060.8988 - val_loss: 5962989809.9726\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 9790328206.7101 - val_loss: 5961222782.2466\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 9965823282.9365 - val_loss: 5959194904.5479\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 10604944752.8508 - val_loss: 5958392376.1096\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 10143952801.1527 - val_loss: 5958622572.7123\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 10183530503.0257 - val_loss: 5959201893.6986\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 9866270490.7856 - val_loss: 5959437532.9315\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 10040382918.9160 - val_loss: 5960669043.7260\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 9643434465.2624 - val_loss: 5959357397.9178\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 9905235925.8456 - val_loss: 5958971854.9041\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 191us/step - loss: 10636147210.5386 - val_loss: 5962866730.0822\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 9317066342.7513 - val_loss: 5959168049.0959\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10144830442.9228 - val_loss: 5960606488.5479\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10280118908.7067 - val_loss: 5964157909.9178\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10191035207.5746 - val_loss: 5964365101.5890\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10395242911.3962 - val_loss: 5963113794.6301\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9757290251.8559 - val_loss: 5958817392.2192\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10078204841.0566 - val_loss: 5959603214.0274\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10705163097.1389 - val_loss: 5966976462.9041\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10027544406.5043 - val_loss: 5967527420.4932\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10128483728.4666 - val_loss: 5967998891.8356\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 9911108305.8937 - val_loss: 5962970364.4932\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 10414631140.3362 - val_loss: 5963485857.3151\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 10354616016.1372 - val_loss: 5963420426.5205\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9718559900.3225 - val_loss: 5959708935.0137\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 9938968136.8919 - val_loss: 5959492145.0959\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 10919556810.8679 - val_loss: 5958554757.2603\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 10187916560.2470 - val_loss: 5955280632.9863\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 10120060618.8679 - val_loss: 5954786205.8082\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 9844717520.5763 - val_loss: 5951611307.8356\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 10564353332.2539 - val_loss: 5953524318.6849\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 10043144994.6895 - val_loss: 5954091965.3699\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 9768526415.9177 - val_loss: 5957803905.7534\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10572837984.6038 - val_loss: 5960327701.0411\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10070745906.4974 - val_loss: 5957179577.8630\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10544283733.1870 - val_loss: 5964571963.6164\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10113524793.9623 - val_loss: 5963145296.6575\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10388406385.2899 - val_loss: 5964821791.5616\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10555969680.0274 - val_loss: 5968963054.4658\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10096923743.7256 - val_loss: 5969502165.9178\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9740738565.2693 - val_loss: 5973849803.3973\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9732587628.8988 - val_loss: 5975689685.9178\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10521189550.7650 - val_loss: 5973784341.0411\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10141239468.1304 - val_loss: 5971663503.7808\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10539268974.2161 - val_loss: 5973383210.0822\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9541180637.3105 - val_loss: 5970584618.0822\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10209130868.3636 - val_loss: 5969511886.9041\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 10233063782.3122 - val_loss: 5968375734.3562\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 9890673988.9400 - val_loss: 5971207041.7534\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9944983764.5283 - val_loss: 5965836393.2055\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10069267269.8182 - val_loss: 5963982637.5890\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10733729152.6587 - val_loss: 5963272041.2055\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10794062496.7136 - val_loss: 5968374356.1644\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10364260998.3671 - val_loss: 5967401009.0959\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10644998473.3310 - val_loss: 5968238048.4384\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 10130688103.6295 - val_loss: 5972143026.8493\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 9848889489.7839 - val_loss: 5968402561.7534\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10349878746.2367 - val_loss: 5967199414.3562\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10489349263.1492 - val_loss: 5967156241.5342\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9925815004.4322 - val_loss: 5964749543.4521\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 10078532819.6501 - val_loss: 5960872426.9589\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10345514540.7890 - val_loss: 5963827431.4521\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9741826269.3105 - val_loss: 5965070441.2055\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9729202870.6690 - val_loss: 5964717476.8219\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10581161293.7221 - val_loss: 5968025407.1233\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10331788064.9331 - val_loss: 5969123229.8082\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10244686624.9331 - val_loss: 5969696690.8493\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10628758331.2796 - val_loss: 5970895026.8493\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10397859639.7667 - val_loss: 5968854791.0137\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10424806928.6861 - val_loss: 5969175250.4110\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9829038090.5386 - val_loss: 5969064135.8904\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9987234052.8302 - val_loss: 5967669612.7123\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9716678065.3997 - val_loss: 5962574918.1370\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10178700664.7547 - val_loss: 5960239566.9041\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 10134968490.3739 - val_loss: 5960466951.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9587601047.9314 - val_loss: 5960331053.5890\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10245339212.4048 - val_loss: 5959056748.7123\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10580073183.5060 - val_loss: 5962465560.5479\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9941824845.7221 - val_loss: 5964383505.5342\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10374660220.7067 - val_loss: 5965480328.7671\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9909071036.8165 - val_loss: 5964085633.7534\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9964689781.2419 - val_loss: 5963892325.6986\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10319888213.6261 - val_loss: 5965962464.4384\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10074601501.8593 - val_loss: 5965851805.8082\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 9979102199.2178 - val_loss: 5962337209.8630\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10220547287.1630 - val_loss: 5967052039.0137\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10249908137.9348 - val_loss: 5970012531.7260\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9593799427.9520 - val_loss: 5962859484.9315\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10059568003.2933 - val_loss: 5964866454.7945\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9635091367.3002 - val_loss: 5960513139.7260\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10137206009.4134 - val_loss: 5959977913.8630\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10146945334.8885 - val_loss: 5960659266.6301\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9731468034.1955 - val_loss: 5959409523.7260\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10108699482.8954 - val_loss: 5963543734.3562\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10049518505.9348 - val_loss: 5963688826.7397\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10157778583.9314 - val_loss: 5967768919.6712\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10084439941.0497 - val_loss: 5959314908.9315\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10112572851.5952 - val_loss: 5962050812.4932\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10076976134.8062 - val_loss: 5959692000.4384\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10059085733.5437 - val_loss: 5960197863.4521\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 10211965918.6278 - val_loss: 5958291049.2055\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10033409151.3413 - val_loss: 5957344859.1781\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9872429644.4048 - val_loss: 5951946275.0685\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 9587972650.1544 - val_loss: 5951883754.9589\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9934177213.2556 - val_loss: 5953130601.2055\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9997957675.0326 - val_loss: 5951308266.9589\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 135us/step - loss: 10080384029.8593 - val_loss: 5948973568.0000\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10332365319.9039 - val_loss: 5946305869.1507\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9810157474.9091 - val_loss: 5942898344.3288\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10403103408.5214 - val_loss: 5943261338.3014\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 10406229729.7015 - val_loss: 5945292919.2329\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10296646763.1424 - val_loss: 5944500262.5753\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 9882877543.6295 - val_loss: 5945149801.2055\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10340414717.8045 - val_loss: 5946593258.9589\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9806045199.8079 - val_loss: 5945465333.4795\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10668532277.5712 - val_loss: 5946344321.7534\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10163554787.0189 - val_loss: 5948118440.3288\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9659581678.8748 - val_loss: 5950281559.6712\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10194230868.3087 - val_loss: 5949327430.1370\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10133590354.1132 - val_loss: 5945821127.8904\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10785022977.7564 - val_loss: 5948412373.9178\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10168046959.9726 - val_loss: 5948631986.8493\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9795947173.1046 - val_loss: 5946546940.4932\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9835532474.1818 - val_loss: 5947846003.7260\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9662853212.2127 - val_loss: 5945801826.1918\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10180010789.3242 - val_loss: 5950974737.5342\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10558489773.8868 - val_loss: 5953295170.6301\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9732908406.9983 - val_loss: 5956215951.7808\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9932452526.7650 - val_loss: 5957055207.4521\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9852733778.9914 - val_loss: 5955294940.9315\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10217735917.5575 - val_loss: 5956603121.9726\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10002684261.4340 - val_loss: 5957442461.8082\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10255507166.1887 - val_loss: 5957410703.7808\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9657411747.3482 - val_loss: 5955459829.4795\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10473570442.7581 - val_loss: 5954650904.5479\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9962255467.1424 - val_loss: 5955856545.3151\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10706687466.0446 - val_loss: 5955973502.2466\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9780641960.6175 - val_loss: 5954204945.5342\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10552615301.0497 - val_loss: 5955033137.0959\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 140us/step - loss: 10127230855.6844 - val_loss: 5958017371.1781\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 10014870912.6587 - val_loss: 5957662407.8904\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9994136801.7015 - val_loss: 5956843407.7808\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10043992766.5729 - val_loss: 5955888243.7260\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9982431664.6312 - val_loss: 5955806590.2466\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9968536797.3105 - val_loss: 5958838159.7808\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9957919074.7993 - val_loss: 5955939552.4384\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10728164729.6329 - val_loss: 5956492589.5890\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10339646351.5883 - val_loss: 5959000056.9863\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10103042799.7530 - val_loss: 5963462298.3014\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9970977235.2110 - val_loss: 5963490535.4521\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10458622714.2916 - val_loss: 5962748777.2055\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10472289608.4528 - val_loss: 5963701644.2740\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10175564194.4700 - val_loss: 5965310888.3288\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10168135031.8765 - val_loss: 5963212021.4795\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10186828396.0206 - val_loss: 5961955285.9178\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10045627207.5746 - val_loss: 5957109760.0000\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10269959347.1561 - val_loss: 5957435896.9863\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10043980775.4100 - val_loss: 5951927765.9178\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9783991726.3259 - val_loss: 5948639765.0411\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9988052674.9640 - val_loss: 5949036196.8219\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9871585843.8148 - val_loss: 5946935730.8493\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9946835537.6741 - val_loss: 5947268902.5753\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9962113679.1492 - val_loss: 5946041831.4521\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10358832561.8388 - val_loss: 5949495173.2603\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9892944497.7290 - val_loss: 5951114562.6301\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9485900605.0360 - val_loss: 5948811253.4795\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10151220854.5592 - val_loss: 5944049222.1370\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10294612912.9605 - val_loss: 5945679219.7260\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10498572165.9280 - val_loss: 5950063917.5890\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9846940236.4048 - val_loss: 5947412192.4384\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10259277869.6672 - val_loss: 5949702648.9863\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10542319643.2247 - val_loss: 5954542206.2466\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10059414510.4357 - val_loss: 5956239991.2329\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10129172018.9365 - val_loss: 5959157170.8493\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10397677226.3739 - val_loss: 5960198315.8356\n",
      "neurons used (32, 64)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 511us/step - loss: 39207840260.3911 - val_loss: 38410686800.6575\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39197323622.3122 - val_loss: 38397426589.8082\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39179825545.4408 - val_loss: 38376314346.9589\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39156367612.9262 - val_loss: 38350747732.1644\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 39124673692.3225 - val_loss: 38322561024.0000\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39088429589.9554 - val_loss: 38283188981.4795\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 39046225364.9674 - val_loss: 38244393661.3699\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 38995564182.1750 - val_loss: 38197118919.8904\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38943800458.7581 - val_loss: 38110412098.6301\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38880639077.8731 - val_loss: 38045739933.8082\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 38811727801.7427 - val_loss: 37984837912.5479\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 38740005429.5712 - val_loss: 37890920560.2192\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 38663403168.7136 - val_loss: 37816855734.3562\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 38572731481.5780 - val_loss: 37724913046.7945\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 38479673899.0326 - val_loss: 37649657351.0137\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38388215758.8199 - val_loss: 37543509567.1233\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38276392700.0480 - val_loss: 37443425714.8493\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38172808545.0429 - val_loss: 37315061058.6301\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 38059600848.5763 - val_loss: 37203579497.2055\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 37930491911.0257 - val_loss: 37083332804.3836\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37819856565.7907 - val_loss: 36987862366.6849\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 37684939900.7067 - val_loss: 36839381468.9315\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 37530799063.6021 - val_loss: 36698563457.7534\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37383597683.0463 - val_loss: 36542199864.1096\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 37258692871.4648 - val_loss: 36365962815.1233\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37086834192.6861 - val_loss: 36200248193.7534\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 36922172038.3671 - val_loss: 36050024419.9452\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 36756597526.3945 - val_loss: 35895941512.7671\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 142us/step - loss: 36593151409.8388 - val_loss: 35717363403.3973\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 36421178717.5300 - val_loss: 35518483554.1918\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 36267598020.7204 - val_loss: 35330956302.0274\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 36079487228.9262 - val_loss: 35182727925.4795\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 35868701093.5437 - val_loss: 34999454537.6438\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 35680470917.0497 - val_loss: 34784016468.1644\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 35446518269.3654 - val_loss: 34557254193.0959\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 35242519304.3431 - val_loss: 34348616942.4658\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 35044534879.7256 - val_loss: 34150275268.3836\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 34835246036.0892 - val_loss: 33912106194.4110\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 34592656361.1664 - val_loss: 33690211370.0822\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 34445080224.7136 - val_loss: 33453348751.7808\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 34143531092.3087 - val_loss: 33250957312.0000\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 33923549883.0600 - val_loss: 32989097535.1233\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 33692340933.5986 - val_loss: 32748237838.0274\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 33435131289.2487 - val_loss: 32502461959.0137\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 33136505408.1098 - val_loss: 32237694106.3014\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 32952396362.6484 - val_loss: 31971411434.9589\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 32654990485.2967 - val_loss: 31719943687.0137\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 32443616004.8302 - val_loss: 31448747527.0137\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 32152229308.3774 - val_loss: 31180543354.7397\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 31915138924.4597 - val_loss: 30899644135.4521\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 31636004554.8679 - val_loss: 30622974316.7123\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 31326970147.5677 - val_loss: 30369021559.2329\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 31101495548.9262 - val_loss: 30097445284.8219\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 30697669026.0309 - val_loss: 29786315677.8082\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 30508761376.0549 - val_loss: 29509653938.8493\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 30193967781.9828 - val_loss: 29205781321.6438\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 29951657934.8199 - val_loss: 28937230307.9452\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 29617344093.9691 - val_loss: 28624162563.5069\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 29304330067.8696 - val_loss: 28358388862.2466\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 29036367893.0772 - val_loss: 28016184390.1370\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 28588050302.0240 - val_loss: 27705399520.4384\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 28368248505.3036 - val_loss: 27425132796.4931\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 28089250016.8233 - val_loss: 27081572800.8767\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 27706392228.2264 - val_loss: 26769596247.6712\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 27438187305.7153 - val_loss: 26487057562.3014\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 27179902800.3568 - val_loss: 26149714060.2740\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 26804598116.5557 - val_loss: 25819149045.4795\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 26511283767.3276 - val_loss: 25456891202.6301\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 26193949395.6501 - val_loss: 25118437993.2055\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 25920313593.4134 - val_loss: 24756455087.3425\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 25606153577.8250 - val_loss: 24442319409.0959\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 25210993296.9057 - val_loss: 24077324259.9452\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 24780243572.8027 - val_loss: 23787987757.5890\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 24503237268.4185 - val_loss: 23448958583.2329\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 24212145332.9125 - val_loss: 23132089470.2466\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 23917423438.6003 - val_loss: 22773253919.5616\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 23566042647.7118 - val_loss: 22429454981.2603\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 23118234211.2384 - val_loss: 22100805505.7534\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 22840217440.1647 - val_loss: 21786284102.1370\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 22561521407.5609 - val_loss: 21430711071.5616\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 22220660969.6055 - val_loss: 21072212374.7945\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 21975469068.2950 - val_loss: 20757601055.5616\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 21499266843.6638 - val_loss: 20390271733.4795\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 21109611913.846 - 0s 145us/step - loss: 21030759120.1372 - val_loss: 20043784977.5342\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 20703408474.0172 - val_loss: 19719473755.1781\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 20582932648.6175 - val_loss: 19389011168.4384\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 20163633464.6449 - val_loss: 19017397991.4521\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 19819821639.1355 - val_loss: 18684092177.5342\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 19523289312.8233 - val_loss: 18357526247.4521\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 19096045121.8662 - val_loss: 18033774620.0548\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 18757314433.5369 - val_loss: 17679109386.5205\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 18537340968.3979 - val_loss: 17361592670.6849\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 141us/step - loss: 18158948871.9039 - val_loss: 17028122062.9041\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 17828085082.0172 - val_loss: 16701665251.9452\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 17537744931.1286 - val_loss: 16365447658.9589\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 17110603797.0772 - val_loss: 16028937230.0274\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 16887677163.3619 - val_loss: 15718920795.1781\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 16549666187.1973 - val_loss: 15410521466.7397\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 16231567029.7907 - val_loss: 15106758010.7397\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 16024058892.2950 - val_loss: 14790220224.8767\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 15550297679.9177 - val_loss: 14450148015.3425\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 15326154010.7856 - val_loss: 14143628133.6986\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 14835823997.1458 - val_loss: 13826647418.7397\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 14683436943.5883 - val_loss: 13517357617.0959\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 14306843878.0926 - val_loss: 13179322915.0685\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 14177211133.8045 - val_loss: 12881825693.8082\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 13839525624.5352 - val_loss: 12587339278.0274\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 13577765545.4957 - val_loss: 12302230647.2329\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 13224516211.0463 - val_loss: 12013663975.4521\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 13224171931.0051 - val_loss: 11724494756.8219\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 12547702360.6998 - val_loss: 11447859754.0822\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 12447260898.5798 - val_loss: 11168621575.0137\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 12154543160.2058 - val_loss: 10900056393.6438\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 11834186578.1132 - val_loss: 10618124764.9315\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 11600788219.1698 - val_loss: 10371057053.8082\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 11402363768.7547 - val_loss: 10126953661.3699\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11039017435.5540 - val_loss: 9883743744.0000\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 11015156685.0635 - val_loss: 9646625686.7945\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10620646738.1132 - val_loss: 9384650590.6849\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10428145932.7341 - val_loss: 9154220726.3562\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10230634079.7256 - val_loss: 8922386242.6301\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10103869120.3293 - val_loss: 8712617731.5068\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9974215365.5986 - val_loss: 8507517082.3014\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9564951314.8816 - val_loss: 8291651436.7123\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9270260542.7925 - val_loss: 8092232605.8082\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9350560130.4151 - val_loss: 7908187676.0548\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9129154019.0189 - val_loss: 7715408208.6575\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8826375682.6346 - val_loss: 7540395477.9178\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 8764844751.6981 - val_loss: 7393173314.6301\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 8526515547.7736 - val_loss: 7241788338.8493\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 8274867045.4340 - val_loss: 7074949982.6849\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8126651058.7170 - val_loss: 6936539248.2192\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8073930081.0429 - val_loss: 6790634464.4384\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8200285877.7907 - val_loss: 6651413917.8082\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7842001729.4271 - val_loss: 6545926105.4247\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7895771098.6758 - val_loss: 6421564840.3288\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7530089363.9794 - val_loss: 6325438232.5479\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7538889627.0051 - val_loss: 6224558427.1781\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7597666732.1304 - val_loss: 6145776040.3288\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7659676181.0772 - val_loss: 6068754442.5205\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7464379948.7890 - val_loss: 5998048631.2329\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7258619673.9074 - val_loss: 5931487856.2192\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7314343840.2744 - val_loss: 5877169709.5890\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7163396217.1938 - val_loss: 5825538160.2192\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7143934480.6861 - val_loss: 5777890696.7671\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7240909800.2882 - val_loss: 5739902064.2192\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7142656953.7427 - val_loss: 5707381917.8082\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7056540818.6621 - val_loss: 5684474936.1096\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7105051258.0720 - val_loss: 5662614556.0548\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7090971355.1149 - val_loss: 5643716723.7260\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7050827292.9811 - val_loss: 5628167245.1507\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7060532604.2676 - val_loss: 5615578511.7808\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7009872715.9657 - val_loss: 5602939795.2877\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7014214162.0034 - val_loss: 5595385659.6164\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6898270242.6895 - val_loss: 5588022272.0000\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6753455438.6003 - val_loss: 5580461129.6438\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6985024957.2556 - val_loss: 5575406325.4795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7063247805.2556 - val_loss: 5569574459.6164\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6915884789.0223 - val_loss: 5563336023.6712\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6990782871.0532 - val_loss: 5563068219.6164\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6924176012.5146 - val_loss: 5558655340.7123\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7165687569.1252 - val_loss: 5554425526.3562\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6941499095.1630 - val_loss: 5549573719.6712\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6923673120.4940 - val_loss: 5547737564.9315\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6932689757.5300 - val_loss: 5547526638.4658\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7121934758.8611 - val_loss: 5550381276.9315\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7097981408.3842 - val_loss: 5547321077.4795\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7034914488.4254 - val_loss: 5545809358.9041\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7145679785.9348 - val_loss: 5546720831.1233\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6804102740.3087 - val_loss: 5545612807.0137\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7054332066.4700 - val_loss: 5544197737.2055\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6879695705.1389 - val_loss: 5544336289.3151\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7087408207.0395 - val_loss: 5544181521.5342\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6780852326.7513 - val_loss: 5541794707.2877\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6880281138.0583 - val_loss: 5541482166.3562\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7219351726.3259 - val_loss: 5541989828.3836\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7066456962.4151 - val_loss: 5540039658.9589\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7075339220.0892 - val_loss: 5539029090.1918\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6846968589.6124 - val_loss: 5538451000.1096\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7123408854.0652 - val_loss: 5537982267.6164\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7171072112.8508 - val_loss: 5538077355.8356\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7063607157.2419 - val_loss: 5535614737.5342\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7054723763.1561 - val_loss: 5535636199.4521\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7040838428.9811 - val_loss: 5538096331.3973\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7140954548.4734 - val_loss: 5538567048.7671\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7153313481.9897 - val_loss: 5538455709.8082\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6773808837.5986 - val_loss: 5536991175.8904\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7075598745.2487 - val_loss: 5537466017.3151\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7061562390.8336 - val_loss: 5537064746.0822\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7059402920.6175 - val_loss: 5536951688.7671\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6949476355.5129 - val_loss: 5538199815.0137\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 6974895457.0429 - val_loss: 5537985641.2055\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7046481956.8851 - val_loss: 5538401644.7123\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7025297053.2007 - val_loss: 5538846158.9041\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7080584652.1852 - val_loss: 5538385934.0274\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7035438866.8816 - val_loss: 5539460586.9589\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7041934301.7496 - val_loss: 5541016421.6986\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7048741024.7136 - val_loss: 5538869114.7397\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6910222514.4974 - val_loss: 5536650443.3973\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7030600252.5969 - val_loss: 5535966976.0000\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7205588746.9777 - val_loss: 5535987592.7671\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7035633172.1990 - val_loss: 5536010906.3014\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7213281666.4151 - val_loss: 5536140333.5890\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7022386035.1561 - val_loss: 5536986133.0411\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6908259140.0617 - val_loss: 5536560741.6986\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6794182805.9554 - val_loss: 5535990584.1096\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7065195037.2007 - val_loss: 5535445202.4110\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7201300924.8165 - val_loss: 5537374513.0959\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6876566887.1904 - val_loss: 5536306982.5753\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6956652265.6055 - val_loss: 5535629101.5890\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6967184568.4254 - val_loss: 5535852554.5205\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7178996238.9297 - val_loss: 5534182052.8219\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7058982515.0463 - val_loss: 5534552881.0959\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6843411867.8834 - val_loss: 5533148871.8904\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6846781643.7461 - val_loss: 5534230829.5890\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7045581129.3310 - val_loss: 5534232088.5479\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7109959806.4631 - val_loss: 5534526260.6027\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7208545719.1081 - val_loss: 5535654575.3425\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7131501396.7479 - val_loss: 5537099656.7671\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7100089355.4168 - val_loss: 5536327869.3699\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7030289607.7942 - val_loss: 5536684796.4932\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7072047922.4974 - val_loss: 5538109429.4795\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 142us/step - loss: 6999286235.9931 - val_loss: 5537618561.7534\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6820430649.9623 - val_loss: 5536770335.5616\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7008743192.1509 - val_loss: 5537571538.4110\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7257419437.0086 - val_loss: 5537172003.0685\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 6811027721.2213 - val_loss: 5535710576.2192\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6876607700.7479 - val_loss: 5535928909.1507\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7042271498.5386 - val_loss: 5535655809.7534\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6919080640.3293 - val_loss: 5534483796.1644\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7105495883.0875 - val_loss: 5535669230.4658\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6875903814.6964 - val_loss: 5536138345.2055\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6941028316.8714 - val_loss: 5536540251.1781\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7022777319.4099 - val_loss: 5537957193.6438\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6993588498.0034 - val_loss: 5537529715.7260\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7113192289.9211 - val_loss: 5538185107.2877\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7013905523.9245 - val_loss: 5538196676.3836\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6959091022.1612 - val_loss: 5537451681.3151\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7150061549.1184 - val_loss: 5536209656.9863\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7042955499.8010 - val_loss: 5537330435.5068\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7035149580.7341 - val_loss: 5538059214.9041\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6925075034.4563 - val_loss: 5538259049.2055\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7021577698.5798 - val_loss: 5537596177.5342\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7038249612.5146 - val_loss: 5537131902.2466\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7009868208.0823 - val_loss: 5536108996.3836\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7090883394.3053 - val_loss: 5537024490.9589\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7242683978.2093 - val_loss: 5538754605.5890\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6999447323.6638 - val_loss: 5538124764.9315\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7055532755.6501 - val_loss: 5537694376.3288\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7083026750.3533 - val_loss: 5539056867.9452\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7071484950.8336 - val_loss: 5538669967.7808\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6926495212.6792 - val_loss: 5539613103.3425\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7027512497.3997 - val_loss: 5538132900.8219\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6832847491.7324 - val_loss: 5535962287.3425\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7175983256.8096 - val_loss: 5536297226.5205\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6926385195.9108 - val_loss: 5536442069.9178\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6936997562.1818 - val_loss: 5535637679.3425\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6983671266.5798 - val_loss: 5535465468.4932\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6936720782.7101 - val_loss: 5536127982.4658\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7183017658.1818 - val_loss: 5536200504.1096\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6869154231.1081 - val_loss: 5536778653.8082\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7141425971.3756 - val_loss: 5535974750.6849\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7101056313.5232 - val_loss: 5536981980.9315\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7074210024.7273 - val_loss: 5536176640.0000\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7048730494.0240 - val_loss: 5535709373.3699\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7156665229.8319 - val_loss: 5536278075.6164\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6884975828.5283 - val_loss: 5535914152.3288\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7047373622.8885 - val_loss: 5536218974.6849\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6941696765.8045 - val_loss: 5535823535.3425\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6942411823.8628 - val_loss: 5535752802.1918\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6984441776.5214 - val_loss: 5535763319.2329\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7022586125.1732 - val_loss: 5536248127.1233\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7178919868.3774 - val_loss: 5537423952.6575\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6844964921.0840 - val_loss: 5536598503.4521\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6993039956.3087 - val_loss: 5536803861.0411\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7205417604.6106 - val_loss: 5537695137.3151\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6917305556.5283 - val_loss: 5536911654.5753\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6810848343.8216 - val_loss: 5536411164.0548\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7129884095.0120 - val_loss: 5536440049.9726\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7026703052.6244 - val_loss: 5536582319.3425\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6954363158.8336 - val_loss: 5536087993.8630\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7099168415.8353 - val_loss: 5535785545.6438\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7104313611.8559 - val_loss: 5535426973.8082\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6876106348.8988 - val_loss: 5535437487.3425\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7187647581.9691 - val_loss: 5534900427.3973\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7028533030.2024 - val_loss: 5534816799.5616\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6941116830.5180 - val_loss: 5534369651.7260\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 140us/step - loss: 7082501372.9262 - val_loss: 5534599641.4247\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7009515008.0000 - val_loss: 5534687442.4110\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 6882993701.7633 - val_loss: 5534249692.9315\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7048720650.5386 - val_loss: 5536116974.4658\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7089302758.0926 - val_loss: 5536172817.5342\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6937940848.8508 - val_loss: 5536121442.1918\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6960221826.4151 - val_loss: 5535154105.8630\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7133144923.7736 - val_loss: 5535015266.1918\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6991353393.1801 - val_loss: 5536258307.5068\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7066129402.7307 - val_loss: 5535382556.0548\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 6970392755.5952 - val_loss: 5535397312.8767\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7113362324.8576 - val_loss: 5535066869.4795\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7291621128.3431 - val_loss: 5534953391.3425\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7115135301.8182 - val_loss: 5535162599.4521\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6863211938.0309 - val_loss: 5535045063.8904\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7013634560.8782 - val_loss: 5534110898.8493\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7008764444.1029 - val_loss: 5533582686.6849\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7297685609.3859 - val_loss: 5534576566.3562\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6957971762.4974 - val_loss: 5536273127.4521\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6978282219.3619 - val_loss: 5534549546.0822\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7072412679.0257 - val_loss: 5535390888.3288\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6851319163.8285 - val_loss: 5536339848.7671\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7024235965.2556 - val_loss: 5535668185.4247\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6862081329.6192 - val_loss: 5535201532.4932\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7092265543.5746 - val_loss: 5534585386.0822\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6975976155.9931 - val_loss: 5535867300.8219\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6911599717.8731 - val_loss: 5535681360.6575\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6991278691.6775 - val_loss: 5535683569.9726\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6974823191.2727 - val_loss: 5536494143.1233\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7070500589.9966 - val_loss: 5536356611.5068\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6998487822.4906 - val_loss: 5536896687.3425\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7091845871.7530 - val_loss: 5536840423.4521\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7221706074.8954 - val_loss: 5537315854.0274\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7233422248.1784 - val_loss: 5537493391.7808\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6859285145.2487 - val_loss: 5537312185.8630\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6903341712.0274 - val_loss: 5536819389.3699\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6917186286.8748 - val_loss: 5536052315.1781\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7016827817.9348 - val_loss: 5536469076.1644\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6952780997.5986 - val_loss: 5536458892.2740\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7091944312.7547 - val_loss: 5536002987.8356\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7134422851.1835 - val_loss: 5535187512.1096\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7018770114.9640 - val_loss: 5535845530.3014\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6846004699.9931 - val_loss: 5535897908.6027\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6941292160.4391 - val_loss: 5535385382.5753\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6778707587.7324 - val_loss: 5535207795.7260\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6838229994.4837 - val_loss: 5535466117.2603\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6973419199.0120 - val_loss: 5535784903.8904\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6915490838.8336 - val_loss: 5535783953.5342\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6953033094.8062 - val_loss: 5535847683.5068\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7019171529.9897 - val_loss: 5535296617.2055\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7092052474.5111 - val_loss: 5535013116.4932\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6947821071.3688 - val_loss: 5535243130.7397\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7052533624.3156 - val_loss: 5535053276.9315\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7073296609.7015 - val_loss: 5535287723.8356\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7106895968.6038 - val_loss: 5535026414.4658\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7247193403.4991 - val_loss: 5536585068.7123\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6855086071.6569 - val_loss: 5536099349.0411\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6996873045.4065 - val_loss: 5534641790.2466\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7130113635.2384 - val_loss: 5535426353.0959\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6915507068.2676 - val_loss: 5535583884.2740\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6944432013.8319 - val_loss: 5535845551.3425\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7070593211.0600 - val_loss: 5535374974.2466\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7013893599.0669 - val_loss: 5533670400.0000\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7091180800.4391 - val_loss: 5534405207.6712\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7241265939.7599 - val_loss: 5534903008.4384\n",
      "Epoch 353/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 145us/step - loss: 6947541874.6072 - val_loss: 5534914907.1781\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6910863701.1870 - val_loss: 5535566483.2877\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6956748864.7684 - val_loss: 5534989648.6575\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6874451742.2985 - val_loss: 5534480896.0000\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6847558753.9211 - val_loss: 5533356547.5068\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7013882079.0669 - val_loss: 5533360976.6575\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6983348176.5763 - val_loss: 5534616835.5068\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7132680385.2075 - val_loss: 5534522915.0685\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6908071227.2796 - val_loss: 5533804347.6164\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6989058384.3568 - val_loss: 5533827068.4932\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6915777673.0017 - val_loss: 5533388922.7397\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7183068601.3036 - val_loss: 5533316706.1918\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7156242917.6535 - val_loss: 5534189175.2329\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6760143965.0909 - val_loss: 5533345637.6986\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7006754166.1201 - val_loss: 5533457274.7397\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6903721195.3619 - val_loss: 5533499244.7123\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7077683979.8559 - val_loss: 5534450730.0822\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6962404609.3173 - val_loss: 5534939942.5753\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7171953388.6792 - val_loss: 5534047161.8630\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7056067915.0875 - val_loss: 5534551537.9726\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7006359788.2401 - val_loss: 5533721603.5068\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7119415002.6758 - val_loss: 5533767083.8356\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7144996008.1784 - val_loss: 5533923882.0822\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7111558079.0120 - val_loss: 5535251035.1781\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6997136824.8645 - val_loss: 5534192447.1233\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6913174548.4185 - val_loss: 5534008867.0685\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7019779760.9605 - val_loss: 5533702922.5205\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7051944966.1475 - val_loss: 5533180479.1233\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6828237583.3688 - val_loss: 5532031147.8356\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7016836404.2539 - val_loss: 5531980238.9041\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 6999063085.6672 - val_loss: 5532358603.3973\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7152511107.7324 - val_loss: 5532085286.5753\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7167905576.8370 - val_loss: 5533282440.7671\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6933590915.2933 - val_loss: 5533820408.9863\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7015403336.4528 - val_loss: 5534076359.8904\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7049309356.1304 - val_loss: 5534068939.3973\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6920771245.0086 - val_loss: 5534260665.8630\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 6961549859.1286 - val_loss: 5534487373.1507\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6942536778.6484 - val_loss: 5534287100.4932\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7138907145.6604 - val_loss: 5535666004.1644\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7119778605.2281 - val_loss: 5535979481.4247\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6903841147.3894 - val_loss: 5534895949.1507\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7001104638.2436 - val_loss: 5534290775.6712\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6906290316.5146 - val_loss: 5534266887.0137\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6859795487.6158 - val_loss: 5535182213.2603\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7187660208.9605 - val_loss: 5535008690.8493\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7268286174.1887 - val_loss: 5535786215.4521\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7154207005.4202 - val_loss: 5536249743.7808\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6897729479.7942 - val_loss: 5536456921.4247\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6810205732.8851 - val_loss: 5535774320.2192\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6974887984.3019 - val_loss: 5536177744.6575\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7013471843.2384 - val_loss: 5535796280.1096\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6885395447.2178 - val_loss: 5534948555.3973\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6985258182.4768 - val_loss: 5535060802.6301\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6840452703.5060 - val_loss: 5534347825.0959\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7248525351.7393 - val_loss: 5535312903.0137\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7049275774.4631 - val_loss: 5535657605.2603\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7014633298.1132 - val_loss: 5536181276.0548\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7187043700.3636 - val_loss: 5535901583.7808\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6889027120.3019 - val_loss: 5535892788.6027\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7176125829.0497 - val_loss: 5536464839.8904\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6945363347.1012 - val_loss: 5536036541.3699\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7121631888.9057 - val_loss: 5536363281.5342\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6906592670.5180 - val_loss: 5534757765.2603\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6965215128.3705 - val_loss: 5534691359.5616\n",
      "Epoch 418/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 140us/step - loss: 6831266808.9743 - val_loss: 5534970090.9589\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6891921753.1389 - val_loss: 5534812766.6849\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7144753858.0858 - val_loss: 5535559918.4658\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7033728189.6947 - val_loss: 5536197463.6712\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6932463949.7221 - val_loss: 5535806639.3425\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7107805389.5026 - val_loss: 5536080959.1233\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6991437713.3448 - val_loss: 5535774779.6164\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6986809491.5403 - val_loss: 5535901422.4658\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6823609480.5626 - val_loss: 5535044527.3425\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6742615066.3465 - val_loss: 5534611820.7123\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 6842888393.1115 - val_loss: 5535304549.6986\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6977751129.5780 - val_loss: 5535130757.2603\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 6921111521.2624 - val_loss: 5535093840.6575\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 6938667352.2607 - val_loss: 5536357926.5753\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 7212320225.7015 - val_loss: 5536374117.6986\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7088866646.5043 - val_loss: 5536841482.5205\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7093640292.9949 - val_loss: 5536886433.3151\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 7043708400.1921 - val_loss: 5537317291.8356\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 6878671125.0772 - val_loss: 5536545104.6575\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7196062712.0961 - val_loss: 5536734698.9589\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7010404359.9039 - val_loss: 5537057616.6575\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7099079178.5386 - val_loss: 5537578730.9589\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7080133882.2916 - val_loss: 5537338013.8082\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 6965775922.0583 - val_loss: 5537920056.1096\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6938865678.4906 - val_loss: 5540481430.7945\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6979643210.2093 - val_loss: 5540998010.7397\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7171496782.6003 - val_loss: 5540930226.8493\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7003005155.4580 - val_loss: 5539411389.3699\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7076160654.2710 - val_loss: 5539033642.0822\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 6957972345.1938 - val_loss: 5539534932.1644\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6870769577.9348 - val_loss: 5537731093.0411\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7156463921.6192 - val_loss: 5536164039.8904\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7130124294.1475 - val_loss: 5536553261.5890\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 6985052137.1664 - val_loss: 5537277257.6438\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6974522521.6878 - val_loss: 5536830506.0822\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6913087437.9417 - val_loss: 5536825052.9315\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7234613413.1046 - val_loss: 5537116721.0959\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7062028576.4940 - val_loss: 5537124913.0959\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7035942333.2556 - val_loss: 5537689848.9863\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7028257890.7993 - val_loss: 5537226303.1233\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7037590266.2916 - val_loss: 5536919720.3288\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7206387956.1441 - val_loss: 5537041891.9452\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7017330452.6381 - val_loss: 5537663726.4658\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6916377372.5420 - val_loss: 5537619315.7260\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7026316100.0617 - val_loss: 5536778075.1781\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6909388951.9314 - val_loss: 5536390894.4658\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7098004935.7942 - val_loss: 5536071858.8493\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6785809294.7101 - val_loss: 5536086485.9178\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 6874353649.9485 - val_loss: 5535076597.4795\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7242561468.8165 - val_loss: 5536248046.4658\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7028469774.9297 - val_loss: 5535055381.0411\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7066901329.6741 - val_loss: 5535522339.0685\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7076152041.6055 - val_loss: 5536465078.3562\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7063513567.5060 - val_loss: 5535824201.6438\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7058381462.6141 - val_loss: 5535584336.6575\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7105361090.9640 - val_loss: 5535611795.2877\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6985435139.5129 - val_loss: 5536633757.8082\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7104737117.0909 - val_loss: 5538027025.5342\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7106223358.2436 - val_loss: 5538740697.4247\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6918699721.9897 - val_loss: 5538527063.6712\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6942179078.5866 - val_loss: 5538537780.6027\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6996747235.2384 - val_loss: 5538312886.3562\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6843356576.2744 - val_loss: 5537230378.0822\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 6881635295.5060 - val_loss: 5536825564.9315\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 7150524731.2796 - val_loss: 5537060534.3562\n",
      "Epoch 483/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 193us/step - loss: 6765041767.6295 - val_loss: 5535572750.0274\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7068381162.9228 - val_loss: 5535512540.9315\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 6941546618.9503 - val_loss: 5534987902.2466\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7098724692.7479 - val_loss: 5534887760.6575\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7171673524.0343 - val_loss: 5534994102.3562\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6877624917.1870 - val_loss: 5534398239.5616\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7060340844.0206 - val_loss: 5533882746.7397\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7080869229.3379 - val_loss: 5534321369.4247\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7075981581.6124 - val_loss: 5534382416.6575\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6875467124.1441 - val_loss: 5534578337.3151\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6978716348.8165 - val_loss: 5534487979.8356\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7182530434.4151 - val_loss: 5534587995.1781\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6878565371.6089 - val_loss: 5534923418.3014\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7047810218.8130 - val_loss: 5535077965.1507\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6953259372.8988 - val_loss: 5535269039.3425\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6926109214.7376 - val_loss: 5537050041.8630\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7042156302.9297 - val_loss: 5536753678.0274\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7000126357.7358 - val_loss: 5536860380.9315\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 6977233643.3619 - val_loss: 5536289209.8630\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6872594985.4957 - val_loss: 5534994663.4521\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7014770017.0429 - val_loss: 5535591921.9726\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7205860279.9863 - val_loss: 5534841575.4521\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7110759179.8559 - val_loss: 5536338474.0822\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7125774374.6415 - val_loss: 5534875465.6438\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 6935093045.1321 - val_loss: 5534926125.5890\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6972569911.7667 - val_loss: 5535177608.7671\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7055355538.2230 - val_loss: 5534825892.8219\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7119405068.2950 - val_loss: 5535207795.7260\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7186492298.3190 - val_loss: 5534598382.4658\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6947472153.9074 - val_loss: 5535654136.9863\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7114926525.2556 - val_loss: 5535229236.6027\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7129215515.2247 - val_loss: 5535935502.0274\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7018566036.8576 - val_loss: 5536423213.5890\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7028494961.2899 - val_loss: 5535728412.0548\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7145188942.1612 - val_loss: 5535916000.4384\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7046670072.9743 - val_loss: 5536943514.3014\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7169594206.4082 - val_loss: 5537453448.7671\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7206068769.3722 - val_loss: 5537142699.8356\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7031155654.0377 - val_loss: 5537029158.5753\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6900080412.3225 - val_loss: 5536730462.6849\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6905107464.7822 - val_loss: 5536361128.3288\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7194712612.4460 - val_loss: 5537307195.6164\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7116842755.0738 - val_loss: 5536653838.0274\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6937548286.6827 - val_loss: 5537333998.4658\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6834309317.1595 - val_loss: 5537331733.0411\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7159961174.0652 - val_loss: 5537675446.3562\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7052353780.5832 - val_loss: 5537390178.1918\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6911521642.7033 - val_loss: 5536831228.4932\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7128488998.6415 - val_loss: 5536527584.4384\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7078476607.2316 - val_loss: 5536195072.0000\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7108514021.2144 - val_loss: 5536956026.7397\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7104677580.6244 - val_loss: 5537030645.4795\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6924364641.9211 - val_loss: 5536626747.6164\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7023080747.4717 - val_loss: 5536449479.8904\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6938387439.7530 - val_loss: 5537473332.6027\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7018366399.0120 - val_loss: 5537853752.1096\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6939484037.0497 - val_loss: 5536282631.0137\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6952565564.1578 - val_loss: 5536632895.1233\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7172630012.9262 - val_loss: 5538116951.6712\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7026212337.9485 - val_loss: 5537464909.1507\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7019265079.3276 - val_loss: 5537380569.4247\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7001936805.5437 - val_loss: 5535766282.5205\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7016836690.5523 - val_loss: 5536470962.8493\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7079606502.0926 - val_loss: 5536737448.3288\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7080370764.8439 - val_loss: 5537632480.4384\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 146us/step - loss: 6971111096.4254 - val_loss: 5537573895.0137\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6993498287.6432 - val_loss: 5536851729.5342\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6988019452.9262 - val_loss: 5536893552.2192\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7033811941.8731 - val_loss: 5536253264.6575\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6810543500.0755 - val_loss: 5536108656.2192\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6968006540.0755 - val_loss: 5535398554.3014\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6884511229.3654 - val_loss: 5535729215.1233\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7110993740.8439 - val_loss: 5535903074.1918\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7022444123.3345 - val_loss: 5535264634.7397\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6869362396.4322 - val_loss: 5535821683.7260\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7137594129.5643 - val_loss: 5536340501.0411\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7094893857.8113 - val_loss: 5536848924.0548\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7136515821.1184 - val_loss: 5538264021.9178\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6880786673.9485 - val_loss: 5536697838.4658\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7130974208.0000 - val_loss: 5536230827.8356\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7038405450.2093 - val_loss: 5535957272.5479\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7078407338.3739 - val_loss: 5536814507.8356\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6846860937.8799 - val_loss: 5536524617.6438\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7022067237.7633 - val_loss: 5537594960.6575\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6995044607.5609 - val_loss: 5537805543.4521\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7011634336.7136 - val_loss: 5537118460.4932\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6897072356.3362 - val_loss: 5537189951.1233\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7123073497.7976 - val_loss: 5536637776.6575\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7056432435.3756 - val_loss: 5535485801.2055\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6856046721.0978 - val_loss: 5535199645.8082\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7080398431.7256 - val_loss: 5535987726.0274\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7144753223.1355 - val_loss: 5536113323.8356\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6965845251.0738 - val_loss: 5536626263.6712\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7032075074.7444 - val_loss: 5536319326.6849\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7013410420.8027 - val_loss: 5535688742.5753\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7165150104.3705 - val_loss: 5535817703.4521\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7071891297.9211 - val_loss: 5535520676.8219\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7144423635.6501 - val_loss: 5536437977.4247\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6978824347.4443 - val_loss: 5537517052.4932\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7043519013.6535 - val_loss: 5538480618.9589\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7120063456.3842 - val_loss: 5538523279.7808\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7196597283.1286 - val_loss: 5538718397.3699\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6932859193.5232 - val_loss: 5538199815.0137\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7022558260.6930 - val_loss: 5538247992.1096\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7020921615.3688 - val_loss: 5538253350.5753\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6935876209.2899 - val_loss: 5537456106.9589\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6894532739.2933 - val_loss: 5537168611.9452\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6957196582.2024 - val_loss: 5538250857.2055\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6865791104.2196 - val_loss: 5538295660.7123\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6895190707.1561 - val_loss: 5537802197.9178\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6961627745.4820 - val_loss: 5537302142.2466\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7071311469.7770 - val_loss: 5537226225.9726\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7004552422.9708 - val_loss: 5536525802.9589\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6900953201.2899 - val_loss: 5535568278.7945\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7101387103.7256 - val_loss: 5535941884.4932\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7034888997.3242 - val_loss: 5535825667.5068\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7212411918.9297 - val_loss: 5536878476.2740\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7003534073.8525 - val_loss: 5536126120.3288\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 6944087456.2744 - val_loss: 5536104391.8904\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7282905714.6072 - val_loss: 5537545619.2877\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7109456941.6672 - val_loss: 5537111853.5890\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6875435297.8113 - val_loss: 5535907419.1781\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6995228724.6930 - val_loss: 5536644243.2877\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6929255024.1921 - val_loss: 5537543704.5479\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6924697292.1852 - val_loss: 5537220720.2192\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7138878918.9160 - val_loss: 5537425218.6301\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6771406006.2298 - val_loss: 5536554594.1918\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6911897186.3602 - val_loss: 5535422344.7671\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6975591080.1784 - val_loss: 5534738095.3425\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6937112846.0515 - val_loss: 5534909937.9726\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 145us/step - loss: 7014438269.1458 - val_loss: 5535680638.2466\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7283553882.4563 - val_loss: 5536562193.5342\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7056528557.0086 - val_loss: 5537338452.1644\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6860479182.3808 - val_loss: 5537483835.6164\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7016470169.6878 - val_loss: 5537797519.7808\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7035545317.2144 - val_loss: 5537145936.6575\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7096532712.7273 - val_loss: 5536166750.6849\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7029194718.1887 - val_loss: 5536993118.6849\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7192131528.6724 - val_loss: 5536541383.8904\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6999355752.9468 - val_loss: 5535758609.5342\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7024405648.9057 - val_loss: 5535624244.6027\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7118747021.8319 - val_loss: 5536221432.9863\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6993043813.4340 - val_loss: 5536601221.2603\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6962002404.7753 - val_loss: 5535919300.3836\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6866359134.4082 - val_loss: 5535790823.4521\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7133148658.8268 - val_loss: 5536053226.9589\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6935041747.6501 - val_loss: 5535102120.3288\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6971254699.6913 - val_loss: 5534781815.2329\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7212185041.4545 - val_loss: 5535177454.4658\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6905478481.2350 - val_loss: 5535510436.8219\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6969330052.1715 - val_loss: 5535878961.0959\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7113026257.8937 - val_loss: 5535452461.5890\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6993756079.2041 - val_loss: 5535904929.3151\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7074321956.0069 - val_loss: 5536222186.9589\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6954673522.6072 - val_loss: 5535231873.7534\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6963039635.1012 - val_loss: 5535249793.7534\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6928130365.9142 - val_loss: 5535063432.7671\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7016727605.5712 - val_loss: 5535951202.1918\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6996949103.5334 - val_loss: 5534936470.7945\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7012916460.6792 - val_loss: 5535456045.5890\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6955812572.8714 - val_loss: 5535588537.8630\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7135333238.1201 - val_loss: 5536855986.8493\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 7087570219.4717 - val_loss: 5536187388.4932\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6929971581.1458 - val_loss: 5535977237.0411\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7169703645.3105 - val_loss: 5536030421.9178\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7028371340.9537 - val_loss: 5536049888.4384\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7072003577.8525 - val_loss: 5535670931.2877\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6924705706.8130 - val_loss: 5536022236.9315\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6941152936.6175 - val_loss: 5536424125.3699\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7225347512.8645 - val_loss: 5536431160.1096\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6932784559.6432 - val_loss: 5535823167.1233\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7085694875.8834 - val_loss: 5535779531.3973\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7046979412.7479 - val_loss: 5535401296.6575\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7001721444.1166 - val_loss: 5535848377.8630\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6915713800.7822 - val_loss: 5536552882.8493\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7102019837.8045 - val_loss: 5536674710.7945\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7205967322.2367 - val_loss: 5537187983.7808\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 6970553675.5266 - val_loss: 5536309030.5753\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 6959184699.2796 - val_loss: 5535721023.1233\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 6905078189.4477 - val_loss: 5535563390.2466\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7042410606.6552 - val_loss: 5536128869.6986\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 6885217633.9211 - val_loss: 5535390456.9863\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 6876177917.3654 - val_loss: 5535677710.0274\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 6921519825.8937 - val_loss: 5535883418.3014\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7135928299.3619 - val_loss: 5536967490.6301\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6940815246.7101 - val_loss: 5536976019.2877\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 6954751875.2933 - val_loss: 5536778240.0000\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7035607255.6021 - val_loss: 5536286912.8767\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 6993100771.8971 - val_loss: 5535537649.9726\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 6938835729.1252 - val_loss: 5535414114.1918\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7079050111.7804 - val_loss: 5535516047.7808\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 6915150300.4322 - val_loss: 5536096343.6712\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7128335531.2521 - val_loss: 5536630307.0685\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 6947297978.1818 - val_loss: 5535963069.3699\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7070352060.8165 - val_loss: 5535385214.2466\n",
      "Epoch 678/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 173us/step - loss: 7054356994.6346 - val_loss: 5535030440.3288\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6995742907.9383 - val_loss: 5534765255.8904\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7073912854.8336 - val_loss: 5534929572.8219\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7042751596.8988 - val_loss: 5534346106.7397\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7030509181.1458 - val_loss: 5534330101.4795\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6900780236.1852 - val_loss: 5533912954.7397\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6891931517.3654 - val_loss: 5533751815.0137\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7058479085.9966 - val_loss: 5534061589.0411\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7185741482.3739 - val_loss: 5534961222.1370\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6984911632.2470 - val_loss: 5534121619.2877\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6980146744.2058 - val_loss: 5534957739.8356\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6961921521.0703 - val_loss: 5534351879.0137\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6862714908.1029 - val_loss: 5534522988.7123\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6944217152.1098 - val_loss: 5532996716.7123\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7180592257.9760 - val_loss: 5534301738.0822\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7089259071.2316 - val_loss: 5535089166.0274\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6883603960.9743 - val_loss: 5534478995.2877\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7211087436.4048 - val_loss: 5535161792.8767\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7059364930.7444 - val_loss: 5535373098.0822\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7116453185.4271 - val_loss: 5534815347.7260\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6955369973.0223 - val_loss: 5535594692.3836\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7095561147.4991 - val_loss: 5534553221.2603\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7047331463.2453 - val_loss: 5534717552.2192\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7238815088.8508 - val_loss: 5534875704.1096\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7028352378.5111 - val_loss: 5536002882.6301\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6865783124.7479 - val_loss: 5535501371.6164\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7148869801.0566 - val_loss: 5535464314.7397\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7158109261.2830 - val_loss: 5535253984.4384\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7100937726.2436 - val_loss: 5535129957.6986\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7125645634.7444 - val_loss: 5534483982.0274\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 6986049961.0566 - val_loss: 5534591992.9863\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7174403014.9160 - val_loss: 5535038456.9863\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6936377515.6913 - val_loss: 5535255362.6301\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7105752200.1235 - val_loss: 5535133955.5068\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 6974871072.9331 - val_loss: 5535203952.2192\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6974008311.2178 - val_loss: 5537025872.6575\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7038191085.9966 - val_loss: 5537070918.1370\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7409877236.1441 - val_loss: 5537444688.6575\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7045132993.2075 - val_loss: 5537638147.5068\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6818099120.0823 - val_loss: 5537199146.0822\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6913567619.2933 - val_loss: 5537488398.0274\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7216815208.0686 - val_loss: 5539115190.3562\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7065325392.3568 - val_loss: 5540066717.8082\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6997885357.8868 - val_loss: 5538711800.9863\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 6923609502.5180 - val_loss: 5539247903.5616\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7165491631.6432 - val_loss: 5539986488.1096\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7088878841.4134 - val_loss: 5538715640.9863\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7118923630.2161 - val_loss: 5538900108.2740\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7050795408.6861 - val_loss: 5539112237.5890\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7224002846.2985 - val_loss: 5539439889.5342\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7042926817.7015 - val_loss: 5539285637.2603\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7160817163.8559 - val_loss: 5540167427.5068\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7026878023.1355 - val_loss: 5540952842.5205\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7004415995.6089 - val_loss: 5540983303.0137\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7069247220.1441 - val_loss: 5540476977.0959\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7030144452.2813 - val_loss: 5539704018.4110\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6991644886.2847 - val_loss: 5539939292.9315\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7159458764.6244 - val_loss: 5539500712.3288\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6918498611.3756 - val_loss: 5538835007.1233\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7077670844.8165 - val_loss: 5539654694.5753\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7085711641.0292 - val_loss: 5539518449.9726\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6803693148.2127 - val_loss: 5538399807.1233\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7054640365.1184 - val_loss: 5538155954.8493\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6964582254.2161 - val_loss: 5538717885.3699\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6887837846.1750 - val_loss: 5538387634.8493\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 169us/step - loss: 7102058509.1732 - val_loss: 5538498637.1507\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6975474885.8182 - val_loss: 5538629407.5616\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6957090761.1115 - val_loss: 5537254000.2192\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7096662243.8971 - val_loss: 5536403322.7397\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6812993781.0223 - val_loss: 5537052661.4795\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7014381979.4443 - val_loss: 5536665810.4110\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7015694046.1887 - val_loss: 5536795690.0822\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6986123750.5317 - val_loss: 5536359406.4658\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6926101378.4151 - val_loss: 5535725911.6712\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7008650101.2419 - val_loss: 5535902337.7534\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 6940442043.4991 - val_loss: 5536913274.7397\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6998418581.2967 - val_loss: 5536685918.6849\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6926079169.2075 - val_loss: 5536900892.0548\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6994027976.6724 - val_loss: 5536115298.1918\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6820109030.0926 - val_loss: 5536745072.2192\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6926965093.4340 - val_loss: 5536521335.2329\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6916291862.3945 - val_loss: 5536349976.5479\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7044542359.4923 - val_loss: 5536021321.6438\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7012691407.2590 - val_loss: 5536304878.4658\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6951925576.4528 - val_loss: 5536892202.0822\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6949992116.9125 - val_loss: 5536751139.0685\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 6797200566.2298 - val_loss: 5536686704.2192\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7050661077.4065 - val_loss: 5536166270.2466\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6962559948.1852 - val_loss: 5535026975.5616\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7041438540.8439 - val_loss: 5534748633.4247\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6916495684.0617 - val_loss: 5535170391.6712\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7030125301.0223 - val_loss: 5534609351.8904\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6907679923.1561 - val_loss: 5534799773.8082\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7193422422.0652 - val_loss: 5534572424.7671\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7075933018.8954 - val_loss: 5534498977.3151\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6902747226.8954 - val_loss: 5534556044.2740\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6920982977.6467 - val_loss: 5533014499.9452\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6996550785.9760 - val_loss: 5533248119.2329\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6939229697.7564 - val_loss: 5533961033.6438\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6869928443.6089 - val_loss: 5534325195.3973\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6957482391.4923 - val_loss: 5534490318.9041\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7047916992.7684 - val_loss: 5534733575.0137\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6800458150.2024 - val_loss: 5535237916.0548\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6888118932.4185 - val_loss: 5533909363.7260\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7045194727.4099 - val_loss: 5533871444.1644\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7109730508.6244 - val_loss: 5534922155.8356\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7049472901.9280 - val_loss: 5535468565.0411\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7140421222.7513 - val_loss: 5535302799.7808\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6909130299.7187 - val_loss: 5534452252.0548\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7303671012.3362 - val_loss: 5535770936.1096\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6874332821.2967 - val_loss: 5536318772.6027\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6970459908.3911 - val_loss: 5535824945.0959\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6864918560.9331 - val_loss: 5535187880.3288\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7106182420.6381 - val_loss: 5535718519.2329\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6913645741.8868 - val_loss: 5535165825.7534\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7121193663.2316 - val_loss: 5534704426.0822\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6904483862.3945 - val_loss: 5534495358.2466\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7182861608.8370 - val_loss: 5535555135.1233\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7032485227.5815 - val_loss: 5535508788.6027\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6848841343.3413 - val_loss: 5534910926.9041\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7087968367.0943 - val_loss: 5533959041.7534\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7084519952.6861 - val_loss: 5534080424.3288\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7096595120.9605 - val_loss: 5534325086.6849\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6889390038.7238 - val_loss: 5533733116.4932\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7112372962.5798 - val_loss: 5534843651.5068\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7141972764.5420 - val_loss: 5535630062.4658\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7057201807.1492 - val_loss: 5535077105.9726\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7115673834.4837 - val_loss: 5534514032.2192\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7149750236.8714 - val_loss: 5535330163.7260\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6853939767.3276 - val_loss: 5535710362.3014\n",
      "Epoch 808/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 152us/step - loss: 6974997020.9811 - val_loss: 5535048307.7260\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7123241975.4374 - val_loss: 5535917711.7808\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6934580707.0189 - val_loss: 5535802648.5479\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 6980096312.6449 - val_loss: 5535015269.6986\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7011034700.4048 - val_loss: 5535760170.0822\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6858878027.3070 - val_loss: 5535521031.0137\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7027364789.3516 - val_loss: 5535636599.2329\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7075356587.6913 - val_loss: 5534886336.8767\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7165585138.3876 - val_loss: 5534875272.7671\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6997864285.5300 - val_loss: 5534385257.2055\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7057964646.7513 - val_loss: 5533700779.8356\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7102032907.4168 - val_loss: 5535038099.2877\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7064797032.9468 - val_loss: 5535008094.6849\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6984581964.8439 - val_loss: 5535280247.2329\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7140464480.6038 - val_loss: 5536339771.6164\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7050353569.1527 - val_loss: 5536008209.5342\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6876934797.3928 - val_loss: 5535847115.3973\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6982818358.4494 - val_loss: 5535472142.0274\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7025082731.5815 - val_loss: 5536590525.3699\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6871003111.4099 - val_loss: 5535617318.5753\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6996345898.8130 - val_loss: 5536411353.4247\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7176360983.7118 - val_loss: 5536311075.0685\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6898877639.3551 - val_loss: 5536357095.4521\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7133832365.8868 - val_loss: 5536122431.1233\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7076310773.9005 - val_loss: 5535922442.5205\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7175027337.8799 - val_loss: 5537131688.3288\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6877238727.7942 - val_loss: 5536705949.8082\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6928524669.1458 - val_loss: 5537997290.9589\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7083758973.3654 - val_loss: 5537578271.5616\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7037054694.9708 - val_loss: 5537071731.7260\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6957481504.9331 - val_loss: 5536981623.2329\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7046177662.0240 - val_loss: 5536078167.6712\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7023554236.3774 - val_loss: 5536691066.7397\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7111592341.7358 - val_loss: 5536841447.4521\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7064053893.4889 - val_loss: 5536144264.7671\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6978418947.9520 - val_loss: 5535633912.9863\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6877476009.4957 - val_loss: 5534696868.8219\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7042550848.9880 - val_loss: 5534194565.2603\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6898368540.9811 - val_loss: 5534501849.4247\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7055639835.6638 - val_loss: 5535382289.5342\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7203623318.6141 - val_loss: 5536307929.4247\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7002350375.0806 - val_loss: 5536217175.6712\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6961171385.7427 - val_loss: 5536089119.5616\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6986404367.8079 - val_loss: 5537457348.3836\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6995938420.3636 - val_loss: 5537229382.1370\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7194875813.5437 - val_loss: 5538224106.9589\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7004101158.6415 - val_loss: 5537582998.7945\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6842831523.3482 - val_loss: 5536947799.6712\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6908172839.9588 - val_loss: 5537333675.8356\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7035871288.2058 - val_loss: 5537834892.2740\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7007440647.0257 - val_loss: 5538386421.4795\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7014083346.0034 - val_loss: 5538966261.4795\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7021199043.8422 - val_loss: 5539264743.4521\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7062104806.9708 - val_loss: 5538691282.4110\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7225764498.6621 - val_loss: 5538200786.4110\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7043052434.2230 - val_loss: 5538219523.5068\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7021628974.5455 - val_loss: 5538930253.1507\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7160689010.6072 - val_loss: 5539006485.0411\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7081197408.3842 - val_loss: 5540061303.2329\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6884531928.9194 - val_loss: 5539116866.6301\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6995473764.5557 - val_loss: 5538238663.8904\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7100932726.5592 - val_loss: 5538053351.4521\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7132934017.9760 - val_loss: 5538360053.4795\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6877964767.5060 - val_loss: 5537817971.7260\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7055313152.4391 - val_loss: 5537585748.1644\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 6997642701.9417 - val_loss: 5537760887.2329\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6899933595.8834 - val_loss: 5536903757.1507\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7153725007.0395 - val_loss: 5537521881.4247\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7000389158.6415 - val_loss: 5537686650.7397\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6874684761.1389 - val_loss: 5538708059.1781\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7118192142.4906 - val_loss: 5538988915.7260\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7062312216.5901 - val_loss: 5538454980.3836\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7092962377.7702 - val_loss: 5537400186.7397\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6988882531.2384 - val_loss: 5536144082.4110\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7120772094.2436 - val_loss: 5536868983.2329\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7041809616.1372 - val_loss: 5536781666.1918\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7083975743.2316 - val_loss: 5535877063.8904\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7043560898.0858 - val_loss: 5536362250.5205\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6985629633.6467 - val_loss: 5537373629.3699\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6885932576.4940 - val_loss: 5536452096.0000\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7216639264.0549 - val_loss: 5536625130.9589\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7012246116.9949 - val_loss: 5536221169.9726\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6847096567.6569 - val_loss: 5535863099.6164\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6985395152.1372 - val_loss: 5536543049.6438\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7052987353.3585 - val_loss: 5536678378.9589\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7037479155.2659 - val_loss: 5536612274.8493\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7168944890.2916 - val_loss: 5536495377.5342\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6899951268.2264 - val_loss: 5535857965.5890\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6908194473.4957 - val_loss: 5535369279.1233\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7087966611.5403 - val_loss: 5535655999.1233\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7032731153.5643 - val_loss: 5535857474.6301\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6876897821.8593 - val_loss: 5535718652.4932\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7112694632.9468 - val_loss: 5536097869.1507\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7003410087.7393 - val_loss: 5536342861.1507\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7005043889.3997 - val_loss: 5536288890.7397\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6929754828.4048 - val_loss: 5535465359.7808\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7139003091.6501 - val_loss: 5535352789.9178\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6978399585.0429 - val_loss: 5535203892.6027\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6964076476.3774 - val_loss: 5535235415.6712\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7018624837.8182 - val_loss: 5535380483.5068\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7175977359.5883 - val_loss: 5535421425.9726\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6970435907.1835 - val_loss: 5536476461.5890\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7080244638.5180 - val_loss: 5536005228.7123\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7075179483.5540 - val_loss: 5535459370.0822\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7010333294.6552 - val_loss: 5535379007.1233\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7073107138.9640 - val_loss: 5534532734.2466\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7054808414.4082 - val_loss: 5535656679.4521\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7081051495.1904 - val_loss: 5535828522.0822\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7108482040.9743 - val_loss: 5536330422.3562\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7142357754.2916 - val_loss: 5537577493.0411\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6830942074.5111 - val_loss: 5536465590.3562\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7054769973.1321 - val_loss: 5536814942.6849\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6980669931.8010 - val_loss: 5535429144.5479\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6997996801.3173 - val_loss: 5535619303.4521\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7081131064.2058 - val_loss: 5535431409.9726\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7024701106.2779 - val_loss: 5534484655.3425\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 260us/step - loss: 6935481851.1698 - val_loss: 5534777575.4521\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 6975044067.0189 - val_loss: 5534921433.4247\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 281us/step - loss: 6888530287.0943 - val_loss: 5534720462.9041\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 7012960713.5506 - val_loss: 5534283074.6301\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 6837377485.0635 - val_loss: 5534002365.3699\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 7021285857.2624 - val_loss: 5534111782.5753\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 7082380108.4048 - val_loss: 5534467811.9452\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 6956114321.3448 - val_loss: 5534110323.7260\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7011019884.0206 - val_loss: 5534743860.6027\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 6958673651.2659 - val_loss: 5535631812.3836\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 6741848936.9468 - val_loss: 5535201746.4110\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 6869044728.0961 - val_loss: 5534533137.5342\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 7092342557.4202 - val_loss: 5534925676.7123\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7120437092.9949 - val_loss: 5535903021.5890\n",
      "Epoch 938/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 194us/step - loss: 7169119124.8576 - val_loss: 5535608116.6027\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6866013541.4340 - val_loss: 5535455575.6712\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 6733003703.1081 - val_loss: 5535014677.0411\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6848810662.8611 - val_loss: 5534307531.3973\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 6986345028.9400 - val_loss: 5534621047.2329\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 6872314693.3791 - val_loss: 5534322866.8493\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7006152286.8473 - val_loss: 5534944796.0548\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7190131285.1870 - val_loss: 5535850587.1781\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 6966110102.6141 - val_loss: 5536163145.6438\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6896964115.3208 - val_loss: 5536275680.4384\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 6854194507.5266 - val_loss: 5537277636.3836\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7070939492.5557 - val_loss: 5537736718.0274\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7013860669.9142 - val_loss: 5537600035.0685\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6928417849.7427 - val_loss: 5537239583.5616\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7065361026.8542 - val_loss: 5536611299.9452\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6945519348.1441 - val_loss: 5537525363.7260\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7034179471.5883 - val_loss: 5537404289.7534\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7070688472.0412 - val_loss: 5537783829.0411\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7081264932.4460 - val_loss: 5536854857.6438\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7131011064.0961 - val_loss: 5536420032.8767\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7019534938.4563 - val_loss: 5537333809.0959\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6999320393.3310 - val_loss: 5537012658.8493\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7112889619.7599 - val_loss: 5537952322.6301\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6953332453.2144 - val_loss: 5536847893.0411\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7102615339.4717 - val_loss: 5537030263.2329\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7088589688.7547 - val_loss: 5536398044.9315\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6881405198.9297 - val_loss: 5536064185.8630\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6990879567.0395 - val_loss: 5538150361.4247\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6931803071.4511 - val_loss: 5536988152.9863\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7139085454.2710 - val_loss: 5536456949.4795\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7145201302.1750 - val_loss: 5536686269.3699\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6926911436.6244 - val_loss: 5536533945.8630\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7120494952.9468 - val_loss: 5535546880.0000\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6933830927.3688 - val_loss: 5535651103.5616\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6936019945.1664 - val_loss: 5534890408.3288\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 6787173535.8353 - val_loss: 5533620974.4658\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6960472162.3602 - val_loss: 5534650143.5616\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7182007879.5746 - val_loss: 5534803747.0685\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 7257778207.6158 - val_loss: 5535873083.6164\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6833843652.2813 - val_loss: 5536284756.1644\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7310581942.2298 - val_loss: 5537931895.2329\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6982896784.0274 - val_loss: 5537427210.5205\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7072588092.1578 - val_loss: 5536654241.3151\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7107512023.1630 - val_loss: 5537067716.3836\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6922964566.9434 - val_loss: 5537391640.5479\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7134186332.6518 - val_loss: 5537970561.7534\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6948197960.8919 - val_loss: 5536423939.5068\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6954576012.0755 - val_loss: 5536022040.5479\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7116394188.6244 - val_loss: 5536560415.5616\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7113952712.6724 - val_loss: 5536833311.5616\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6978687324.6518 - val_loss: 5536169370.3014\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6871119086.8748 - val_loss: 5536630005.4795\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6904338587.4443 - val_loss: 5536807711.5616\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6815157549.2281 - val_loss: 5535938167.2329\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7137975297.7564 - val_loss: 5535794046.2466\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6833614285.9417 - val_loss: 5535032488.3288\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7150112561.6192 - val_loss: 5536124693.0411\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6969769793.8662 - val_loss: 5535811426.1918\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6836389573.5986 - val_loss: 5535676714.0822\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7074439830.1750 - val_loss: 5535418844.9315\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7010250963.6501 - val_loss: 5535447401.2055\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7147337190.5317 - val_loss: 5535546094.4658\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6956887375.4786 - val_loss: 5535751455.5616\n",
      "neurons used (64, 32)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 542us/step - loss: 39208886728.6724 - val_loss: 38415873486.9041\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 154us/step - loss: 39203300894.7376 - val_loss: 38407250340.8219\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 39194512280.3705 - val_loss: 38396301676.7123\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 39182320553.9348 - val_loss: 38382238874.3014\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 39166838306.2504 - val_loss: 38368339939.9452\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 39148111879.0257 - val_loss: 38343886006.3562\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39126770816.2196 - val_loss: 38320538890.5205\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 39102013489.1801 - val_loss: 38296103416.9863\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39074274045.8045 - val_loss: 38269572166.1370\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39041413520.4666 - val_loss: 38251975890.4110\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39008962092.7890 - val_loss: 38206864454.1370\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 38972650715.5540 - val_loss: 38168611068.4931\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 38931626584.6998 - val_loss: 38128253124.3836\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38888898124.4048 - val_loss: 38080263602.8493\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38835432010.6484 - val_loss: 38022831118.0274\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 38796143185.6741 - val_loss: 37974016589.1507\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38743221158.4220 - val_loss: 37915055370.5205\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38687156599.8765 - val_loss: 37848457945.4247\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 38626589258.6484 - val_loss: 37789007058.4110\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38567494826.3739 - val_loss: 37726170238.2466\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38500550037.7359 - val_loss: 37669570560.0000\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38425488793.2487 - val_loss: 37611570246.1370\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 38353226441.1115 - val_loss: 37536594761.6438\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38291953541.0497 - val_loss: 37457953581.5890\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38215220454.0926 - val_loss: 37373322450.4110\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38130653436.9262 - val_loss: 37290541420.7123\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38048895228.9262 - val_loss: 37209649909.4795\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37966276407.7667 - val_loss: 37127804703.5616\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 37885750396.7067 - val_loss: 37027830461.3699\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37794862685.9691 - val_loss: 36938695722.0822\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 37698921038.1612 - val_loss: 36857507138.6301\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 37602422590.7924 - val_loss: 36749611737.4247\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 37503709436.9262 - val_loss: 36634580683.3973\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37391637421.4477 - val_loss: 36533750405.2603\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 37291719017.8250 - val_loss: 36424984660.1644\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 37179863549.3654 - val_loss: 36325343344.2192\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 37101805118.3533 - val_loss: 36201664483.9452\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 36921834286.9846 - val_loss: 36106663851.8356\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 36850450410.9228 - val_loss: 35996223964.9315\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 36748533594.8954 - val_loss: 35863982641.0959\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 36598376957.3654 - val_loss: 35741909160.3288\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 36487376474.4563 - val_loss: 35613398843.6164\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 36356293387.8559 - val_loss: 35477949089.3151\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 36238139855.6981 - val_loss: 35342643340.2740\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 36125072803.7873 - val_loss: 35205197290.9589\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 35994024557.7770 - val_loss: 35080723918.9041\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 35828548792.4254 - val_loss: 34940452415.1233\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 35707859140.7204 - val_loss: 34796814644.6027\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 35528827498.2641 - val_loss: 34660454231.6712\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 35403144429.1184 - val_loss: 34499963861.9178\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 35210728808.0686 - val_loss: 34365314174.2466\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 35143840495.7530 - val_loss: 34231467639.2329\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 34983077441.8662 - val_loss: 34079598563.9452\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 34842828339.8148 - val_loss: 33915550285.1507\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 34660977015.8765 - val_loss: 33759626506.5205\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 34454888690.3876 - val_loss: 33600163250.8493\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 34322926477.8319 - val_loss: 33433315075.5069\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 34139443916.6244 - val_loss: 33267093672.3288\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 34033268813.2830 - val_loss: 33101492897.3151\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 33887713213.2556 - val_loss: 32942879393.3151\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 33642015563.0875 - val_loss: 32779792832.8767\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 34552699904.000 - 0s 146us/step - loss: 33474501637.2693 - val_loss: 32619841059.0685\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 33312460905.3859 - val_loss: 32443182991.7808\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 33156957122.5249 - val_loss: 32261261901.1507\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 32919094551.2727 - val_loss: 32060947021.1507\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 169us/step - loss: 32806729924.7204 - val_loss: 31884267688.3288\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 32567603948.2401 - val_loss: 31689918744.5479\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 32499637644.9537 - val_loss: 31517132828.0548\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 32258436557.9417 - val_loss: 31301234856.3288\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 32090701342.7376 - val_loss: 31111629304.9863\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 31822672307.5952 - val_loss: 30920696200.7671\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 31624066376.4528 - val_loss: 30747782354.4110\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 31493958492.6518 - val_loss: 30541332199.4521\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 31323350534.1475 - val_loss: 30333426337.3151\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 31134995278.6003 - val_loss: 30158211156.1644\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 30861011488.4940 - val_loss: 29929100133.6986\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 30698138450.1132 - val_loss: 29737314556.4931\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 30498128532.4185 - val_loss: 29517044581.6986\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 30307375146.1544 - val_loss: 29313980640.4384\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 30134338906.0172 - val_loss: 29117501832.7671\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 29857781173.3516 - val_loss: 28904903778.1918\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 29706513799.6844 - val_loss: 28707195216.6575\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 29441857377.9211 - val_loss: 28515657587.7260\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 29282763552.9331 - val_loss: 28293202649.4247\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 29096411936.9331 - val_loss: 28066562384.6575\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 28859440911.3688 - val_loss: 27864283472.6575\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 28716799283.3756 - val_loss: 27635310872.5479\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 28364370085.1046 - val_loss: 27436131313.9726\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 28196783453.5300 - val_loss: 27192611741.8082\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 27986159925.1321 - val_loss: 26940069130.5205\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 27775482435.6226 - val_loss: 26721744755.7260\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 27392546703.5883 - val_loss: 26510573960.7671\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 27401074756.5009 - val_loss: 26261504392.7671\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 27051207994.4014 - val_loss: 26067441439.5616\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26778639150.9846 - val_loss: 25806360239.3425\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 26514827650.4151 - val_loss: 25601973514.5205\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 26359415342.5455 - val_loss: 25342212208.2192\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 26212823672.3156 - val_loss: 25142267791.7808\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 25913870451.9245 - val_loss: 24928461613.5890\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25787816541.9691 - val_loss: 24681959367.8904\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 25403874892.4048 - val_loss: 24435962697.6438\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 25180646890.0446 - val_loss: 24190135310.0274\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 24891040421.9828 - val_loss: 23965990855.8904\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 24636309057.8662 - val_loss: 23740110118.5753\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 24619330593.3722 - val_loss: 23492981886.2466\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 24345416175.3139 - val_loss: 23255017079.2329\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 23960541194.5386 - val_loss: 23009790008.1096\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 23921952704.7684 - val_loss: 22748546595.0685\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 23623460477.5849 - val_loss: 22525939010.6301\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 23401671579.8834 - val_loss: 22299146099.7260\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 23144162223.2041 - val_loss: 22076077589.0411\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 22912154323.6501 - val_loss: 21836464759.2329\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 22607359058.5523 - val_loss: 21592877771.3973\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 22399406680.6998 - val_loss: 21339763712.0000\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 22161156666.8405 - val_loss: 21101184701.3699\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 21933973742.8748 - val_loss: 20850330525.8082\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 21640332128.1647 - val_loss: 20598582959.3425\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 21406070437.9828 - val_loss: 20375848581.2603\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 21210399731.7050 - val_loss: 20092575407.3425\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 20993284020.4734 - val_loss: 19880517253.2603\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 20699304891.4991 - val_loss: 19656957643.3973\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 20510162294.1201 - val_loss: 19425378907.1781\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 20447900819.5403 - val_loss: 19169592291.9452\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 20102888676.3362 - val_loss: 18954838212.3836\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 19747506998.0103 - val_loss: 18741967535.3425\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 19510261341.9691 - val_loss: 18499944644.3836\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 19437288268.8439 - val_loss: 18290642761.6438\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 19057135178.6484 - val_loss: 18012197481.2055\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 19003047656.7273 - val_loss: 17772243028.1644\n",
      "Epoch 130/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 150us/step - loss: 18598817721.7427 - val_loss: 17534465304.5479\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 18408117077.6261 - val_loss: 17291058610.8493\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 18064081018.9503 - val_loss: 17041815860.6027\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 17917447022.2161 - val_loss: 16836904202.5205\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 17780877975.9314 - val_loss: 16585290317.1507\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 17483610356.1441 - val_loss: 16329156832.4384\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 17307472195.1835 - val_loss: 16106294257.9726\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 17020547827.2659 - val_loss: 15895192393.6438\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 16834944066.7444 - val_loss: 15654036746.5205\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 16521137473.4271 - val_loss: 15423663146.0822\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 16390067619.7873 - val_loss: 15164567229.3699\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 16112965145.4683 - val_loss: 14943695100.4932\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 15934317397.6261 - val_loss: 14709857195.8356\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 15540809011.3756 - val_loss: 14489139887.3425\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 15416258609.1801 - val_loss: 14269495829.0411\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 15375852460.5695 - val_loss: 14049762135.6712\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 15027467592.4528 - val_loss: 13826515266.6301\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 14675967731.2659 - val_loss: 13633547881.2055\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 14677130837.1870 - val_loss: 13396172561.5342\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 14275991025.0703 - val_loss: 13164604864.8767\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 14289164830.7376 - val_loss: 12961153599.1233\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 14090062066.3877 - val_loss: 12742484494.0274\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 13740998596.2813 - val_loss: 12531496924.9315\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 13614187909.9280 - val_loss: 12344315840.8767\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 13375956349.1458 - val_loss: 12139036349.3699\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 13656097092.9400 - val_loss: 11923217471.1233\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 13189456302.3259 - val_loss: 11728210824.7671\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12913258358.9983 - val_loss: 11538323371.8356\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 12757238430.9571 - val_loss: 11328116518.5753\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12632211115.2521 - val_loss: 11142796743.8904\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 12340626314.3190 - val_loss: 10948801991.8904\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 12181637278.0789 - val_loss: 10777663677.3699\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11929355166.0789 - val_loss: 10577553099.3973\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 11913918922.4288 - val_loss: 10390927703.6712\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 11621963724.6244 - val_loss: 10215426405.6986\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 11518867336.5626 - val_loss: 10042573319.0137\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11417509796.6655 - val_loss: 9883616410.3014\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11014362542.3259 - val_loss: 9703549573.2603\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 11157965885.4751 - val_loss: 9527391386.3014\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10583304517.8182 - val_loss: 9363697060.8219\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10755566251.6913 - val_loss: 9207266830.0274\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10428142564.3362 - val_loss: 9040241369.4247\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10561824128.6587 - val_loss: 8901143376.6575\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10309102094.0515 - val_loss: 8748546118.1370\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9899692570.7856 - val_loss: 8590625322.0822\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10096318860.0755 - val_loss: 8450729864.7671\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9536808656.1372 - val_loss: 8300686314.9589\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9755673809.0154 - val_loss: 8162437456.6575\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9676190204.0480 - val_loss: 8022165160.3288\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9409035954.2779 - val_loss: 7887449438.6849\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9170663676.0480 - val_loss: 7758063440.6575\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9192329709.5575 - val_loss: 7633535740.4932\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9241315061.0223 - val_loss: 7515974066.8493\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9097239906.7993 - val_loss: 7389648657.5342\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 8985201729.8662 - val_loss: 7278898705.5342\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 8689006602.5386 - val_loss: 7173130303.1233\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8849345698.0309 - val_loss: 7070016848.6575\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8627576840.7822 - val_loss: 6975928961.7534\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8453972742.5866 - val_loss: 6880385725.3699\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8338701751.9863 - val_loss: 6784998214.1370\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 8338877635.4031 - val_loss: 6705188443.1781\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8319047711.6158 - val_loss: 6619466597.6986\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 8362699838.3533 - val_loss: 6537569609.6438\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8041421331.3208 - val_loss: 6458531208.7671\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 139us/step - loss: 8205468259.2384 - val_loss: 6393251762.8493\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 8127129942.2847 - val_loss: 6326272701.3699\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 8011554983.7393 - val_loss: 6265834327.6712\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7873638408.7822 - val_loss: 6207766310.5753\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7917671518.4082 - val_loss: 6143165411.9452\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7888270699.5815 - val_loss: 6088732152.9863\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7986296477.2007 - val_loss: 6041440652.2740\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7861842949.2693 - val_loss: 6000767561.6438\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7527110521.6329 - val_loss: 5960628073.2055\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7909368142.76 - 0s 145us/step - loss: 7735021863.0806 - val_loss: 5925914918.5753\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7563128717.8319 - val_loss: 5889411647.1233\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7900688738.7993 - val_loss: 5855099784.7671\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7330244450.7993 - val_loss: 5826472770.6301\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7703094060.3499 - val_loss: 5799233928.7671\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7367179201.6467 - val_loss: 5771857250.1918\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7637734854.9160 - val_loss: 5744179901.3699\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 8035875982.2710 - val_loss: 5723257582.4658\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7469948000.6038 - val_loss: 5707730221.5890\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7522170938.8405 - val_loss: 5697157646.0274\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7533187699.0463 - val_loss: 5681107968.0000\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7355782188.7890 - val_loss: 5668456440.9863\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7456326528.6587 - val_loss: 5664416178.8493\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7559102747.6638 - val_loss: 5654731677.8082\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7427878287.5883 - val_loss: 5643172092.4932\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7541325369.0840 - val_loss: 5636768385.7534\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7727207863.1081 - val_loss: 5631066943.1233\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7289729645.7770 - val_loss: 5619884298.5205\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7366679492.2813 - val_loss: 5613006399.1233\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7825646488.1509 - val_loss: 5609739313.0959\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7581789995.4717 - val_loss: 5606550640.2192\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7848414294.0652 - val_loss: 5602738705.5342\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7553934574.8748 - val_loss: 5601937141.4795\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7559622027.1973 - val_loss: 5598508547.5068\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7638820386.6895 - val_loss: 5595233630.6849\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7192923439.8628 - val_loss: 5588880853.9178\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7163475061.6810 - val_loss: 5587918293.9178\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7461613461.5163 - val_loss: 5585121195.8356\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7433143278.4357 - val_loss: 5588710312.3288\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7623361702.8611 - val_loss: 5582976624.2192\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7523838101.2967 - val_loss: 5582043171.0685\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7676668098.0858 - val_loss: 5578889713.9726\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7348792654.1612 - val_loss: 5577596910.4658\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7399120942.3259 - val_loss: 5577451064.1096\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7593322531.1286 - val_loss: 5572468774.5753\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7530746869.4614 - val_loss: 5572545665.7534\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7582300389.2144 - val_loss: 5568659908.3836\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7664369363.6501 - val_loss: 5568578602.0822\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7787296594.9914 - val_loss: 5570084541.3699\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7399667756.3499 - val_loss: 5570153998.0274\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7635616655.5883 - val_loss: 5569252243.2877\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7641592712.5626 - val_loss: 5570205937.9726\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7517194454.2847 - val_loss: 5567103954.4110\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7759689908.0343 - val_loss: 5567139328.0000\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7629328155.6638 - val_loss: 5565774721.7534\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7472990217.6604 - val_loss: 5565927248.6575\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7644414172.4322 - val_loss: 5567569415.0137\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7247597053.3654 - val_loss: 5565892965.6986\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7721627787.6364 - val_loss: 5565795917.1507\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7645796509.6398 - val_loss: 5568012435.2877\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7696480835.6226 - val_loss: 5570264176.2192\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7659017665.6467 - val_loss: 5572439650.1918\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7577577387.6913 - val_loss: 5572273835.8356\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7757901516.6244 - val_loss: 5572302791.8904\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7661915927.2727 - val_loss: 5573320451.5068\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7347947036.9811 - val_loss: 5571143872.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7561064822.9983 - val_loss: 5569749419.8356\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7412971054.5455 - val_loss: 5567807326.6849\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7728986347.3619 - val_loss: 5568308697.4247\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7388722513.2350 - val_loss: 5568466018.1918\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7683515483.3345 - val_loss: 5569948002.1918\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7247843989.2967 - val_loss: 5567923389.3699\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7550073007.2041 - val_loss: 5567935018.0822\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7724515929.5780 - val_loss: 5566961222.1370\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7697377139.4854 - val_loss: 5566058061.1507\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7420497307.8834 - val_loss: 5565284239.7808\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7361521799.6844 - val_loss: 5562815466.9589\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7573275000.7547 - val_loss: 5563773773.1507\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7560331662.7101 - val_loss: 5564108873.6438\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7133247077.4340 - val_loss: 5562624490.9589\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7388128316.5969 - val_loss: 5561917576.7671\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7191454718.2436 - val_loss: 5559580791.2329\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7499608887.7667 - val_loss: 5559369230.0274\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7507541411.7873 - val_loss: 5559780159.1233\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7446892024.9743 - val_loss: 5559564266.9589\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7531933039.0943 - val_loss: 5559604879.7808\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7205513909.7907 - val_loss: 5557186949.2603\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7721747263.2316 - val_loss: 5559192547.9452\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7358237142.7238 - val_loss: 5558648351.5616\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7560800145.3448 - val_loss: 5558311438.0274\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7244664733.6398 - val_loss: 5560460063.5616\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7658591844.9949 - val_loss: 5559133720.5479\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7289141948.8165 - val_loss: 5560992185.8630\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7724823068.9811 - val_loss: 5562875819.8356\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7569726474.5386 - val_loss: 5563075415.6712\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7174042415.8628 - val_loss: 5561107456.0000\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7420595970.1955 - val_loss: 5559336910.9041\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7435127388.2127 - val_loss: 5559461845.9178\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7632262364.4322 - val_loss: 5560392192.0000\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7540932473.6329 - val_loss: 5560274481.0959\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7413588669.6947 - val_loss: 5560174283.3973\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7461438689.7015 - val_loss: 5560445461.0411\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7410264634.8405 - val_loss: 5559356345.8630\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7478573843.7599 - val_loss: 5558653145.4247\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7446900424.2333 - val_loss: 5561600932.8219\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7590231057.5643 - val_loss: 5562330525.8082\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7625952514.6346 - val_loss: 5563297918.2466\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7512283570.2779 - val_loss: 5563089702.5753\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7217425350.9160 - val_loss: 5563333267.2877\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7123955993.0292 - val_loss: 5564652999.8904\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7405713804.0755 - val_loss: 5563969031.0137\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7619644048.9057 - val_loss: 5563904455.8904\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7675424006.5866 - val_loss: 5563660586.0822\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7284816871.8491 - val_loss: 5562430337.7534\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7629305186.7993 - val_loss: 5562984097.3151\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7653048380.5969 - val_loss: 5563286471.8904\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7523933486.1063 - val_loss: 5564848618.9589\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7176033254.5317 - val_loss: 5564497120.4384\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7427685607.8491 - val_loss: 5564730943.1233\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7581577323.1424 - val_loss: 5566076500.1644\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7609691968.5489 - val_loss: 5568843916.2740\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7694825502.2985 - val_loss: 5569971080.7671\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7554058530.6895 - val_loss: 5570952714.5205\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7333840780.9537 - val_loss: 5571029349.6986\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7630230206.5729 - val_loss: 5569014307.0685\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7594105026.9640 - val_loss: 5570493415.4521\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7272844341.5712 - val_loss: 5567609052.9315\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7315270648.9743 - val_loss: 5566026201.4247\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7326617359.3688 - val_loss: 5563996167.0137\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7573598938.6758 - val_loss: 5564863817.6438\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7657877853.5300 - val_loss: 5562536661.9178\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 143us/step - loss: 7383164854.2298 - val_loss: 5563369885.8082\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7631359485.3654 - val_loss: 5563324580.8219\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7488767072.6038 - val_loss: 5563327726.4658\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7506628002.4700 - val_loss: 5563033368.5479\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7380520926.6278 - val_loss: 5562262079.1233\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7972665229.8319 - val_loss: 5562578291.7260\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7619177855.7804 - val_loss: 5563191169.7534\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7538558503.5197 - val_loss: 5563233609.6438\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7408253892.2813 - val_loss: 5565177505.3151\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7486964272.3019 - val_loss: 5567086556.9315\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7243126791.0257 - val_loss: 5565463762.4110\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7365279557.8182 - val_loss: 5566025321.2055\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7660594082.9091 - val_loss: 5565326904.1096\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7450620937.6604 - val_loss: 5564302027.3973\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7664944278.1750 - val_loss: 5564930318.0274\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7329203798.9434 - val_loss: 5563716600.9863\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7391539671.6021 - val_loss: 5563642690.6301\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7476066623.6707 - val_loss: 5564985834.9589\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7522975596.8988 - val_loss: 5564687458.1918\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7569293537.7015 - val_loss: 5564239321.4247\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7330515676.4322 - val_loss: 5561089739.3973\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7453552468.7479 - val_loss: 5562242118.1370\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7764725462.0652 - val_loss: 5563022890.0822\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7593114327.1630 - val_loss: 5562737720.1096\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7516796196.4460 - val_loss: 5563184194.6301\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7491757558.3396 - val_loss: 5561280813.5890\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7461991027.0463 - val_loss: 5561629261.1507\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7496389650.4425 - val_loss: 5560493718.7945\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7438281832.9468 - val_loss: 5561056459.3973\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7350721515.8010 - val_loss: 5562322751.1233\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7671687491.4031 - val_loss: 5563177689.4247\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7564733508.5009 - val_loss: 5560444170.5205\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7798414995.5403 - val_loss: 5561198101.0411\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7636611193.1938 - val_loss: 5561646062.4658\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 7421288846.7101 - val_loss: 5561488910.0274\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 252us/step - loss: 7390282299.7187 - val_loss: 5560581807.3425\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 7241277735.5197 - val_loss: 5561199342.4658\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 271us/step - loss: 7383045004.9537 - val_loss: 5562125582.0274\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 7636850217.2762 - val_loss: 5564245721.4247\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 7419809362.1132 - val_loss: 5565066296.1096\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 7389627732.7479 - val_loss: 5565327458.1918\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7401347834.2916 - val_loss: 5565070104.5479\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7369479457.8113 - val_loss: 5565958165.0411\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7542732847.4237 - val_loss: 5565891808.4384\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7582793068.8988 - val_loss: 5565846980.3836\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7309575737.9623 - val_loss: 5564779197.3699\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7424343858.4974 - val_loss: 5566242016.4384\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7350868954.2367 - val_loss: 5564390743.6712\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7641839477.2419 - val_loss: 5564045873.0959\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7449644102.2573 - val_loss: 5563461968.6575\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7607392313.9623 - val_loss: 5563401019.6164\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7736511606.1201 - val_loss: 5564028801.7534\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7609489153.3173 - val_loss: 5563913230.0274\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 7850693606.5317 - val_loss: 5563774435.9452\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7756478151.3551 - val_loss: 5562847119.7808\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7490404121.9074 - val_loss: 5564865781.4795\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7435738667.0326 - val_loss: 5562705243.1781\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7487361070.5455 - val_loss: 5562060596.6027\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7715163420.5420 - val_loss: 5559946513.5342\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7625582810.6758 - val_loss: 5561649976.1096\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7517457021.5849 - val_loss: 5563543296.0000\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7681006232.3705 - val_loss: 5564735712.4384\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7436802245.5986 - val_loss: 5564746555.6164\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7419879208.8370 - val_loss: 5563899518.2466\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7624388925.0360 - val_loss: 5564866966.7945\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 174us/step - loss: 7682156125.9691 - val_loss: 5564815507.2877\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7676154391.7118 - val_loss: 5563942957.5890\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7452767493.2693 - val_loss: 5564071441.5342\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7691130339.8971 - val_loss: 5564528268.2740\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7584738915.6775 - val_loss: 5565828962.1918\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7354786126.6003 - val_loss: 5565530518.7945\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7509762960.4666 - val_loss: 5564032497.9726\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7584836575.5060 - val_loss: 5562728952.9863\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7687591741.0360 - val_loss: 5563430336.8767\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7397238998.2847 - val_loss: 5565782864.6575\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7468445230.5455 - val_loss: 5565808973.1507\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7532806990.6003 - val_loss: 5563808501.4795\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7599316693.4065 - val_loss: 5564075421.8082\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7504037237.2419 - val_loss: 5564908494.9041\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7315877004.5146 - val_loss: 5562587030.7945\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7399379968.0000 - val_loss: 5563750554.3014\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7434162947.9520 - val_loss: 5564130304.0000\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7342410439.3551 - val_loss: 5563874668.7123\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7284960298.1544 - val_loss: 5563712575.1233\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7514301415.4099 - val_loss: 5564279653.6986\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7518460304.4666 - val_loss: 5564046672.6575\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7423614182.9708 - val_loss: 5565218069.0411\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7307206972.1578 - val_loss: 5565153630.6849\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7665643562.1544 - val_loss: 5565625708.7123\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7781972272.7410 - val_loss: 5565307399.0137\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7490307686.7513 - val_loss: 5564516022.3562\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7525424119.2178 - val_loss: 5564249501.8082\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7519833928.8919 - val_loss: 5565808647.0137\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7363743224.0961 - val_loss: 5563584361.2055\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7300674888.4528 - val_loss: 5563862920.7671\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7604209052.7616 - val_loss: 5564653988.8219\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7512408165.8731 - val_loss: 5564423048.7671\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7530286750.0789 - val_loss: 5562362525.8082\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7643208738.2504 - val_loss: 5562197805.5890\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7447131820.1304 - val_loss: 5562288212.1644\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7446626550.7787 - val_loss: 5561067292.0548\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7596690290.6072 - val_loss: 5561801552.6575\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7544539787.6364 - val_loss: 5562437646.0274\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7524550585.7427 - val_loss: 5561374004.6027\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7622533065.5506 - val_loss: 5559185941.0411\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7329246650.6209 - val_loss: 5558579908.3836\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7491839766.3945 - val_loss: 5558487495.8904\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7472151075.1286 - val_loss: 5558139570.8493\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7315479360.5489 - val_loss: 5558428826.3014\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7508732525.7770 - val_loss: 5557747024.6575\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7540455153.9485 - val_loss: 5559039992.9863\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7493615212.0206 - val_loss: 5558900465.9726\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7485709330.4425 - val_loss: 5558688508.4932\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7602747896.9743 - val_loss: 5559656721.5342\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7511481225.4408 - val_loss: 5559812432.6575\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7319377091.4031 - val_loss: 5559684201.2055\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7439251663.6981 - val_loss: 5557460066.1918\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7548041061.4340 - val_loss: 5558960359.4521\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7145052289.0978 - val_loss: 5557940897.3151\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7496699842.9640 - val_loss: 5558200930.1918\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7423204639.1767 - val_loss: 5557336235.8356\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7573202235.2796 - val_loss: 5558041291.3973\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7342622944.8233 - val_loss: 5558028333.5890\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7596606602.7581 - val_loss: 5558156161.7534\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7776618590.8473 - val_loss: 5560065809.5342\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7611407790.3259 - val_loss: 5558491683.0685\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7185351966.2985 - val_loss: 5559147891.7260\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7531775804.8165 - val_loss: 5559083509.4795\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7652591696.7959 - val_loss: 5559749989.6986\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7481229371.7187 - val_loss: 5559528830.2466\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 7340991497.6604 - val_loss: 5559159429.2603\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7691499757.9966 - val_loss: 5559527122.4110\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7762600652.6244 - val_loss: 5561159746.6301\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7467042665.3859 - val_loss: 5562306763.3973\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7530812215.7667 - val_loss: 5562344419.9452\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7203519103.3413 - val_loss: 5561471600.2192\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7484746850.7993 - val_loss: 5560219009.7534\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7415124535.3276 - val_loss: 5560816562.8493\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7640307853.8319 - val_loss: 5561528614.5753\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7292062867.5403 - val_loss: 5561752078.0274\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7574014268.1578 - val_loss: 5562271975.4521\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7611895623.5746 - val_loss: 5563425676.2740\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7476149338.0172 - val_loss: 5563439987.7260\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7436760586.5386 - val_loss: 5562898130.4110\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7575793590.2298 - val_loss: 5561563143.0137\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7470441435.1149 - val_loss: 5561349232.2192\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7814086647.2178 - val_loss: 5560504954.7397\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7420667391.5609 - val_loss: 5559871775.5616\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7955675913.2213 - val_loss: 5562004122.3014\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7398460727.7667 - val_loss: 5560894109.8082\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7534756684.8439 - val_loss: 5560813834.5205\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7173330397.7496 - val_loss: 5558579494.5753\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7607006588.2676 - val_loss: 5558932774.5753\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7437346845.8593 - val_loss: 5557761686.7945\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7283508281.9623 - val_loss: 5557733930.0822\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7836321379.2384 - val_loss: 5559066336.4384\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7731481892.4460 - val_loss: 5559629820.4932\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7669463816.3431 - val_loss: 5560431363.5068\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7296994986.3739 - val_loss: 5561458926.4658\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7553534229.5163 - val_loss: 5561647496.7671\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7447512411.3345 - val_loss: 5561787963.6164\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7321812765.4202 - val_loss: 5562340723.7260\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7512757385.8799 - val_loss: 5563792636.4932\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7636644907.0326 - val_loss: 5564506360.9863\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7563633259.1424 - val_loss: 5565110587.6164\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7498384384.0000 - val_loss: 5566166268.4932\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7703165198.4906 - val_loss: 5566592736.4384\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7565995791.3688 - val_loss: 5568386735.3425\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7534248246.4494 - val_loss: 5566981295.3425\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7250531355.2247 - val_loss: 5565286862.9041\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7351260417.3173 - val_loss: 5567327161.8630\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7629184858.0172 - val_loss: 5566189781.9178\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7318791777.4820 - val_loss: 5565883335.8904\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7587954277.8731 - val_loss: 5565705889.3151\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7228223546.8405 - val_loss: 5565696967.8904\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7642791875.4031 - val_loss: 5564581235.7260\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7460406477.5026 - val_loss: 5565794128.6575\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7347811041.7015 - val_loss: 5565390350.0274\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7606858197.4065 - val_loss: 5565043529.6438\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7384079814.9160 - val_loss: 5565118092.2740\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7413114530.4700 - val_loss: 5565076395.8356\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7504794890.9777 - val_loss: 5563658604.7123\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 136us/step - loss: 7590596845.9966 - val_loss: 5563209812.1644\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7511742221.6123 - val_loss: 5564160455.8904\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7450627086.9297 - val_loss: 5563634772.1644\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7268754459.2247 - val_loss: 5561347114.0822\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7472081544.1235 - val_loss: 5561712534.7945\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7407200390.3671 - val_loss: 5559913107.2877\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7678613831.5746 - val_loss: 5559829454.9041\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 6923721993.84 - 0s 141us/step - loss: 7342581742.4357 - val_loss: 5559018134.7945\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7200927353.1938 - val_loss: 5558615741.3699\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7715220684.6244 - val_loss: 5559990461.3699\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7589244286.0240 - val_loss: 5560988766.6849\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7536322806.7787 - val_loss: 5563253963.3973\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7489357040.6312 - val_loss: 5561939238.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7677835540.6381 - val_loss: 5562291680.4384\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7364353468.3774 - val_loss: 5561417454.4658\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7718390088.4528 - val_loss: 5561470141.3699\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7520013311.1218 - val_loss: 5562124207.3425\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7668264585.8799 - val_loss: 5562940973.5890\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7575162760.5626 - val_loss: 5563726392.1096\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7493523060.8027 - val_loss: 5564167876.3836\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7682866908.4322 - val_loss: 5565682232.1096\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7817654361.5780 - val_loss: 5566509525.9178\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7888489747.3208 - val_loss: 5567610459.1781\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7286395627.3619 - val_loss: 5566863616.0000\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7512177286.3671 - val_loss: 5566410467.9452\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7354030505.9348 - val_loss: 5568892871.8904\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7539503191.8216 - val_loss: 5567328021.0411\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7571545135.4237 - val_loss: 5568685988.8219\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7830891175.3002 - val_loss: 5569574982.1370\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7651618638.6003 - val_loss: 5568536330.5205\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7376314000.0274 - val_loss: 5568640985.4247\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7266823531.5815 - val_loss: 5568819599.7808\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7602607968.1647 - val_loss: 5567451213.1507\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7779760674.2504 - val_loss: 5566947278.9041\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7631515780.6106 - val_loss: 5566125080.5479\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7816447539.8148 - val_loss: 5565455949.1507\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7441395209.2213 - val_loss: 5565736658.4110\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7534461501.4751 - val_loss: 5566355389.3699\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7472661404.3225 - val_loss: 5566754584.5479\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7550138653.4202 - val_loss: 5568755333.2603\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7712662786.1955 - val_loss: 5568109006.9041\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7416504019.6501 - val_loss: 5568124423.0137\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7521967885.6123 - val_loss: 5569588522.0822\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7271496040.0686 - val_loss: 5568054671.7808\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7598898090.3739 - val_loss: 5566863616.0000\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7523679504.2470 - val_loss: 5566734620.0548\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7673336642.3053 - val_loss: 5565764096.0000\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7425361898.0446 - val_loss: 5566094826.9589\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7780268042.5386 - val_loss: 5567501501.3699\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7534942316.4597 - val_loss: 5566363588.3836\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7380870479.4786 - val_loss: 5565399762.4110\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7799362888.4528 - val_loss: 5564802430.2466\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7569745734.6964 - val_loss: 5564168430.4658\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7524917744.6312 - val_loss: 5565736412.9315\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7420092275.4854 - val_loss: 5565150544.6575\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7412781434.5111 - val_loss: 5563495171.5068\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7620208491.5815 - val_loss: 5563988886.7945\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7458324553.7702 - val_loss: 5564081039.7808\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7344602178.7444 - val_loss: 5563467811.0685\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7371766568.8370 - val_loss: 5564872511.1233\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7633539028.0892 - val_loss: 5564262221.1507\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7529759646.0789 - val_loss: 5564047696.6575\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7371257200.8508 - val_loss: 5563127639.6712\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7467224562.8268 - val_loss: 5562246010.7397\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7500583971.1286 - val_loss: 5562542781.3699\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7651695399.9588 - val_loss: 5564242467.0685\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7772490250.5386 - val_loss: 5565460283.6164\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 7672142535.3551 - val_loss: 5565031501.1507\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 299us/step - loss: 7447620395.4717 - val_loss: 5566175046.1370\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 1s 442us/step - loss: 7686601878.1750 - val_loss: 5566065460.6027\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 1s 601us/step - loss: 7620243465.6604 - val_loss: 5565899537.5342\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 1s 665us/step - loss: 7407423697.0154 - val_loss: 5564536684.7123\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 1s 742us/step - loss: 7582036638.0789 - val_loss: 5565141658.3014\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 1s 797us/step - loss: 7517088034.6895 - val_loss: 5566805223.4521\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 1s 647us/step - loss: 7624251857.8937 - val_loss: 5567189370.7397\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 1s 520us/step - loss: 7831732293.3791 - val_loss: 5567896099.0685\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 1s 457us/step - loss: 7512824801.2624 - val_loss: 5566566119.4521\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 1s 444us/step - loss: 7370537376.7136 - val_loss: 5566235858.4110\n",
      "Epoch 584/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 379us/step - loss: 7440194670.6552 - val_loss: 5566118319.3425\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 344us/step - loss: 7701578766.0515 - val_loss: 5566990939.1781\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 331us/step - loss: 7623948445.2007 - val_loss: 5567871351.2329\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 299us/step - loss: 7177968388.8302 - val_loss: 5567708587.8356\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 312us/step - loss: 7650052731.8285 - val_loss: 5567913612.2740\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 286us/step - loss: 7597386003.7599 - val_loss: 5567304213.0411\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 344us/step - loss: 7605968018.2230 - val_loss: 5567367672.9863\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 305us/step - loss: 7573319041.9760 - val_loss: 5567822160.6575\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 279us/step - loss: 7325419270.5866 - val_loss: 5567145293.1507\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 295us/step - loss: 7457576956.0480 - val_loss: 5568743178.5205\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 7474356065.9211 - val_loss: 5568671011.0685\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 257us/step - loss: 7325830270.4631 - val_loss: 5567671825.5342\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 255us/step - loss: 7303989829.3791 - val_loss: 5566501986.1918\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 241us/step - loss: 7284100998.8062 - val_loss: 5565872899.5068\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 264us/step - loss: 7481743765.2967 - val_loss: 5564412871.8904\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 7643737939.8696 - val_loss: 5564902364.9315\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 255us/step - loss: 7372196695.8216 - val_loss: 5563883548.0548\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 7663070598.8062 - val_loss: 5563078975.1233\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 7410270291.4305 - val_loss: 5561482429.3699\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 7318314283.0326 - val_loss: 5561686710.3562\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 7364206992.4666 - val_loss: 5560978712.5479\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 7282303450.2367 - val_loss: 5560398970.7397\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 7292684836.0069 - val_loss: 5559988118.7945\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 7285235516.5969 - val_loss: 5557971350.7945\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 7519284532.2539 - val_loss: 5557779792.6575\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 7379818337.9211 - val_loss: 5558154590.6849\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 7466178258.7719 - val_loss: 5557762402.1918\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7546079258.3465 - val_loss: 5559282758.1370\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 7501282283.8010 - val_loss: 5559163146.5205\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 7677238217.1115 - val_loss: 5560118629.6986\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7253774159.9177 - val_loss: 5559075026.4110\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7392065328.3019 - val_loss: 5559279644.0548\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7421043337.4408 - val_loss: 5559438606.0274\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7534082544.1921 - val_loss: 5559257459.7260\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 7594265950.4082 - val_loss: 5560074071.6712\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7467836457.2762 - val_loss: 5561096437.4795\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 7697625595.6089 - val_loss: 5561876290.6301\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 7565316335.3139 - val_loss: 5562204664.9863\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7597429851.3345 - val_loss: 5561650498.6301\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7387360275.3208 - val_loss: 5562043034.3014\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 7505376509.3654 - val_loss: 5562662126.4658\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 7400678955.0326 - val_loss: 5563585599.1233\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 7440054279.4648 - val_loss: 5563868735.1233\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7607753552.3568 - val_loss: 5563607001.4247\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7591324728.2058 - val_loss: 5563786106.7397\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 7623576276.5283 - val_loss: 5565464533.9178\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7475708281.6329 - val_loss: 5564783198.6849\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 7497161037.7221 - val_loss: 5562283688.3288\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7890679736.8645 - val_loss: 5563328995.9452\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7561483180.5695 - val_loss: 5565474079.5616\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 7587041153.5369 - val_loss: 5565035060.6027\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7532962085.7633 - val_loss: 5565256563.7260\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7192393501.4202 - val_loss: 5563611549.8082\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7343569849.7427 - val_loss: 5562562275.9452\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7473732274.2779 - val_loss: 5563882555.6164\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7514883697.2899 - val_loss: 5563787677.8082\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7385164735.0120 - val_loss: 5562179910.1370\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7639677796.5557 - val_loss: 5561392766.2466\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 7527931965.4751 - val_loss: 5562056763.6164\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7341795002.6209 - val_loss: 5562140521.2055\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7598865719.7667 - val_loss: 5562441636.8219\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7180948207.7530 - val_loss: 5561860913.0959\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7506412363.0875 - val_loss: 5562291680.4384\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7474124861.4751 - val_loss: 5560896175.3425\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 7612710517.6810 - val_loss: 5561486237.8082\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 187us/step - loss: 7346034749.4751 - val_loss: 5560290700.2740\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7482049715.1561 - val_loss: 5559712564.6027\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7579830525.3654 - val_loss: 5559832698.7397\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7671027544.2607 - val_loss: 5561071777.3151\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7413347289.3585 - val_loss: 5560720692.6027\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7577460943.2590 - val_loss: 5560364130.1918\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7366505311.2864 - val_loss: 5559231943.8904\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7551417669.8182 - val_loss: 5560001146.7397\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7571439457.9211 - val_loss: 5561828888.5479\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7293312926.9571 - val_loss: 5559695626.5205\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7285667779.4031 - val_loss: 5560160789.0411\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7644815256.3705 - val_loss: 5559417105.5342\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7687378726.2024 - val_loss: 5560813834.5205\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7386594066.0034 - val_loss: 5560318737.5342\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7555391001.4683 - val_loss: 5560809016.1096\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7543508178.7719 - val_loss: 5560112871.4521\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7390113431.9314 - val_loss: 5560230301.8082\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7730056422.0926 - val_loss: 5561725545.2055\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7385450390.1750 - val_loss: 5564196067.9452\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7152161359.0395 - val_loss: 5563222577.0959\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7680578938.5111 - val_loss: 5564860289.7534\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7616501285.3242 - val_loss: 5564637681.9726\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7530807844.0069 - val_loss: 5564689912.9863\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7379736981.7358 - val_loss: 5564820388.8219\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7635368110.7650 - val_loss: 5566132062.6849\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7541321090.4151 - val_loss: 5566246182.5753\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7494692932.5009 - val_loss: 5565876848.2192\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7722525685.4614 - val_loss: 5566711537.9726\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7223565780.0892 - val_loss: 5565188215.2329\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7242076380.4322 - val_loss: 5564689141.4795\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7643679816.0137 - val_loss: 5564938204.9315\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7454880201.1115 - val_loss: 5564539525.2603\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7469266071.0532 - val_loss: 5563261597.8082\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7267994192.7959 - val_loss: 5563500382.6849\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7452318669.5026 - val_loss: 5563726392.1096\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7583678157.5026 - val_loss: 5565027061.4795\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7682237106.2779 - val_loss: 5565400260.3836\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7335454056.0686 - val_loss: 5564957134.9041\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7587544285.3105 - val_loss: 5564213809.0959\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7724102807.0532 - val_loss: 5565214919.8904\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7857072463.4786 - val_loss: 5565530518.7945\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7668073733.7084 - val_loss: 5567727202.1918\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7679648832.1098 - val_loss: 5569359240.7671\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7384676347.1698 - val_loss: 5567948828.0548\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7477794953.0017 - val_loss: 5566740220.4932\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7700312206.7101 - val_loss: 5565554035.7260\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7289473732.9400 - val_loss: 5565662860.2740\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7654230065.1801 - val_loss: 5566512643.5068\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7363738075.9931 - val_loss: 5566236380.9315\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7663991179.1973 - val_loss: 5565301072.6575\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7341731067.1698 - val_loss: 5564026259.2877\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7403395409.2350 - val_loss: 5562381543.4521\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7674378931.5952 - val_loss: 5563187256.1096\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7342871247.2590 - val_loss: 5563253900.2740\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7397342289.6741 - val_loss: 5562427609.4247\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7563841947.8834 - val_loss: 5563290055.8904\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7514177530.7307 - val_loss: 5563798815.5616\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7558398570.2642 - val_loss: 5562939981.1507\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7644010211.8971 - val_loss: 5562776842.5205\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7469211619.8971 - val_loss: 5563453832.7671\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7369317635.5129 - val_loss: 5564002595.0685\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7647295805.9142 - val_loss: 5564999434.5205\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7384010854.7513 - val_loss: 5563023219.7260\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7569536758.7787 - val_loss: 5564878248.3288\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7382224272.0274 - val_loss: 5564792277.9178\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 7514526201.8525 - val_loss: 5564716316.0548\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7309206841.5232 - val_loss: 5563765612.7123\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7799351703.4923 - val_loss: 5563143441.5342\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7428875899.8285 - val_loss: 5563823451.1781\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7435707540.8576 - val_loss: 5563848269.1507\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7851073667.2933 - val_loss: 5565218703.7808\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7618388173.0635 - val_loss: 5563906994.8493\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7655761844.4734 - val_loss: 5566372541.3699\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7331150422.9434 - val_loss: 5566787576.9863\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7697119965.3105 - val_loss: 5565740800.0000\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7504710243.6775 - val_loss: 5565504056.1096\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7628601180.6518 - val_loss: 5565661317.2603\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7535838389.7907 - val_loss: 5565463208.3288\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7533881835.8010 - val_loss: 5567268562.4110\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7408015259.4443 - val_loss: 5566627832.9863\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7560459277.1732 - val_loss: 5568337288.7671\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7279895619.6226 - val_loss: 5567561847.2329\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7609777725.4751 - val_loss: 5566899873.3151\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7540125970.4425 - val_loss: 5566778855.4521\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7472419347.3208 - val_loss: 5569088189.3699\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7398977665.0978 - val_loss: 5568958772.6027\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7541452832.4940 - val_loss: 5568186325.9178\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7396582616.0412 - val_loss: 5568168255.1233\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7563856919.7118 - val_loss: 5566764466.8493\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7451117825.3173 - val_loss: 5566620068.8219\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7387082692.2813 - val_loss: 5565910131.7260\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7249883332.5009 - val_loss: 5565109563.6164\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7542284967.3002 - val_loss: 5563791949.1507\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7878469400.1509 - val_loss: 5565520362.9589\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7481963810.6895 - val_loss: 5564491740.9315\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7537594214.3122 - val_loss: 5565242851.9452\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7500455670.7787 - val_loss: 5565016246.3562\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7443159928.7547 - val_loss: 5566922815.1233\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7505518876.5420 - val_loss: 5565958964.6027\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7441750177.1527 - val_loss: 5565870220.2740\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7090012766.4082 - val_loss: 5564326301.8082\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7423747275.7461 - val_loss: 5563701539.0685\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7645539898.8405 - val_loss: 5563946930.8493\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7454815024.7410 - val_loss: 5563259339.3973\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7670944027.6638 - val_loss: 5563280818.8493\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7613878330.8405 - val_loss: 5563630528.8767\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7580998272.0000 - val_loss: 5564883273.6438\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7322699154.6621 - val_loss: 5563364401.0959\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7583480029.3105 - val_loss: 5564288561.0959\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7514773739.3619 - val_loss: 5562967580.0548\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7650448869.6535 - val_loss: 5564085093.6986\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7292878840.9743 - val_loss: 5564253117.3699\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7392014286.3808 - val_loss: 5562065253.6986\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7294474835.4305 - val_loss: 5560925155.9452\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7056656787.9794 - val_loss: 5559666025.2055\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7446269044.8027 - val_loss: 5559169427.2877\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7636670650.1818 - val_loss: 5560688654.0274\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7489033472.4391 - val_loss: 5560539139.5068\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7426424816.1921 - val_loss: 5560802040.9863\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7566096667.2247 - val_loss: 5563569299.2877\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7657552457.7702 - val_loss: 5564753758.6849\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7478816165.5437 - val_loss: 5565809884.9315\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7522520061.3654 - val_loss: 5566778101.4795\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7704288129.5369 - val_loss: 5566062862.0274\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7246450804.8027 - val_loss: 5564198992.6575\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7598524766.4082 - val_loss: 5564277255.0137\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7478768055.1081 - val_loss: 5564464625.9726\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7518992021.2967 - val_loss: 5565179293.8082\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7480600053.9005 - val_loss: 5563950549.9178\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7411632102.5317 - val_loss: 5562526271.1233\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 149us/step - loss: 7612475572.0343 - val_loss: 5563438146.6301\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7488614970.4014 - val_loss: 5565280929.3151\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7507849695.5060 - val_loss: 5566305427.2877\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7466755423.2864 - val_loss: 5567728415.5616\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7602032792.8096 - val_loss: 5569974398.2466\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7640330166.2298 - val_loss: 5568134115.9452\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7439864358.6415 - val_loss: 5567516279.2329\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7482664800.1647 - val_loss: 5566976298.0822\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7735544371.8148 - val_loss: 5566626198.7945\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7443596502.2847 - val_loss: 5566558004.6027\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7550920646.9160 - val_loss: 5566988175.7808\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7427836328.6175 - val_loss: 5566657837.5890\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7218271320.2607 - val_loss: 5565309846.7945\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7498021145.9074 - val_loss: 5565500935.0137\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7372768138.3190 - val_loss: 5565898625.7534\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7489921251.0189 - val_loss: 5565830557.8082\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7659279810.9640 - val_loss: 5564909290.9589\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7540215743.8902 - val_loss: 5566182385.9726\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7430919305.4408 - val_loss: 5566551902.6849\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7512321320.8370 - val_loss: 5566859698.8493\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7454765573.7084 - val_loss: 5568041443.9452\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7344973422.6552 - val_loss: 5568347121.9726\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7390692682.2093 - val_loss: 5566965202.4110\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7527901365.7907 - val_loss: 5565488625.9726\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7512465539.7324 - val_loss: 5564744321.7534\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7689653788.1029 - val_loss: 5565025546.5205\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7318023348.0343 - val_loss: 5565598358.7945\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7514981924.8851 - val_loss: 5564534917.2603\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7479598043.1149 - val_loss: 5565026121.6438\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7388928404.8576 - val_loss: 5564397778.4110\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7568450940.2676 - val_loss: 5566396913.9726\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7536390150.1475 - val_loss: 5566705081.8630\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7508477089.5918 - val_loss: 5565713920.0000\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7284135108.7204 - val_loss: 5565625379.0685\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7802382876.1029 - val_loss: 5567082355.7260\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7854112149.7358 - val_loss: 5567288863.5616\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7333892532.4734 - val_loss: 5567562289.0959\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7830018078.72 - 0s 147us/step - loss: 7337522175.1218 - val_loss: 5565425762.1918\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7712983944.1235 - val_loss: 5567379687.4521\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7369119249.5643 - val_loss: 5566187604.1644\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7390400427.6913 - val_loss: 5566064569.8630\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7459401089.5369 - val_loss: 5566612914.8493\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7397802745.4134 - val_loss: 5564424619.8356\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7437251408.3568 - val_loss: 5563275113.2055\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7762453006.9297 - val_loss: 5564293337.4247\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7584614336.3293 - val_loss: 5565465582.4658\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7473551540.0343 - val_loss: 5565474079.5616\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7474226038.9983 - val_loss: 5564709505.7534\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7184588470.6690 - val_loss: 5563505429.0411\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7560588259.0189 - val_loss: 5563758437.6986\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7555935116.9537 - val_loss: 5566569847.2329\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7500058263.9314 - val_loss: 5565721838.4658\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7458698220.6792 - val_loss: 5565170105.8630\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7509259819.0326 - val_loss: 5565001040.6575\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7546974570.7033 - val_loss: 5566450915.9452\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7601059959.4374 - val_loss: 5566690914.1918\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7303293562.5111 - val_loss: 5564816531.2877\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7489821153.2624 - val_loss: 5566383219.7260\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7761894170.7856 - val_loss: 5565887060.1644\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7380727378.5523 - val_loss: 5566358654.2466\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7445503017.2762 - val_loss: 5564327683.5068\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7370712207.5883 - val_loss: 5565393057.3151\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7513613439.3413 - val_loss: 5565078633.2055\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7488737710.3259 - val_loss: 5564869007.7808\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7596938501.2693 - val_loss: 5563597985.3151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7585542012.7067 - val_loss: 5564177891.9452\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7560635058.2779 - val_loss: 5564453340.9315\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7597863231.6707 - val_loss: 5564819399.8904\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7585833316.9949 - val_loss: 5564766674.4110\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7406033906.8268 - val_loss: 5564681251.0685\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7651812945.6741 - val_loss: 5565503312.6575\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7435871989.4614 - val_loss: 5565348681.6438\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7422944588.4048 - val_loss: 5565707323.6164\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7663713127.1904 - val_loss: 5565009671.0137\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7458473277.0360 - val_loss: 5565437043.7260\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7665056390.3671 - val_loss: 5565451228.9315\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7931586732.1304 - val_loss: 5566621120.8767\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7487695716.1166 - val_loss: 5567648876.7123\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7397199775.3962 - val_loss: 5565812311.6712\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7427461091.8971 - val_loss: 5566533653.0411\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7601133481.0566 - val_loss: 5566442022.5753\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7522964012.7890 - val_loss: 5564954161.0959\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7345460024.2058 - val_loss: 5565507640.1096\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7490216791.3825 - val_loss: 5564107081.6438\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 8049461524.1990 - val_loss: 5566031198.6849\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7451079124.0892 - val_loss: 5565116549.2603\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7548628333.0086 - val_loss: 5565473974.3562\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7731533568.8782 - val_loss: 5567451213.1507\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7685838837.4614 - val_loss: 5568323093.0411\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7174619791.1492 - val_loss: 5567366740.1644\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7582396273.7290 - val_loss: 5567438840.9863\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7451920982.0652 - val_loss: 5566592406.7945\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7491792782.7101 - val_loss: 5564492926.2466\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7178676553.3310 - val_loss: 5563274282.0822\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7553011005.0360 - val_loss: 5564092107.3973\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7502479381.9554 - val_loss: 5563058407.4521\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7400664516.2813 - val_loss: 5566364724.6027\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7507355062.6690 - val_loss: 5567502420.1644\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7658116117.0772 - val_loss: 5567475185.9726\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7435289596.0480 - val_loss: 5566808256.8767\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7588456904.6724 - val_loss: 5563834283.8356\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7552661161.0566 - val_loss: 5564364898.1918\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7625129267.3756 - val_loss: 5563716600.9863\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7268755467.8559 - val_loss: 5563042023.4521\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7670615382.5043 - val_loss: 5560783886.0274\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7381653029.7633 - val_loss: 5559583319.6712\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7806671827.6501 - val_loss: 5561989870.4658\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7559489139.9245 - val_loss: 5560913144.9863\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7606693733.4340 - val_loss: 5560876256.4384\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7426496492.6792 - val_loss: 5561661524.1644\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7556207053.5026 - val_loss: 5561673261.5890\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7512392650.4288 - val_loss: 5560218238.2466\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7664325774.2710 - val_loss: 5560414804.1644\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7550060062.7376 - val_loss: 5559981539.9452\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7352953416.4528 - val_loss: 5558852215.2329\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7682988823.7118 - val_loss: 5559531092.1644\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7315977804.4048 - val_loss: 5559994150.5753\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7467662713.6329 - val_loss: 5558294044.0548\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7481549616.7410 - val_loss: 5558696433.9726\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7600087841.8113 - val_loss: 5555939349.0411\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7630190751.3962 - val_loss: 5557286919.0137\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7556204810.0995 - val_loss: 5559476627.2877\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7245547503.7530 - val_loss: 5559336251.6164\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7473054621.6398 - val_loss: 5559564049.5342\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7777205388.5146 - val_loss: 5560761494.7945\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7566532409.5232 - val_loss: 5561502358.7945\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7278995169.2624 - val_loss: 5560894085.2603\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7405225397.3516 - val_loss: 5560039536.2192\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7577734150.1475 - val_loss: 5561849196.7123\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7662847200.8233 - val_loss: 5561187243.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7424560022.6141 - val_loss: 5561540194.1918\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7414531270.9160 - val_loss: 5561296163.0685\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7505603482.1269 - val_loss: 5560722126.9041\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7548033478.9160 - val_loss: 5561368993.3151\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7485206622.8473 - val_loss: 5561494692.8219\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7451923311.0943 - val_loss: 5561594971.1781\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7403358523.7187 - val_loss: 5563638419.2877\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7506801455.8628 - val_loss: 5563084515.9452\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7594264019.2110 - val_loss: 5563321764.8219\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7288730038.8885 - val_loss: 5562188975.3425\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7454567606.6690 - val_loss: 5562584491.8356\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7637392796.3225 - val_loss: 5563449694.6849\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7934199072.0549 - val_loss: 5562741388.2740\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7477418742.7787 - val_loss: 5562216184.9863\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7320659421.7496 - val_loss: 5562736345.4247\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7839383304.3431 - val_loss: 5563016521.6438\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7348055768.9194 - val_loss: 5563810980.8219\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7441706762.5386 - val_loss: 5563734720.8767\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7316582984.8919 - val_loss: 5561667310.4658\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7364188289.0978 - val_loss: 5562307591.0137\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7404185295.2590 - val_loss: 5561663123.2877\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7589206676.4185 - val_loss: 5560461908.1644\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7708770983.3002 - val_loss: 5562531755.8356\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7500564893.6398 - val_loss: 5563480912.6575\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7613767641.3585 - val_loss: 5563560111.3425\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7334725572.2813 - val_loss: 5563099265.7534\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7381649933.6124 - val_loss: 5562247301.2603\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7198183683.0738 - val_loss: 5563510145.7534\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7486628697.5780 - val_loss: 5565059587.5068\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7481937683.7599 - val_loss: 5565538465.3151\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7382290338.9091 - val_loss: 5564333143.6712\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7508125360.5214 - val_loss: 5565707541.0411\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7473365554.9365 - val_loss: 5566102808.5479\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7628853030.2024 - val_loss: 5566075286.7945\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7516472538.6758 - val_loss: 5566238456.9863\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7347482683.7187 - val_loss: 5565517080.5479\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7451295956.5283 - val_loss: 5564288178.8493\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7355362996.0343 - val_loss: 5563352898.6301\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7433641987.5129 - val_loss: 5562178342.5753\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7544497305.6878 - val_loss: 5562870471.8904\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7575335705.9074 - val_loss: 5564951594.0822\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7489608939.3619 - val_loss: 5563040178.8493\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7408474620.4871 - val_loss: 5562248458.5205\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7630525491.8148 - val_loss: 5564264619.8356\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7583124617.8799 - val_loss: 5565808366.4658\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7416540051.1012 - val_loss: 5562818251.3973\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7492675019.3070 - val_loss: 5562510118.5753\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7549027547.5540 - val_loss: 5564168293.6986\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7537090188.9537 - val_loss: 5564262659.5068\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7390791723.0326 - val_loss: 5562682971.1781\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7405492575.2864 - val_loss: 5562232309.4795\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7445559642.0172 - val_loss: 5561527022.4658\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7510645072.3568 - val_loss: 5560642244.3836\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7701195213.9417 - val_loss: 5560540188.0548\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7487454490.7856 - val_loss: 5560349282.1918\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7475831388.2127 - val_loss: 5561315040.4384\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7399567093.4614 - val_loss: 5561216203.3973\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7290315369.3859 - val_loss: 5563494677.0411\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7345989769.0017 - val_loss: 5563196219.6164\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7378674868.9125 - val_loss: 5562588819.2877\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7554170176.9880 - val_loss: 5563673908.6027\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7425816667.3345 - val_loss: 5562568556.7123\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7360899636.6930 - val_loss: 5561652897.3151\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7538300674.1955 - val_loss: 5561697683.2877\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7517458888.6724 - val_loss: 5564119436.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7482274837.5163 - val_loss: 5563584662.7945\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7339676596.9125 - val_loss: 5563249379.9452\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7643969994.8679 - val_loss: 5561477141.0411\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7482232549.2144 - val_loss: 5560986322.4110\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7573547894.1201 - val_loss: 5561979532.2740\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7456430507.2521 - val_loss: 5561496155.1781\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7484423599.2041 - val_loss: 5559986133.9178\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7426618994.1681 - val_loss: 5559573321.6438\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7624693345.4820 - val_loss: 5561183526.5753\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7635319832.5901 - val_loss: 5562804820.1644\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7363199091.9245 - val_loss: 5562192236.7123\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7592482074.7856 - val_loss: 5562512903.0137\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 7273112520.6724 - val_loss: 5562340723.7260\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7428464849.0154 - val_loss: 5560815209.2055\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7356083206.1475 - val_loss: 5561612750.9041\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7691441967.8628 - val_loss: 5561858209.3151\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7454615318.3945 - val_loss: 5559808936.3288\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7401114983.1904 - val_loss: 5560022787.5068\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7527582950.9708 - val_loss: 5560253166.4658\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 137us/step - loss: 7759716618.0995 - val_loss: 5560243659.3973\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7436478543.0395 - val_loss: 5560872732.0548\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7201500177.5643 - val_loss: 5560704575.1233\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7381331311.0943 - val_loss: 5560048815.3425\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7615877162.1544 - val_loss: 5559768348.0548\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7368469964.1852 - val_loss: 5558518482.4110\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7352362153.0566 - val_loss: 5558858899.2877\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7356183908.9949 - val_loss: 5559916081.0959\n",
      "neurons used (16, 8)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 515us/step - loss: 39209659130.2916 - val_loss: 38417650084.8219\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39207777611.9657 - val_loss: 38414853105.9726\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 39205054825.8250 - val_loss: 38412518442.0822\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 39201819091.2110 - val_loss: 38409990087.8904\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39197259884.8988 - val_loss: 38406311150.4658\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39192124653.1184 - val_loss: 38399594215.4521\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39186395975.5746 - val_loss: 38393676056.5479\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 39179149480.6175 - val_loss: 38387896544.4384\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 39172722154.0446 - val_loss: 38379403853.1507\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39163160101.7633 - val_loss: 38368940480.8767\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39155418970.8954 - val_loss: 38355677576.7671\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39145713783.4374 - val_loss: 38346856279.6712\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 39133524249.0292 - val_loss: 38335598648.1096\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 39123960222.5180 - val_loss: 38325696259.5069\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 39110199531.3619 - val_loss: 38312186725.6986\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 39099204525.4477 - val_loss: 38299865340.4931\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39084492606.7924 - val_loss: 38288466368.8767\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 39071629691.3894 - val_loss: 38274020786.8493\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 39058321794.4151 - val_loss: 38259239276.7123\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 39041688324.8302 - val_loss: 38241371851.3973\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 39020284125.3105 - val_loss: 38224332547.5069\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 39004257408.2196 - val_loss: 38206766486.7945\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 38990239480.5352 - val_loss: 38186625528.9863\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38965954900.7479 - val_loss: 38165787016.7671\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38942280568.7547 - val_loss: 38145484042.5205\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38932382145.6467 - val_loss: 38122896874.9589\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38901975689.8799 - val_loss: 38101173907.2877\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38883341738.8130 - val_loss: 38078802901.9178\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 38865775484.2676 - val_loss: 38053874730.0822\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38837972373.7359 - val_loss: 38031574899.7260\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 38816938005.0772 - val_loss: 38007754387.2877\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38799110495.2864 - val_loss: 37982328018.4110\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38773721288.2333 - val_loss: 37957473546.5205\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38743875791.2590 - val_loss: 37929620241.5342\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38710351130.7856 - val_loss: 37901770976.4384\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38681810518.9434 - val_loss: 37880666392.5479\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 38659227577.7427 - val_loss: 37850981923.0685\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 38619881436.8714 - val_loss: 37816834160.2192\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 38589416101.9828 - val_loss: 37786826723.9452\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 138us/step - loss: 38571841901.3379 - val_loss: 37755915783.0137\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 38524819768.6449 - val_loss: 37722789298.8493\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 38502617688.6998 - val_loss: 37688855958.7945\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38465410906.8954 - val_loss: 37649261834.5205\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 38424089145.0841 - val_loss: 37617055098.7397\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 38384157711.8079 - val_loss: 37584260615.0137\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 38372040050.6072 - val_loss: 37546582240.4384\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 38328233731.0738 - val_loss: 37509352798.6849\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 38289312302.5454 - val_loss: 37469738362.7397\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 38250680776.6724 - val_loss: 37437221509.2603\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38206836050.9914 - val_loss: 37398437859.9452\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38162927334.9708 - val_loss: 37359662683.1781\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 38132800861.5300 - val_loss: 37315071495.0137\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38078314285.2281 - val_loss: 37273938761.6438\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38064676516.2264 - val_loss: 37232261035.8356\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38022874598.5317 - val_loss: 37188318642.8493\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 37977681041.7839 - val_loss: 37144673686.7945\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 37926983746.7444 - val_loss: 37102479836.9315\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37870395420.1029 - val_loss: 37055036654.4658\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 37887647863.4374 - val_loss: 37009328773.2603\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 37792342852.0618 - val_loss: 36966003978.5205\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37762407274.7033 - val_loss: 36917009169.5342\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 37730337881.5780 - val_loss: 36873814184.3288\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 37661739945.9348 - val_loss: 36826437800.3288\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 37622258271.7256 - val_loss: 36781673878.7945\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37580661122.4151 - val_loss: 36746400220.9315\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 37521030416.2470 - val_loss: 36690577941.0411\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37452934128.1921 - val_loss: 36637064851.2877\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 37402059883.1424 - val_loss: 36584071701.0411\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 37393953091.1835 - val_loss: 36535440903.0137\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 37292597567.6707 - val_loss: 36484279815.0137\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 37272981504.0000 - val_loss: 36438367807.1233\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 37188589241.3036 - val_loss: 36378879523.0685\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 37123319997.6947 - val_loss: 36318651434.0822\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 37102636929.5369 - val_loss: 36261558524.4931\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 37092004373.9554 - val_loss: 36205021436.4931\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 36983967772.1029 - val_loss: 36153461549.5890\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 36956256175.2041 - val_loss: 36090768678.5753\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 36847340521.1664 - val_loss: 36029914238.2466\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 36758700713.4957 - val_loss: 35968646186.0822\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 36736436642.0309 - val_loss: 35911990510.4658\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 36727718861.0635 - val_loss: 35847568173.5890\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 36636747677.6398 - val_loss: 35789260435.2877\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 36558111517.4202 - val_loss: 35728253404.9315\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 36462175030.0103 - val_loss: 35661672223.5616\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 36377199038.1338 - val_loss: 35596163043.9452\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 36384485379.5129 - val_loss: 35543954333.8082\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 244us/step - loss: 36331463323.4443 - val_loss: 35475875026.4110\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 332us/step - loss: 36227551836.2127 - val_loss: 35410258144.4384\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 1s 464us/step - loss: 36128297852.2676 - val_loss: 35337366934.7945\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 1s 442us/step - loss: 36144950410.7581 - val_loss: 35265487801.8630\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 421us/step - loss: 36065595859.2110 - val_loss: 35207608656.6575\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 400us/step - loss: 36016115241.2762 - val_loss: 35136077431.2329\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 360us/step - loss: 35982174780.5969 - val_loss: 35073274360.9863\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 347us/step - loss: 35832328690.8268 - val_loss: 34992480031.5616\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 332us/step - loss: 35773981936.6312 - val_loss: 34923274997.4795\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 1s 479us/step - loss: 35685051249.7290 - val_loss: 34845040640.0000\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 328us/step - loss: 35690497331.3756 - val_loss: 34780710771.7260\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 333us/step - loss: 35606870209.2076 - val_loss: 34710227028.1644\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 321us/step - loss: 35502178823.9039 - val_loss: 34643348494.0274\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 295us/step - loss: 35390982070.2298 - val_loss: 34572417220.3836\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 35680525411.096 - 0s 308us/step - loss: 35397703219.8148 - val_loss: 34490768566.3562\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 329us/step - loss: 35292737820.5420 - val_loss: 34428396137.2055\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 304us/step - loss: 35159052070.2024 - val_loss: 34354829255.8904\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 352us/step - loss: 35204113947.2247 - val_loss: 34277700201.2055\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 325us/step - loss: 35100591267.3482 - val_loss: 34210797455.7808\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 274us/step - loss: 34943786874.5111 - val_loss: 34121513184.4384\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 253us/step - loss: 34925729669.0497 - val_loss: 34046903057.5342\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 270us/step - loss: 34858247085.4477 - val_loss: 33967247247.7808\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 266us/step - loss: 34780207736.3156 - val_loss: 33891551821.1507\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 34634301222.2024 - val_loss: 33825110128.2192\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 262us/step - loss: 34650278748.6518 - val_loss: 33742472879.3425\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 34456683268.8302 - val_loss: 33661638908.4931\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 34467774130.2779 - val_loss: 33571108751.7808\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 257us/step - loss: 34312471954.2230 - val_loss: 33489252688.6575\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 34314733929.8250 - val_loss: 33408317468.0548\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 34175582801.6741 - val_loss: 33332208625.9726\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 34123033078.3396 - val_loss: 33254484809.6438\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 33998981025.1527 - val_loss: 33161225314.1918\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 33989835883.1424 - val_loss: 33079992488.3288\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 33955119230.4631 - val_loss: 33002134289.5342\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 33729773132.4048 - val_loss: 32911031281.9726\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 225us/step - loss: 33772581896.7822 - val_loss: 32823751637.9178\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 33644828524.4597 - val_loss: 32726749857.3151\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 33661804754.7719 - val_loss: 32652024453.2603\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 33501787555.7873 - val_loss: 32555979256.9863\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 33343734592.5489 - val_loss: 32462767286.3562\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 33296982823.9588 - val_loss: 32377153115.1781\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 33125223253.6261 - val_loss: 32287653691.6164\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 33060962816.8782 - val_loss: 32210507355.1781\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 33066927232.2196 - val_loss: 32119920499.7260\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 32891590901.9005 - val_loss: 32033015359.1233\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 32700889196.8988 - val_loss: 31942979135.1233\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 32831997259.9657 - val_loss: 31856046332.4931\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 32697072293.9828 - val_loss: 31766031177.6438\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 32708389043.1561 - val_loss: 31670496326.1370\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 32479745391.0943 - val_loss: 31578692874.5205\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 32351546822.9160 - val_loss: 31479468649.2055\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 32312752883.2659 - val_loss: 31386830567.4521\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 32331076230.3671 - val_loss: 31289790211.5069\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 32220058566.0377 - val_loss: 31196449834.0822\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 255us/step - loss: 32107685062.4768 - val_loss: 31094441731.5069\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 31920304071.7942 - val_loss: 30999180863.1233\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 31928423692.7341 - val_loss: 30890054810.3014\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 31582379213.5026 - val_loss: 30798467633.0959\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 31703340469.3516 - val_loss: 30706323399.8904\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 31636406106.8954 - val_loss: 30600988307.2877\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 31346372130.2504 - val_loss: 30503432079.7808\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 31462232780.6244 - val_loss: 30405458144.4384\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 31258734342.5866 - val_loss: 30308685094.5753\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 31059664853.8456 - val_loss: 30207460786.8493\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 31170279866.6209 - val_loss: 30110394368.0000\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 30743024978.9914 - val_loss: 30010014649.8630\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 30787694830.8748 - val_loss: 29906993404.4931\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 30780000424.6175 - val_loss: 29804812203.8356\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 30665750306.6895 - val_loss: 29713484140.7123\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 30650409342.9022 - val_loss: 29620899503.3425\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 30373991608.4254 - val_loss: 29502442173.3699\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 30399324616.6724 - val_loss: 29412176124.4931\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 30240032219.9931 - val_loss: 29304783296.8767\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 30142513865.1115 - val_loss: 29201939666.4110\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 30007617128.5077 - val_loss: 29097633427.2877\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 29791377450.1544 - val_loss: 28999591515.1781\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 29869057436.7616 - val_loss: 28894933356.7123\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 29798769374.1887 - val_loss: 28793627185.0959\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 29599131893.9005 - val_loss: 28671947004.4931\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 184us/step - loss: 29432512847.4786 - val_loss: 28564419541.9178\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 29236162549.4614 - val_loss: 28465936860.9315\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 29396491314.9365 - val_loss: 28361280301.5890\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 29356354400.1647 - val_loss: 28245482538.0822\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 28951025161.6604 - val_loss: 28123733342.6849\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 29027389239.7667 - val_loss: 28018042234.7397\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 28754788945.6741 - val_loss: 27905888508.4931\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 28755038980.8302 - val_loss: 27800041023.1233\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 28784901627.6089 - val_loss: 27699241633.3151\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 28465100424.1235 - val_loss: 27596939712.8767\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 28728026380.7341 - val_loss: 27491464991.5616\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 28305362325.7358 - val_loss: 27376997866.9589\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 28472854426.1269 - val_loss: 27273547719.8904\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 28253552415.1767 - val_loss: 27164495086.4658\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 28103460769.1527 - val_loss: 27048056579.5069\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 27857350153.6604 - val_loss: 26931597115.6164\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 27781861558.6690 - val_loss: 26828235004.4931\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 27813193942.2847 - val_loss: 26712445404.9315\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 27880271703.3825 - val_loss: 26597077272.5479\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 27562801067.6912 - val_loss: 26480264767.1233\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 27640988269.7770 - val_loss: 26361899933.8082\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 27488091766.5592 - val_loss: 26246305932.2740\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 27279718189.2281 - val_loss: 26138893943.2329\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 26891626288.7410 - val_loss: 26030078653.3699\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 26921504090.0172 - val_loss: 25915896425.2055\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 26965016916.7479 - val_loss: 25797294753.3151\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 26801303397.4340 - val_loss: 25677943288.9863\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 26657499905.3173 - val_loss: 25563903018.0822\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 26470459182.9846 - val_loss: 25448668426.5205\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 26438579345.7839 - val_loss: 25338297386.0822\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 26368486380.6792 - val_loss: 25229389936.2192\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 26332288272.2470 - val_loss: 25115339930.3014\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 26095522947.7324 - val_loss: 24988862772.6027\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 26043811068.9262 - val_loss: 24860333855.5616\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 25808533672.6175 - val_loss: 24759979190.3562\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 25828593776.4117 - val_loss: 24644618436.3836\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 25535716431.0395 - val_loss: 24516585612.2740\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 25401197169.2899 - val_loss: 24403307982.9041\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 25317238745.3585 - val_loss: 24288355959.2329\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 25633150925.0635 - val_loss: 24173358991.7808\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 25527014969.0840 - val_loss: 24056397515.3973\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 25160094033.2350 - val_loss: 23923199495.0137\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 24960221162.9228 - val_loss: 23818676560.6575\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 24840841268.6930 - val_loss: 23695646916.3836\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 24653273685.1870 - val_loss: 23581909216.4384\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 24843555033.7976 - val_loss: 23465225314.1918\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 24432206273.6467 - val_loss: 23336934301.8082\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 24362820402.4974 - val_loss: 23219952008.7671\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 24432810563.6226 - val_loss: 23097081631.5616\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 24307789578.0995 - val_loss: 22977765319.8904\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 24114035604.8576 - val_loss: 22859000284.9315\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 23932718531.4031 - val_loss: 22731230614.7945\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 23883776043.9108 - val_loss: 22606168779.3973\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 23840198322.2779 - val_loss: 22481503779.0685\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 23934750807.8216 - val_loss: 22370483929.4247\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 23226141681.9485 - val_loss: 22249965287.4521\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 23315644421.2693 - val_loss: 22129923562.9589\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 23379456498.8268 - val_loss: 22009584163.0685\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 23431859149.0635 - val_loss: 21900132015.3425\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 22941931253.0223 - val_loss: 21785774374.5753\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 23184401557.2967 - val_loss: 21680755164.9315\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 22723238741.6261 - val_loss: 21547508287.1233\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 22540216223.3962 - val_loss: 21421339493.6986\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 22834421935.6432 - val_loss: 21315681125.6986\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 162us/step - loss: 22429838457.1938 - val_loss: 21182510823.4521\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 22325818447.0395 - val_loss: 21066402114.6301\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 22364520451.5129 - val_loss: 20945280504.9863\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 21823198866.6621 - val_loss: 20827648182.3562\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 21875836727.7667 - val_loss: 20693609023.1233\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 22000898578.4425 - val_loss: 20586222311.4521\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 21863377556.4185 - val_loss: 20450659973.2603\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 21875729866.4288 - val_loss: 20340831526.5753\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 21360494876.5420 - val_loss: 20230480278.7945\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 21316763623.4099 - val_loss: 20118763884.7123\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 21448804438.0652 - val_loss: 19989972360.7671\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 21214966852.5009 - val_loss: 19878826559.1233\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 20994263472.0823 - val_loss: 19751083611.1781\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 20983288206.7101 - val_loss: 19618316498.4110\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 20948623577.7976 - val_loss: 19494105691.1781\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 21008205321.6604 - val_loss: 19379316202.9589\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 20545364472.0961 - val_loss: 19260237290.9589\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 20684343039.5609 - val_loss: 19130457298.4110\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 20617064534.9434 - val_loss: 19014334407.8904\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 20540736158.9571 - val_loss: 18898529280.0000\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 21312416890.880 - 0s 148us/step - loss: 20490559923.5952 - val_loss: 18757429444.3836\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 20027498464.3842 - val_loss: 18640322321.5342\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 19422558987.8559 - val_loss: 18526613419.8356\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 19585638800.4666 - val_loss: 18416339996.0548\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 19716100817.8937 - val_loss: 18293252432.6575\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 20056289873.6741 - val_loss: 18192633070.4658\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 19780162537.1664 - val_loss: 18068578037.4795\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 19383908921.0840 - val_loss: 17943433187.9452\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 19423439518.9571 - val_loss: 17817793016.9863\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 18950018272.8233 - val_loss: 17701033226.5205\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 19289577949.7496 - val_loss: 17588755638.3562\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 18862281236.1990 - val_loss: 17469636060.9315\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 18910554814.5729 - val_loss: 17351352895.1233\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 18862449121.2624 - val_loss: 17231345902.4658\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 18504381172.1441 - val_loss: 17118947748.8219\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 18623506960.6861 - val_loss: 16992534794.5205\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 18736384679.7393 - val_loss: 16878100746.5205\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 18283660758.7238 - val_loss: 16766006398.2466\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 18145892501.2967 - val_loss: 16647153327.3425\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 18032419469.3928 - val_loss: 16522903187.2877\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 17789884280.7547 - val_loss: 16410996848.2192\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 18326434292.5832 - val_loss: 16300435512.1096\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 17808313584.6312 - val_loss: 16183829209.4247\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 17926129395.2659 - val_loss: 16074168923.1781\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 17738709775.3688 - val_loss: 15955180978.8493\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 17647842368.9880 - val_loss: 15843369408.8767\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 17572425461.0223 - val_loss: 15730197377.7534\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 17715386111.5609 - val_loss: 15617263545.8630\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 17304780643.6775 - val_loss: 15498815375.7808\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 16696610799.3139 - val_loss: 15385729248.4384\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 16436191758.9297 - val_loss: 15277618919.4521\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 16693188103.9039 - val_loss: 15161248417.3151\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 16898548397.0086 - val_loss: 15047697842.8493\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 16716575861.6810 - val_loss: 14936756658.8493\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 16448213515.4168 - val_loss: 14815220273.0959\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 17175515279.1492 - val_loss: 14706217927.8904\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 16353513997.1732 - val_loss: 14591989128.7671\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 16271396602.2916 - val_loss: 14481782138.7397\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 16443089127.8491 - val_loss: 14364651646.2466\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 15914573665.9211 - val_loss: 14260178396.9315\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 15816405982.6278 - val_loss: 14147312471.6712\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 15913148059.4443 - val_loss: 14038749113.8630\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 16184802124.8439 - val_loss: 13925332234.5205\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 16155191229.2556 - val_loss: 13807875913.6438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 15959014177.8113 - val_loss: 13710756022.3562\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 15420566889.8250 - val_loss: 13610903972.8219\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 15175316052.3088 - val_loss: 13507525702.1370\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 15124376193.0978 - val_loss: 13390763358.6849\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 15064796751.9177 - val_loss: 13288820469.4795\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 15163234880.1098 - val_loss: 13181231651.0685\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 15731376412.5420 - val_loss: 13085575841.3151\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 14963003982.1612 - val_loss: 12980705560.5479\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 14438689776.1921 - val_loss: 12869344213.9178\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 14510618155.0326 - val_loss: 12763926457.8630\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 15049687350.0103 - val_loss: 12665442745.8630\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 14970112180.9125 - val_loss: 12556722323.2877\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 14456937872.4666 - val_loss: 12460240187.6164\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 14436893822.4631 - val_loss: 12357940539.6164\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 14645942142.0240 - val_loss: 12258506702.9041\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 14369126561.5918 - val_loss: 12162717913.4247\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 14420216707.2933 - val_loss: 12050692671.1233\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 14549049984.2196 - val_loss: 11939789929.2055\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 14097740868.5009 - val_loss: 11843070597.2603\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 14177802141.6398 - val_loss: 11747459836.4932\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 13619364853.4614 - val_loss: 11652363881.2055\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 13844627304.9468 - val_loss: 11546138778.3014\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 13919578312.2333 - val_loss: 11462515242.0822\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 14159167543.3276 - val_loss: 11369306455.6712\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 13776481520.6312 - val_loss: 11266428338.8493\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 13201065832.9468 - val_loss: 11192929574.5753\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 13740413946.7307 - val_loss: 11076420313.4247\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 13200863559.5746 - val_loss: 10985549634.6301\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 13399571577.1938 - val_loss: 10888469938.8493\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 13524176520.5626 - val_loss: 10800849134.4658\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 13107651476.8576 - val_loss: 10701681348.3836\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 12871641140.6930 - val_loss: 10608244322.1918\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 12799396864.0000 - val_loss: 10519926019.5068\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 13167470462.0240 - val_loss: 10436144205.1507\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 13062751753.6604 - val_loss: 10359797255.0137\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 13039400492.7890 - val_loss: 10288935031.2329\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12491771125.0223 - val_loss: 10192865230.9041\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 12497945842.3877 - val_loss: 10101253912.5479\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 12644874245.2693 - val_loss: 10014548977.9726\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 12196118840.6449 - val_loss: 9911620299.3973\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 12610970378.0995 - val_loss: 9825011207.0137\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 12448893728.9331 - val_loss: 9729222992.6575\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 12715362472.6175 - val_loss: 9651037282.1918\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 12269989186.7444 - val_loss: 9585186710.7945\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 12090274875.7187 - val_loss: 9512599201.3151\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 12351246407.1355 - val_loss: 9433784270.9041\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 12420739121.1801 - val_loss: 9349109212.9315\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 12143892775.0806 - val_loss: 9264340297.6438\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11797457677.6123 - val_loss: 9183616063.1233\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 11936567738.1818 - val_loss: 9115525091.9452\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 11823251537.6741 - val_loss: 9041242048.8767\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 12395416992.2744 - val_loss: 8963089611.3973\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 11708210690.6346 - val_loss: 8881710620.0548\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 11686379825.6192 - val_loss: 8812902266.7397\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11588179469.1732 - val_loss: 8738845394.4110\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 12108822759.8491 - val_loss: 8661773473.3151\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11265007280.5214 - val_loss: 8595921050.3014\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 11142551701.2967 - val_loss: 8525234828.2740\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 11636893551.9726 - val_loss: 8466258726.5753\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 11195315812.9949 - val_loss: 8405192283.1781\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 11071804143.7530 - val_loss: 8341799409.9726\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 11668110176.1647 - val_loss: 8282440072.7671\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 11272255563.5266 - val_loss: 8215473832.3288\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11369503131.4443 - val_loss: 8150531773.3699\n",
      "Epoch 358/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 11405676185.6878 - val_loss: 8086690612.6027\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11204450246.0377 - val_loss: 8020953116.0548\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10951419274.3190 - val_loss: 7956461098.0822\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10899836238.6003 - val_loss: 7905687264.4384\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10755901798.3122 - val_loss: 7840755361.3151\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 11066739816.5077 - val_loss: 7795505201.0959\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10626373274.5660 - val_loss: 7737441700.8219\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10673651589.0497 - val_loss: 7685217237.9178\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10809369196.8988 - val_loss: 7629009856.8767\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10453227087.9177 - val_loss: 7570838556.0548\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10841441494.2847 - val_loss: 7517052612.3836\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 11035685332.0892 - val_loss: 7459463560.7671\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 11084265710.8748 - val_loss: 7414944508.4932\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10803821187.7324 - val_loss: 7367206070.3562\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10692540060.3225 - val_loss: 7316472853.0411\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11480461629.9142 - val_loss: 7271726104.5479\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10918997555.8148 - val_loss: 7220591721.2055\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10585728523.4168 - val_loss: 7180844551.0137\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10407193514.8130 - val_loss: 7136294214.1370\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10327364915.3756 - val_loss: 7086245765.2603\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10727653428.6930 - val_loss: 7054240950.3562\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10146021152.9331 - val_loss: 7004286144.8767\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10420736354.7993 - val_loss: 6970893596.0548\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10834922448.5763 - val_loss: 6932498021.6986\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 10388680426.4837 - val_loss: 6897748893.8082\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 10463275137.9760 - val_loss: 6869380169.6438\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 10570737296.9057 - val_loss: 6835528623.3425\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 9884623501.3928 - val_loss: 6799513880.5479\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 11123118295.1630 - val_loss: 6769504157.8082\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9967233225.1115 - val_loss: 6732608308.6027\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10360760017.8937 - val_loss: 6704286432.4384\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10333156559.2590 - val_loss: 6676625590.3562\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10318224974.1612 - val_loss: 6643625335.2329\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10322633577.8250 - val_loss: 6621238159.7808\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10585897912.8645 - val_loss: 6602637217.3151\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10155506390.2847 - val_loss: 6573055067.1781\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10016151444.8576 - val_loss: 6549815183.7808\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10587922683.1698 - val_loss: 6526988203.8356\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10597971721.2213 - val_loss: 6506861308.4932\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10712359222.8885 - val_loss: 6482873014.3562\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10235813915.2247 - val_loss: 6465974696.3288\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10283785943.1630 - val_loss: 6446749447.0137\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10362963049.3859 - val_loss: 6427891946.9589\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9841937393.9485 - val_loss: 6413052100.3836\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10447604702.6278 - val_loss: 6386873999.7808\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10050048908.0755 - val_loss: 6366443891.7260\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10030324574.4082 - val_loss: 6350364472.1096\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9998128985.1389 - val_loss: 6334478378.0822\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10182494913.2075 - val_loss: 6312318961.9726\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10033426936.9743 - val_loss: 6301093902.0274\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10497781795.1286 - val_loss: 6290750691.9452\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10524913798.3671 - val_loss: 6275493873.9726\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10156442335.9451 - val_loss: 6258845468.0548\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10023459025.0154 - val_loss: 6251285156.8219\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10265995611.7736 - val_loss: 6238270485.0411\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10235347080.1235 - val_loss: 6226647401.2055\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10443621365.4614 - val_loss: 6216217824.4384\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9810871112.4528 - val_loss: 6204811505.9726\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9223561973.9005 - val_loss: 6193842933.4795\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10054147643.7187 - val_loss: 6182691520.8767\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10040363297.8113 - val_loss: 6180680058.7397\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10078491467.9657 - val_loss: 6170582268.4932\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9739000345.4683 - val_loss: 6159380052.1644\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10183581752.2058 - val_loss: 6158800983.6712\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 158us/step - loss: 10079800390.2573 - val_loss: 6152273818.3014\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10191101482.1544 - val_loss: 6147425013.4795\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9929112047.3139 - val_loss: 6134570986.9589\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10242863053.9417 - val_loss: 6123828714.9589\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9980007829.7358 - val_loss: 6114360123.6164\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10254975358.9022 - val_loss: 6117042596.8219\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10086579537.2350 - val_loss: 6121739828.6027\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10135555200.2196 - val_loss: 6112967978.0822\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10345789770.2093 - val_loss: 6111630690.1918\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10117373985.3722 - val_loss: 6101261350.5753\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9803608744.6175 - val_loss: 6091731568.2192\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10296500152.8645 - val_loss: 6083945864.7671\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10098415186.5523 - val_loss: 6079970647.6712\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9520558756.2264 - val_loss: 6072089845.4795\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9959067704.6449 - val_loss: 6066677616.2192\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9742049969.3997 - val_loss: 6059747433.2055\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10210020756.4185 - val_loss: 6062133265.5342\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10034974493.8593 - val_loss: 6050812703.5616\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9854811069.2556 - val_loss: 6048639014.5753\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9910213093.6535 - val_loss: 6039690730.9589\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10648672234.9228 - val_loss: 6038203276.2740\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10057886581.2419 - val_loss: 6036902729.6438\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9857750334.7925 - val_loss: 6033701512.7671\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9571736533.8456 - val_loss: 6036006298.3014\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9660671559.1355 - val_loss: 6034661821.3699\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10612765864.6175 - val_loss: 6031739556.8219\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10703894755.4580 - val_loss: 6026661810.8493\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9628462861.6123 - val_loss: 6020448084.1644\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10234460291.7324 - val_loss: 6020131917.1507\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10223027521.4271 - val_loss: 6019366294.7945\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10253227933.6398 - val_loss: 6011198492.0548\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10562218419.5952 - val_loss: 6012544669.8082\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10653199119.3688 - val_loss: 6010777684.1644\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 9509414410.666 - 0s 146us/step - loss: 10297192830.9022 - val_loss: 6011862405.2603\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10848723853.8319 - val_loss: 6014041151.1233\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10162774364.6518 - val_loss: 6015435067.6164\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10392619758.8748 - val_loss: 6021087600.2192\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10147576276.9674 - val_loss: 6020927235.5068\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10222803455.1218 - val_loss: 6017039395.0685\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9981372812.9537 - val_loss: 6020505200.2192\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10439361426.2230 - val_loss: 6020542786.6301\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 11020546855.384 - 0s 141us/step - loss: 10359418700.8439 - val_loss: 6014674267.1781\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9721704943.3139 - val_loss: 6007807011.0685\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10116595007.6707 - val_loss: 6008593190.5753\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10364772378.3465 - val_loss: 6007777521.9726\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10451584983.6021 - val_loss: 6006827085.1507\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9733872425.7153 - val_loss: 5999835535.7808\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10316060810.7581 - val_loss: 5998018780.9315\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10194902616.6998 - val_loss: 5997930243.5068\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10124651642.0720 - val_loss: 5994089654.3562\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9932595699.7050 - val_loss: 5989803477.9178\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10466250335.7256 - val_loss: 5988691533.1507\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10172749151.2864 - val_loss: 5990095819.3973\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10112631757.0635 - val_loss: 5987867847.8904\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10148357286.8611 - val_loss: 5985874474.0822\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10282939010.8542 - val_loss: 5986937484.2740\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10089372592.0823 - val_loss: 5989548452.8219\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9996382929.8937 - val_loss: 5987862461.3699\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10058634354.1681 - val_loss: 5987687487.1233\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10398328192.6587 - val_loss: 5983108976.2192\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10525381350.9708 - val_loss: 5984445969.5342\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10609343288.6449 - val_loss: 5984994381.1507\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9989738146.4700 - val_loss: 5981754806.3562\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10539000965.4889 - val_loss: 5976988142.4658\n",
      "Epoch 486/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 144us/step - loss: 9752549832.6724 - val_loss: 5971550246.5753\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9924127215.3139 - val_loss: 5968385627.1781\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10318196121.2487 - val_loss: 5970798816.4384\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9835272365.8868 - val_loss: 5971552925.8082\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10472330204.8714 - val_loss: 5966804031.1233\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10264962987.6913 - val_loss: 5967805071.7808\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9908848583.7942 - val_loss: 5969317390.0274\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10364590630.6415 - val_loss: 5969360026.3014\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9750927293.2556 - val_loss: 5966895700.1644\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9854254752.7136 - val_loss: 5967404333.5890\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10046861594.7856 - val_loss: 5964200511.1233\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9864206516.0343 - val_loss: 5961082943.1233\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 10004671444.0892 - val_loss: 5960141568.0000\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9998722786.5798 - val_loss: 5958619788.2740\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10403920016.9057 - val_loss: 5963311121.5342\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10399483518.4631 - val_loss: 5961851058.8493\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9903715980.5146 - val_loss: 5960511761.5342\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10506395643.6089 - val_loss: 5959507189.4795\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9574800578.0858 - val_loss: 5957261539.9452\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9923382159.5883 - val_loss: 5950640415.5616\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 10430969809.8937 - val_loss: 5947982844.4932\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10325760757.0223 - val_loss: 5952274284.7123\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10146636390.3122 - val_loss: 5953567733.4795\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10798438702.9846 - val_loss: 5957784747.8356\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10925027101.4202 - val_loss: 5959131619.9452\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10942958656.1098 - val_loss: 5959159148.7123\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10512086881.9211 - val_loss: 5959029139.2877\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10138873798.9160 - val_loss: 5957090542.4658\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10368781908.3087 - val_loss: 5958456277.9178\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10800993830.6415 - val_loss: 5959280334.9041\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10117700435.8696 - val_loss: 5963405915.1781\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9922262928.0274 - val_loss: 5962705155.5068\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10146662089.1115 - val_loss: 5961599691.3973\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9816777276.5969 - val_loss: 5959086083.5068\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10384715895.4374 - val_loss: 5964375727.3425\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9770178986.8130 - val_loss: 5965404920.9863\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9789271161.1938 - val_loss: 5965870009.8630\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10360110712.3156 - val_loss: 5965299136.8767\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10238849819.6638 - val_loss: 5964085633.7534\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 10298217013.5712 - val_loss: 5966025475.5068\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 10476019044.5557 - val_loss: 5966735268.8219\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 10092085642.7581 - val_loss: 5964802686.2466\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 10341708732.3774 - val_loss: 5959404452.8219\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 10178619239.1904 - val_loss: 5957705910.3562\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 10220574653.2556 - val_loss: 5957763871.5616\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 10101990707.8148 - val_loss: 5957143173.2603\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10106377521.6192 - val_loss: 5957497126.5753\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9755968072.0137 - val_loss: 5955957977.4247\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10178077906.7719 - val_loss: 5954713231.7808\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 10293613229.0086 - val_loss: 5944848384.0000\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10202290935.6569 - val_loss: 5949249472.8767\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 9993467897.8525 - val_loss: 5950678538.5205\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 9691648851.8696 - val_loss: 5952053619.7260\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10250123399.2453 - val_loss: 5950887760.6575\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 10131210288.3019 - val_loss: 5950613262.0274\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 9557584476.2127 - val_loss: 5949691714.6301\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10527310256.0823 - val_loss: 5949450685.3699\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10335736851.3208 - val_loss: 5951177868.2740\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9802088156.4322 - val_loss: 5948793336.9863\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10084429125.8182 - val_loss: 5950052821.9178\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10338470939.2247 - val_loss: 5950086484.1644\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9721217178.5660 - val_loss: 5945918576.2192\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10139919554.9640 - val_loss: 5943843485.8082\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9982142753.8113 - val_loss: 5946519222.3562\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10650532173.7221 - val_loss: 5945943089.0959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10276672529.5643 - val_loss: 5944352778.5205\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10282162681.8525 - val_loss: 5942833376.4384\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10170220324.4460 - val_loss: 5942955590.1370\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9839693639.5746 - val_loss: 5938284302.0274\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 10050753746.7719 - val_loss: 5935958121.2055\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10362795406.7101 - val_loss: 5940267397.2603\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9981625603.0738 - val_loss: 5937933838.0274\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10226631790.6552 - val_loss: 5943273482.5205\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9780304078.3808 - val_loss: 5946069525.0411\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10229056835.1835 - val_loss: 5944668791.2329\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10106614615.3825 - val_loss: 5946095135.5616\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9826095478.9983 - val_loss: 5948359771.1781\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9677521102.3808 - val_loss: 5948045417.2055\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10250812680.3431 - val_loss: 5949099975.8904\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10206844492.4048 - val_loss: 5946925308.4932\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9729219847.4648 - val_loss: 5950008502.3562\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 10100059712.9880 - val_loss: 5950517689.8630\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9795283834.5111 - val_loss: 5950290298.7397\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10030111504.2470 - val_loss: 5951985579.8356\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10236734212.8302 - val_loss: 5946616474.3014\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10355268622.0515 - val_loss: 5950119367.8904\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10273086356.8576 - val_loss: 5954488109.5890\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10381317062.0377 - val_loss: 5959479352.1096\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9505776888.5352 - val_loss: 5959513754.3014\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10138977586.0583 - val_loss: 5961057381.6986\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9910464296.8370 - val_loss: 5959038379.8356\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10200683512.9743 - val_loss: 5956209558.7945\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9665570974.0789 - val_loss: 5951343791.3425\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10286552499.5952 - val_loss: 5948696449.7534\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9919237108.5832 - val_loss: 5949097976.9863\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10343112664.4803 - val_loss: 5952857473.7534\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9986869567.6707 - val_loss: 5945455700.1644\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10115350649.1938 - val_loss: 5942935025.9726\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10084230317.8868 - val_loss: 5943059827.7260\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10128090054.9160 - val_loss: 5943726174.6849\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9777605268.4185 - val_loss: 5942501965.1507\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10281975281.9485 - val_loss: 5946906792.3288\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10172552741.7633 - val_loss: 5947591150.4658\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10174195062.9983 - val_loss: 5951950977.7534\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9797966295.6021 - val_loss: 5949942152.7671\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10252036116.1990 - val_loss: 5952157219.0685\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10137382766.2161 - val_loss: 5949509372.4932\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10183307778.6346 - val_loss: 5951668444.9315\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10038944284.1029 - val_loss: 5949575581.8082\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9919641087.1218 - val_loss: 5946918407.0137\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10191980433.3448 - val_loss: 5948889242.3014\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9614911208.7273 - val_loss: 5947725031.4521\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9717410751.8902 - val_loss: 5950528652.2740\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10320516646.2024 - val_loss: 5950669971.2877\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10273133508.2813 - val_loss: 5946933219.9452\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9588999914.4837 - val_loss: 5943906304.0000\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10215644437.5163 - val_loss: 5943359992.9863\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10436727305.6604 - val_loss: 5946303894.7945\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10372572408.5352 - val_loss: 5946333110.3562\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10391601714.0583 - val_loss: 5946361224.7671\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10287497294.1612 - val_loss: 5944861089.3151\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10277396151.5472 - val_loss: 5942330094.4658\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10071380777.7153 - val_loss: 5939929291.3973\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9877343918.7650 - val_loss: 5939195251.7260\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9925438360.8096 - val_loss: 5941342600.7671\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10199724820.6381 - val_loss: 5941195295.5616\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9823467558.6415 - val_loss: 5937641317.6986\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10137325604.0069 - val_loss: 5936608049.0959\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10414368445.6947 - val_loss: 5936255733.4795\n",
      "Epoch 615/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 9878233607.9039 - val_loss: 5927433899.8356\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9801832065.0978 - val_loss: 5930249345.7534\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10144860439.2727 - val_loss: 5934322140.9315\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 9649238513.0703 - val_loss: 5932510186.9589\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10129135567.6981 - val_loss: 5932177748.1644\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9705268353.9760 - val_loss: 5930113045.0411\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9849196267.3619 - val_loss: 5930478883.0685\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10298888316.7067 - val_loss: 5934552078.0274\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10407077440.9880 - val_loss: 5940324667.6164\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 11220944932.8851 - val_loss: 5939547690.0822\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10661746183.9039 - val_loss: 5940961728.8767\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10456244505.0292 - val_loss: 5942514084.8219\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10360986862.8748 - val_loss: 5945665781.4795\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10240527166.7925 - val_loss: 5943575141.6986\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10177516912.8508 - val_loss: 5941601357.1507\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10061265033.8799 - val_loss: 5942999141.6986\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 10461520108.307 - 0s 142us/step - loss: 10233233589.7907 - val_loss: 5944103371.3973\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10095418656.0549 - val_loss: 5946349676.7123\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10406628128.0549 - val_loss: 5946989792.4384\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9954141771.5266 - val_loss: 5947198106.3014\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10586103890.5523 - val_loss: 5949626038.3562\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10146140356.7204 - val_loss: 5948494413.1507\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9938661425.1801 - val_loss: 5952660504.5479\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9877168676.0069 - val_loss: 5950448520.7671\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10532569172.3087 - val_loss: 5950553838.4658\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10012869909.5163 - val_loss: 5950717250.6301\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10231684776.6175 - val_loss: 5957646009.8630\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10287263210.0446 - val_loss: 5954064180.6027\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10747943751.5746 - val_loss: 5952848233.2055\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10199898268.3225 - val_loss: 5952465057.3151\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10351285168.9605 - val_loss: 5954645784.5479\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9984535847.9588 - val_loss: 5955731189.4795\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10769868706.9091 - val_loss: 5963049037.1507\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 10201279004.9811 - val_loss: 5970648109.5890\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10583104015.8079 - val_loss: 5970099666.4110\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10380384793.4683 - val_loss: 5972311832.5479\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10464511491.5129 - val_loss: 5972940656.2192\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9883517454.9297 - val_loss: 5971388461.5890\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10377604103.9039 - val_loss: 5971288365.5890\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 10494644234.5386 - val_loss: 5971195314.8493\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10067302187.4717 - val_loss: 5969400996.8219\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10432844812.2950 - val_loss: 5975604578.1918\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10376357066.8679 - val_loss: 5978090573.1507\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10322038993.0154 - val_loss: 5976890830.9041\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10389412763.8834 - val_loss: 5975724887.6712\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9741118668.6244 - val_loss: 5968214969.8630\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10037118032.7959 - val_loss: 5963830138.7397\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10121961854.9022 - val_loss: 5964683351.6712\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9921446017.5369 - val_loss: 5960522296.1096\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10264238284.6244 - val_loss: 5962399456.4384\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9757205576.8919 - val_loss: 5959879967.5616\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10062448642.6346 - val_loss: 5959048128.8767\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10387588894.2985 - val_loss: 5959744831.1233\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10494551416.3156 - val_loss: 5960091861.9178\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9922204475.2796 - val_loss: 5960022096.6575\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10113470952.2882 - val_loss: 5960636072.3288\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10856677418.1544 - val_loss: 5958741903.7808\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10144805578.8679 - val_loss: 5957737948.9315\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9964874251.4168 - val_loss: 5951061651.2877\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10437754725.4340 - val_loss: 5953194531.0685\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9733325418.2642 - val_loss: 5953906568.7671\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9901510058.8130 - val_loss: 5954285813.4795\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10159923272.0137 - val_loss: 5950858629.2603\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9923578819.4031 - val_loss: 5946082514.4110\n",
      "Epoch 679/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 152us/step - loss: 10247835905.3173 - val_loss: 5945308387.9452\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10224872793.1389 - val_loss: 5942487993.8630\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10447437017.7976 - val_loss: 5942375928.9863\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10384447306.2093 - val_loss: 5943612107.3973\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10129718623.2864 - val_loss: 5940847886.0274\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10464033812.1990 - val_loss: 5944677351.4521\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10114618336.3842 - val_loss: 5948125990.5753\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10451105630.4082 - val_loss: 5949455843.9452\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10021213068.0755 - val_loss: 5954947541.9178\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10513256140.6244 - val_loss: 5956537526.3562\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10481877118.4631 - val_loss: 5959759710.6849\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10199899088.5763 - val_loss: 5959712368.2192\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9779059139.4031 - val_loss: 5959120489.2055\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9837429139.9794 - val_loss: 5955884522.9589\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9967889237.6261 - val_loss: 5951633393.9726\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10377154232.4254 - val_loss: 5952610970.3014\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10214593250.5798 - val_loss: 5950134440.3288\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10140169569.9211 - val_loss: 5949391945.6438\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10808594323.1012 - val_loss: 5953637614.4658\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10237243869.3105 - val_loss: 5947958107.1781\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10234522806.6690 - val_loss: 5946846393.8630\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10884285519.0395 - val_loss: 5943670110.6849\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10461925969.6741 - val_loss: 5943166064.2192\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10298286217.0017 - val_loss: 5945525738.9589\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10083229145.3585 - val_loss: 5943144286.6849\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10168359971.1286 - val_loss: 5942732863.1233\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10196066099.3756 - val_loss: 5939852919.2329\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9945706570.2093 - val_loss: 5941874817.7534\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10192329446.9708 - val_loss: 5942073140.6027\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9906807158.9983 - val_loss: 5935251799.6712\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10511305541.8182 - val_loss: 5936122518.7945\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10077424315.0600 - val_loss: 5932040626.8493\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10160081198.9846 - val_loss: 5931250905.4247\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10192115942.0926 - val_loss: 5931625310.6849\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10542727013.4340 - val_loss: 5936136574.2466\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9945227550.2985 - val_loss: 5935070222.0274\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9762028976.0823 - val_loss: 5935153327.3425\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 9679575111.680 - 0s 147us/step - loss: 10410440514.3053 - val_loss: 5935827526.1370\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10013582070.7787 - val_loss: 5934318332.4932\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9573083322.1818 - val_loss: 5931577259.8356\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9988828893.3105 - val_loss: 5931668185.4247\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9906081292.2950 - val_loss: 5933856841.6438\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10399178229.4614 - val_loss: 5932049583.3425\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9797338645.9554 - val_loss: 5929815481.8630\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10123428896.4940 - val_loss: 5932809479.0137\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9576592165.3242 - val_loss: 5938013162.9589\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 10228048549.9828 - val_loss: 5935982991.7808\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10149306009.6878 - val_loss: 5936739545.4247\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10297706710.2847 - val_loss: 5935777806.0274\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10193673600.6587 - val_loss: 5937912116.6027\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10839340813.6123 - val_loss: 5938395605.9178\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9718592656.0274 - val_loss: 5935604960.4384\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10265667307.3619 - val_loss: 5935833698.1918\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10562251180.5695 - val_loss: 5937521201.0959\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10360778674.7170 - val_loss: 5941915041.3151\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10204886333.0360 - val_loss: 5943516717.5890\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9614652581.1046 - val_loss: 5944038827.8356\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9910905959.6295 - val_loss: 5946869609.2055\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10057259102.8473 - val_loss: 5952705104.6575\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10035661146.0172 - val_loss: 5952162314.5205\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9824869664.0549 - val_loss: 5958678478.9041\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10166816337.6741 - val_loss: 5962757653.0411\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10074071345.6192 - val_loss: 5961322646.7945\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9244222363.8834 - val_loss: 5961326027.3973\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 153us/step - loss: 10111089219.6226 - val_loss: 5962714848.4384\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9065161510.2024 - val_loss: 5960224490.9589\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10467058229.5712 - val_loss: 5961282237.3699\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9932919571.7599 - val_loss: 5958111228.4932\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10075051525.2693 - val_loss: 5957909034.0822\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10066575658.5935 - val_loss: 5960451121.0959\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10549023127.4923 - val_loss: 5957410703.7808\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10285165430.1201 - val_loss: 5962464403.2877\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9713379501.0086 - val_loss: 5959145170.4110\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10245981057.5369 - val_loss: 5959203303.4521\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10253205268.6381 - val_loss: 5958671970.1918\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9927970139.7736 - val_loss: 5957372780.7123\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9681490070.1750 - val_loss: 5955969641.2055\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9975777483.7461 - val_loss: 5958509168.2192\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10139783399.4100 - val_loss: 5957137902.4658\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10260700633.3585 - val_loss: 5956232802.1918\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10051797590.9434 - val_loss: 5953267080.7671\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9938302586.0720 - val_loss: 5954816638.2466\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10134403704.3156 - val_loss: 5950041971.7260\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10304852565.1870 - val_loss: 5949891861.0411\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10474543362.1955 - val_loss: 5948329570.1918\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10502384390.5866 - val_loss: 5947901138.4110\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9852135598.7650 - val_loss: 5946939732.1644\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 10093814267.6089 - val_loss: 5949284828.9315\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9929202898.7719 - val_loss: 5950420999.0137\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9976553642.3739 - val_loss: 5952654023.8904\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9972921353.6604 - val_loss: 5953422521.8630\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10254644034.3053 - val_loss: 5953868989.3699\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9936932056.0412 - val_loss: 5952832007.0137\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9804283413.0772 - val_loss: 5953953907.7260\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10451187188.5832 - val_loss: 5949418204.9315\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10270779534.2710 - val_loss: 5948778264.5479\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10157185572.0069 - val_loss: 5944956822.7945\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10273884416.4391 - val_loss: 5950424127.1233\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10257028191.7256 - val_loss: 5950049216.8767\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10083873026.1955 - val_loss: 5950135541.4795\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10217844954.6758 - val_loss: 5947700346.7397\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9915407985.2899 - val_loss: 5946420392.3288\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10086614366.4082 - val_loss: 5946627906.6301\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9816779837.4751 - val_loss: 5946766069.4795\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9642229181.2556 - val_loss: 5941786076.9315\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9791987489.8113 - val_loss: 5944166954.0822\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10122778228.8027 - val_loss: 5944586860.7123\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9503782626.5798 - val_loss: 5942109878.3562\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10267254007.6569 - val_loss: 5941900957.8082\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9807218369.2075 - val_loss: 5941743875.5068\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9965968748.4597 - val_loss: 5943726174.6849\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10312059146.9777 - val_loss: 5944569589.4795\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9861115556.2264 - val_loss: 5944030684.9315\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9838028477.6947 - val_loss: 5943844720.2192\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10267053344.9331 - val_loss: 5942055227.6164\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10163394760.2333 - val_loss: 5939809427.2877\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10619705733.0497 - val_loss: 5941548421.2603\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10417058842.3465 - val_loss: 5948574229.0411\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10220698129.1252 - val_loss: 5946366968.9863\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10862200234.8130 - val_loss: 5948945783.2329\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10209328870.9708 - val_loss: 5950473766.5753\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10591592548.1166 - val_loss: 5953193345.7534\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9881174943.3962 - val_loss: 5957009169.5342\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10210714638.0515 - val_loss: 5957580807.0137\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10172876650.7033 - val_loss: 5957642317.1507\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10115298627.1835 - val_loss: 5962328814.4658\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10096136659.2110 - val_loss: 5962866730.0822\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9875285373.1458 - val_loss: 5963531786.5205\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9829284135.0806 - val_loss: 5961720144.6575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9974843147.8559 - val_loss: 5959440012.2740\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 10238555736.6998 - val_loss: 5958701189.2603\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10252898137.1389 - val_loss: 5959601916.4932\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10933669267.9794 - val_loss: 5960277377.7534\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10059252656.9605 - val_loss: 5960268870.1370\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9958192678.6415 - val_loss: 5962199815.0137\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 10551853705.8799 - val_loss: 5962112890.7397\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9808477923.4580 - val_loss: 5963258571.3973\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10490462367.8353 - val_loss: 5964085633.7534\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10137088535.7118 - val_loss: 5968348798.2466\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9604052540.5969 - val_loss: 5966935036.4932\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10618470475.5266 - val_loss: 5970079372.2740\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9934610334.9571 - val_loss: 5970772157.3699\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9916059551.3962 - val_loss: 5968618218.9589\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10111649101.7221 - val_loss: 5969315727.7808\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10040377973.6810 - val_loss: 5971457620.1644\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10340911712.6038 - val_loss: 5968793585.9726\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10194319792.5214 - val_loss: 5968701040.2192\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10249906430.6827 - val_loss: 5965649765.6986\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9900729603.0738 - val_loss: 5961823617.7534\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9972181734.9708 - val_loss: 5963991145.2055\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9595734019.5129 - val_loss: 5960195191.2329\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10281203206.1475 - val_loss: 5958197139.2877\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9316736950.2298 - val_loss: 5956914603.8356\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10714670505.9348 - val_loss: 5959999838.6849\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10110762081.4820 - val_loss: 5956516141.5890\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11014139310.3259 - val_loss: 5959450550.3562\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9877939021.7221 - val_loss: 5953368232.3288\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10038233448.0686 - val_loss: 5954013611.8356\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9826981498.0720 - val_loss: 5952983587.0685\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9950116113.1252 - val_loss: 5952171418.3014\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10141543444.1990 - val_loss: 5956235958.3562\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10339671490.5249 - val_loss: 5953405839.7808\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10637159458.2504 - val_loss: 5959481884.0548\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10368541945.4134 - val_loss: 5960980883.2877\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10557302357.1870 - val_loss: 5961794900.1644\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10296439326.7376 - val_loss: 5956678042.3014\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9499448986.5660 - val_loss: 5953624677.6986\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10059877335.6021 - val_loss: 5953072899.5068\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10813197155.6775 - val_loss: 5953658462.6849\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10185885618.7170 - val_loss: 5958355210.5205\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10796852768.4940 - val_loss: 5958799156.6027\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9983236050.3328 - val_loss: 5965069848.5479\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10134317056.0000 - val_loss: 5960946140.9315\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10298030716.7067 - val_loss: 5961620711.4521\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10036562049.9760 - val_loss: 5961066517.0411\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10214582142.0240 - val_loss: 5957764797.3699\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10451891956.1441 - val_loss: 5958309221.6986\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9929180041.4408 - val_loss: 5959645394.4110\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10146362911.1767 - val_loss: 5960656110.4658\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9810298518.1750 - val_loss: 5957667811.9452\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10022761362.2230 - val_loss: 5957139259.6164\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9864272202.2093 - val_loss: 5955955245.5890\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 9746308775.7393 - val_loss: 5953652574.6849\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10364730013.2007 - val_loss: 5955796076.7123\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10121075919.2590 - val_loss: 5953172750.0274\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 9938650482.6072 - val_loss: 5953522488.1096\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9856966032.4666 - val_loss: 5952311134.6849\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9962384042.8130 - val_loss: 5946986159.3425\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10417132212.0343 - val_loss: 5952820988.4932\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10204047879.9039 - val_loss: 5952889056.4384\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9756972511.5060 - val_loss: 5953603941.6986\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10210257515.1424 - val_loss: 5953819171.0685\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 10220756681.1115 - val_loss: 5950385467.6164\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 170us/step - loss: 9987756295.4648 - val_loss: 5947565399.6712\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9770731495.4100 - val_loss: 5946952630.3562\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10107561218.1955 - val_loss: 5948779558.5753\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10441362414.4357 - val_loss: 5950832145.5342\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10079202425.6329 - val_loss: 5951818415.3425\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10566353793.5369 - val_loss: 5956516678.1370\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9888417637.4340 - val_loss: 5952125327.7808\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9879754263.7118 - val_loss: 5949263500.2740\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9925941548.3499 - val_loss: 5948898282.9589\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10307532826.3465 - val_loss: 5950281559.6712\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10118977824.9331 - val_loss: 5949241722.7397\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 10038515000.6449 - val_loss: 5951919847.4521\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 10265882618.7307 - val_loss: 5956516141.5890\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 9859554223.2041 - val_loss: 5951992874.0822\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10236679691.4168 - val_loss: 5958668929.7534\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 10394676410.1818 - val_loss: 5959780702.6849\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 10669851588.2813 - val_loss: 5964739057.9726\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 10001530980.1166 - val_loss: 5964740636.0548\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 10051451861.8456 - val_loss: 5965833657.8630\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10415054537.1115 - val_loss: 5966249584.2192\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10093496242.7170 - val_loss: 5968783805.3699\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10411018081.0429 - val_loss: 5965872745.2055\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10126309265.3448 - val_loss: 5970143572.1644\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10029244389.6535 - val_loss: 5967827000.1096\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9825930542.1063 - val_loss: 5968412791.2329\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10228506922.5935 - val_loss: 5972123921.5342\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10593722230.9983 - val_loss: 5970218138.3014\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10091615233.7564 - val_loss: 5968708590.4658\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 9782724517.5437 - val_loss: 5965765467.1781\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10001802449.8937 - val_loss: 5965769412.3836\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10064000424.1784 - val_loss: 5962834719.5616\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10123450626.1955 - val_loss: 5965760256.0000\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10032828662.7787 - val_loss: 5963369934.9041\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10071771348.5283 - val_loss: 5960745065.2055\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10330777770.3739 - val_loss: 5958273272.9863\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10890503125.8456 - val_loss: 5961680331.3973\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9847744057.0840 - val_loss: 5964561955.0685\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9880375338.1544 - val_loss: 5956735182.9041\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9802029201.7839 - val_loss: 5955685744.2192\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9885825948.7616 - val_loss: 5952917570.6301\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10283555134.7925 - val_loss: 5952858659.0685\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10293858933.6810 - val_loss: 5952709218.1918\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9995025069.8868 - val_loss: 5957366727.8904\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 9832374106.8954 - val_loss: 5955225410.6301\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10218705577.4957 - val_loss: 5956643580.4932\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 10580390773.2419 - val_loss: 5955390968.9863\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10173649354.4288 - val_loss: 5955801375.5616\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10198920192.0000 - val_loss: 5954706979.0685\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10407787360.1647 - val_loss: 5958000976.6575\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10324484146.0583 - val_loss: 5955759787.8356\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9636708210.1681 - val_loss: 5950101391.7808\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10096133019.8834 - val_loss: 5954357430.3562\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10126544608.8233 - val_loss: 5955889197.5890\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10064280435.4854 - val_loss: 5957729409.7534\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10435409956.0069 - val_loss: 5956648314.7397\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9993947927.2727 - val_loss: 5956436935.8904\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10484788864.2196 - val_loss: 5959151089.9726\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9994161000.9468 - val_loss: 5960123195.6164\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9851099977.3310 - val_loss: 5958976504.9863\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10345346903.8216 - val_loss: 5958212103.0137\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10375973187.1835 - val_loss: 5957083865.4247\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 9831609928.8919 - val_loss: 5955741075.2877\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10426835439.3139 - val_loss: 5953297649.9726\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10269107674.2367 - val_loss: 5952077676.7123\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10021831482.4014 - val_loss: 5955277978.3014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10136059743.2864 - val_loss: 5953533930.9589\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9818341703.5746 - val_loss: 5952879254.7945\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9447138969.6878 - val_loss: 5952937573.6986\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10882924728.8645 - val_loss: 5955107889.0959\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10696428356.9400 - val_loss: 5956193693.8082\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9217259312.7410 - val_loss: 5953215435.3973\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10245047626.2093 - val_loss: 5956226998.3562\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10177557394.2230 - val_loss: 5957803116.7123\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10036994615.7667 - val_loss: 5953234989.5890\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10013166119.5197 - val_loss: 5951220977.9726\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10094400809.7153 - val_loss: 5950747563.8356\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9967853618.9365 - val_loss: 5950815379.2877\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10322718280.8919 - val_loss: 5949854250.0822\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9879348626.2230 - val_loss: 5949982642.8493\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9711033322.4837 - val_loss: 5949351206.5753\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9574999714.4700 - val_loss: 5944525841.5342\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9960442703.4786 - val_loss: 5941428918.3562\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10011726082.1955 - val_loss: 5940920007.8904\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10411748732.2676 - val_loss: 5942820138.0822\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10094696948.5832 - val_loss: 5942057703.4521\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10914493078.1750 - val_loss: 5944052378.3014\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9995394847.1767 - val_loss: 5947742492.0548\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9840831946.4288 - val_loss: 5947580696.5479\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9670372088.5352 - val_loss: 5947512544.4384\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10030423256.0412 - val_loss: 5945554838.7945\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 10593961861.120 - 0s 147us/step - loss: 10354929498.4563 - val_loss: 5945788952.5479\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10139116964.6655 - val_loss: 5947202132.1644\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10271039396.6655 - val_loss: 5951550702.4658\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10531740484.0618 - val_loss: 5951899220.1644\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10368298386.2230 - val_loss: 5953234147.9452\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 9857545029.8182 - val_loss: 5950363381.4795\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9903506957.1732 - val_loss: 5949360815.3425\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10339522598.6415 - val_loss: 5945176141.1507\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9766891903.7804 - val_loss: 5944274712.5479\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10273473060.0069 - val_loss: 5944666308.3836\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10015935298.3053 - val_loss: 5941054607.7808\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10411871251.3208 - val_loss: 5942937052.9315\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9805284914.0583 - val_loss: 5940872875.8356\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10485686303.6158 - val_loss: 5942707340.2740\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10353517242.1818 - val_loss: 5943372140.7123\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10013133599.1767 - val_loss: 5938965826.6301\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10023298016.3842 - val_loss: 5941093596.9315\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10048968417.7015 - val_loss: 5944541422.4658\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10093535521.8113 - val_loss: 5945516887.6712\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 9888877183.3413 - val_loss: 5942276765.8082\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10118195783.1355 - val_loss: 5940051634.8493\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10677357239.5472 - val_loss: 5942816108.7123\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10126433849.0840 - val_loss: 5944665519.3425\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10188682261.0772 - val_loss: 5946743643.1781\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10048590036.0892 - val_loss: 5950312556.7123\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10286698878.9022 - val_loss: 5948015889.5342\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9731502628.0069 - val_loss: 5946759732.6027\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 9972342766.4357 - val_loss: 5946410755.5068\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 9741612017.0703 - val_loss: 5946633882.3014\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10455046506.7033 - val_loss: 5945565120.8767\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9956271112.7822 - val_loss: 5949478270.2466\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 11161855774.720 - 0s 145us/step - loss: 10640509779.8696 - val_loss: 5951683064.9863\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10178377381.9828 - val_loss: 5952279552.0000\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10410391295.5609 - val_loss: 5958537061.6986\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10193730728.6175 - val_loss: 5961450797.5890\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10664849175.7118 - val_loss: 5964453670.5753\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9814657832.8370 - val_loss: 5957909034.0822\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10647082071.8216 - val_loss: 5956362695.8904\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10673451368.0686 - val_loss: 5958999327.5616\n",
      "neurons used (8, 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 576us/step - loss: 39208807436.2950 - val_loss: 38415781888.0000\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 39202991959.3825 - val_loss: 38408097315.0685\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 39193824401.7839 - val_loss: 38397093803.8356\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 39181343011.5677 - val_loss: 38381553074.8493\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 39166024965.7084 - val_loss: 38366844928.0000\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 39146962227.3756 - val_loss: 38348449427.2877\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 39124496275.1012 - val_loss: 38321946371.5069\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 39100158738.8816 - val_loss: 38296868274.8493\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 39071012902.6415 - val_loss: 38269669937.0959\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 225us/step - loss: 39041911616.5489 - val_loss: 38237489488.6575\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 39006866851.7873 - val_loss: 38194781310.2466\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 38969663719.8491 - val_loss: 38155077070.9041\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 266us/step - loss: 38929314466.4700 - val_loss: 38116750265.8630\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 38886367470.8748 - val_loss: 38071061349.6986\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 38840250101.0223 - val_loss: 38025952718.9041\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 250us/step - loss: 38793218192.0274 - val_loss: 37968344611.0685\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 38733249653.6810 - val_loss: 37911029114.7397\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 38685647951.0395 - val_loss: 37857125558.3562\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 38623038658.9640 - val_loss: 37790691832.9863\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 266us/step - loss: 38558805071.0395 - val_loss: 37724314778.3014\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 38493913344.4391 - val_loss: 37655684530.8493\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 38424722261.6261 - val_loss: 37593524139.8356\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 38356296487.9588 - val_loss: 37520277279.5616\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 38288804022.6690 - val_loss: 37452486487.6712\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 38198226571.6364 - val_loss: 37372752797.8082\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 38124801531.6089 - val_loss: 37298359730.8493\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 38052884655.6432 - val_loss: 37213080085.0411\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 37965773597.4202 - val_loss: 37130415903.5616\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 37874925571.5129 - val_loss: 37040089733.2603\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 37778581212.4323 - val_loss: 36948747221.9178\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 37680624715.5266 - val_loss: 36854199225.8630\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 37598203103.0669 - val_loss: 36748260899.0685\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 37493224649.9897 - val_loss: 36646007962.3014\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 37415760212.7479 - val_loss: 36535807495.0137\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 37289249895.6295 - val_loss: 36427218831.7808\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 37196030422.7238 - val_loss: 36322176631.2329\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 37063123059.9245 - val_loss: 36214611182.4658\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 36963088078.3808 - val_loss: 36097478066.8493\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 36856809805.7221 - val_loss: 35990485609.2055\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 36736843849.7702 - val_loss: 35853620658.8493\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 36611243779.0738 - val_loss: 35740637408.4384\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 36493326427.3345 - val_loss: 35639826740.6027\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 36352560063.0120 - val_loss: 35526497350.1370\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 36230691012.7204 - val_loss: 35381830333.3699\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 36127821174.1201 - val_loss: 35258847400.3288\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 35969097468.0480 - val_loss: 35118946107.6164\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 35819913504.0549 - val_loss: 34991015599.3425\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 35673553798.8062 - val_loss: 34845510445.5890\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 35565616663.7118 - val_loss: 34703731277.1507\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 35412109273.3585 - val_loss: 34543182553.4247\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 35272036524.1304 - val_loss: 34387406539.3973\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 35124937216.8782 - val_loss: 34243106900.1644\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 34980104947.2659 - val_loss: 34080866163.7260\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 34788708931.6226 - val_loss: 33931580682.5205\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 34630471212.7890 - val_loss: 33758821221.6986\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 34506902329.5232 - val_loss: 33592651186.8493\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 34356561895.4100 - val_loss: 33450725880.9863\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 34189936594.3328 - val_loss: 33284707370.0822\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 33983292055.9314 - val_loss: 33103569344.8767\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 33763353924.9400 - val_loss: 32927692800.0000\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 33636869508.1715 - val_loss: 32756477306.7397\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 33472809954.1407 - val_loss: 32596695180.2740\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 33341673879.4923 - val_loss: 32421488106.9589\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 33074385113.7976 - val_loss: 32238775478.3562\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 201us/step - loss: 32994503737.9623 - val_loss: 32067391516.0548\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 32798382410.2093 - val_loss: 31879483055.3425\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 32589239547.1698 - val_loss: 31696865925.2603\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 32384034383.9177 - val_loss: 31502499615.5616\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 32241730084.0069 - val_loss: 31322806468.3836\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 32114531986.6621 - val_loss: 31133387172.8219\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 31817311349.6810 - val_loss: 30935848735.5616\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 31663546979.2384 - val_loss: 30701432972.2740\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 31464224385.0978 - val_loss: 30505678427.1781\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 31250522347.3619 - val_loss: 30321167205.6986\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 31115206248.5077 - val_loss: 30128826283.8356\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 30915908968.0686 - val_loss: 29931339635.7260\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 30657388554.5386 - val_loss: 29715092269.5890\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 30447616709.5986 - val_loss: 29551022051.9452\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 30268084873.8799 - val_loss: 29338525106.8493\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 30068318053.4340 - val_loss: 29140784618.9589\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 29878608708.0618 - val_loss: 28907803633.9726\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 29687341147.3345 - val_loss: 28683882215.4521\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 29486794938.1818 - val_loss: 28453263556.3836\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 29250645348.5557 - val_loss: 28234830777.8630\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 28984108219.9383 - val_loss: 28026104088.5479\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 28704989753.0840 - val_loss: 27808451036.9315\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 28579569765.8731 - val_loss: 27587866231.2329\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 28300636044.0755 - val_loss: 27365684153.8630\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 28170804043.0875 - val_loss: 27131445781.0411\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 28020188881.8937 - val_loss: 26910156323.0685\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 27792195053.5575 - val_loss: 26699456007.0137\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 27434145781.4614 - val_loss: 26483197362.8493\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 27168595929.3585 - val_loss: 26253234540.7123\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 27068401084.3774 - val_loss: 26025836992.8767\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 26826869171.5952 - val_loss: 25800370007.6712\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 26570784585.3310 - val_loss: 25567663819.3973\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 26405639830.1750 - val_loss: 25325920760.9863\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 26106422575.8628 - val_loss: 25086451263.1233\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 25833107505.1801 - val_loss: 24856183906.1918\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 25702329359.8079 - val_loss: 24607691313.0959\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 25505272967.2453 - val_loss: 24374108075.8356\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25104822468.7204 - val_loss: 24142759907.9452\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 25018435977.4408 - val_loss: 23913557398.7945\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 24888049941.5163 - val_loss: 23672507153.5342\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 24543475571.4854 - val_loss: 23438128394.5205\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 24305667684.9949 - val_loss: 23208522289.0959\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 24099905163.6364 - val_loss: 22967627691.8356\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 23567595546.3465 - val_loss: 22728643569.9726\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 23400776667.1149 - val_loss: 22477580778.9589\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 23298892239.6981 - val_loss: 22248112534.7945\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 23214144492.6792 - val_loss: 22019521662.2466\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 22904171114.2642 - val_loss: 21786488691.7260\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 22610989618.0583 - val_loss: 21522872909.1507\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 22376533318.6964 - val_loss: 21281617821.8082\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 22180964503.0532 - val_loss: 21037628626.4110\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 21944896366.2161 - val_loss: 20805518826.9589\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 21668575274.1544 - val_loss: 20582081788.4931\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 21437718821.3242 - val_loss: 20319929077.4795\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 21221038628.0069 - val_loss: 20086725674.0822\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 21041060869.2693 - val_loss: 19833714056.7671\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 20734663727.4237 - val_loss: 19575254815.5616\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 20663699993.4683 - val_loss: 19349370865.9726\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 20214747829.7907 - val_loss: 19106737390.4658\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 19956672118.5592 - val_loss: 18871784560.2192\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 19709742224.0274 - val_loss: 18630034249.6438\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 19658723229.6398 - val_loss: 18413997070.0274\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 19377967086.4357 - val_loss: 18173372331.8356\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 19148845561.8525 - val_loss: 17914334306.1918\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 165us/step - loss: 18802636540.0480 - val_loss: 17656677376.0000\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 18619682984.6175 - val_loss: 17434011816.3288\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 18405866685.6947 - val_loss: 17192942690.1918\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 18209529276.3774 - val_loss: 16966316943.7808\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 18092167956.6381 - val_loss: 16732333378.6301\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 17701165349.3242 - val_loss: 16511149280.4384\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 17596410857.1664 - val_loss: 16262279111.8904\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 17203149323.4168 - val_loss: 16029051034.3014\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 17071543913.3859 - val_loss: 15820190102.7945\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 16824577775.7530 - val_loss: 15589249977.8630\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 16582594415.9726 - val_loss: 15354781611.8356\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 16477016136.0137 - val_loss: 15145375491.5068\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 15993388783.7530 - val_loss: 14919862987.3973\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 15903514659.1286 - val_loss: 14675869878.3562\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 15703993057.7015 - val_loss: 14445063378.4110\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 15296238028.1852 - val_loss: 14220721208.1096\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 15105876638.9571 - val_loss: 13985191248.6575\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 14998339858.8816 - val_loss: 13787414219.3973\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 14692829902.3808 - val_loss: 13563895527.4521\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 14650893578.9777 - val_loss: 13341781623.2329\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 14259787362.3602 - val_loss: 13142030798.9041\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 14296240133.2693 - val_loss: 12930253164.7123\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 14121900339.3756 - val_loss: 12740206234.3014\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 13573531105.2624 - val_loss: 12522088062.2466\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 13498975040.5489 - val_loss: 12310163252.6027\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 13413459170.5798 - val_loss: 12101104099.9452\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 13434872898.7444 - val_loss: 11889734663.0137\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 12922970851.4580 - val_loss: 11684647606.3562\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 13096898790.0926 - val_loss: 11488898188.2740\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 12539527117.0635 - val_loss: 11290746122.5205\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 12504924459.4717 - val_loss: 11111579739.1781\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 12252610199.9314 - val_loss: 10920023201.3151\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 12100223175.3551 - val_loss: 10732795805.8082\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 11979888677.7633 - val_loss: 10556397133.1507\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11790731850.6484 - val_loss: 10363770655.5616\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 11744766810.0172 - val_loss: 10195661171.7260\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 11516505498.1269 - val_loss: 10010737152.0000\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 11354698200.4803 - val_loss: 9835252202.9589\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10963651688.5077 - val_loss: 9657455167.1233\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 10767315396.923 - 0s 144us/step - loss: 10904927098.5111 - val_loss: 9503261710.0274\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10869830854.4768 - val_loss: 9334457091.5068\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10435017473.3173 - val_loss: 9170254399.1233\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10435281036.5146 - val_loss: 9008352908.2740\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10293775995.8285 - val_loss: 8843767871.1233\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 10126521521.3997 - val_loss: 8695088555.8356\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 10268745959.8491 - val_loss: 8552985936.6575\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9898576540.7616 - val_loss: 8411262632.3288\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 9843401665.6467 - val_loss: 8258126279.8904\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 9679165383.7942 - val_loss: 8112337569.3151\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9691097801.9897 - val_loss: 7983705817.4247\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9403274631.6844 - val_loss: 7849338557.3699\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9225722895.3688 - val_loss: 7730283849.6438\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9036335204.5557 - val_loss: 7602290519.6712\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9018095863.6569 - val_loss: 7478273599.1233\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 9028360763.2796 - val_loss: 7371139317.4795\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8920205831.9039 - val_loss: 7250550682.3014\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8761517465.2487 - val_loss: 7138806268.4932\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8650347876.5557 - val_loss: 7047591588.8219\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8822500891.2247 - val_loss: 6950354302.2466\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8626030714.9503 - val_loss: 6860737732.3836\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8483523436.4597 - val_loss: 6769262542.9041\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8293367970.9091 - val_loss: 6677742286.9041\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8286185466.7307 - val_loss: 6596541485.5890\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8173183063.8216 - val_loss: 6509049484.2740\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 146us/step - loss: 8263208716.2950 - val_loss: 6437442139.1781\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 8150156565.5163 - val_loss: 6366484518.5753\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 8011792232.9468 - val_loss: 6302410008.5479\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7769830746.8954 - val_loss: 6244741288.3288\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7963818183.7942 - val_loss: 6181695635.2877\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7956940377.5780 - val_loss: 6120543147.8356\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7809656083.3208 - val_loss: 6070374435.0685\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7964936058.5111 - val_loss: 6023291062.3562\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7920102627.4580 - val_loss: 5983567808.8767\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7685358570.0446 - val_loss: 5939578143.5616\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7808614216.4528 - val_loss: 5900875172.8219\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7287483370.9228 - val_loss: 5865381558.3562\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7534038902.9983 - val_loss: 5834805479.4521\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7382293185.2075 - val_loss: 5808799484.4932\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7639910840.8645 - val_loss: 5787332972.7123\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7510782131.1561 - val_loss: 5760967715.0685\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7417201616.5763 - val_loss: 5744594828.2740\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7753235091.5403 - val_loss: 5726462600.7671\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7351748386.6895 - val_loss: 5707772356.3836\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7392541054.9022 - val_loss: 5688905798.1370\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7586688336.3568 - val_loss: 5676893401.4247\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7592839947.8559 - val_loss: 5664179943.4521\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7402199872.5489 - val_loss: 5653708252.9315\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7480280832.4391 - val_loss: 5642602895.7808\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7359703603.3756 - val_loss: 5636479824.6575\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7602519814.5866 - val_loss: 5628652743.8904\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7566104969.4408 - val_loss: 5621387116.7123\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7681052332.1304 - val_loss: 5615871354.7397\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7571826386.7719 - val_loss: 5609596808.7671\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7506523115.3619 - val_loss: 5604699455.1233\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7767959186.2230 - val_loss: 5600476272.2192\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7852483555.8971 - val_loss: 5597305000.3288\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7581155890.7170 - val_loss: 5596456062.2466\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7694987026.0034 - val_loss: 5593790281.6438\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7458690118.6964 - val_loss: 5589352921.4247\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7279522864.3019 - val_loss: 5586026853.6986\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7463126877.9691 - val_loss: 5581515018.5205\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7370110886.8611 - val_loss: 5579419963.6164\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7704178562.8542 - val_loss: 5580315546.3014\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7373861155.5678 - val_loss: 5576889687.6712\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7577393305.6878 - val_loss: 5575425423.7808\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7868892364.6244 - val_loss: 5575515942.5753\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7740431295.8902 - val_loss: 5575614937.4247\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7483942190.1063 - val_loss: 5573363052.7123\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7459415317.5163 - val_loss: 5571411740.0548\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7304996749.8319 - val_loss: 5567407139.0685\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7313118856.1235 - val_loss: 5568871266.1918\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7460450497.2075 - val_loss: 5567727479.2329\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7385188438.9434 - val_loss: 5566567059.2877\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7301051448.2058 - val_loss: 5566416184.1096\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7531955784.8919 - val_loss: 5566147135.1233\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7412031651.3482 - val_loss: 5567879609.8630\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7574167914.7033 - val_loss: 5568421656.5479\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7713596452.0069 - val_loss: 5569460269.5890\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7489419986.7719 - val_loss: 5569006234.3014\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7349884543.3413 - val_loss: 5567383888.6575\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7357358192.8508 - val_loss: 5566593094.1370\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7566406582.2298 - val_loss: 5566095437.1507\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7688988660.5832 - val_loss: 5565165662.6849\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7528290737.8388 - val_loss: 5565303590.5753\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7717418336.1647 - val_loss: 5565209207.2329\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7305915146.0995 - val_loss: 5564345968.2192\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7442633280.1098 - val_loss: 5564498088.3288\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7397747446.7787 - val_loss: 5565598109.8082\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7876132171.0875 - val_loss: 5565503666.8493\n",
      "Epoch 258/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 153us/step - loss: 7446067086.2710 - val_loss: 5565405334.7945\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7587989290.5935 - val_loss: 5566090801.0959\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7541722141.8593 - val_loss: 5564890613.4795\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7382879171.4031 - val_loss: 5565047667.7260\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7549097597.5849 - val_loss: 5565125568.8767\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7464783668.2539 - val_loss: 5566510956.7123\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7449408851.4305 - val_loss: 5565996558.0274\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7352457586.6072 - val_loss: 5567030478.9041\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 7136402109.6947 - val_loss: 5565236087.2329\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7518887447.7118 - val_loss: 5566684117.9178\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7499283552.6038 - val_loss: 5565774553.4247\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 250us/step - loss: 7593436107.3070 - val_loss: 5567743137.3151\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7187069626.1818 - val_loss: 5567305622.7945\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7883453318.3671 - val_loss: 5566437028.8219\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7549188607.1218 - val_loss: 5566161358.9041\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7423392328.8919 - val_loss: 5567422113.3151\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7557160729.2487 - val_loss: 5566958627.0685\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 7791572392.1784 - val_loss: 5567800425.2055\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7431412721.9485 - val_loss: 5569066916.8219\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7366825666.9640 - val_loss: 5568671565.1507\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7536140865.8662 - val_loss: 5568634438.1370\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7578022710.0103 - val_loss: 5568752489.2055\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 225us/step - loss: 7573387929.2487 - val_loss: 5568816671.5616\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 7904125599.1767 - val_loss: 5570301383.8904\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 7082400138.3190 - val_loss: 5568493676.7123\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 7310128184.2058 - val_loss: 5567516945.5342\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 7494103982.1063 - val_loss: 5567303694.0274\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 325us/step - loss: 7516590255.6432 - val_loss: 5567346905.4247\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 260us/step - loss: 7417402538.8130 - val_loss: 5567529261.5890\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 7391501792.3842 - val_loss: 5565553264.2192\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 7559207175.0257 - val_loss: 5566455744.8767\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7176827703.7667 - val_loss: 5566155719.8904\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7454216993.3722 - val_loss: 5565196428.2740\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7797385014.0103 - val_loss: 5566817034.5205\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7330090678.6690 - val_loss: 5565726169.4247\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7576941493.3516 - val_loss: 5564278987.3973\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7078459086.8199 - val_loss: 5563035658.5205\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7507939588.8302 - val_loss: 5562473531.6164\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7731369743.3688 - val_loss: 5562944143.7808\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7479644118.7238 - val_loss: 5562943319.6712\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7448350739.7599 - val_loss: 5566018560.0000\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7578853008.9057 - val_loss: 5564575417.8630\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7578542120.3979 - val_loss: 5563558519.2329\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7548369296.4666 - val_loss: 5561211686.5753\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 387us/step - loss: 7522187567.4237 - val_loss: 5559678169.4247\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 314us/step - loss: 7384975144.8370 - val_loss: 5557891591.0137\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 291us/step - loss: 7439902232.5901 - val_loss: 5557347815.4521\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 7414523178.8130 - val_loss: 5556956928.0000\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 7581328966.2573 - val_loss: 5558938995.7260\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7374959856.1921 - val_loss: 5558211657.6438\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7640420072.7273 - val_loss: 5560461024.4384\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7518482904.4803 - val_loss: 5559983577.4247\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7531561010.4974 - val_loss: 5559170605.5890\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7611060466.3877 - val_loss: 5560188191.5616\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7494037005.1732 - val_loss: 5559752160.4384\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7478060210.2779 - val_loss: 5558590997.0411\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7494354757.8182 - val_loss: 5559524650.0822\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7402326287.3688 - val_loss: 5559199344.2192\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7554070765.1184 - val_loss: 5560355678.6849\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7439937520.1921 - val_loss: 5560547762.8493\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7464837175.3276 - val_loss: 5560105026.6301\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7389736893.2556 - val_loss: 5559879841.3151\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7309123398.2573 - val_loss: 5560872539.1781\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7627449478.5866 - val_loss: 5558794050.6301\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7548487990.4494 - val_loss: 5559896116.6027\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 166us/step - loss: 7564948528.3019 - val_loss: 5562565032.3288\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7118070119.1904 - val_loss: 5561849582.4658\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7545978611.2659 - val_loss: 5561403707.6164\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7346469337.7976 - val_loss: 5560743971.0685\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7410052916.2539 - val_loss: 5561818718.6849\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7578052623.8079 - val_loss: 5561319914.9589\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7381975679.3413 - val_loss: 5560469760.0000\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7146785212.8165 - val_loss: 5559092925.3699\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7650577872.5763 - val_loss: 5558456179.7260\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7370995885.8868 - val_loss: 5558929478.1370\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7517543436.2950 - val_loss: 5558922787.0685\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7574113925.4889 - val_loss: 5557266842.3014\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7537212079.6432 - val_loss: 5556223203.9452\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7568101172.2539 - val_loss: 5556668160.0000\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7440020834.7993 - val_loss: 5555663528.3288\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7888092305.7839 - val_loss: 5556817436.0548\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7384794381.6124 - val_loss: 5557957817.8630\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7329317665.8113 - val_loss: 5559242569.6438\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7649999742.9022 - val_loss: 5560649072.2192\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7233908476.9262 - val_loss: 5561248333.1507\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7560663273.6055 - val_loss: 5562454044.0548\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7377818616.9743 - val_loss: 5560237736.3288\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7551233426.2230 - val_loss: 5559903856.2192\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7281246716.9262 - val_loss: 5561060236.2740\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7542764227.8422 - val_loss: 5558627492.8219\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7326329929.7702 - val_loss: 5559177272.1096\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7470459750.3122 - val_loss: 5558321944.5479\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7732097543.9039 - val_loss: 5559481750.7945\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7406336863.2864 - val_loss: 5560278724.3836\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7410808421.8731 - val_loss: 5560334739.2877\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7502243767.1081 - val_loss: 5560731269.2603\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7472380605.6947 - val_loss: 5560196706.1918\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7643460513.1527 - val_loss: 5559989830.1370\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7485598229.33 - 0s 145us/step - loss: 7383675693.2281 - val_loss: 5560858683.6164\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7358718951.4099 - val_loss: 5558928292.8219\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7572588601.9623 - val_loss: 5557995316.6027\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7468964145.6192 - val_loss: 5557300564.1644\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7328291465.8799 - val_loss: 5556868688.6575\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7697465922.7444 - val_loss: 5558502491.1781\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7699147396.6106 - val_loss: 5559296662.7945\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7613344561.6192 - val_loss: 5559988227.5068\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7599065977.6329 - val_loss: 5561385931.3973\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7531600518.3671 - val_loss: 5560555642.7397\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7719884153.6329 - val_loss: 5561705261.5890\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7497933033.1664 - val_loss: 5562365531.1781\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7612226152.9468 - val_loss: 5563556008.3288\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7598323468.7341 - val_loss: 5563229639.8904\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7657509230.2161 - val_loss: 5563764918.3562\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7608544458.4288 - val_loss: 5562941026.1918\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7493461842.1132 - val_loss: 5561857388.7123\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 7482996339.0463 - val_loss: 5560701629.3699\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7734736664.1509 - val_loss: 5562090282.0822\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7372670620.7616 - val_loss: 5561589269.0411\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7407199993.4134 - val_loss: 5561349232.2192\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7468418865.6192 - val_loss: 5559385172.1644\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7441964407.8765 - val_loss: 5560728877.5890\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7455909729.4820 - val_loss: 5561183800.1096\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7536330888.5626 - val_loss: 5559298423.2329\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7454324949.4065 - val_loss: 5560810885.2603\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7254796866.3053 - val_loss: 5561765474.1918\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7516091600.1372 - val_loss: 5562351637.0411\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 7577015560.3431 - val_loss: 5562517118.2466\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7397356966.4220 - val_loss: 5560294673.5342\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7625434097.9485 - val_loss: 5561384062.2466\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7851593972.1441 - val_loss: 5561050588.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7503697219.1835 - val_loss: 5561175096.1096\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7424125939.7050 - val_loss: 5559813397.0411\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7741612837.3242 - val_loss: 5560341076.1644\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7507276606.3533 - val_loss: 5561936510.2466\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7477825903.0943 - val_loss: 5560325407.5616\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7433367845.7633 - val_loss: 5559954056.7671\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7526764761.7976 - val_loss: 5558570962.4110\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7490570282.1544 - val_loss: 5559106882.6301\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7534144504.0961 - val_loss: 5560142395.6164\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7565667613.4202 - val_loss: 5559583589.6986\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7594902311.9588 - val_loss: 5562104277.9178\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7353938295.8765 - val_loss: 5560619572.6027\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7714213169.6192 - val_loss: 5561151982.4658\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7418722595.5678 - val_loss: 5560713426.4110\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7569387318.8885 - val_loss: 5561733312.8767\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7513252837.6535 - val_loss: 5563036152.9863\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7507568096.3842 - val_loss: 5563872438.3562\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7681502343.2453 - val_loss: 5563148624.6575\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7332228413.4751 - val_loss: 5561751145.2055\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7468896080.3568 - val_loss: 5562198766.4658\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7282281902.7650 - val_loss: 5563864849.5342\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7441770079.7256 - val_loss: 5563928782.9041\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7475787574.8885 - val_loss: 5563288870.5753\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7315644290.6346 - val_loss: 5562003456.0000\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7395300120.1509 - val_loss: 5562031791.3425\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7500989021.0909 - val_loss: 5560894993.5342\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7416073558.0652 - val_loss: 5559453611.8356\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7602839725.8868 - val_loss: 5559642844.9315\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7493485696.2196 - val_loss: 5560334518.3562\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7406604913.2899 - val_loss: 5559375949.1507\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7363171565.5575 - val_loss: 5559725364.6027\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7434686526.3533 - val_loss: 5559598795.3973\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7552298865.7290 - val_loss: 5558951164.4932\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7684875039.1767 - val_loss: 5560205431.2329\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7505140862.4631 - val_loss: 5560410953.6438\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7511671065.0292 - val_loss: 5561119523.0685\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7531281049.6878 - val_loss: 5561762552.9863\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7487640459.6364 - val_loss: 5561471414.3562\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7642760008.0137 - val_loss: 5561695144.3288\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7522181154.6895 - val_loss: 5560930062.0274\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7527744490.9228 - val_loss: 5559521672.7671\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7425889673.8799 - val_loss: 5562033439.5616\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7596064794.7856 - val_loss: 5561306638.0274\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7549051826.2779 - val_loss: 5561639143.4521\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7619760389.7084 - val_loss: 5562501432.1096\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7208478024.4528 - val_loss: 5562353734.1370\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7348715107.2384 - val_loss: 5562742321.0959\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7429033500.1029 - val_loss: 5561536967.8904\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7744291863.7118 - val_loss: 5562482190.0274\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7469929985.3173 - val_loss: 5561724794.7397\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7426232583.4648 - val_loss: 5562211636.6027\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7323945030.2573 - val_loss: 5562435436.7123\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7129391582.6278 - val_loss: 5562794517.0411\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7383856007.2453 - val_loss: 5562885691.6164\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7498639218.6072 - val_loss: 5563675395.5068\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7610077671.4099 - val_loss: 5563387925.0411\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7379133282.7993 - val_loss: 5564245307.6164\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7663094711.9863 - val_loss: 5563532042.5205\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7798768654.0515 - val_loss: 5563857485.1507\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7360863257.0292 - val_loss: 5564003422.6849\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7789443706.9503 - val_loss: 5565294234.3014\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7405677959.6844 - val_loss: 5564442112.0000\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7277265078.4494 - val_loss: 5564545841.0959\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7675372287.7804 - val_loss: 5565351718.5753\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7545674160.0823 - val_loss: 5564835654.1370\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 179us/step - loss: 7496690298.0720 - val_loss: 5563693326.0274\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7668343439.1492 - val_loss: 5563790104.5479\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7712029891.8422 - val_loss: 5564613603.9452\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7157523168.8233 - val_loss: 5561745302.7945\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7420512155.0051 - val_loss: 5562154496.0000\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7562679081.7153 - val_loss: 5560128981.9178\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7395098216.5077 - val_loss: 5561201930.5205\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7642021830.0377 - val_loss: 5562649144.1096\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7486769317.1046 - val_loss: 5562974278.1370\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7480973827.5129 - val_loss: 5562401995.3973\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7592948098.4151 - val_loss: 5562428987.6164\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7547158759.8491 - val_loss: 5562762176.8767\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7456556502.7238 - val_loss: 5560400019.2877\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7352111491.2933 - val_loss: 5558504360.3288\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7523401153.6467 - val_loss: 5557116514.1918\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7510392157.9691 - val_loss: 5557415508.1644\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7374650199.3825 - val_loss: 5556791288.9863\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7410306140.2127 - val_loss: 5558164879.7808\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7414301350.8611 - val_loss: 5557052878.9041\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7450401533.8045 - val_loss: 5558192952.1096\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7455446008.9743 - val_loss: 5560649903.3425\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7741895555.2933 - val_loss: 5559421952.0000\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7451117645.2830 - val_loss: 5559815266.1918\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7328199339.2521 - val_loss: 5557377767.4521\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7719112014.6003 - val_loss: 5559257351.0137\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7432925633.6467 - val_loss: 5560039697.5342\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7824330196.5283 - val_loss: 5560503366.1370\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7561857131.5815 - val_loss: 5559722201.4247\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7249541753.1938 - val_loss: 5559925637.2603\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7506045858.9091 - val_loss: 5561468682.5205\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7304968986.7856 - val_loss: 5561516186.3014\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7686998171.4443 - val_loss: 5561319006.6849\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7598721815.2727 - val_loss: 5563485247.1233\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7231726815.9451 - val_loss: 5562851559.4521\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7364375279.7530 - val_loss: 5562712772.3836\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7377344390.8062 - val_loss: 5562042701.1507\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7527948847.8628 - val_loss: 5560850277.6986\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7467465771.9108 - val_loss: 5559891519.1233\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7571211688.6175 - val_loss: 5559412504.5479\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7254055370.8679 - val_loss: 5561982509.5890\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7437525050.8405 - val_loss: 5560802977.3151\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7399912315.3894 - val_loss: 5561042246.1370\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7250402501.5986 - val_loss: 5560694720.8767\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7308241759.7256 - val_loss: 5561615005.8082\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7548944884.5832 - val_loss: 5562891786.5205\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7400561997.7221 - val_loss: 5560256610.1918\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7534573238.6690 - val_loss: 5558149309.3699\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7515158436.6655 - val_loss: 5558544924.0548\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7316861530.4563 - val_loss: 5557891261.3699\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7401765064.2333 - val_loss: 5557752937.2055\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7706009763.3482 - val_loss: 5558519857.0959\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7376795924.6381 - val_loss: 5559471507.2877\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7485454166.5043 - val_loss: 5560036036.3836\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7504090986.7033 - val_loss: 5560095796.6027\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7398751016.3979 - val_loss: 5560035489.3151\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7349902786.5249 - val_loss: 5559686712.1096\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7592024821.0223 - val_loss: 5560046942.6849\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7395010441.4408 - val_loss: 5559398273.7534\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7369037242.1818 - val_loss: 5559414328.1096\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7370211821.5575 - val_loss: 5558595566.4658\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7616504911.9177 - val_loss: 5560112517.2603\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7572311116.4048 - val_loss: 5561013237.4795\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7377569661.1458 - val_loss: 5561649180.0548\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7621555619.7873 - val_loss: 5561566172.9315\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7274526470.5866 - val_loss: 5560302072.9863\n",
      "Epoch 518/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 173us/step - loss: 7470046937.7976 - val_loss: 5559763228.0548\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7664340501.9554 - val_loss: 5559386382.0274\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7397758961.0703 - val_loss: 5560451580.4932\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7860510382.7650 - val_loss: 5561939354.3014\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7621812982.3396 - val_loss: 5560884550.1370\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7414327518.1887 - val_loss: 5561932182.7945\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7473045735.8491 - val_loss: 5562034211.0685\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7492490934.6690 - val_loss: 5561966332.4932\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7568250980.1166 - val_loss: 5562793331.7260\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7358721719.5472 - val_loss: 5561074253.1507\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7311442147.4580 - val_loss: 5559311721.2055\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7622444702.9571 - val_loss: 5560219009.7534\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7620876263.4099 - val_loss: 5559762098.8493\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7563075528.6724 - val_loss: 5560727004.9315\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7539191875.6226 - val_loss: 5562513674.5205\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7640728291.0189 - val_loss: 5563127173.2603\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7448138383.1492 - val_loss: 5563344299.8356\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7323871764.1990 - val_loss: 5562960464.6575\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7508974440.9468 - val_loss: 5561494008.9863\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7347645381.1595 - val_loss: 5560900667.6164\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7086730881.0978 - val_loss: 5560038792.7671\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7553634009.7976 - val_loss: 5560675050.9589\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7393967183.9177 - val_loss: 5559391144.3288\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7804377916.1578 - val_loss: 5560206209.7534\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7798283494.0926 - val_loss: 5562341993.2055\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7322575781.5437 - val_loss: 5562550335.1233\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7490143037.9142 - val_loss: 5563172394.0822\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7531637336.6998 - val_loss: 5562104390.1370\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7380331727.2590 - val_loss: 5562056816.2192\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7488359046.3671 - val_loss: 5562557510.1370\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7155427920.7959 - val_loss: 5560955244.7123\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7616069014.6141 - val_loss: 5560594922.9589\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7651023912.3979 - val_loss: 5559603557.6986\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7632660174.3808 - val_loss: 5561178816.8767\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7499882593.4820 - val_loss: 5560869726.6849\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7460463939.1835 - val_loss: 5559290052.3836\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7537431633.6741 - val_loss: 5559700472.9863\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7682032611.0189 - val_loss: 5562033965.5890\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7406827021.1732 - val_loss: 5562140328.3288\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7878148203.5815 - val_loss: 5563776150.7945\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7464613303.1081 - val_loss: 5565209736.7671\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7440660945.8937 - val_loss: 5565068589.5890\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7636634646.8336 - val_loss: 5564381688.9863\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7467401624.3705 - val_loss: 5563497156.3836\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7418399287.3276 - val_loss: 5562974001.0959\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7387645898.4288 - val_loss: 5563741808.2192\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7623832841.2213 - val_loss: 5564621157.6986\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7520434628.2813 - val_loss: 5564485505.7534\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7441667397.8182 - val_loss: 5563133818.7397\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7393512055.4374 - val_loss: 5564362134.7945\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7505876478.2436 - val_loss: 5563070260.6027\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7285258224.1921 - val_loss: 5563063057.5342\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7758420854.1201 - val_loss: 5562329031.8904\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7636507679.6158 - val_loss: 5564278987.3973\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7428489283.6226 - val_loss: 5564455438.0274\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7618985309.9691 - val_loss: 5563982209.7534\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7631918629.3242 - val_loss: 5563508820.1644\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7534130489.0840 - val_loss: 5563986537.2055\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7511849848.3156 - val_loss: 5563033726.2466\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7602982834.7170 - val_loss: 5562726028.2740\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7465937778.6072 - val_loss: 5563164419.5068\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7494771868.3225 - val_loss: 5562288983.6712\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7624543031.7667 - val_loss: 5561721354.5205\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7402918778.5111 - val_loss: 5561060786.8493\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7444563570.6072 - val_loss: 5562338823.0137\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 7440084357.0497 - val_loss: 5562065772.7123\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7402832865.2624 - val_loss: 5563038495.5616\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7293952405.7358 - val_loss: 5560444689.5342\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7680410700.4048 - val_loss: 5559843910.1370\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7434210652.2127 - val_loss: 5561131541.0411\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7254693612.2401 - val_loss: 5561444408.1096\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7713250998.6690 - val_loss: 5563114047.1233\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7136441388.3499 - val_loss: 5561798705.0959\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7651913401.3036 - val_loss: 5562259491.0685\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7460449151.3413 - val_loss: 5562406515.7260\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7738025758.2985 - val_loss: 5561491743.5616\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7609223499.9657 - val_loss: 5561928486.5753\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7506720692.4734 - val_loss: 5561670817.3151\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7404606052.1166 - val_loss: 5561953076.6027\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7555771780.6106 - val_loss: 5563032597.0411\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7426889520.7410 - val_loss: 5561864465.5342\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7399572805.3791 - val_loss: 5561415967.5616\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7321623908.5557 - val_loss: 5560812593.0959\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7411183187.4305 - val_loss: 5563092129.3151\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7367650340.0069 - val_loss: 5562188098.6301\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7506313477.2693 - val_loss: 5562563787.3973\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7370390950.4220 - val_loss: 5561821692.4932\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7708840191.5609 - val_loss: 5562126465.7534\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7537368399.4786 - val_loss: 5562076051.2877\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7458861793.7015 - val_loss: 5561052847.3425\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7916333777.8937 - val_loss: 5562292367.7808\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7481820152.9743 - val_loss: 5561454244.8219\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7579095906.7993 - val_loss: 5563735218.8493\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7671443822.7650 - val_loss: 5563874065.5342\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7477827476.8576 - val_loss: 5563268737.7534\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7378773081.1389 - val_loss: 5562883180.7123\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7510321184.9331 - val_loss: 5562982357.9178\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7394769999.0395 - val_loss: 5562983346.8493\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7494368113.7290 - val_loss: 5562043532.2740\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7502703347.7050 - val_loss: 5562795148.2740\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7426925439.7804 - val_loss: 5562652917.4795\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7446284005.2144 - val_loss: 5564057210.7397\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7500745115.0051 - val_loss: 5562630887.4521\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7436782312.7273 - val_loss: 5562936923.1781\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7542432853.6261 - val_loss: 5563790139.6164\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7333295550.1338 - val_loss: 5563653831.8904\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7453253689.9623 - val_loss: 5564524347.6164\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7409716410.1818 - val_loss: 5565335601.0959\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7608728176.8508 - val_loss: 5566254963.7260\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7484395020.2950 - val_loss: 5568124061.8082\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7340587865.1389 - val_loss: 5566605105.0959\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7589352657.0154 - val_loss: 5566200470.7945\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7482138200.6998 - val_loss: 5565093418.0822\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7286151528.0686 - val_loss: 5564809380.8219\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7590208391.2453 - val_loss: 5564930370.6301\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7638492644.7753 - val_loss: 5565507640.1096\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7508809324.0206 - val_loss: 5565291804.0548\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7648215989.7907 - val_loss: 5565812311.6712\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7468776473.4683 - val_loss: 5564593215.1233\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7590404019.5952 - val_loss: 5564698546.8493\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7503844543.4511 - val_loss: 5563621032.3288\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7609607577.2487 - val_loss: 5562880203.3973\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7529492985.8525 - val_loss: 5561639252.1644\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7454637352.8370 - val_loss: 5561556890.3014\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7465761312.0549 - val_loss: 5561164463.3425\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7426508377.5780 - val_loss: 5559038590.2466\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7170979217.3448 - val_loss: 5559068728.1096\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7541881714.6072 - val_loss: 5559565006.9041\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7626317507.8422 - val_loss: 5560221685.4795\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7470665696.3842 - val_loss: 5560005053.3699\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 170us/step - loss: 7833643311.8628 - val_loss: 5559400342.7945\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7703448793.3585 - val_loss: 5560680146.4110\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7751616598.0652 - val_loss: 5562206015.1233\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7774578600.1784 - val_loss: 5561622994.4110\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7271851339.9657 - val_loss: 5560468101.2603\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7541149071.5883 - val_loss: 5561280070.1370\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7638543992.7547 - val_loss: 5562554774.7945\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7519540898.0309 - val_loss: 5563785440.4384\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7705603064.9743 - val_loss: 5565460613.2603\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7566453740.6792 - val_loss: 5565785708.7123\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7290755354.3465 - val_loss: 5565279137.3151\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7273096572.2676 - val_loss: 5563392364.7123\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7413713589.3516 - val_loss: 5563945829.6986\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7792434465.8113 - val_loss: 5565425979.6164\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7302630833.8388 - val_loss: 5565083816.3288\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7389699004.1578 - val_loss: 5565440438.3562\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7545254339.4031 - val_loss: 5565236750.0274\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7505269839.0395 - val_loss: 5566015189.9178\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7526433681.3448 - val_loss: 5563167182.9041\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7719334503.6295 - val_loss: 5563901531.1781\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7626395714.7444 - val_loss: 5562384054.3562\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7163757808.6312 - val_loss: 5562999457.3151\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7625877995.8010 - val_loss: 5562997416.3288\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7624150489.3585 - val_loss: 5563393935.7808\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7420393496.5901 - val_loss: 5564507633.9726\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7657240200.1235 - val_loss: 5566520376.1096\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7536788644.2264 - val_loss: 5565293020.9315\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7674768306.7170 - val_loss: 5566454110.6849\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7666530657.9211 - val_loss: 5566472833.7534\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7394655999.5609 - val_loss: 5565738152.3288\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7523393728.3293 - val_loss: 5565608020.1644\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7147587846.5866 - val_loss: 5567483967.1233\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7359849563.7736 - val_loss: 5567443617.3151\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7346203282.6621 - val_loss: 5566789838.9041\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7380187811.3482 - val_loss: 5566599722.0822\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7517613004.1852 - val_loss: 5567451823.3425\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7679753139.5952 - val_loss: 5568510667.3973\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7537563510.1201 - val_loss: 5568145436.0548\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7581837584.2470 - val_loss: 5568324888.5479\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 7709363865.6878 - val_loss: 5568828051.2877\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 7480495431.5746 - val_loss: 5566933616.2192\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 269us/step - loss: 7412863826.1132 - val_loss: 5564760323.5068\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 271us/step - loss: 7423275506.8268 - val_loss: 5563536671.5616\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 279us/step - loss: 7534209250.5798 - val_loss: 5562556430.0274\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 263us/step - loss: 7660414495.6158 - val_loss: 5562924572.0548\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 269us/step - loss: 7362666710.2847 - val_loss: 5562872102.5753\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 7746818419.0463 - val_loss: 5562131175.4521\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 267us/step - loss: 7584729434.0172 - val_loss: 5561386510.0274\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 265us/step - loss: 7507279648.4940 - val_loss: 5561317404.0548\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 257us/step - loss: 7567694162.9914 - val_loss: 5560421607.4521\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 7738905378.6895 - val_loss: 5559950584.9863\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 268us/step - loss: 7727246113.8113 - val_loss: 5560868429.1507\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 7448275630.3259 - val_loss: 5560714492.4932\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 255us/step - loss: 7577728979.2110 - val_loss: 5559183987.7260\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 286us/step - loss: 7377996634.4563 - val_loss: 5560632025.4247\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 274us/step - loss: 7370304701.6947 - val_loss: 5560768354.1918\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 7422288484.1166 - val_loss: 5560345922.6301\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 7524405154.0309 - val_loss: 5561274339.9452\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 280us/step - loss: 7842376004.9400 - val_loss: 5561524346.7397\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 7819796317.9691 - val_loss: 5563035044.8219\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 257us/step - loss: 7356398953.8250 - val_loss: 5563073430.7945\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 281us/step - loss: 7570024929.2624 - val_loss: 5561767897.4247\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 286us/step - loss: 7264669302.5592 - val_loss: 5562750015.1233\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 256us/step - loss: 7444627758.9846 - val_loss: 5562935513.4247\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 240us/step - loss: 7735907779.4031 - val_loss: 5564630955.8356\n",
      "Epoch 713/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 223us/step - loss: 7800874685.2556 - val_loss: 5564124622.9041\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 7353425533.5849 - val_loss: 5564084294.1370\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7711715187.4854 - val_loss: 5564105538.6301\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 7506797901.7221 - val_loss: 5564205448.7671\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 7255136194.0858 - val_loss: 5562794103.2329\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 7261452138.2642 - val_loss: 5563124357.2603\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 7506479415.7667 - val_loss: 5561487668.6027\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7340886905.1938 - val_loss: 5561192476.0548\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7761806033.0154 - val_loss: 5562651921.5342\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7606761816.2607 - val_loss: 5563100040.7671\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7639468189.2007 - val_loss: 5564352561.0959\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7693678769.3997 - val_loss: 5565922665.2055\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7532680754.4974 - val_loss: 5564081902.4658\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7557161606.8062 - val_loss: 5564034342.5753\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7303765796.8851 - val_loss: 5564336369.9726\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7538899218.0034 - val_loss: 5564982222.9041\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7651668072.9468 - val_loss: 5566694834.8493\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7196898306.6346 - val_loss: 5564963261.3699\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7523268919.7667 - val_loss: 5564267765.4795\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7247742248.8370 - val_loss: 5564161143.2329\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7503247353.4134 - val_loss: 5563973302.3562\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7452490594.3602 - val_loss: 5564633884.0548\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7545082345.1664 - val_loss: 5565852580.8219\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7475699149.0635 - val_loss: 5565658995.7260\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7511198083.2933 - val_loss: 5564513265.9726\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7608574065.2899 - val_loss: 5564029818.7397\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7587681332.6930 - val_loss: 5563744073.6438\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7692871684.3911 - val_loss: 5563570428.4932\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7440831981.5575 - val_loss: 5563618282.9589\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7496275517.4751 - val_loss: 5565727828.1644\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7611221130.7581 - val_loss: 5563691228.9315\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7448204074.5935 - val_loss: 5565413032.3288\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7579688307.4854 - val_loss: 5564706058.5205\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7496864554.5935 - val_loss: 5564021437.3699\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7363375250.6621 - val_loss: 5563917420.7123\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7825831683.0738 - val_loss: 5563255808.0000\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7546505166.8199 - val_loss: 5564347819.8356\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7565826120.8919 - val_loss: 5561145782.3562\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7467403677.6398 - val_loss: 5560647672.9863\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7527042296.9743 - val_loss: 5560725875.7260\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 264us/step - loss: 7369736796.2127 - val_loss: 5558557401.4247\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7644723049.8250 - val_loss: 5558922103.2329\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7675357228.7890 - val_loss: 5559566328.9863\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7660426213.6535 - val_loss: 5561277012.1644\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7465772954.1269 - val_loss: 5562646387.7260\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7236315368.2882 - val_loss: 5561946652.0548\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7393305174.9434 - val_loss: 5560925464.5479\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7775318935.4923 - val_loss: 5559492215.2329\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7674329736.1235 - val_loss: 5558601678.9041\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7498903485.2556 - val_loss: 5559537558.7945\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7202473198.8748 - val_loss: 5558927303.8904\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 7408316816.9057 - val_loss: 5558045162.9589\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7756169262.5455 - val_loss: 5559458872.1096\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7603680132.1715 - val_loss: 5559711789.5890\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7265246466.1955 - val_loss: 5561178427.6164\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7800152468.8576 - val_loss: 5562166377.2055\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7623948060.5420 - val_loss: 5562542781.3699\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7579845026.0309 - val_loss: 5563935070.6849\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7561514127.1492 - val_loss: 5562643932.9315\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7557529271.5472 - val_loss: 5564804692.1644\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7569898218.9228 - val_loss: 5563758055.4521\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7303140633.0292 - val_loss: 5562006794.5205\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7424624077.0635 - val_loss: 5561912123.6164\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7443438973.5849 - val_loss: 5562616888.1096\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7364634180.5009 - val_loss: 5560704497.9726\n",
      "Epoch 778/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 166us/step - loss: 7466037153.1527 - val_loss: 5564481066.0822\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7621000119.9863 - val_loss: 5564880426.0822\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7369170459.2247 - val_loss: 5564781210.3014\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7432081638.9708 - val_loss: 5565198805.9178\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7690762042.4014 - val_loss: 5566295043.5068\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7485654277.7084 - val_loss: 5564021875.7260\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7691527659.8010 - val_loss: 5564749838.0274\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7438777633.8113 - val_loss: 5562320987.1781\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7585644031.1218 - val_loss: 5561632753.9726\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7372755986.4425 - val_loss: 5563022448.2192\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7652328044.8988 - val_loss: 5564092296.7671\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7579117269.4065 - val_loss: 5564755743.5616\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7541247908.6655 - val_loss: 5566197903.7808\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7355909483.5815 - val_loss: 5565336071.0137\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7558209579.9108 - val_loss: 5565211058.8493\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7723724973.8868 - val_loss: 5565023168.8767\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7626257469.4751 - val_loss: 5565182527.1233\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7463012905.2762 - val_loss: 5564676727.2329\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7377176700.7067 - val_loss: 5566521287.8904\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7718959014.4220 - val_loss: 5566199310.0274\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7530691315.2659 - val_loss: 5565786841.4247\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7746610139.9931 - val_loss: 5565991395.9452\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7394194951.9039 - val_loss: 5565909279.5616\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7633863316.8576 - val_loss: 5563745202.8493\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7385362492.5969 - val_loss: 5564119874.6301\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7350338865.6192 - val_loss: 5562948194.1918\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7475982119.5197 - val_loss: 5562580662.3562\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7633730130.5523 - val_loss: 5562463112.7671\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7205064199.9039 - val_loss: 5562770172.4932\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7769691388.9262 - val_loss: 5562643932.9315\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7533799375.6981 - val_loss: 5565140855.2329\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7749859546.6758 - val_loss: 5566963796.1644\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7459091842.4151 - val_loss: 5566191665.0959\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7454767772.7616 - val_loss: 5567592034.1918\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7281184542.2985 - val_loss: 5567185635.9452\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7509051323.4991 - val_loss: 5567108650.0822\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7550116163.1835 - val_loss: 5567747503.3425\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7243834457.5780 - val_loss: 5566702756.8219\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7444752860.8714 - val_loss: 5565267294.6849\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7598370192.0274 - val_loss: 5564749838.0274\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7518290519.8216 - val_loss: 5563915102.6849\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7566143860.3636 - val_loss: 5564250771.2877\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7446756067.4580 - val_loss: 5562424516.3836\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7504251201.4271 - val_loss: 5562849602.6301\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7714227791.0395 - val_loss: 5562607791.3425\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7623733359.9726 - val_loss: 5563752013.1507\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7296019278.1612 - val_loss: 5563252083.7260\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7648047642.3465 - val_loss: 5562779128.9863\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7690964263.0806 - val_loss: 5563046298.3014\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7393043287.3825 - val_loss: 5562756113.5342\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7358818765.9417 - val_loss: 5562706319.7808\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7316919167.3413 - val_loss: 5561108087.2329\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7354320840.6724 - val_loss: 5562172002.1918\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7154580268.3499 - val_loss: 5561625066.9589\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7740003821.1184 - val_loss: 5561401063.4521\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7367067502.2161 - val_loss: 5561937639.4521\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7350523699.3756 - val_loss: 5561214085.2603\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7496600870.2024 - val_loss: 5561664140.2740\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7453520533.2967 - val_loss: 5561211132.4932\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7650973958.5866 - val_loss: 5561730861.5890\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7520640709.5986 - val_loss: 5562896394.5205\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7605723386.7307 - val_loss: 5562325451.3973\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7361782729.1115 - val_loss: 5561656839.0137\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7608132437.6261 - val_loss: 5562783786.0822\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7491606263.6569 - val_loss: 5562389542.5753\n",
      "Epoch 843/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 155us/step - loss: 7536326512.8508 - val_loss: 5562541161.2055\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7393353397.3516 - val_loss: 5562813489.0959\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7600658503.1355 - val_loss: 5562541739.8356\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7278647268.7753 - val_loss: 5560926867.2877\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7303330316.7341 - val_loss: 5559855370.5205\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7749652692.0892 - val_loss: 5562045296.2192\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7836779975.7942 - val_loss: 5564540437.0411\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7472183195.0051 - val_loss: 5565853191.0137\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7517467516.2676 - val_loss: 5567753938.4110\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7393785240.3705 - val_loss: 5567684776.3288\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7303523825.9485 - val_loss: 5568628108.2740\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7408826836.9674 - val_loss: 5569181783.6712\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7779278469.4889 - val_loss: 5569184105.2055\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7439223588.4460 - val_loss: 5567536994.1918\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7318807871.0120 - val_loss: 5566960036.8219\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 7583511481.7427 - val_loss: 5567431385.4247\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 7456213071.0395 - val_loss: 5565770695.8904\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 7499583376.0274 - val_loss: 5566827916.2740\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7703955832.7547 - val_loss: 5567498194.4110\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7549663484.0480 - val_loss: 5568630128.2192\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7769388724.0343 - val_loss: 5569720656.6575\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 7223412892.3225 - val_loss: 5569485473.3151\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7331178951.3551 - val_loss: 5568363260.4932\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7471965249.8662 - val_loss: 5567930431.1233\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7704125485.6672 - val_loss: 5567960761.8630\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7397081383.0806 - val_loss: 5567450718.6849\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7493192600.3705 - val_loss: 5567876187.1781\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7626553253.5437 - val_loss: 5567789897.6438\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7401121042.0034 - val_loss: 5566638097.5342\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7477853153.2624 - val_loss: 5568356793.8630\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7396554658.9091 - val_loss: 5566389262.0274\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7210954208.3842 - val_loss: 5565286862.9041\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7628494352.6861 - val_loss: 5564898282.9589\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7748795111.8491 - val_loss: 5565426116.3836\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7646963070.9022 - val_loss: 5564187879.4521\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7711626620.2676 - val_loss: 5565976660.1644\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7750477356.7890 - val_loss: 5564658239.1233\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7613079144.9468 - val_loss: 5564805383.0137\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7457754594.5798 - val_loss: 5564519746.6301\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7218441863.2453 - val_loss: 5562511773.8082\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7739317667.3482 - val_loss: 5562489799.8904\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7633574451.8148 - val_loss: 5563918490.3014\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7535711844.5557 - val_loss: 5563884957.8082\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7562252138.7033 - val_loss: 5563554325.0411\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7717220677.8182 - val_loss: 5565007416.1096\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7496929900.0206 - val_loss: 5565454269.3699\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7394997788.1029 - val_loss: 5564345168.6575\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7491012968.0686 - val_loss: 5565356515.9452\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7419752296.9468 - val_loss: 5562977532.4932\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7611596338.9365 - val_loss: 5562908847.3425\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7448563984.2470 - val_loss: 5562884313.4247\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7225972275.8148 - val_loss: 5561742904.1096\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7441187803.9931 - val_loss: 5562149621.4795\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7525708367.0395 - val_loss: 5562673348.3836\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7661392512.6587 - val_loss: 5563220869.2603\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7431943614.1338 - val_loss: 5562712576.0000\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7300079288.4254 - val_loss: 5562117561.8630\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7582857934.3808 - val_loss: 5563214693.6986\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7485250058.0995 - val_loss: 5563261678.4658\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7282097212.1578 - val_loss: 5563664804.8219\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7341045847.8216 - val_loss: 5562990244.8219\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7147240521.7702 - val_loss: 5561237861.6986\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7328788177.0154 - val_loss: 5560288662.7945\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7398760566.1201 - val_loss: 5560472071.0137\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7382853807.6432 - val_loss: 5558476764.9315\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 7282907901.8045 - val_loss: 5558365892.3836\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7364391800.7547 - val_loss: 5559329749.9178\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7479655894.7238 - val_loss: 5559631612.4932\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7341735392.3842 - val_loss: 5558436611.5068\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7436501064.8919 - val_loss: 5557270415.7808\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7415358312.9468 - val_loss: 5558399821.1507\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7216878358.3945 - val_loss: 5558654954.9589\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7589360751.0943 - val_loss: 5560079433.6438\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7420390016.2196 - val_loss: 5558556657.9726\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7550005745.9485 - val_loss: 5558882577.5342\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7296482174.9022 - val_loss: 5558682097.9726\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7418791294.0240 - val_loss: 5559653032.3288\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7480014863.8079 - val_loss: 5562374186.0822\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7543295522.6895 - val_loss: 5562692474.7397\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7876945496.6998 - val_loss: 5564348233.6438\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 7466893046.7787 - val_loss: 5563492716.7123\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7533211458.3053 - val_loss: 5564268593.0959\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7681229174.1201 - val_loss: 5566154674.8493\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7260365068.2950 - val_loss: 5565871082.9589\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7660198601.9897 - val_loss: 5566352219.1781\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7548328871.3002 - val_loss: 5567114808.1096\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7662998880.1647 - val_loss: 5568510060.7123\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7698590207.1218 - val_loss: 5569607897.4247\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7516588087.7667 - val_loss: 5570625774.4658\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7311938890.6484 - val_loss: 5568970429.3699\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7384817303.9314 - val_loss: 5568176513.7534\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7703198222.9297 - val_loss: 5568037439.1233\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7729748598.5592 - val_loss: 5569198199.2329\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7394623258.7856 - val_loss: 5570815586.1918\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7541964419.7324 - val_loss: 5571283385.8630\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7712546111.6707 - val_loss: 5571979930.3014\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7646145978.6209 - val_loss: 5569523638.3562\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7589037275.5540 - val_loss: 5567596014.4658\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7194310938.7856 - val_loss: 5568585342.2466\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7290984629.7907 - val_loss: 5569055007.5616\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7382757294.3259 - val_loss: 5568708334.4658\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7303508918.2298 - val_loss: 5567950153.6438\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7541886732.2950 - val_loss: 5570002477.5890\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7302650929.1801 - val_loss: 5570894406.1370\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7517386723.8971 - val_loss: 5569793034.5205\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7485043799.8216 - val_loss: 5569314391.6712\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7540172622.6003 - val_loss: 5567158906.7397\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7320314210.3602 - val_loss: 5566343995.6164\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7419551148.5695 - val_loss: 5566086961.0959\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7519424332.8439 - val_loss: 5565563311.3425\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7430772252.1029 - val_loss: 5565889707.8356\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7567818571.9657 - val_loss: 5567143999.1233\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7187840930.9091 - val_loss: 5566410218.9589\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7273111202.4700 - val_loss: 5565441514.9589\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7386662994.5523 - val_loss: 5563968778.5205\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7511819494.0926 - val_loss: 5564652750.9041\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7250292901.1046 - val_loss: 5564496292.8219\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7493963435.2521 - val_loss: 5565892965.6986\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7326867739.6638 - val_loss: 5563917971.2877\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7436740987.3894 - val_loss: 5563132661.4795\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7479279753.8799 - val_loss: 5563134807.6712\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7452820624.9057 - val_loss: 5562298767.7808\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7401565877.3516 - val_loss: 5560930724.8219\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7614195837.5849 - val_loss: 5562878990.0274\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7567644787.0463 - val_loss: 5564489398.3562\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7530688247.6569 - val_loss: 5564839844.8219\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7550347708.3774 - val_loss: 5566027530.5205\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7668403790.6003 - val_loss: 5566511703.6712\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7632182522.2916 - val_loss: 5567620481.7534\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7519982092.2950 - val_loss: 5566127812.3836\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 159us/step - loss: 7634160571.4991 - val_loss: 5567795529.6438\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7347755884.0206 - val_loss: 5567828760.5479\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7463119090.3877 - val_loss: 5566528350.6849\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7732291896.6449 - val_loss: 5566764712.3288\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7430732475.9383 - val_loss: 5564678136.9863\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7552942473.4408 - val_loss: 5563766384.2192\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7450295627.0875 - val_loss: 5564114228.6027\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7521247051.9657 - val_loss: 5564374601.6438\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7515473065.4957 - val_loss: 5565040113.9726\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7468097554.4425 - val_loss: 5565211058.8493\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7237141109.6810 - val_loss: 5563199249.5342\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7576213147.4443 - val_loss: 5563276463.3425\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7686876776.5077 - val_loss: 5563716572.9315\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7722729248.0549 - val_loss: 5563643406.0274\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7735643038.5180 - val_loss: 5567061076.1644\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7678929696.0549 - val_loss: 5565908564.1644\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7453037683.0463 - val_loss: 5566670455.2329\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7462839046.5866 - val_loss: 5564829415.4521\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7624362431.8902 - val_loss: 5564027693.5890\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7375572815.4786 - val_loss: 5563694511.3425\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7356460697.6878 - val_loss: 5562212653.5890\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7610319780.2264 - val_loss: 5564745289.6438\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7613763374.9846 - val_loss: 5566133339.1781\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7518112739.8971 - val_loss: 5564661991.4521\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7488405943.9863 - val_loss: 5565430727.8904\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7324063232.4391 - val_loss: 5564199487.1233\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7360749928.0686 - val_loss: 5565334713.8630\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7439771853.9417 - val_loss: 5566043483.1781\n",
      "neurons used (8, 64)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 597us/step - loss: 39207553547.4168 - val_loss: 38410973408.4384\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 39196637292.8988 - val_loss: 38400970583.6712\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39178804538.4014 - val_loss: 38379796031.1233\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39154813216.0549 - val_loss: 38359822728.7671\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 39123637334.0652 - val_loss: 38330232383.1233\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39087540838.7513 - val_loss: 38285812329.2055\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 39044601606.5866 - val_loss: 38234868160.8767\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 38993344424.1784 - val_loss: 38184739573.4795\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38937662514.9365 - val_loss: 38134099855.7808\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 38875785988.8302 - val_loss: 38072474469.6986\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 38806253610.1544 - val_loss: 37992923640.9863\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38737026748.8165 - val_loss: 37908363516.4931\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 38653552243.0463 - val_loss: 37821906663.4521\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 38570258147.4580 - val_loss: 37731189605.6986\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 38477456561.3997 - val_loss: 37648761757.8082\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38381181837.8319 - val_loss: 37548080198.1370\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 38273079215.2041 - val_loss: 37425751979.8356\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 38169733917.4202 - val_loss: 37305517967.7808\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 38052076953.2487 - val_loss: 37208025340.4931\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 37931319194.1269 - val_loss: 37091054718.2466\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 37804828064.2744 - val_loss: 36967961473.7534\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 37681739154.2230 - val_loss: 36812390371.9452\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 37538229218.1406 - val_loss: 36666956645.6986\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 37403978813.4751 - val_loss: 36523243295.5616\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 37228406239.5060 - val_loss: 36359094496.4384\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 37090055773.9691 - val_loss: 36230029929.2055\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 36929176521.5506 - val_loss: 36069039005.8082\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 36756924788.3636 - val_loss: 35902206569.2055\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 36612661662.5180 - val_loss: 35689539359.5616\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 36408434962.0034 - val_loss: 35476308248.5479\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 36220756512.4940 - val_loss: 35278839751.8904\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 36039084544.8782 - val_loss: 35125870816.4384\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 35857026812.0480 - val_loss: 34926292543.1233\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 35678285936.4117 - val_loss: 34724671235.5069\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 35452278453.7907 - val_loss: 34535338096.2192\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 35235400737.3722 - val_loss: 34310499734.7945\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 405us/step - loss: 35048733353.4957 - val_loss: 34077733677.5890\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 283us/step - loss: 34798974968.9743 - val_loss: 33861309790.6849\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 34601158339.8422 - val_loss: 33641600322.6301\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 34373274014.5180 - val_loss: 33367461747.7260\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 34133730154.7033 - val_loss: 33148869169.0959\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 33876837265.3448 - val_loss: 32919899458.6301\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 33686507621.8731 - val_loss: 32689945614.0274\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 33414970548.9125 - val_loss: 32389421476.8219\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 33185030741.1870 - val_loss: 32127354851.9452\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 32889111813.7084 - val_loss: 31889940564.1644\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 32683701579.9657 - val_loss: 31631424694.3562\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 32339823663.4237 - val_loss: 31375668602.7397\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 32157905774.2161 - val_loss: 31137583552.8767\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 31851861738.4837 - val_loss: 30802571937.3151\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 31591827975.9039 - val_loss: 30556657523.7260\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 31326707311.5334 - val_loss: 30292767365.2603\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 31086754329.4683 - val_loss: 30006465858.6301\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 30721180772.1166 - val_loss: 29726963038.6849\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 30429316710.400 - 0s 151us/step - loss: 30413922114.3053 - val_loss: 29431946955.3973\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 30219087987.9245 - val_loss: 29195506982.5753\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 29886703022.3259 - val_loss: 28898085481.2055\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 29663722979.0189 - val_loss: 28615294639.3425\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 29323141727.7256 - val_loss: 28268349131.3973\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 28973938220.7890 - val_loss: 27954962375.8904\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 28665212288.6587 - val_loss: 27641091450.7397\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 28388742683.2247 - val_loss: 27304394443.3973\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 28062905073.5094 - val_loss: 27009303004.9315\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 27766139206.6964 - val_loss: 26703763456.0000\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 27373150453.9005 - val_loss: 26358894423.6712\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 27073889102.6003 - val_loss: 26044164881.5342\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 26831101461.9554 - val_loss: 25742985552.6575\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 26470020946.1132 - val_loss: 25423527936.0000\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26175515632.1921 - val_loss: 25099676686.0274\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 25845459667.6501 - val_loss: 24771366182.5753\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 25583378762.2093 - val_loss: 24427428906.0822\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 25186168508.8165 - val_loss: 24089616888.9863\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 24878526102.1750 - val_loss: 23751679719.4521\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 24481504991.9451 - val_loss: 23387460425.6438\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 24154899787.9657 - val_loss: 23042123186.8493\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 23785578931.5952 - val_loss: 22732226616.1096\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 23583118931.4305 - val_loss: 22407857039.7808\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 23225261389.7221 - val_loss: 22073324544.0000\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 22787965792.1647 - val_loss: 21664665936.6575\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 22467895959.9314 - val_loss: 21330271975.4521\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 22172108993.2075 - val_loss: 20976869993.2055\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 21810562390.5043 - val_loss: 20642608675.0685\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 21569034489.4134 - val_loss: 20321382049.3151\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 21041325461.7358 - val_loss: 19966224089.4247\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 20891953483.9657 - val_loss: 19583532551.0137\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 20409929380.2264 - val_loss: 19265864675.9452\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 20252237030.0926 - val_loss: 18967984955.6164\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 19741279358.4631 - val_loss: 18620102501.6986\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 19504182503.8491 - val_loss: 18270169326.4658\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 19191388102.0377 - val_loss: 17927038527.1233\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 18759429030.4220 - val_loss: 17613375964.9315\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 18486729668.2813 - val_loss: 17269637358.4658\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 18018468655.8628 - val_loss: 16956853823.1233\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 17747440912.2470 - val_loss: 16621240235.8356\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 17459383030.7787 - val_loss: 16271154877.3699\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 17080328785.6741 - val_loss: 15964266369.7534\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 16868437840.3568 - val_loss: 15624295480.1096\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 16333980095.8902 - val_loss: 15272984590.0274\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 16233467747.6775 - val_loss: 14965392846.9041\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 15920960791.2727 - val_loss: 14641368779.3973\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 15618649397.1321 - val_loss: 14305879923.7260\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 15283346570.7581 - val_loss: 13982547168.4384\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 14783509695.4511 - val_loss: 13681215221.4795\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 14701280285.8593 - val_loss: 13384790408.7671\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 14346369087.2316 - val_loss: 13062342389.4795\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 14130380348.5969 - val_loss: 12771067805.8082\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 13741112293.6535 - val_loss: 12450380526.4658\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 13488059513.1938 - val_loss: 12151303062.7945\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 13186116922.4014 - val_loss: 11897233001.2055\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 12919492815.2590 - val_loss: 11617219990.7945\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 12697149938.8268 - val_loss: 11338380687.7808\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 12329792482.1407 - val_loss: 11057445481.2055\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 11952074564.0618 - val_loss: 10796477320.7671\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 11993145177.1389 - val_loss: 10543097785.8630\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 11568432017.3448 - val_loss: 10302041943.6712\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 11392623954.9914 - val_loss: 10051113633.3151\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11040299851.0875 - val_loss: 9806994558.2466\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10939792877.5575 - val_loss: 9560874671.3425\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10551302720.9880 - val_loss: 9335568313.8630\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10274909705.6604 - val_loss: 9084693426.8493\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10329873247.2864 - val_loss: 8859417880.5479\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9962449562.5660 - val_loss: 8633392689.0959\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9833679494.3671 - val_loss: 8420186673.0959\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9507153231.4786 - val_loss: 8197417100.2740\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 9398647079.5197 - val_loss: 7999554805.4795\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9217958088.2333 - val_loss: 7825845065.6438\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8839393966.3259 - val_loss: 7682681245.8082\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8876347097.7976 - val_loss: 7513652441.4247\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8679431506.5523 - val_loss: 7342675189.4795\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8579679551.6707 - val_loss: 7192696470.7945\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8352798287.9177 - val_loss: 7047129042.4110\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8239600745.3859 - val_loss: 6900431829.9178\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8237142267.1698 - val_loss: 6760926572.7123\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7891408935.9588 - val_loss: 6627856327.8904\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7905454345.2213 - val_loss: 6506347039.5616\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7684473726.9022 - val_loss: 6398132385.3151\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7709159997.4751 - val_loss: 6304833627.1781\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7696536014.8199 - val_loss: 6211691134.2466\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7429255679.1218 - val_loss: 6115019716.3836\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7491245925.8731 - val_loss: 6045548561.5342\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7364005775.5883 - val_loss: 5975902940.9315\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7260336589.9417 - val_loss: 5912219669.0411\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7204065610.2093 - val_loss: 5860012354.6301\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7261524809.3310 - val_loss: 5818690247.8904\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7130472852.4185 - val_loss: 5765638189.5890\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7283937434.5660 - val_loss: 5728470773.4795\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6974590994.4425 - val_loss: 5707222794.5205\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7049855607.4374 - val_loss: 5681260214.3562\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7015423974.5317 - val_loss: 5657521920.0000\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7009768340.8576 - val_loss: 5639343096.9863\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7117275136.8782 - val_loss: 5627840028.0548\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7055876730.0720 - val_loss: 5615304374.3562\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6996292822.2847 - val_loss: 5600055194.3014\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7095068064.2744 - val_loss: 5589632196.3836\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7203535706.8954 - val_loss: 5582528739.9452\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7200321701.5437 - val_loss: 5574774159.7808\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 6914378424.32 - 0s 147us/step - loss: 7061933895.5746 - val_loss: 5573015502.9041\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6808925155.8971 - val_loss: 5565193121.3151\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7153114779.2247 - val_loss: 5560959568.6575\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6954932875.6364 - val_loss: 5554200737.3151\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7125450550.6690 - val_loss: 5551896933.6986\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7187520576.1098 - val_loss: 5549462899.7260\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7195484293.0497 - val_loss: 5546180495.7808\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7180923585.2075 - val_loss: 5547769610.5205\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 153us/step - loss: 7064559993.1938 - val_loss: 5545666679.2329\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7008021561.9623 - val_loss: 5546114784.4384\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6968851982.4906 - val_loss: 5542564636.0548\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6937444674.3053 - val_loss: 5541115826.8493\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6861369561.7976 - val_loss: 5540040069.2603\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7013807897.9074 - val_loss: 5541728119.2329\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6996416100.9949 - val_loss: 5541936604.9315\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6966488040.2882 - val_loss: 5541914375.0137\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6980188496.7959 - val_loss: 5539200406.7945\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6899164373.4065 - val_loss: 5543173474.1918\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7166505095.2453 - val_loss: 5544269115.6164\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7156239033.3036 - val_loss: 5547006400.8767\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6820310157.3928 - val_loss: 5544931843.5068\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7060552257.8662 - val_loss: 5541758113.3151\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7196346331.9931 - val_loss: 5540064333.1507\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7012130513.0154 - val_loss: 5539620285.3699\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6978453159.7393 - val_loss: 5539121828.8219\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7017130943.0120 - val_loss: 5539208314.7397\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7020105158.9160 - val_loss: 5537874361.8630\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7106766047.9451 - val_loss: 5537689733.2603\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7167832141.7221 - val_loss: 5537479953.5342\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7028014250.3739 - val_loss: 5537610681.8630\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6916358512.8508 - val_loss: 5534043297.3151\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6885073177.9074 - val_loss: 5533401522.8493\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6947173707.7461 - val_loss: 5535966481.5342\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6982184305.2899 - val_loss: 5536297717.4795\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6973908086.5592 - val_loss: 5535582916.3836\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6984194898.1132 - val_loss: 5535077105.9726\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7115698493.0360 - val_loss: 5534224096.4384\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7136879101.3654 - val_loss: 5534291470.0274\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6853943783.4099 - val_loss: 5533995148.2740\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7021951082.2642 - val_loss: 5532704052.6027\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7073789378.5249 - val_loss: 5533411229.8082\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7114168666.0172 - val_loss: 5533915521.7534\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7072392536.2607 - val_loss: 5535221549.5890\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7114054084.2813 - val_loss: 5533670186.0822\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7069834372.1715 - val_loss: 5534502638.4658\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7108484816.1372 - val_loss: 5534795860.1644\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6966074407.0806 - val_loss: 5533481464.9863\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6842128992.3842 - val_loss: 5534464543.5616\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7007036924.4871 - val_loss: 5534175751.0137\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7100022946.9091 - val_loss: 5534295867.6164\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7140910019.8422 - val_loss: 5534916916.6027\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6978152804.5557 - val_loss: 5534003855.7808\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6986539518.2436 - val_loss: 5536411325.3699\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7421857566.72 - 0s 144us/step - loss: 7143487367.2453 - val_loss: 5536362250.5205\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6995522430.0240 - val_loss: 5537160163.9452\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7235817609.0017 - val_loss: 5538900381.8082\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6766851025.8937 - val_loss: 5538381038.4658\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7007885975.0532 - val_loss: 5538105112.5479\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6931907718.3671 - val_loss: 5537692650.9589\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6976328627.5952 - val_loss: 5536082284.7123\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7040290995.1561 - val_loss: 5534273641.2055\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7240488336.4666 - val_loss: 5534608461.1507\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6944202338.7993 - val_loss: 5533823894.7945\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6856336469.6261 - val_loss: 5534889987.5068\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7171155846.8062 - val_loss: 5534215792.2192\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7011359346.1681 - val_loss: 5534201624.5479\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6796960025.4683 - val_loss: 5533984333.1507\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7106405124.8302 - val_loss: 5535480288.4384\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6972391413.9005 - val_loss: 5534371349.0411\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7046129202.0583 - val_loss: 5534975179.3973\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7083679906.0309 - val_loss: 5534853309.3699\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6909100554.9777 - val_loss: 5534881742.9041\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 7043826139.1149 - val_loss: 5534518699.8356\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 6909077169.3997 - val_loss: 5533252530.8493\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 6908501534.7376 - val_loss: 5532947764.6027\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 6859286012.0480 - val_loss: 5534143060.1644\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 6943623110.9160 - val_loss: 5533969225.6438\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 7073351591.3002 - val_loss: 5536362885.2603\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 6861958673.5643 - val_loss: 5535589824.8767\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7039838477.6124 - val_loss: 5535947022.0274\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 6994397662.6278 - val_loss: 5535215377.5342\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 6925469595.8834 - val_loss: 5534137912.1096\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 7012318633.0566 - val_loss: 5533176684.7123\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 7210373407.1767 - val_loss: 5532995569.9726\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 7088005642.5386 - val_loss: 5533545282.6301\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 6982051286.2847 - val_loss: 5535035819.8356\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7082484986.2916 - val_loss: 5534753251.9452\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 7152146738.4974 - val_loss: 5534613240.9863\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7116262353.2350 - val_loss: 5534434318.0274\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 7029556511.6158 - val_loss: 5534307531.3973\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 6983999914.8130 - val_loss: 5533025693.8082\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 6914524232.8919 - val_loss: 5533588280.1096\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 6912590522.1818 - val_loss: 5533439544.1096\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7029238742.7238 - val_loss: 5533751829.0411\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 6952450549.9005 - val_loss: 5533577331.7260\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 6968753018.0720 - val_loss: 5533460269.5890\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 6981042233.5232 - val_loss: 5533066660.8219\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 6863481831.4099 - val_loss: 5533349835.3973\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7112923666.8816 - val_loss: 5533413603.9452\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7035961458.1681 - val_loss: 5534261086.6849\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7048333344.4940 - val_loss: 5534349838.0274\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7127251885.4477 - val_loss: 5535210909.8082\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 6947859636.4734 - val_loss: 5534693425.0959\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7081587666.3328 - val_loss: 5535243684.8219\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 6987549639.7942 - val_loss: 5534578652.9315\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 6999416675.6775 - val_loss: 5533739639.2329\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 6963362879.6707 - val_loss: 5533893646.0274\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 6901414487.8216 - val_loss: 5534099610.3014\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 6788079972.1166 - val_loss: 5533645182.2466\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6924639560.4528 - val_loss: 5533241196.7123\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 6813733714.9914 - val_loss: 5533472389.2603\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7052115268.5009 - val_loss: 5534000622.4658\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 6897110450.2779 - val_loss: 5533538381.1507\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6988633043.6501 - val_loss: 5533969874.4110\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 6955969590.4494 - val_loss: 5533074168.9863\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 6981455979.1424 - val_loss: 5534511237.2603\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7090849678.2710 - val_loss: 5534025103.7808\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7072165581.0635 - val_loss: 5534389468.9315\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7001553167.8079 - val_loss: 5533256777.6438\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6976115660.1852 - val_loss: 5532564623.7808\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6938224531.5403 - val_loss: 5532846711.2329\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7108560505.6329 - val_loss: 5533666254.9041\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7078343209.2762 - val_loss: 5534006001.9726\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7029544802.7993 - val_loss: 5533836161.7534\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6948105375.8353 - val_loss: 5533745071.3425\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7082267100.4322 - val_loss: 5534148250.3014\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7065349267.5403 - val_loss: 5534074585.4247\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6971929719.4374 - val_loss: 5533345020.4932\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7076068770.4700 - val_loss: 5534685457.5342\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7182720843.5266 - val_loss: 5535144837.2603\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7012094205.8045 - val_loss: 5537230890.0822\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6965063729.1801 - val_loss: 5536232469.0411\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6912119154.6072 - val_loss: 5536158092.2740\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7066489427.4305 - val_loss: 5536964825.4247\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7025991039.3413 - val_loss: 5537805417.2055\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7051208049.7290 - val_loss: 5537105295.7808\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7160355472.9057 - val_loss: 5535655164.4932\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 169us/step - loss: 7190900729.4134 - val_loss: 5537133441.7534\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6869177031.7942 - val_loss: 5536708138.0822\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7197788263.8491 - val_loss: 5537334699.8356\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7122088474.7856 - val_loss: 5536523677.8082\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7076617621.7358 - val_loss: 5536205220.8219\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7020605163.3619 - val_loss: 5535206392.9863\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7005867302.2024 - val_loss: 5535100198.5753\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7161975810.6346 - val_loss: 5535733205.9178\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6893308227.1835 - val_loss: 5536092223.1233\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7022219548.5420 - val_loss: 5535839119.7808\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7107073813.9554 - val_loss: 5534770190.0274\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6894106293.3516 - val_loss: 5534406817.3151\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7048324891.6638 - val_loss: 5535912651.3973\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6956201730.1955 - val_loss: 5535470283.3973\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6964771801.7976 - val_loss: 5535190913.7534\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6912669180.4871 - val_loss: 5535434976.4384\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6927225644.7890 - val_loss: 5535363440.2192\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6954137380.0069 - val_loss: 5536630812.0548\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6852255962.6758 - val_loss: 5536375653.6986\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6903428313.7976 - val_loss: 5535026680.9863\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6894445108.6930 - val_loss: 5534462043.1781\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6802626013.7496 - val_loss: 5532768760.9863\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6881632142.7101 - val_loss: 5531821034.9589\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7102044310.1750 - val_loss: 5531576088.5479\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7190145120.1647 - val_loss: 5533369617.5342\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7240846069.9005 - val_loss: 5534635541.0411\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7041130795.9108 - val_loss: 5534040835.5068\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6850426718.4082 - val_loss: 5533676656.2192\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 6978493698.1955 - val_loss: 5533739933.8082\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7065199170.7444 - val_loss: 5535061984.4384\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 6888821572.9400 - val_loss: 5534554750.2466\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6981584990.8473 - val_loss: 5535991464.3288\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 6757686224.5763 - val_loss: 5534589930.9589\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7009476272.5214 - val_loss: 5535214556.9315\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7215917308.9262 - val_loss: 5536876291.5068\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7335670652.2676 - val_loss: 5538423632.6575\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7260965181.9142 - val_loss: 5538875528.7671\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7144779561.7153 - val_loss: 5539733665.3151\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7062037078.0652 - val_loss: 5538690019.9452\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6997732463.5334 - val_loss: 5538912606.6849\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7069242879.1218 - val_loss: 5538801344.8767\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7028618780.9811 - val_loss: 5538878534.1370\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7090689427.1012 - val_loss: 5538900753.5342\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6995768959.3413 - val_loss: 5538277628.4932\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7165722265.6878 - val_loss: 5539428597.4795\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7199339935.8353 - val_loss: 5539401321.2055\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6952273993.7702 - val_loss: 5540312695.2329\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6978176569.9623 - val_loss: 5539727647.5616\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6975086221.3928 - val_loss: 5539757624.1096\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7152758774.7787 - val_loss: 5539630115.0685\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7133400079.8079 - val_loss: 5540067180.7123\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7060805207.8216 - val_loss: 5539343808.8767\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7035913683.2110 - val_loss: 5539154936.9863\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7009361627.5540 - val_loss: 5539203713.7534\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6960457511.9588 - val_loss: 5537600227.9452\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7064073402.1818 - val_loss: 5536444282.7397\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6888944875.3619 - val_loss: 5536191207.4521\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6984787718.5866 - val_loss: 5535061069.1507\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7002221125.3791 - val_loss: 5535983146.0822\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6969694895.6432 - val_loss: 5534532671.1233\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7179279531.2521 - val_loss: 5535591999.1233\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7331297339.07 - 0s 146us/step - loss: 7128163355.2247 - val_loss: 5537536683.8356\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6964805357.9966 - val_loss: 5536488342.7945\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7222161005.7770 - val_loss: 5537398279.0137\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7037714164.1441 - val_loss: 5537472603.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7008817538.4151 - val_loss: 5536458029.5890\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7002061822.6827 - val_loss: 5536580169.6438\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7141172062.4082 - val_loss: 5537155464.7671\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7040744072.1235 - val_loss: 5537352265.6438\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7072482424.7547 - val_loss: 5537936755.7260\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7132365162.7033 - val_loss: 5538289635.9452\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7117754360.0961 - val_loss: 5538433855.1233\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6916226293.9005 - val_loss: 5538765319.0137\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6909681267.0463 - val_loss: 5539421415.4521\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6956794790.4220 - val_loss: 5538490220.7123\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6963848396.6244 - val_loss: 5537117688.9863\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6949850910.7376 - val_loss: 5538158795.3973\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6981311159.5472 - val_loss: 5537268385.3151\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6816386247.3551 - val_loss: 5536943973.6986\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7059447848.3979 - val_loss: 5537045160.3288\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7207501196.0755 - val_loss: 5537275202.6301\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6973352928.3842 - val_loss: 5536155879.4521\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6881243680.4940 - val_loss: 5535073714.8493\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7036765070.7101 - val_loss: 5535168603.1781\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7048591756.9537 - val_loss: 5534684321.3151\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7033666365.0360 - val_loss: 5535541767.0137\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7005198541.5026 - val_loss: 5535845253.2603\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7160458011.6638 - val_loss: 5535540904.3288\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7182419351.4923 - val_loss: 5536410034.8493\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6982841621.5163 - val_loss: 5537507896.1096\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7002345360.9057 - val_loss: 5538349610.0822\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7048549754.5111 - val_loss: 5537699654.1370\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7095077829.1595 - val_loss: 5538391769.4247\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6980005882.7307 - val_loss: 5539345888.4384\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6961369804.6244 - val_loss: 5538249268.6027\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6932889726.4631 - val_loss: 5537273996.2740\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7177103082.4837 - val_loss: 5536255074.1918\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6988074834.1132 - val_loss: 5536832308.6027\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6934861897.7702 - val_loss: 5536477352.3288\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7089883704.2058 - val_loss: 5536365255.8904\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6950552605.4202 - val_loss: 5535827441.9726\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6975522446.2710 - val_loss: 5536336320.8767\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7100870310.8611 - val_loss: 5536127712.4384\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7132857112.1509 - val_loss: 5536328451.5068\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7091999056.3568 - val_loss: 5535974210.6301\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7080043400.5626 - val_loss: 5536036327.4521\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6977284548.2813 - val_loss: 5536386461.8082\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7095018364.7067 - val_loss: 5535853259.3973\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7095685778.6621 - val_loss: 5534667961.8630\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6935144949.4614 - val_loss: 5534419080.7671\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6913711206.3122 - val_loss: 5533681190.5753\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7000595320.7547 - val_loss: 5533835863.6712\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6934550057.2762 - val_loss: 5534192120.9863\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7027673393.6192 - val_loss: 5533809734.1370\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7026995832.3156 - val_loss: 5533587470.0274\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7007162761.4408 - val_loss: 5532663471.3425\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6903909590.2847 - val_loss: 5532985077.4795\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6890009371.6638 - val_loss: 5532753253.6986\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7170345147.9383 - val_loss: 5533118358.7945\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6957415875.4031 - val_loss: 5533612112.6575\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6966117602.1407 - val_loss: 5533495099.6164\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6928946241.8662 - val_loss: 5533851711.1233\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7174452620.9537 - val_loss: 5534905501.8082\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6806978385.0154 - val_loss: 5535323069.3699\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6907734848.9880 - val_loss: 5536498751.1233\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7103032493.0086 - val_loss: 5536509818.7397\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6967913374.5180 - val_loss: 5535876159.1233\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7002293851.3345 - val_loss: 5535423175.8904\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7236786399.0669 - val_loss: 5536788465.9726\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7077335096.2058 - val_loss: 5536783900.0548\n",
      "Epoch 424/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 146us/step - loss: 6866298688.5489 - val_loss: 5535925135.7808\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7107260692.6381 - val_loss: 5534784231.4521\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6939514660.4460 - val_loss: 5534160685.5890\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7105743997.1458 - val_loss: 5534489726.2466\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6908354180.1715 - val_loss: 5534453107.7260\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6919219759.4237 - val_loss: 5534106182.1370\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7064941557.4614 - val_loss: 5533391949.1507\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7041264294.8611 - val_loss: 5532841002.0822\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7035453968.6861 - val_loss: 5532978042.7397\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6926911055.4786 - val_loss: 5532890210.1918\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6909767364.7204 - val_loss: 5532911293.3699\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7020518209.8662 - val_loss: 5534685541.6986\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6721372978.4974 - val_loss: 5532260636.0548\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7022657540.3911 - val_loss: 5532986781.8082\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7014234258.6621 - val_loss: 5532999837.8082\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7131142310.8611 - val_loss: 5533896830.2466\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7120194140.6518 - val_loss: 5533562027.8356\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7156883163.5540 - val_loss: 5534106448.6575\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6998102819.5678 - val_loss: 5533494180.8219\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7024523766.7787 - val_loss: 5532633543.8904\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6932949850.0172 - val_loss: 5533554702.0274\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7038202446.1612 - val_loss: 5533121746.4110\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6879885437.5849 - val_loss: 5533313714.8493\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7026463095.8765 - val_loss: 5533493809.0959\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7062138767.5883 - val_loss: 5534608033.3151\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6763119302.9160 - val_loss: 5533786143.5616\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6910297458.6072 - val_loss: 5533559271.4521\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7055902413.5026 - val_loss: 5533876581.6986\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7026148517.9828 - val_loss: 5534582307.0685\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7022094309.6535 - val_loss: 5534542995.2877\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7068017279.3413 - val_loss: 5534331546.3014\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6967064479.8353 - val_loss: 5534078983.0137\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7203454097.7839 - val_loss: 5534433774.4658\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6976810666.3739 - val_loss: 5534647559.0137\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7054304378.9503 - val_loss: 5535207669.4795\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6972450123.9657 - val_loss: 5534946030.4658\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7077162680.8645 - val_loss: 5535583477.4795\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7074238485.0772 - val_loss: 5535814094.9041\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7164880579.8422 - val_loss: 5535961803.3973\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7135036005.8731 - val_loss: 5536154581.9178\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6920071167.1218 - val_loss: 5534986450.4110\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6972648889.3036 - val_loss: 5535992407.6712\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6974891193.3036 - val_loss: 5536748982.3562\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7223755711.8902 - val_loss: 5537825139.7260\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7047734620.2127 - val_loss: 5538673569.3151\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7013031444.1990 - val_loss: 5538405698.6301\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6999645453.6124 - val_loss: 5537255588.8219\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7051463430.5866 - val_loss: 5535872760.9863\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6759863415.4374 - val_loss: 5534346106.7397\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6794873199.0943 - val_loss: 5533487949.1507\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6770586622.2436 - val_loss: 5533598421.9178\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6890181156.8851 - val_loss: 5533515134.2466\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6960689532.2676 - val_loss: 5533898811.6164\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7194819520.7684 - val_loss: 5534571274.5205\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6980216262.9160 - val_loss: 5534107125.4795\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6964429959.2453 - val_loss: 5535202991.3425\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6908006167.2727 - val_loss: 5536050986.0822\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6839495732.6930 - val_loss: 5536258033.9726\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6945520042.8130 - val_loss: 5535659036.0548\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6989859659.0875 - val_loss: 5536382008.1096\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6830944950.6690 - val_loss: 5535720882.8493\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6922230696.1784 - val_loss: 5536261807.3425\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6838674496.1098 - val_loss: 5534298252.2740\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7150700041.6604 - val_loss: 5535600555.8356\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6893959268.1166 - val_loss: 5536113218.6301\n",
      "Epoch 489/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 141us/step - loss: 7078540029.1458 - val_loss: 5536044905.2055\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7037856104.9468 - val_loss: 5536417799.0137\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6885088814.9846 - val_loss: 5537655190.7945\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7164248581.9280 - val_loss: 5537830385.9726\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6832447177.5506 - val_loss: 5537395305.2055\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6807398214.2573 - val_loss: 5535857130.9589\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6946357765.2693 - val_loss: 5535902720.0000\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6963163763.9245 - val_loss: 5536344158.6849\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7014069211.1149 - val_loss: 5536252570.3014\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7025250549.9005 - val_loss: 5536329394.8493\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7148457313.0429 - val_loss: 5536529891.9452\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7247357920.3842 - val_loss: 5536663839.5616\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7007874356.2539 - val_loss: 5536224469.9178\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6820368879.7530 - val_loss: 5535333754.7397\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7045933525.8456 - val_loss: 5535464967.0137\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6941349688.6449 - val_loss: 5536622732.2740\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6907116422.3671 - val_loss: 5536457054.6849\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7031032843.4168 - val_loss: 5537080937.2055\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6856301755.0600 - val_loss: 5537002243.5068\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6834848523.4168 - val_loss: 5537531248.2192\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7104063113.0017 - val_loss: 5536592790.7945\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7200769427.9794 - val_loss: 5535717361.9726\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6953858921.3859 - val_loss: 5534934163.2877\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7006355016.8919 - val_loss: 5534635541.0411\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7161426197.5163 - val_loss: 5534072256.8767\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6985551226.5111 - val_loss: 5534680604.0548\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6946782214.1475 - val_loss: 5535040329.6438\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6938313438.1887 - val_loss: 5534321516.7123\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7100927627.6364 - val_loss: 5534472483.0685\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6867952528.9057 - val_loss: 5535048121.8630\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7074794610.1681 - val_loss: 5536367111.0137\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7095683818.4837 - val_loss: 5535529447.4521\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7000092441.4683 - val_loss: 5535316963.9452\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6888406258.3876 - val_loss: 5534485076.1644\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7081974695.7393 - val_loss: 5534637652.1644\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7079677923.0189 - val_loss: 5535059946.9589\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6903171849.6604 - val_loss: 5535254713.8630\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6954175273.7153 - val_loss: 5535521265.9726\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6937968086.7238 - val_loss: 5535700115.2877\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7025638096.1372 - val_loss: 5534762460.9315\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6968886907.8285 - val_loss: 5534506061.1507\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6841169801.4408 - val_loss: 5532871567.7808\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6848086851.6226 - val_loss: 5533093141.0411\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7022571437.0086 - val_loss: 5533711514.3014\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7140894465.3173 - val_loss: 5533459683.9452\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7034042915.1286 - val_loss: 5533984950.3562\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7041660163.9520 - val_loss: 5534890229.4795\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7045986766.8199 - val_loss: 5534661737.2055\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6997638887.1904 - val_loss: 5535753692.9315\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7079368733.4202 - val_loss: 5534517058.6301\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7265804533.0223 - val_loss: 5534739456.0000\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7007468342.8885 - val_loss: 5535138226.8493\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7024269996.1304 - val_loss: 5534642495.1233\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6987778441.0017 - val_loss: 5534269432.9863\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7041881210.9503 - val_loss: 5534771270.1370\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6958332703.1767 - val_loss: 5534492054.7945\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6912139487.9451 - val_loss: 5534164676.3836\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7024991578.0172 - val_loss: 5534117916.0548\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7117219669.6261 - val_loss: 5533377648.2192\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7072453240.3156 - val_loss: 5535441597.3699\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7020773660.5420 - val_loss: 5535235415.6712\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7011421401.7976 - val_loss: 5534734833.9726\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6981564192.4940 - val_loss: 5535215991.2329\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7053429038.9846 - val_loss: 5534631999.1233\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6980438584.2058 - val_loss: 5534506916.8219\n",
      "Epoch 554/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 160us/step - loss: 7060952025.7976 - val_loss: 5535017177.4247\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7020392288.1647 - val_loss: 5534426182.1370\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6964807150.4357 - val_loss: 5534502687.5616\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7098987332.0617 - val_loss: 5535279251.2877\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6920557762.0858 - val_loss: 5535386273.3151\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7006212913.6192 - val_loss: 5535600555.8356\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6996175007.8353 - val_loss: 5535609217.7534\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6895209028.5009 - val_loss: 5535330135.6712\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6985234258.9914 - val_loss: 5534074694.1370\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7181583584.8233 - val_loss: 5534504209.5342\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7031359437.0635 - val_loss: 5535459804.9315\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6983927985.3997 - val_loss: 5535410975.5616\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6903921664.0000 - val_loss: 5535585223.8904\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6961572605.8045 - val_loss: 5534047982.4658\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6941321829.8731 - val_loss: 5534210237.3699\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6822348309.0772 - val_loss: 5533155363.0685\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7075573979.5540 - val_loss: 5532907337.6438\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7240758997.4065 - val_loss: 5533614956.7123\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6960977853.2556 - val_loss: 5532846129.0959\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7175258328.9194 - val_loss: 5532630471.8904\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7014033686.3945 - val_loss: 5533141328.6575\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6921933634.3053 - val_loss: 5533027987.2877\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7000363151.1492 - val_loss: 5533464049.9726\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7104435827.0463 - val_loss: 5535028462.4658\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6909913026.5249 - val_loss: 5533786280.3288\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6933003594.2093 - val_loss: 5533828285.3699\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7114196373.7358 - val_loss: 5534934110.6849\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6989802922.8130 - val_loss: 5535083120.2192\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7042086098.3328 - val_loss: 5535230825.2055\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6848435643.0600 - val_loss: 5535014329.8630\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7073197236.9125 - val_loss: 5534103015.4521\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7010325142.1750 - val_loss: 5533364616.7671\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6955584910.7101 - val_loss: 5533846436.8219\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6844389778.2230 - val_loss: 5534461271.6712\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7006208750.4357 - val_loss: 5534835347.2877\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6844512186.6209 - val_loss: 5533984312.1096\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6897101221.9828 - val_loss: 5533375884.2740\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7019090836.8576 - val_loss: 5533678855.0137\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7032509681.0703 - val_loss: 5533679875.5068\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7226066217.7153 - val_loss: 5533570588.0548\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6833783140.5557 - val_loss: 5533244615.8904\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6871246112.0549 - val_loss: 5533341015.6712\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6929362740.5832 - val_loss: 5533762966.7945\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7168921059.8971 - val_loss: 5535924918.3562\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6979616013.1732 - val_loss: 5537526447.3425\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6930948022.2298 - val_loss: 5537255129.4247\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7113170947.0738 - val_loss: 5537279526.5753\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6938452658.7170 - val_loss: 5537912519.8904\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6898422645.6810 - val_loss: 5537075999.5616\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6998772923.9383 - val_loss: 5536158471.0137\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6911579086.8199 - val_loss: 5535603757.5890\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6977104849.4545 - val_loss: 5536621788.9315\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6968004200.9468 - val_loss: 5536073075.7260\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6933070333.3654 - val_loss: 5534826005.0411\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7089974724.2813 - val_loss: 5535176458.5205\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7166357070.6003 - val_loss: 5534935264.4384\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6965722084.7753 - val_loss: 5534533898.5205\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7079770120.7822 - val_loss: 5535175574.7945\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7014091007.5609 - val_loss: 5535404656.2192\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7080209538.8542 - val_loss: 5535674827.3973\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6875351224.4254 - val_loss: 5535044622.0274\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6936424231.5197 - val_loss: 5535358288.6575\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6890635221.8456 - val_loss: 5533667643.6164\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7103005420.2401 - val_loss: 5534395335.8904\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7177962899.9794 - val_loss: 5534208862.6849\n",
      "Epoch 619/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 144us/step - loss: 6870092215.9863 - val_loss: 5534381133.1507\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6945063182.4906 - val_loss: 5534837339.1781\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7153457687.7118 - val_loss: 5535092073.2055\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7006540351.4511 - val_loss: 5536865806.0274\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7025917714.0034 - val_loss: 5536296216.5479\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7090858142.0789 - val_loss: 5536378315.3973\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7116445691.6089 - val_loss: 5536639526.5753\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7092404468.1441 - val_loss: 5536655395.0685\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7020105621.7358 - val_loss: 5536358575.3425\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6895413988.7753 - val_loss: 5536681822.6849\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6983986495.6707 - val_loss: 5537471631.7808\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6777941483.3619 - val_loss: 5536784601.4247\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6992433531.3894 - val_loss: 5537423118.0274\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6982925835.4168 - val_loss: 5537064234.0822\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6998699798.3945 - val_loss: 5536204032.0000\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6993685832.4528 - val_loss: 5536344593.5342\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6964121408.9880 - val_loss: 5536374440.3288\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7030351919.4237 - val_loss: 5536135978.0822\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6813386409.4957 - val_loss: 5536195170.1918\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6938472992.9331 - val_loss: 5534554616.9863\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7106261395.5403 - val_loss: 5534702711.2329\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6924007214.1063 - val_loss: 5535606016.0000\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7069915936.0549 - val_loss: 5535265707.8356\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7001782045.4202 - val_loss: 5535158889.2055\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6971267256.4254 - val_loss: 5535658043.6164\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7056322518.2847 - val_loss: 5535829139.2877\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6967838777.0840 - val_loss: 5535740177.5342\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7028712316.2676 - val_loss: 5534838173.8082\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7019112407.6021 - val_loss: 5535086395.6164\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7125330264.2607 - val_loss: 5535748096.0000\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7258943130.5660 - val_loss: 5535921474.6301\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7035110967.9863 - val_loss: 5535793881.4247\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7249350934.8336 - val_loss: 5535494256.2192\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6949003222.7238 - val_loss: 5534345040.6575\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7137814618.8954 - val_loss: 5535961856.0000\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6998923038.2985 - val_loss: 5536407040.0000\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6963952817.3997 - val_loss: 5535718708.6027\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6925377564.1029 - val_loss: 5535382450.8493\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7042270262.4494 - val_loss: 5536029001.6438\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7050073572.7753 - val_loss: 5535523412.1644\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6887960642.7444 - val_loss: 5535314838.7945\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7279231524.0069 - val_loss: 5534355715.5068\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6994116339.7050 - val_loss: 5534229437.3699\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7021072957.0360 - val_loss: 5534184889.8630\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7093548462.3259 - val_loss: 5535538211.0685\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6932233246.7376 - val_loss: 5535338681.8630\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6942716828.7616 - val_loss: 5536382008.1096\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7135760687.8628 - val_loss: 5536683092.1644\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6997708896.6038 - val_loss: 5536912205.1507\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6869011686.0926 - val_loss: 5536825052.9315\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7171383438.2710 - val_loss: 5535987112.3288\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6949379835.1698 - val_loss: 5535797360.2192\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7051978486.3396 - val_loss: 5536698434.6301\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6995424638.9022 - val_loss: 5535917981.8082\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7045924885.0772 - val_loss: 5535047532.7123\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7181179464.8919 - val_loss: 5534861652.1644\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6915664114.3876 - val_loss: 5534324343.2329\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7228524209.3997 - val_loss: 5535916224.8767\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6864643713.0978 - val_loss: 5534969073.9726\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6991174878.1887 - val_loss: 5535048847.7808\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7066180795.4991 - val_loss: 5534892859.6164\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7014139380.5832 - val_loss: 5534907739.1781\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7159608391.1355 - val_loss: 5535079059.2877\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7046917538.0309 - val_loss: 5534602857.2055\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7096418023.4099 - val_loss: 5535087293.3699\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 7140335459.6775 - val_loss: 5535087875.5068\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6957285080.9194 - val_loss: 5534951564.2740\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7032189553.2899 - val_loss: 5536413057.7534\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6926871954.6621 - val_loss: 5536534640.2192\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7147384064.4391 - val_loss: 5537128076.2740\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6848515478.6141 - val_loss: 5535452033.7534\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7073240227.7873 - val_loss: 5535661056.0000\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7077752226.4700 - val_loss: 5535082853.6986\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6932202622.0240 - val_loss: 5534799850.9589\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7031201069.6672 - val_loss: 5536076708.8219\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7057004740.2813 - val_loss: 5535124171.3973\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7002857359.5883 - val_loss: 5535605809.0959\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7134969793.2075 - val_loss: 5535663672.1096\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6950553375.1767 - val_loss: 5535314270.6849\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7073310934.2847 - val_loss: 5535143220.6027\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7032123763.4854 - val_loss: 5534911221.4795\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6966485136.0274 - val_loss: 5534810595.9452\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7033949240.2058 - val_loss: 5535367581.8082\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7336020937.1115 - val_loss: 5537669688.1096\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6959013253.0497 - val_loss: 5538208333.1507\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6863186872.4254 - val_loss: 5537944351.5616\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7151222053.3242 - val_loss: 5539407682.6301\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6815614799.4786 - val_loss: 5538080136.7671\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6773484958.5180 - val_loss: 5536732237.1507\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7029517791.5060 - val_loss: 5536710347.3973\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7035872463.2590 - val_loss: 5537861744.2192\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7087175764.3087 - val_loss: 5536984863.5616\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6857662113.5918 - val_loss: 5537352816.2192\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7134333902.8199 - val_loss: 5537591611.6164\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7096181788.1029 - val_loss: 5537009902.4658\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7155330790.0926 - val_loss: 5537736788.1644\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7053199696.3568 - val_loss: 5537426351.3425\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6973207102.3533 - val_loss: 5537814275.5068\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6870152369.8388 - val_loss: 5537056168.3288\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7161727085.9966 - val_loss: 5537561224.7671\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 6951059805.5300 - val_loss: 5537630990.0274\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6909818102.7787 - val_loss: 5537575921.9726\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7018469501.1458 - val_loss: 5537754241.7534\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6910228803.1835 - val_loss: 5537375358.2466\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6948526582.5592 - val_loss: 5537421929.2055\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7205977797.5986 - val_loss: 5537625045.9178\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7169260844.7890 - val_loss: 5538774580.6027\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6956227748.2264 - val_loss: 5538200786.4110\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6903365542.4220 - val_loss: 5537147847.8904\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7002558767.8628 - val_loss: 5537430647.2329\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7073901460.8576 - val_loss: 5537453518.9041\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7032880763.8285 - val_loss: 5537858286.4658\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6833294862.9297 - val_loss: 5537550855.0137\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7040686036.0892 - val_loss: 5537995456.8767\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6962215121.0154 - val_loss: 5537929756.0548\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7112723528.0137 - val_loss: 5538643943.4521\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7005319389.3105 - val_loss: 5538259270.1370\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6994234245.9280 - val_loss: 5537794496.8767\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6805933378.7444 - val_loss: 5537554018.1918\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7234192650.9777 - val_loss: 5537420522.9589\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6934762034.4974 - val_loss: 5536970706.4110\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6875677401.7976 - val_loss: 5536716603.6164\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7051771218.1132 - val_loss: 5536957885.3699\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7061668386.2504 - val_loss: 5536162742.3562\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6840145695.1767 - val_loss: 5536186062.9041\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6917701874.3876 - val_loss: 5535743295.1233\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7006357948.3774 - val_loss: 5534917702.1370\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6911730802.1681 - val_loss: 5535424441.8630\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7095439734.1201 - val_loss: 5535706978.1918\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6950463758.9297 - val_loss: 5536284219.6164\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 143us/step - loss: 6963792773.4889 - val_loss: 5536392416.4384\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6769040780.5146 - val_loss: 5537199040.8767\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6904677937.1801 - val_loss: 5536756806.1370\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7066099790.1612 - val_loss: 5537267164.9315\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6939330536.2882 - val_loss: 5535786804.6027\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6997379677.9691 - val_loss: 5536329615.7808\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6981564537.1938 - val_loss: 5536228597.4795\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6861933319.4648 - val_loss: 5536162661.6986\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6777224619.2521 - val_loss: 5535545635.0685\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6741537698.4700 - val_loss: 5533725913.4247\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7000858465.9211 - val_loss: 5534465448.3288\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7058007036.0480 - val_loss: 5535084417.7534\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6923269452.4048 - val_loss: 5535313418.5205\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6980769667.2933 - val_loss: 5534421090.1918\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6917000637.2556 - val_loss: 5535019106.1918\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6989650841.6878 - val_loss: 5535144086.7945\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7042160316.8165 - val_loss: 5535191885.1507\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7069572126.7376 - val_loss: 5535680638.2466\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7071041770.4837 - val_loss: 5535272637.3699\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7043903547.2796 - val_loss: 5535514248.7671\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7001720106.5935 - val_loss: 5535287422.2466\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7151799843.1286 - val_loss: 5535724024.9863\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7043036142.4357 - val_loss: 5535865386.0822\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6896656197.8182 - val_loss: 5535860111.7808\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7208907119.9726 - val_loss: 5535507042.1918\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6875413749.9005 - val_loss: 5535726262.3562\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6976417789.3654 - val_loss: 5535783150.4658\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6981192651.3070 - val_loss: 5535302182.5753\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6965981299.9245 - val_loss: 5535043093.0411\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6966160192.5489 - val_loss: 5535608754.8493\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7161846886.7513 - val_loss: 5536208832.8767\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6958029845.0772 - val_loss: 5536602809.8630\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6937640559.5334 - val_loss: 5536895740.4932\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6989616621.5575 - val_loss: 5536266303.1233\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6911226194.1132 - val_loss: 5535657605.2603\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6977068330.5935 - val_loss: 5534994663.4521\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7074837205.4065 - val_loss: 5535281671.0137\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6989138261.6261 - val_loss: 5536165600.4384\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7096851340.9537 - val_loss: 5535713998.9041\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6870131863.0532 - val_loss: 5535430792.7671\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6874727579.0051 - val_loss: 5534740613.2603\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7028722207.1767 - val_loss: 5535296932.8219\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7253406447.7530 - val_loss: 5534907272.7671\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6974029503.4511 - val_loss: 5534678107.1781\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7041012786.9365 - val_loss: 5535053809.9726\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6888215646.8473 - val_loss: 5535176079.7808\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6904205999.6432 - val_loss: 5534445434.7397\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7142856489.7153 - val_loss: 5536002339.0685\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6985145349.2693 - val_loss: 5536841745.5342\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7103391887.1492 - val_loss: 5536892423.0137\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7051186028.4597 - val_loss: 5536684761.4247\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7035538213.3242 - val_loss: 5535735141.6986\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6843651779.8422 - val_loss: 5535684036.3836\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7011094775.6569 - val_loss: 5536891023.7808\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7133205447.7942 - val_loss: 5537095476.6027\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6997269543.5197 - val_loss: 5536375169.7534\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6917675961.7427 - val_loss: 5535854034.4110\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6888214724.7204 - val_loss: 5535617108.1644\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6855045160.3979 - val_loss: 5536333515.3973\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7062800890.7307 - val_loss: 5536381208.5479\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6987564399.5334 - val_loss: 5535420373.9178\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7001086557.9691 - val_loss: 5535170125.1507\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7281055185.0154 - val_loss: 5535677804.7123\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7097302656.2196 - val_loss: 5536322588.0548\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6927438388.6930 - val_loss: 5536210389.9178\n",
      "Epoch 814/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 7095924465.5094 - val_loss: 5536007694.0274\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7137783281.9485 - val_loss: 5536169801.6438\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7184389157.7633 - val_loss: 5536141220.8219\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7082555697.1801 - val_loss: 5537465214.2466\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7054476800.8782 - val_loss: 5538220410.7397\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 6972598507.8010 - val_loss: 5538253108.6027\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7045769820.2127 - val_loss: 5537794496.8767\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6992092003.6775 - val_loss: 5536789598.6849\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6974652785.7290 - val_loss: 5537041271.2329\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7112955843.4031 - val_loss: 5537424166.5753\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7066634286.9846 - val_loss: 5537238769.9726\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6886083125.5712 - val_loss: 5535975238.1370\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6917943427.7324 - val_loss: 5535639425.7534\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7066800218.4563 - val_loss: 5537076181.9178\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6986913624.2607 - val_loss: 5536418500.3836\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6970792665.7976 - val_loss: 5536079773.8082\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7044547017.5506 - val_loss: 5536019491.0685\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7095493077.4065 - val_loss: 5535745907.7260\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6971742253.2281 - val_loss: 5535781340.9315\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6932447766.8336 - val_loss: 5535043934.6849\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7061056085.1870 - val_loss: 5534127188.1644\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7083081776.3019 - val_loss: 5535000495.3425\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6919947080.4528 - val_loss: 5536219872.4384\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6925824198.0377 - val_loss: 5535771900.4932\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7017662726.5866 - val_loss: 5536777784.1096\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7029494156.9537 - val_loss: 5535578876.4932\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7111620973.3379 - val_loss: 5535405866.0822\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6802950275.7324 - val_loss: 5535363576.9863\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7153006536.6724 - val_loss: 5536022156.2740\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6954675233.3722 - val_loss: 5536532031.1233\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6822120096.7136 - val_loss: 5535609617.5342\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7028641120.1647 - val_loss: 5535105020.4932\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7048044367.0395 - val_loss: 5534118827.8356\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7004963257.7427 - val_loss: 5535508599.2329\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7033623415.8765 - val_loss: 5536397098.0822\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7107901057.0978 - val_loss: 5536389646.0274\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6737407414.6690 - val_loss: 5535747710.2466\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7070799847.4099 - val_loss: 5534717362.8493\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7019557873.0703 - val_loss: 5533739937.3151\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6985793914.5111 - val_loss: 5534236026.7397\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7191631994.9503 - val_loss: 5534283053.5890\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6884398209.0978 - val_loss: 5534547747.0685\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7142147490.0309 - val_loss: 5534683577.8630\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7093824923.8834 - val_loss: 5535067542.7945\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6951139654.6964 - val_loss: 5534886228.1644\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7194201920.5489 - val_loss: 5535650777.4247\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6942027516.4871 - val_loss: 5535126948.8219\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7016488865.1527 - val_loss: 5533916601.8630\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 139us/step - loss: 7075960610.6895 - val_loss: 5533985511.4521\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7075965678.8748 - val_loss: 5533963221.9178\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6979057795.7324 - val_loss: 5533853373.3699\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7168903570.2230 - val_loss: 5533293448.7671\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7071023033.7427 - val_loss: 5533923555.9452\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7150532568.9194 - val_loss: 5533434115.5068\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7016347269.4889 - val_loss: 5533736830.2466\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6965592048.1921 - val_loss: 5533958266.7397\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7091363047.8491 - val_loss: 5534863801.8630\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7070618084.9949 - val_loss: 5535692494.9041\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6923907844.6106 - val_loss: 5535440124.4932\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6870422193.3997 - val_loss: 5535458114.6301\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7145879215.2041 - val_loss: 5536365929.2055\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7106279984.3019 - val_loss: 5535246574.4658\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6912542791.1355 - val_loss: 5534532814.9041\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7114470664.3431 - val_loss: 5534469151.5616\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7147070331.3894 - val_loss: 5534080424.3288\n",
      "Epoch 879/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 164us/step - loss: 6906946068.1990 - val_loss: 5534148713.2055\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7075111925.4614 - val_loss: 5535819369.2055\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7059719052.5146 - val_loss: 5535158191.3425\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7015225406.3533 - val_loss: 5534747237.6986\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 260us/step - loss: 6994680043.3619 - val_loss: 5534327822.0274\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 6906817235.6501 - val_loss: 5533893263.7808\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7020331986.3328 - val_loss: 5534172128.4384\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7004728449.0978 - val_loss: 5533295293.3699\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6963435123.0463 - val_loss: 5533798070.3562\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6807245537.7015 - val_loss: 5534172966.5753\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7159372581.3242 - val_loss: 5535552764.4932\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7136376854.8336 - val_loss: 5535123508.6027\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7101645454.7101 - val_loss: 5534873315.9452\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7046822805.2967 - val_loss: 5535376180.6027\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7004441853.8045 - val_loss: 5535453134.9041\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7073943650.3602 - val_loss: 5534950407.0137\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7104314858.9228 - val_loss: 5534823665.9726\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7085110315.9108 - val_loss: 5535387199.1233\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6975695085.1184 - val_loss: 5536148118.7945\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6996269619.8148 - val_loss: 5536332929.7534\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7228562588.3225 - val_loss: 5536677989.6986\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7125987025.8937 - val_loss: 5537902037.9178\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7074886672.2470 - val_loss: 5538375111.8904\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6916987189.1321 - val_loss: 5537278741.0411\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6928088882.9365 - val_loss: 5536566363.1781\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7002865011.4854 - val_loss: 5536433607.8904\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6917717314.3053 - val_loss: 5535606798.0274\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7014306066.0034 - val_loss: 5535251413.9178\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7065851687.5197 - val_loss: 5535523419.1781\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6904464985.5780 - val_loss: 5535810111.1233\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7106288286.0789 - val_loss: 5535663363.5068\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7154079213.3379 - val_loss: 5535472580.3836\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6877938966.3945 - val_loss: 5535116891.1781\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7009617779.9245 - val_loss: 5535534932.1644\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6779063613.0360 - val_loss: 5535023489.7534\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6907182559.0669 - val_loss: 5535056152.5479\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6952358330.6209 - val_loss: 5535591893.9178\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7087219573.2419 - val_loss: 5534830493.8082\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6973351646.1887 - val_loss: 5534965496.9863\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6906372648.8370 - val_loss: 5535143978.0822\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6958314343.1904 - val_loss: 5535465047.6712\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7096605749.33 - 0s 149us/step - loss: 6971492840.2882 - val_loss: 5535842987.8356\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7247902034.5523 - val_loss: 5537251510.3562\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7033194786.6895 - val_loss: 5537034204.9315\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7143498033.6192 - val_loss: 5536404564.1644\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7011410833.5643 - val_loss: 5537093505.7534\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6976337545.4408 - val_loss: 5536302241.3151\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6959420840.6175 - val_loss: 5536396102.1370\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6894896038.4220 - val_loss: 5535973810.8493\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7050064303.2041 - val_loss: 5536225770.9589\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7044859188.6930 - val_loss: 5536326319.3425\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 299us/step - loss: 7024022853.8182 - val_loss: 5536307361.3151\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 6920390149.7084 - val_loss: 5535721184.4384\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6960104156.4322 - val_loss: 5535285875.7260\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7192411127.2178 - val_loss: 5536467021.1507\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7036855823.8079 - val_loss: 5536588259.9452\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6934085312.3293 - val_loss: 5536074608.2192\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7178594074.7856 - val_loss: 5536487529.2055\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6896994444.5146 - val_loss: 5535610501.2603\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7041559500.1852 - val_loss: 5536503218.8493\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6877494831.4237 - val_loss: 5536680153.4247\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7134038336.5489 - val_loss: 5536840184.9863\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7147381146.1269 - val_loss: 5537703132.9315\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6940220685.6124 - val_loss: 5536952810.9589\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7016142432.6038 - val_loss: 5536585159.8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6977079282.8268 - val_loss: 5536734698.9589\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7015131106.1407 - val_loss: 5535690839.6712\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7033913684.7479 - val_loss: 5536014350.0274\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7303258055.7942 - val_loss: 5536904917.9178\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6980323556.3362 - val_loss: 5535766682.3014\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6965155522.0858 - val_loss: 5535330086.5753\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7186401123.2384 - val_loss: 5536332414.2466\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6926074876.4871 - val_loss: 5536498102.3562\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6957789674.4837 - val_loss: 5536369187.0685\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7009132824.1509 - val_loss: 5535619303.4521\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6747071610.9503 - val_loss: 5534273718.3562\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7237875253.1321 - val_loss: 5535041809.5342\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7004687248.6861 - val_loss: 5535064860.0548\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6848245431.5472 - val_loss: 5534803904.8767\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7099250459.6638 - val_loss: 5535798896.2192\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6974123869.5300 - val_loss: 5535605994.9589\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6886015023.4237 - val_loss: 5534842543.3425\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7031703794.3876 - val_loss: 5534473763.0685\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7084793568.8233 - val_loss: 5535341936.2192\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7028068342.3396 - val_loss: 5535142880.4384\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6861987869.4202 - val_loss: 5535904385.7534\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7209984076.4048 - val_loss: 5536322012.9315\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6921875099.4443 - val_loss: 5536483762.8493\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6968073029.8182 - val_loss: 5535977826.1918\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7131203696.4117 - val_loss: 5535510163.2877\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7084551566.7101 - val_loss: 5534936926.6849\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7013254476.8439 - val_loss: 5534418670.4658\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6928847869.3654 - val_loss: 5534548444.9315\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6924671592.5077 - val_loss: 5534323343.7808\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7043193057.7015 - val_loss: 5535270975.1233\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6964547715.7324 - val_loss: 5535206098.4110\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6926499892.6930 - val_loss: 5535797086.6849\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7116081921.7564 - val_loss: 5536820199.4521\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7084069763.2933 - val_loss: 5537610976.4384\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7008745262.1063 - val_loss: 5537781535.5616\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7081140070.3122 - val_loss: 5538924736.8767\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7211272188.4871 - val_loss: 5539315070.2466\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6849621090.3602 - val_loss: 5538756692.1644\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7166904121.5232 - val_loss: 5538925624.1096\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7027771051.2521 - val_loss: 5539473891.9452\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7156361740.2950 - val_loss: 5538953244.0548\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7145155995.0051 - val_loss: 5537779778.6301\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6938331072.7684 - val_loss: 5537015993.8630\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7079781344.3842 - val_loss: 5538015645.8082\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7075695412.9125 - val_loss: 5538873845.4795\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7138369016.0961 - val_loss: 5538903299.5068\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7017701572.7204 - val_loss: 5539323525.2603\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7033404437.0772 - val_loss: 5538115254.3562\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7048730451.8696 - val_loss: 5537637123.5068\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6968596829.5300 - val_loss: 5537228547.5068\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6938127008.2744 - val_loss: 5537946918.5753\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7024049792.2196 - val_loss: 5536778106.7397\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6972043681.1527 - val_loss: 5536014535.8904\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7286811356.4322 - val_loss: 5536585507.0685\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7025434347.3619 - val_loss: 5536901239.2329\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7093853118.1338 - val_loss: 5537727712.4384\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6989310655.4511 - val_loss: 5538475989.9178\n",
      "neurons used (16, 64)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 543us/step - loss: 39207699264.5489 - val_loss: 38411468968.3288\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 39197095412.5832 - val_loss: 38397113329.9726\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 39179374430.4082 - val_loss: 38376772593.9726\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 39154860404.3636 - val_loss: 38360071210.0822\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 39124357668.0069 - val_loss: 38323534553.4247\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 39088374778.7307 - val_loss: 38285977123.0685\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 39046094756.6655 - val_loss: 38242871604.6027\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 160us/step - loss: 38994575254.6141 - val_loss: 38179678628.8219\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 38940901692.1578 - val_loss: 38115354848.4384\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38879332910.5454 - val_loss: 38062327331.0685\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38808796347.9382 - val_loss: 37989983442.4110\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38734235187.8148 - val_loss: 37903261696.0000\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 38659103872.2196 - val_loss: 37831290094.4658\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 38572764256.6038 - val_loss: 37740519760.6575\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38482175167.4511 - val_loss: 37643625794.6301\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 38373528528.5763 - val_loss: 37548752110.4658\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 38284181286.2024 - val_loss: 37436874611.7260\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38170115772.8165 - val_loss: 37329159995.6164\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38055438627.5677 - val_loss: 37193705275.6164\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 37937610983.8491 - val_loss: 37051393009.9726\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 37808110242.4700 - val_loss: 36950867014.1370\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 37674305824.0549 - val_loss: 36815118925.1507\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 37546882137.5780 - val_loss: 36669100088.1096\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 37386283050.1544 - val_loss: 36542966769.9726\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 37236557866.1544 - val_loss: 36392003331.5069\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 37095844939.5266 - val_loss: 36240599797.4795\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 36919265364.3087 - val_loss: 36075789971.2877\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 36776373534.2985 - val_loss: 35868578184.7671\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 36580313007.2041 - val_loss: 35717968264.7671\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 36403947425.1527 - val_loss: 35549648531.2877\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 36248870694.2024 - val_loss: 35389379682.1918\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 36052474231.8765 - val_loss: 35178433886.6849\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 35851317444.7204 - val_loss: 34967483013.2603\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 35632423207.0806 - val_loss: 34742143172.3836\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 35448000764.9262 - val_loss: 34530864282.3014\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 35249974207.0120 - val_loss: 34336609911.2329\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 35038589560.3156 - val_loss: 34122626005.9178\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 34823198684.8714 - val_loss: 33892918762.9589\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 34634190440.5077 - val_loss: 33682767703.6712\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 34370223948.8439 - val_loss: 33470683444.6027\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 34106226832.0274 - val_loss: 33224070887.4521\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 33903232381.1458 - val_loss: 33003683896.1096\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 33656329611.1973 - val_loss: 32736723925.9178\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 33398818517.4065 - val_loss: 32481509376.0000\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 33162931001.5232 - val_loss: 32206519057.5342\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 32949658878.6827 - val_loss: 31953329839.3425\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 32697947868.4323 - val_loss: 31706076538.7397\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 32397456589.5026 - val_loss: 31421870332.4931\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 32091890960.2470 - val_loss: 31188442995.7260\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 31815962016.2744 - val_loss: 30924437307.6164\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 31569579951.2041 - val_loss: 30644228741.2603\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 31319014907.6089 - val_loss: 30358433511.4521\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 31081931574.0103 - val_loss: 30096018979.0685\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 30752632944.4117 - val_loss: 29790264390.1370\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 30416223918.7650 - val_loss: 29481039030.3562\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 30216100440.6998 - val_loss: 29210239312.6575\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 29894027850.6484 - val_loss: 28898688631.2329\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 29542736202.2093 - val_loss: 28578634148.8219\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 29288118092.8439 - val_loss: 28267038972.4931\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 28999183396.8851 - val_loss: 27977536974.9041\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 28754000237.3379 - val_loss: 27668268214.3562\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 28346129033.8799 - val_loss: 27348152207.7808\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 28142438705.6192 - val_loss: 27022832906.5205\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 27785948541.1458 - val_loss: 26701066520.5479\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 27467021903.9177 - val_loss: 26388436318.6849\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 27173528187.8285 - val_loss: 26085024950.3562\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 26797090619.2796 - val_loss: 25758233978.7397\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 27063012597.760 - 0s 149us/step - loss: 26582236376.0412 - val_loss: 25448245332.1644\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 26266100319.7256 - val_loss: 25079853504.8767\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 25858410987.8010 - val_loss: 24751878873.4247\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 25528895867.3894 - val_loss: 24431047048.7671\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 174us/step - loss: 25184871229.0360 - val_loss: 24111382107.1781\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 24883345885.7496 - val_loss: 23772109809.9726\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 24446776174.2161 - val_loss: 23411330426.7397\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 24192298059.5266 - val_loss: 23063339092.1644\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 23720969923.8422 - val_loss: 22748949097.2055\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 23521837869.2281 - val_loss: 22411078193.0959\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 23202704722.9914 - val_loss: 22046173478.5753\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 22862133546.5935 - val_loss: 21747367052.2740\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 22546141809.2899 - val_loss: 21400582410.5205\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 22105633551.3688 - val_loss: 21048469658.3014\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 21818442453.4065 - val_loss: 20695275912.7671\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 21488755545.1389 - val_loss: 20395871877.2603\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 21157585370.2367 - val_loss: 20057411780.3836\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 20633806440.5077 - val_loss: 19682863188.1644\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 20463332922.8405 - val_loss: 19370775888.6575\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 20238312462.0515 - val_loss: 19006358542.0274\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 19865580721.3997 - val_loss: 18661474346.0822\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 19501591859.3756 - val_loss: 18345675509.4795\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 19183791674.8405 - val_loss: 18008593604.3836\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 18798131630.3259 - val_loss: 17698701424.2192\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 18406218240.8782 - val_loss: 17331317086.6849\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 17956460378.8954 - val_loss: 17003992849.5342\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 17776783440.7959 - val_loss: 16704432703.1233\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 17514154988.6792 - val_loss: 16341395456.0000\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 17196221232.7410 - val_loss: 16030704092.9315\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 16809758294.0652 - val_loss: 15680640476.9315\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 16403051455.0120 - val_loss: 15353523466.5205\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 16131121840.5214 - val_loss: 15037581578.5205\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 16012098177.0978 - val_loss: 14693680969.6438\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 15540117309.0360 - val_loss: 14396610055.0137\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 15206826781.4202 - val_loss: 14083940394.0822\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 15007315760.7410 - val_loss: 13754040474.3014\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 14654358059.0326 - val_loss: 13437361194.0822\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 14211054449.7290 - val_loss: 13110308513.3151\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 14097284786.2779 - val_loss: 12841681625.4247\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 13705382198.8885 - val_loss: 12510103124.1644\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 13418305200.5214 - val_loss: 12204217596.4932\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 13122089980.9262 - val_loss: 11920994584.5479\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 12865733505.5369 - val_loss: 11637980068.8219\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 12535982723.7324 - val_loss: 11354082486.3562\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 12373702778.9503 - val_loss: 11056807290.7397\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 12018519047.9039 - val_loss: 10815782266.7397\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 11832274907.1149 - val_loss: 10564408151.6712\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 11526447901.4202 - val_loss: 10293233222.1370\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 11444176627.2659 - val_loss: 10056776290.1918\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 11147870859.6364 - val_loss: 9826390352.6575\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 10776372118.6141 - val_loss: 9583282309.2603\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 10722444431.1492 - val_loss: 9358717804.7123\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10524383778.2504 - val_loss: 9118186769.5342\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10173259917.1732 - val_loss: 8876700440.5479\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 9965442428.7067 - val_loss: 8683813172.6027\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9729179386.2916 - val_loss: 8456242295.2329\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9587574866.5523 - val_loss: 8260663534.4658\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 9369865285.3791 - val_loss: 8054132848.2192\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 9289186335.6158 - val_loss: 7855790613.0411\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9001499020.0755 - val_loss: 7656863793.0959\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9008060908.6792 - val_loss: 7488455104.8767\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8702674292.3636 - val_loss: 7335211099.1781\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8566837650.2230 - val_loss: 7153138645.9178\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8363047990.4494 - val_loss: 7011800232.3288\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8236123573.3516 - val_loss: 6873740775.4521\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8147598249.0566 - val_loss: 6745959553.7534\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8083007579.3345 - val_loss: 6620391648.4384\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7865921556.1990 - val_loss: 6507374725.2603\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 170us/step - loss: 7807144678.0926 - val_loss: 6412655780.8219\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7697750881.9211 - val_loss: 6315786527.5616\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7650401672.5626 - val_loss: 6209632757.4795\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7649522989.2281 - val_loss: 6135284907.8356\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7414208541.8593 - val_loss: 6064576000.0000\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7527437981.2007 - val_loss: 6005605018.3014\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7172322683.3894 - val_loss: 5932911959.6712\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7211839893.9554 - val_loss: 5885338915.0685\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7166247379.2110 - val_loss: 5832230357.9178\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7359578943.6707 - val_loss: 5789260912.2192\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7158714688.5489 - val_loss: 5752915571.7260\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7166787006.5729 - val_loss: 5718007001.4247\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7170683975.1355 - val_loss: 5686084004.8219\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6869867202.0858 - val_loss: 5664399900.0548\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7089482784.4940 - val_loss: 5647426402.1918\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6965250642.1132 - val_loss: 5634607517.8082\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6962901387.1973 - val_loss: 5619560525.1507\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 6974171301.9828 - val_loss: 5605857164.2740\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6959122888.6724 - val_loss: 5596191898.3014\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7026677552.7410 - val_loss: 5583692266.9589\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 6967500287.1218 - val_loss: 5579806797.1507\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7006120815.0943 - val_loss: 5574964420.3836\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7067529151.4511 - val_loss: 5569949850.3014\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6939736463.5883 - val_loss: 5563915849.6438\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6963845803.2521 - val_loss: 5557235073.7534\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6940832611.6775 - val_loss: 5554173359.3425\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7116830623.3962 - val_loss: 5550177132.7123\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7059946645.2967 - val_loss: 5548888498.8493\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7053436563.5403 - val_loss: 5546644430.9041\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7205977814.2847 - val_loss: 5544410161.0959\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6848532122.1269 - val_loss: 5543807887.7808\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6973162823.5746 - val_loss: 5541825760.4384\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7057541692.5969 - val_loss: 5542115966.2466\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7143816855.9314 - val_loss: 5541073415.0137\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6913207615.6707 - val_loss: 5541333314.6301\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6993336865.3722 - val_loss: 5541321384.3288\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6854291358.0789 - val_loss: 5539665877.9178\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7028470591.6707 - val_loss: 5539937125.6986\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 6893021648.5763 - val_loss: 5540154550.3562\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6972974475.1973 - val_loss: 5540265528.1096\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7032582835.1561 - val_loss: 5540715821.5890\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6943498127.5883 - val_loss: 5539883288.5479\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 6983738887.9039 - val_loss: 5539324012.7123\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6999510893.3379 - val_loss: 5538794278.5753\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7007375280.0823 - val_loss: 5537933515.3973\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7101765307.0600 - val_loss: 5536360184.9863\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7010373566.1338 - val_loss: 5536227335.0137\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7239133744.3019 - val_loss: 5538126749.8082\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7105935778.4700 - val_loss: 5537502411.3973\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7164830191.3139 - val_loss: 5535920668.0548\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6937339073.2075 - val_loss: 5536542271.1233\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6957788928.4391 - val_loss: 5537378703.7808\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6841153746.7719 - val_loss: 5537346307.5068\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7087536603.9931 - val_loss: 5536915371.8356\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6857532600.4254 - val_loss: 5536350306.1918\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7215445563.7187 - val_loss: 5536574155.3973\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 6956993267.2659 - val_loss: 5535845684.6027\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7094422062.5455 - val_loss: 5536235246.4658\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7083311180.4048 - val_loss: 5537118523.6164\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7084004545.2075 - val_loss: 5537618782.6849\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7106043197.9142 - val_loss: 5537637902.0274\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7024955836.8165 - val_loss: 5537677199.7808\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6896675934.8473 - val_loss: 5536386083.0685\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6915035907.0738 - val_loss: 5536387107.0685\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7133853058.8542 - val_loss: 5537587855.7808\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 166us/step - loss: 7211628582.6415 - val_loss: 5537544868.8219\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7005483480.0412 - val_loss: 5538848648.7671\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7015411088.4666 - val_loss: 5539310760.3288\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7222334575.5334 - val_loss: 5539430841.8630\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6928481439.8353 - val_loss: 5538798227.2877\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 6992501135.5883 - val_loss: 5538763425.3151\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7045521520.4117 - val_loss: 5538625216.8767\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7140317603.3482 - val_loss: 5540520693.4795\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 6880890306.5249 - val_loss: 5540209713.0959\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7211762394.6758 - val_loss: 5540118836.6027\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7054490698.6484 - val_loss: 5539806060.7123\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7137343173.5986 - val_loss: 5539755537.5342\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 6933117682.3876 - val_loss: 5539872280.5479\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7163902192.6312 - val_loss: 5539069888.8767\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 6783592920.4803 - val_loss: 5538693695.1233\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6831199000.1509 - val_loss: 5536959284.6027\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7091485072.4666 - val_loss: 5535735296.0000\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7176076239.6981 - val_loss: 5535998253.5890\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6913466194.9914 - val_loss: 5535083933.8082\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6844629734.9708 - val_loss: 5535017605.2603\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7023123630.7650 - val_loss: 5535006046.6849\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6941685553.1801 - val_loss: 5534973485.5890\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7030571757.9966 - val_loss: 5535079550.2466\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7074191367.0257 - val_loss: 5535262025.6438\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7031364461.7770 - val_loss: 5535887668.6027\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6849775560.6724 - val_loss: 5535385810.4110\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7070622383.2041 - val_loss: 5537859205.2603\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6988728379.7187 - val_loss: 5537465259.8356\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6994214216.4528 - val_loss: 5538005020.0548\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6997650955.4168 - val_loss: 5537837911.6712\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7048875116.8988 - val_loss: 5538917888.0000\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7031140189.5300 - val_loss: 5539018997.4795\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6971275453.6947 - val_loss: 5537203708.4932\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6867010126.1612 - val_loss: 5536843102.6849\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6981079017.6055 - val_loss: 5536144215.6712\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7070226687.5609 - val_loss: 5536452604.4932\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7190859492.7753 - val_loss: 5536974314.9589\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6925288091.4443 - val_loss: 5538035157.9178\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6933374700.2401 - val_loss: 5538572245.9178\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7214038616.6998 - val_loss: 5538466282.9589\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7014122305.4271 - val_loss: 5536989254.1370\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7103348143.2041 - val_loss: 5537752509.3699\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7067463355.0600 - val_loss: 5536694356.1644\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7014063737.1938 - val_loss: 5536764191.5616\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6969294055.8491 - val_loss: 5536978740.6027\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6892091473.6741 - val_loss: 5536130689.7534\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7073753220.3911 - val_loss: 5535409187.0685\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6918965899.6364 - val_loss: 5534677693.3699\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6952215094.8885 - val_loss: 5535026067.2877\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7057471370.3190 - val_loss: 5535909284.8219\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7040983253.4065 - val_loss: 5535377790.2466\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7044926536.0137 - val_loss: 5534733578.5205\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6986947052.8988 - val_loss: 5536194440.7671\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6842808067.0738 - val_loss: 5535089499.1781\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6944437904.0274 - val_loss: 5534188235.3973\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6931548437.5163 - val_loss: 5533934037.9178\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6978769987.6226 - val_loss: 5534205180.4932\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7063322617.8525 - val_loss: 5535040252.4932\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7027966412.1852 - val_loss: 5534966142.2466\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6982979246.7650 - val_loss: 5534826005.0411\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6866220222.1338 - val_loss: 5534694259.7260\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6934621671.4099 - val_loss: 5534286265.8630\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6862445968.4666 - val_loss: 5533646013.3699\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6953185933.3928 - val_loss: 5534858864.2192\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6959975734.0103 - val_loss: 5534134208.8767\n",
      "Epoch 266/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 6964371237.3242 - val_loss: 5533957632.0000\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7126649802.4288 - val_loss: 5534459655.0137\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7043261661.3105 - val_loss: 5534069549.5890\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6989447506.5523 - val_loss: 5532852553.6438\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6929134579.7050 - val_loss: 5532771292.9315\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6791755428.6655 - val_loss: 5532606288.6575\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7034428539.8285 - val_loss: 5532154855.4521\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7254321432.1509 - val_loss: 5532681805.1507\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6909692072.6175 - val_loss: 5533461212.9315\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6863926018.1955 - val_loss: 5533159199.5616\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6844655117.1732 - val_loss: 5534135786.9589\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7062805927.3002 - val_loss: 5534117593.4247\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7075733841.2350 - val_loss: 5533372089.8630\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7121337971.0463 - val_loss: 5532984130.6301\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7045973219.4580 - val_loss: 5532532097.7534\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7014442277.3242 - val_loss: 5533743545.8630\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7028099586.6346 - val_loss: 5533487672.1096\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6996691837.1458 - val_loss: 5532955318.3562\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7152981487.3139 - val_loss: 5534298003.2877\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7026130872.8645 - val_loss: 5535899921.5342\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6992460439.0532 - val_loss: 5536328696.9863\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6887088208.7959 - val_loss: 5535798896.2192\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7079260906.4837 - val_loss: 5536277079.6712\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 6935308313.9074 - val_loss: 5536626747.6164\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7071955048.5077 - val_loss: 5536456763.6164\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6995532054.3945 - val_loss: 5537325603.0685\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7312946616.8645 - val_loss: 5536248663.6712\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7015315824.8508 - val_loss: 5535598374.5753\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6718855834.5660 - val_loss: 5533741034.9589\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6884021902.2710 - val_loss: 5533757362.8493\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6963091656.6724 - val_loss: 5534294422.7945\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6941495385.5780 - val_loss: 5533434606.4658\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7158378888.5626 - val_loss: 5533831146.9589\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6784472735.8353 - val_loss: 5533836477.3699\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7020658592.2744 - val_loss: 5535109856.4384\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7002742874.0172 - val_loss: 5534507726.9041\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7064817395.2659 - val_loss: 5534856321.7534\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6933916220.5969 - val_loss: 5534299346.4110\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7165254010.5111 - val_loss: 5534982771.7260\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6901805361.1801 - val_loss: 5534413122.6301\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7021553087.8902 - val_loss: 5534610154.9589\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7202331807.8353 - val_loss: 5535308764.9315\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7161942415.1492 - val_loss: 5534791125.9178\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6997130634.3190 - val_loss: 5535938970.3014\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7080311486.7925 - val_loss: 5536519203.0685\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6976895723.3619 - val_loss: 5535783462.5753\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6849295475.0463 - val_loss: 5535438886.5753\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6901692633.3585 - val_loss: 5534748633.4247\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7068670738.0034 - val_loss: 5534930940.4932\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6929192583.2453 - val_loss: 5535670878.6849\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7009194849.9211 - val_loss: 5534736236.7123\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6896763497.3859 - val_loss: 5534718895.3425\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6982902086.6964 - val_loss: 5533407694.9041\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7096323176.5077 - val_loss: 5533542207.1233\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6881008935.0806 - val_loss: 5533961780.6027\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6843465996.2950 - val_loss: 5534570418.8493\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7046793127.3002 - val_loss: 5535256169.2055\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7031481866.5386 - val_loss: 5534358338.6301\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7021058152.5077 - val_loss: 5533794335.5616\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6964316663.2178 - val_loss: 5534182666.5205\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6976386703.1492 - val_loss: 5534072495.3425\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7046976956.3774 - val_loss: 5532593457.0959\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7096180766.7376 - val_loss: 5533250770.4110\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7035350692.2264 - val_loss: 5532922368.0000\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7063110538.3190 - val_loss: 5533635471.7808\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 145us/step - loss: 7102124094.3533 - val_loss: 5533803460.3836\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7025790680.9194 - val_loss: 5533678855.0137\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6920362948.2813 - val_loss: 5535365702.1370\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6947871586.7993 - val_loss: 5535024881.9726\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6885216383.3413 - val_loss: 5533984950.3562\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7135705850.7307 - val_loss: 5535661490.8493\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7087536378.2916 - val_loss: 5535708398.4658\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7077194755.5129 - val_loss: 5535566181.6986\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7136438035.7599 - val_loss: 5534372008.3288\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7049532411.6089 - val_loss: 5535040950.3562\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7062118900.1441 - val_loss: 5534445946.7397\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6988359825.7839 - val_loss: 5534382178.1918\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7045206669.3928 - val_loss: 5534596050.4110\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7134110974.6827 - val_loss: 5534358629.6986\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6899476040.4528 - val_loss: 5533755392.0000\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7035461454.6003 - val_loss: 5534423495.8904\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6882511898.1269 - val_loss: 5533859447.2329\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7248454830.7650 - val_loss: 5534009189.6986\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6866016316.5969 - val_loss: 5533224970.5205\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6824039432.7822 - val_loss: 5532500739.5068\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7069649121.7015 - val_loss: 5533797018.3014\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6939562813.0360 - val_loss: 5533681109.9178\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7250062607.3688 - val_loss: 5534036494.0274\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6942669441.0978 - val_loss: 5533197718.7945\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6849052919.6569 - val_loss: 5533909314.6301\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6927724854.0103 - val_loss: 5532991396.8219\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7234460450.6895 - val_loss: 5534533740.7123\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6998580323.6775 - val_loss: 5534068188.9315\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6829060591.3139 - val_loss: 5534594433.7534\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6967121944.5901 - val_loss: 5534514032.2192\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6984351506.8816 - val_loss: 5533968317.3699\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6729160963.5129 - val_loss: 5533159210.0822\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6979985471.2316 - val_loss: 5534324041.6438\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7072038584.4254 - val_loss: 5535005594.3014\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7059230226.8816 - val_loss: 5535846224.6575\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6785957020.7616 - val_loss: 5535330591.5616\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7043508331.5815 - val_loss: 5535287317.0411\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7069839628.7341 - val_loss: 5535156848.2192\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6949479919.3139 - val_loss: 5534726463.1233\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7074726228.3087 - val_loss: 5536002321.5342\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7018654720.8782 - val_loss: 5536601677.1507\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6854889965.5575 - val_loss: 5535641389.5890\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7142472355.3482 - val_loss: 5536186571.3973\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7022117591.1630 - val_loss: 5535389601.3151\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7018685959.0257 - val_loss: 5534580076.7123\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6859117135.0395 - val_loss: 5534645896.7671\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6849355466.4288 - val_loss: 5534526961.9726\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7117610026.1544 - val_loss: 5535907804.9315\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6890753501.7496 - val_loss: 5536149651.2877\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7270209399.8765 - val_loss: 5536580306.4110\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6845720276.3087 - val_loss: 5536165782.7945\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7079919950.6003 - val_loss: 5535891953.9726\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7158434339.1286 - val_loss: 5535760924.0548\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6912987417.9074 - val_loss: 5534949628.4932\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7033010238.3533 - val_loss: 5533889332.6027\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7151230417.4545 - val_loss: 5534569962.9589\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7157661393.8937 - val_loss: 5534278919.0137\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7015886672.3568 - val_loss: 5534330560.8767\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6946586322.7719 - val_loss: 5534750278.1370\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6955382668.7341 - val_loss: 5534655480.9863\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6924462426.8954 - val_loss: 5534143025.0959\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7044576063.6707 - val_loss: 5533055793.0959\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7124749730.9091 - val_loss: 5533094392.9863\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6945884322.4700 - val_loss: 5532995534.9041\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6972114257.2350 - val_loss: 5533904040.3288\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 152us/step - loss: 6908001982.1338 - val_loss: 5534464000.0000\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7002510926.1612 - val_loss: 5534335060.1644\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7056045216.7136 - val_loss: 5534183280.2192\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7077705604.6106 - val_loss: 5534068532.6027\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6866079251.3208 - val_loss: 5535091207.0137\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7294275089.5643 - val_loss: 5535629203.2877\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6912123855.2590 - val_loss: 5533964670.2466\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7004827108.3362 - val_loss: 5535620565.9178\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6835165779.4305 - val_loss: 5535118876.0548\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7043972023.9863 - val_loss: 5534920893.3699\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7015262369.5918 - val_loss: 5535290753.7534\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7100189030.3122 - val_loss: 5535558901.4795\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6967369470.6827 - val_loss: 5535609698.1918\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6854823030.9983 - val_loss: 5535194434.6301\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7011421474.6895 - val_loss: 5536523881.2055\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6877733640.3431 - val_loss: 5535278521.8630\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7187071867.3894 - val_loss: 5534937116.0548\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7009324346.4014 - val_loss: 5534082917.6986\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7004999658.9228 - val_loss: 5534426504.7671\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7012060627.2110 - val_loss: 5533508124.0548\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7153648444.1578 - val_loss: 5535167565.1507\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6897111656.5077 - val_loss: 5535738795.8356\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7020500322.3602 - val_loss: 5535591921.9726\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7069027488.7136 - val_loss: 5535457434.3014\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6903652260.6655 - val_loss: 5536342408.7671\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7021288760.2058 - val_loss: 5536052266.0822\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6935542325.5712 - val_loss: 5534606581.4795\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6805751488.3293 - val_loss: 5534798700.7123\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6974683718.2573 - val_loss: 5535433265.0959\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6962878296.2607 - val_loss: 5536621788.9315\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7058424434.1681 - val_loss: 5538311294.2466\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7158244352.8782 - val_loss: 5536626014.6849\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7080936325.0497 - val_loss: 5536873114.3014\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7024001291.8559 - val_loss: 5537175779.9452\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6824751128.5901 - val_loss: 5535055640.5479\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7087675827.5952 - val_loss: 5535167407.3425\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7048870381.9966 - val_loss: 5535323069.3699\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6997219807.0669 - val_loss: 5536261540.8219\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7154971161.4683 - val_loss: 5536433320.3288\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7134307253.3516 - val_loss: 5537843319.2329\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7100643063.6569 - val_loss: 5537875929.4247\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7095314941.3654 - val_loss: 5538622288.6575\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6811999974.9708 - val_loss: 5537159722.0822\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7097199377.1252 - val_loss: 5536632733.8082\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6893627231.9451 - val_loss: 5536439997.3699\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6947773593.6878 - val_loss: 5536716435.2877\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7142597049.7427 - val_loss: 5536487210.0822\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6820956303.1492 - val_loss: 5536724669.3699\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6973827316.1441 - val_loss: 5536273204.6027\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7095175109.1595 - val_loss: 5534589601.3151\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6922487454.5180 - val_loss: 5534325630.2466\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7100699611.1149 - val_loss: 5534341954.6301\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6995579950.5455 - val_loss: 5534437116.4932\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6938122801.1801 - val_loss: 5534312363.8356\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6970468464.4117 - val_loss: 5534063258.3014\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7218381516.6244 - val_loss: 5534452252.0548\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7093331178.4837 - val_loss: 5536212865.7534\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7005166884.4460 - val_loss: 5536475023.7808\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6973979773.5849 - val_loss: 5536699486.6849\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6849758774.0103 - val_loss: 5536751440.6575\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6986864410.5660 - val_loss: 5535452889.4247\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6972737700.6655 - val_loss: 5535250365.3699\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7165946206.4082 - val_loss: 5535703320.5479\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6923592574.9022 - val_loss: 5535187743.5616\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7051306810.4014 - val_loss: 5536452096.0000\n",
      "Epoch 461/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 152us/step - loss: 7070486047.1767 - val_loss: 5535688227.0685\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7075921554.6621 - val_loss: 5534771929.4247\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7096513770.9228 - val_loss: 5534890299.6164\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7161221298.2779 - val_loss: 5536389646.0274\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6985771396.6106 - val_loss: 5536330801.0959\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6989173692.3774 - val_loss: 5535734068.6027\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6769177923.1835 - val_loss: 5532791646.6849\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7152669242.4014 - val_loss: 5534741553.0959\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7069291627.5815 - val_loss: 5534753153.7534\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7043988572.2127 - val_loss: 5535718708.6027\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7098824653.9417 - val_loss: 5535114232.9863\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6988627108.6655 - val_loss: 5535540981.4795\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6925056373.2419 - val_loss: 5535216440.1096\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7052545921.5369 - val_loss: 5536580544.8767\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6861803711.8902 - val_loss: 5536830611.2877\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7023284102.8062 - val_loss: 5536516131.0685\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 6911943862.6690 - val_loss: 5537312617.2055\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7012808707.5129 - val_loss: 5537238692.8219\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7267331114.1544 - val_loss: 5537283359.5616\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7115336396.6244 - val_loss: 5536643057.9726\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7321615875.0738 - val_loss: 5536834360.1096\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6991098995.4854 - val_loss: 5535488760.9863\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7034773184.3293 - val_loss: 5536025151.1233\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7051883858.1132 - val_loss: 5535564400.2192\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7048372555.9657 - val_loss: 5536872525.1507\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7018212773.5437 - val_loss: 5536093688.9863\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7230614159.1492 - val_loss: 5536754035.7260\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7116003700.8027 - val_loss: 5537036368.6575\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6991240939.3619 - val_loss: 5536621596.0548\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7054253644.4048 - val_loss: 5535933748.6027\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7050951473.6192 - val_loss: 5536436224.0000\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7002601631.8353 - val_loss: 5535235208.7671\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7012757480.2882 - val_loss: 5534513341.3699\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7006848786.4425 - val_loss: 5534649147.6164\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7012133107.2659 - val_loss: 5534817869.1507\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7019255252.9674 - val_loss: 5534865737.6438\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6919419391.1218 - val_loss: 5536011691.8356\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7043764202.9228 - val_loss: 5534975516.0548\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7083907868.1029 - val_loss: 5534420795.6164\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6977163692.5695 - val_loss: 5534668340.6027\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7098002247.5746 - val_loss: 5535424869.6986\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 6976481361.6741 - val_loss: 5535994375.0137\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6978029257.1115 - val_loss: 5535316458.9589\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6838195440.6312 - val_loss: 5534719677.3699\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7287936218.6758 - val_loss: 5535783360.8767\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7033843669.8456 - val_loss: 5534900427.3973\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7173945723.3894 - val_loss: 5533970512.6575\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6973793153.5369 - val_loss: 5533692759.6712\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 6991103688.6724 - val_loss: 5534568623.3425\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6924934235.3345 - val_loss: 5534549626.7397\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6897847589.3242 - val_loss: 5533987040.4384\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6782530113.4271 - val_loss: 5533312056.1096\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7086064029.6398 - val_loss: 5533057746.4110\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6944165176.6449 - val_loss: 5532807185.5342\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7112478480.2470 - val_loss: 5532655531.8356\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6876605428.5832 - val_loss: 5533074593.3151\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7161243273.0017 - val_loss: 5532887264.4384\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7111003585.6467 - val_loss: 5533417808.6575\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6942451346.6621 - val_loss: 5534372548.3836\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6948632807.8491 - val_loss: 5533753347.5068\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6897414598.9160 - val_loss: 5533923555.9452\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7075131148.7341 - val_loss: 5533091033.4247\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6944905331.0463 - val_loss: 5532533065.6438\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 6962791884.1852 - val_loss: 5533367211.8356\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7077062933.0772 - val_loss: 5534878705.9726\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 153us/step - loss: 6960053130.3190 - val_loss: 5534998001.9726\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7134951560.5626 - val_loss: 5535755460.3836\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7032256596.3087 - val_loss: 5536670579.7260\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6921045462.7238 - val_loss: 5535507638.3562\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7052440491.6913 - val_loss: 5534738270.6849\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7193034589.5300 - val_loss: 5536375685.2603\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6947504576.3293 - val_loss: 5536169479.0137\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6879544322.6346 - val_loss: 5535993971.7260\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7194317034.0446 - val_loss: 5537224437.4795\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6914840638.3533 - val_loss: 5536843635.7260\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6932349187.0738 - val_loss: 5537408666.3014\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7186971479.3825 - val_loss: 5535858856.3288\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6970135500.1852 - val_loss: 5535561047.6712\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6976665526.2298 - val_loss: 5535981476.8219\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7138123036.9811 - val_loss: 5536398483.2877\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7076491198.1338 - val_loss: 5536334111.5616\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7121194939.4991 - val_loss: 5537359268.8219\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7025663573.1870 - val_loss: 5536473280.8767\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6844825533.4751 - val_loss: 5534647236.3836\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7133719791.7530 - val_loss: 5535105080.1096\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6979877486.6552 - val_loss: 5535045677.5890\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7047233348.9400 - val_loss: 5534542125.5890\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6933100429.8319 - val_loss: 5534860452.8219\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6977797597.7496 - val_loss: 5534987902.2466\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7027442971.6638 - val_loss: 5534769418.5205\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7227719092.2539 - val_loss: 5535215910.5753\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6769283778.0858 - val_loss: 5534962067.2877\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6850034708.6381 - val_loss: 5534473847.2329\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6987567438.1612 - val_loss: 5534790550.7945\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7009303579.2247 - val_loss: 5535291609.4247\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7106623981.5575 - val_loss: 5536024793.4247\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6834164946.3328 - val_loss: 5536142385.0959\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7004807117.0635 - val_loss: 5534697636.8219\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7198845774.6003 - val_loss: 5534947878.5753\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7080411088.1372 - val_loss: 5535213276.9315\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7066635999.5060 - val_loss: 5535982171.1781\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6781064281.5780 - val_loss: 5535331271.8904\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6781296584.6724 - val_loss: 5534276187.1781\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7121324940.0755 - val_loss: 5535362072.5479\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6917047071.6158 - val_loss: 5534398239.5616\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7029476422.2573 - val_loss: 5534488519.8904\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7047719928.9743 - val_loss: 5534975200.4384\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7026830220.9537 - val_loss: 5535130680.1096\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7035987963.6089 - val_loss: 5535237274.3014\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7081685127.6844 - val_loss: 5535872554.0822\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7051701322.6484 - val_loss: 5535706497.7534\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7174391887.9177 - val_loss: 5536688997.6986\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6947655372.6244 - val_loss: 5535318233.4247\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6960457842.1681 - val_loss: 5534905915.6164\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6833562310.4768 - val_loss: 5534715143.0137\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6960146788.5557 - val_loss: 5535560072.7671\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6945945207.4374 - val_loss: 5536312200.7671\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7116375457.5918 - val_loss: 5535809304.5479\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7038906460.2127 - val_loss: 5535558680.5479\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7110678016.8782 - val_loss: 5535481498.3014\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6913983468.6792 - val_loss: 5535314305.7534\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7040070422.3945 - val_loss: 5536077031.4521\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7406988006.0926 - val_loss: 5536248930.1918\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7184613625.4134 - val_loss: 5537929756.0548\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7150993253.4340 - val_loss: 5537376974.9041\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6965438159.2590 - val_loss: 5537687923.7260\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6967294551.8216 - val_loss: 5536206020.3836\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7078959859.2659 - val_loss: 5535841763.9452\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7011982053.2144 - val_loss: 5534779027.2877\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6826489639.9588 - val_loss: 5534468257.3151\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 145us/step - loss: 6974775490.9640 - val_loss: 5534489782.3562\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6974820199.1904 - val_loss: 5534812500.1644\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7063038746.1269 - val_loss: 5535112700.4932\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7096348416.4391 - val_loss: 5536235036.0548\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7074756873.2213 - val_loss: 5535668686.9041\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6984206935.8216 - val_loss: 5535904073.6438\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6985724690.8816 - val_loss: 5535625201.9726\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7139165006.1612 - val_loss: 5536419173.6986\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7218709928.1784 - val_loss: 5536963173.6986\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7148683278.9297 - val_loss: 5536376895.1233\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7143261739.9108 - val_loss: 5535609084.4932\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7077442547.2659 - val_loss: 5535820957.8082\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7178034940.9262 - val_loss: 5536125250.6301\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7091824674.6895 - val_loss: 5537835400.7671\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7067793347.4031 - val_loss: 5537036095.1233\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7042508712.1784 - val_loss: 5537072384.0000\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7142741854.4082 - val_loss: 5536527423.1233\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7006263777.2624 - val_loss: 5535317265.5342\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7151824874.0446 - val_loss: 5535419525.2603\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7064774408.7822 - val_loss: 5535245655.6712\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7021141369.1938 - val_loss: 5536517235.7260\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6965264669.4202 - val_loss: 5537647545.8630\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6963138238.5729 - val_loss: 5537634065.5342\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7048817358.8199 - val_loss: 5537581399.6712\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6961570714.5660 - val_loss: 5537236311.6712\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7076904492.7890 - val_loss: 5536890592.4384\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7167677992.8370 - val_loss: 5535892714.9589\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6920537196.8988 - val_loss: 5535824201.6438\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6985123674.8954 - val_loss: 5535743652.8219\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7072912855.6021 - val_loss: 5536532216.9863\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7109303350.4494 - val_loss: 5536689457.0959\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7155110905.4134 - val_loss: 5537762808.9863\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6975677034.2642 - val_loss: 5537188088.9863\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6884108887.8216 - val_loss: 5535397586.4110\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7016969555.8696 - val_loss: 5534337609.6438\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6960518141.3654 - val_loss: 5533757790.6849\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6803439554.0858 - val_loss: 5534131606.7945\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7096421946.8405 - val_loss: 5533939017.6438\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6995078441.2762 - val_loss: 5534348659.7260\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7037041656.9743 - val_loss: 5535476490.5205\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6851511232.7684 - val_loss: 5533900337.0959\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6919115995.7736 - val_loss: 5534628457.2055\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7053763462.3671 - val_loss: 5534421521.5342\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6927539421.3105 - val_loss: 5534751140.8219\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7012066380.4048 - val_loss: 5533196112.6575\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7185877975.6021 - val_loss: 5533401684.1644\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6841037565.8045 - val_loss: 5533028681.6438\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7198968628.2539 - val_loss: 5533658616.9863\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6970719850.2642 - val_loss: 5533799928.9863\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6857213027.2384 - val_loss: 5534181453.1507\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6951487175.3551 - val_loss: 5533130436.3836\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7147614265.9623 - val_loss: 5534265536.8767\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7000456506.4014 - val_loss: 5534237755.6164\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7080054205.6947 - val_loss: 5534871941.2603\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7086641185.3722 - val_loss: 5535654035.2877\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7164821339.7736 - val_loss: 5536654974.2466\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6921197345.8113 - val_loss: 5534849921.7534\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6986073642.5935 - val_loss: 5535192635.6164\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7134745305.7976 - val_loss: 5535400269.1507\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7215314881.6467 - val_loss: 5535759068.9315\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7232395637.2419 - val_loss: 5535336314.7397\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7022126102.3945 - val_loss: 5535733374.2466\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7051484418.1955 - val_loss: 5535434976.4384\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7157781030.2024 - val_loss: 5536397613.5890\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7039910729.7702 - val_loss: 5536709835.3973\n",
      "Epoch 656/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 144us/step - loss: 7039159823.8079 - val_loss: 5538081195.8356\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7114456138.2093 - val_loss: 5537834993.9726\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6939088391.0257 - val_loss: 5538337823.5616\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7133292921.1938 - val_loss: 5538712611.0685\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6891332068.7753 - val_loss: 5538426739.7260\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6934003170.5798 - val_loss: 5538464333.1507\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6967796464.1921 - val_loss: 5538036890.3014\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7114005927.3002 - val_loss: 5538058969.4247\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6864613860.7753 - val_loss: 5536227243.8356\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6832054203.9383 - val_loss: 5535877579.3973\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6857399423.3413 - val_loss: 5534299640.9863\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6972066789.6535 - val_loss: 5534778459.1781\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6919697581.8868 - val_loss: 5533598446.4658\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6815848686.4357 - val_loss: 5532997379.5068\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7041248430.3259 - val_loss: 5533389725.8082\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7171610186.6484 - val_loss: 5534712432.2192\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7037778444.7341 - val_loss: 5534756043.3973\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6806526412.1852 - val_loss: 5534484844.7123\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6921127762.9914 - val_loss: 5534185422.9041\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7060747096.6998 - val_loss: 5535289866.5205\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6726060963.7873 - val_loss: 5535250551.2329\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6938409387.6913 - val_loss: 5534835697.9726\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6702093714.2230 - val_loss: 5534704029.8082\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7009647534.7650 - val_loss: 5534929863.8904\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6982442590.8473 - val_loss: 5535278528.8767\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7092659553.9211 - val_loss: 5536496022.7945\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7048169763.5678 - val_loss: 5536621056.0000\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7039232268.7341 - val_loss: 5535531435.8356\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6905418130.2230 - val_loss: 5535518828.7123\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6999051267.5129 - val_loss: 5535815539.7260\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6911542488.9194 - val_loss: 5535870285.1507\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7110500666.4014 - val_loss: 5536034924.7123\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7030367451.1149 - val_loss: 5535874886.1370\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7030624710.9160 - val_loss: 5536782826.9589\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7055344358.9708 - val_loss: 5537146368.0000\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6783606883.6775 - val_loss: 5535571883.8356\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7157208485.9828 - val_loss: 5536924040.7671\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7032218206.8473 - val_loss: 5537175727.3425\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6885266413.5575 - val_loss: 5536209656.9863\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7106787539.6501 - val_loss: 5536607042.6301\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7100810073.1389 - val_loss: 5536794290.8493\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7013941114.0720 - val_loss: 5537018823.8904\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7057635896.2058 - val_loss: 5537920519.0137\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7047381835.9657 - val_loss: 5537736170.9589\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7008898939.3894 - val_loss: 5536014350.0274\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7054047079.1904 - val_loss: 5534545702.5753\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6879685021.2007 - val_loss: 5535016714.5205\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6937682096.5214 - val_loss: 5536161129.2055\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6923979247.3139 - val_loss: 5534725877.4795\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7205875384.4254 - val_loss: 5535466706.4110\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7170606692.9949 - val_loss: 5536057564.9315\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7061365219.4580 - val_loss: 5537359374.0274\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7223780368.2470 - val_loss: 5536760909.1507\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6874215910.5317 - val_loss: 5535790276.3836\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7256302264.4254 - val_loss: 5538063973.6986\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7118701575.0257 - val_loss: 5537524392.3288\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6982301861.5437 - val_loss: 5537682119.8904\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7178723851.4168 - val_loss: 5538483894.3562\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7026323044.5557 - val_loss: 5538453167.3425\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7127280602.2367 - val_loss: 5537494282.5205\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6931546272.7136 - val_loss: 5537299498.0822\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7048050150.5317 - val_loss: 5537817971.7260\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7009892640.9331 - val_loss: 5536789840.6575\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6916761604.3911 - val_loss: 5536419173.6986\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7015091658.8679 - val_loss: 5537089658.7397\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 145us/step - loss: 6862226207.1767 - val_loss: 5536971278.0274\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6955690674.7170 - val_loss: 5536460561.5342\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7184508862.1338 - val_loss: 5536366570.9589\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7017314001.8937 - val_loss: 5535995181.5890\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7057803956.9125 - val_loss: 5536679336.3288\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6983480660.7479 - val_loss: 5536682545.0959\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7052110819.8971 - val_loss: 5536706952.7671\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7045362540.4597 - val_loss: 5536170061.1507\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6992233951.0669 - val_loss: 5536922897.5342\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7076267458.5249 - val_loss: 5536615592.3288\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6908288263.4648 - val_loss: 5536951927.2329\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7109644477.6947 - val_loss: 5535833088.0000\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7090716938.9777 - val_loss: 5536623587.9452\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6871893609.3859 - val_loss: 5535990685.8082\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7025391053.9417 - val_loss: 5535196636.9315\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6980474223.0943 - val_loss: 5534969470.2466\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7099459778.9640 - val_loss: 5534538366.2466\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6933794195.1012 - val_loss: 5534331399.0137\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6810524150.3396 - val_loss: 5534189469.8082\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7032255791.8628 - val_loss: 5534312384.8767\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6977186787.8971 - val_loss: 5534598670.0274\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7122422339.6226 - val_loss: 5535009816.5479\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6960534974.1338 - val_loss: 5534829687.2329\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6953325659.3345 - val_loss: 5533862126.4658\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7046181683.3756 - val_loss: 5533562027.8356\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6947560302.2161 - val_loss: 5533254606.9041\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6756367469.3379 - val_loss: 5532622027.3973\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 6642816177.23 - 0s 147us/step - loss: 6807710457.8525 - val_loss: 5532265885.8082\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7010030770.2779 - val_loss: 5532838463.1233\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6914579245.2281 - val_loss: 5533677066.5205\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6939089475.1835 - val_loss: 5533582651.6164\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 6841032084.8576 - val_loss: 5534032952.1096\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6893974032.6861 - val_loss: 5533747052.7123\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6889631920.0823 - val_loss: 5534159082.9589\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6889942781.8045 - val_loss: 5534230352.6575\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7115640535.1630 - val_loss: 5534711730.8493\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7033665308.5420 - val_loss: 5535988827.1781\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6948186230.1201 - val_loss: 5536264612.8219\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7162611489.3722 - val_loss: 5536449132.7123\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6995185374.1887 - val_loss: 5535639502.9041\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6920444399.3139 - val_loss: 5535765651.2877\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6977827876.8851 - val_loss: 5536452046.9041\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7062089201.0703 - val_loss: 5535850313.6438\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7135535251.9794 - val_loss: 5535640176.2192\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7090327060.1990 - val_loss: 5535019968.8767\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7072349644.1852 - val_loss: 5535991523.9452\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6927286978.0858 - val_loss: 5535045063.8904\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6861911763.6501 - val_loss: 5534488730.3014\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6901325077.5163 - val_loss: 5535623634.4110\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7179976393.1115 - val_loss: 5535817913.8630\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7099550571.1424 - val_loss: 5534777736.7671\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6932674293.9005 - val_loss: 5534669459.2877\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7190927375.8079 - val_loss: 5534239891.2877\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7007250862.3259 - val_loss: 5534385236.1644\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6730405123.9520 - val_loss: 5534534894.4658\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7008739334.5866 - val_loss: 5534298778.3014\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6951586138.0172 - val_loss: 5535552066.6301\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7081402422.4494 - val_loss: 5535739402.5205\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 6978710155.1973 - val_loss: 5537059811.9452\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6815129721.1938 - val_loss: 5536699244.7123\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6949397141.2967 - val_loss: 5536113860.3836\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7119487891.9794 - val_loss: 5535458963.2877\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 6922975026.4974 - val_loss: 5535047988.6027\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7059209417.9897 - val_loss: 5536529499.1781\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7055769622.8336 - val_loss: 5535652015.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6867480278.2847 - val_loss: 5536090385.5342\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6995159450.7856 - val_loss: 5535861781.0411\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7196238027.7461 - val_loss: 5535376075.3973\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7012577629.5300 - val_loss: 5535511706.3014\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7030974089.0017 - val_loss: 5536520121.8630\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6945600482.1407 - val_loss: 5536123939.0685\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7027573133.8319 - val_loss: 5536718062.4658\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6900161591.3276 - val_loss: 5536176450.6301\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6980968468.6381 - val_loss: 5536417469.3699\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6879950773.3516 - val_loss: 5535296932.8219\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7034103819.4168 - val_loss: 5536376351.5616\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7059260640.3842 - val_loss: 5535420892.9315\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6901725410.5798 - val_loss: 5534018735.3425\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6967566129.6192 - val_loss: 5534168842.5205\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6926538965.8456 - val_loss: 5533030554.3014\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6982786007.6021 - val_loss: 5532852108.2740\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7037829223.6295 - val_loss: 5533287122.4110\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7003426918.7513 - val_loss: 5535026309.2603\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7093756669.8045 - val_loss: 5534108321.3151\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6895505290.7581 - val_loss: 5534765255.8904\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6909782432.2744 - val_loss: 5533710325.4795\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6892818202.3465 - val_loss: 5533340615.8904\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7038639580.8714 - val_loss: 5533824042.0822\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6916839385.3585 - val_loss: 5534544503.2329\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7092757013.0772 - val_loss: 5534701266.4110\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7068386614.4494 - val_loss: 5534916871.0137\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6972401002.7033 - val_loss: 5535106826.5205\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7145989790.9571 - val_loss: 5535773247.1233\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7037102226.6621 - val_loss: 5535400083.2877\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6944770445.3928 - val_loss: 5536232609.3151\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7094907663.3688 - val_loss: 5537231296.8767\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6992809037.7221 - val_loss: 5536674433.7534\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7150868401.8388 - val_loss: 5538302449.9726\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7088687458.7993 - val_loss: 5538849055.5616\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7000155171.1286 - val_loss: 5537383858.8493\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7127432990.2985 - val_loss: 5538171069.3699\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6954371304.7273 - val_loss: 5537922083.0685\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7182117801.9348 - val_loss: 5537986461.8082\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7086354038.5592 - val_loss: 5538705358.9041\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6979366637.1184 - val_loss: 5538688469.9178\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7049888446.5729 - val_loss: 5537815762.4110\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6893428632.3705 - val_loss: 5537584640.0000\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7153500445.4202 - val_loss: 5538408293.6986\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7046150504.5077 - val_loss: 5536658824.7671\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7208048228.1166 - val_loss: 5536439190.7945\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6930522350.4357 - val_loss: 5536444009.2055\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7234161423.3688 - val_loss: 5536947315.7260\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6868505874.0034 - val_loss: 5536126499.0685\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 6845432673.9211 - val_loss: 5534314846.6849\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6882971539.5403 - val_loss: 5534718674.4110\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7236507406.4906 - val_loss: 5534683767.2329\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6993612160.6587 - val_loss: 5535277020.9315\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6945545370.5660 - val_loss: 5534691496.3288\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6988657545.0017 - val_loss: 5534964132.8219\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7142174681.3585 - val_loss: 5534658293.4795\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6993026779.1149 - val_loss: 5533425159.0137\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7060765959.4648 - val_loss: 5534035610.3014\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7023106351.8628 - val_loss: 5534369329.0959\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 6945691965.44 - 0s 150us/step - loss: 7210602509.1732 - val_loss: 5535427422.6849\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7039152983.3825 - val_loss: 5534958707.7260\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7134615472.0823 - val_loss: 5535711442.4110\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 6932570775.9314 - val_loss: 5534591726.4658\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7226619594.8679 - val_loss: 5535042637.1507\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6964532036.0617 - val_loss: 5534181691.6164\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7117983778.2504 - val_loss: 5534646405.2603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7097852869.5986 - val_loss: 5534224475.1781\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6918879281.1801 - val_loss: 5533991971.0685\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7167120877.5575 - val_loss: 5533560242.8493\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7150097660.9262 - val_loss: 5534968453.2603\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7235757612.7890 - val_loss: 5534677760.0000\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6986241508.7753 - val_loss: 5535362826.5205\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7166662944.0549 - val_loss: 5534749148.9315\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7131006698.4837 - val_loss: 5535697990.1370\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6931879762.9914 - val_loss: 5535929365.0411\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6953116867.8422 - val_loss: 5535894703.3425\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6935023847.1904 - val_loss: 5535816283.1781\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6876451671.8216 - val_loss: 5536064813.5890\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6734007281.0703 - val_loss: 5535055640.5479\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6977637493.6810 - val_loss: 5534667663.7808\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7058710746.6758 - val_loss: 5535358071.2329\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6956737960.1784 - val_loss: 5535024881.9726\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6966068137.0566 - val_loss: 5535089565.8082\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7113044933.1595 - val_loss: 5535932949.0411\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7228576919.0532 - val_loss: 5535382335.1233\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7042944959.0120 - val_loss: 5535183447.6712\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7163765156.6655 - val_loss: 5535617472.8767\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7197966952.5077 - val_loss: 5536503625.6438\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7243142619.1149 - val_loss: 5537429086.6849\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7075220711.8491 - val_loss: 5537556494.0274\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7019992325.7084 - val_loss: 5536906152.3288\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7046597151.6158 - val_loss: 5536459400.7671\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7032752993.9211 - val_loss: 5536877988.8219\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6962396065.5918 - val_loss: 5537445144.5479\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 6892312720.0274 - val_loss: 5536754565.2603\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6911493050.4014 - val_loss: 5536502948.8219\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6974046011.2796 - val_loss: 5535491633.0959\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7086428361.9897 - val_loss: 5536262641.9726\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6841740179.1012 - val_loss: 5536110556.9315\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7112315783.0257 - val_loss: 5535820091.6164\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7128930959.1492 - val_loss: 5535747524.3836\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 6800203164.7616 - val_loss: 5535187743.5616\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7029651464.7822 - val_loss: 5535195458.6301\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6681324819.3208 - val_loss: 5535429681.0959\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7095529747.3208 - val_loss: 5536415694.9041\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7131315709.8045 - val_loss: 5536164555.3973\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6951365932.3499 - val_loss: 5536772716.7123\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7018766896.3019 - val_loss: 5536293137.5342\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7022341713.6741 - val_loss: 5535245304.9863\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6924327012.9949 - val_loss: 5534732835.0685\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 6920673040.2470 - val_loss: 5535365372.4932\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7031997515.5266 - val_loss: 5535166492.0548\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7256877051.6089 - val_loss: 5534522031.3425\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6968265167.2590 - val_loss: 5534884565.9178\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6859900559.5883 - val_loss: 5535003577.8630\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7091126188.1304 - val_loss: 5534492489.6438\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7151818490.2916 - val_loss: 5535272960.0000\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6953495273.6055 - val_loss: 5536094586.7397\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6854460437.9554 - val_loss: 5535344303.3425\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6859479279.7530 - val_loss: 5535165825.7534\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7061235796.3087 - val_loss: 5535237379.5068\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6922520639.2316 - val_loss: 5534849553.5342\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7113853923.8971 - val_loss: 5535149403.1781\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7098944427.6913 - val_loss: 5534939314.8493\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6953777411.9520 - val_loss: 5535178983.4521\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7060586389.7358 - val_loss: 5534704029.8082\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7029267751.0806 - val_loss: 5534014492.0548\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6963781785.6878 - val_loss: 5533555228.0548\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6899403372.0206 - val_loss: 5533293448.7671\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7295870042.4563 - val_loss: 5535101706.5205\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 6973227208.2333 - val_loss: 5535078634.9589\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 145us/step - loss: 7067123813.4340 - val_loss: 5535288316.4932\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7033873587.1561 - val_loss: 5534017416.7671\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7004781030.5317 - val_loss: 5533539671.6712\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7043235261.2556 - val_loss: 5533481457.9726\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7064579986.2230 - val_loss: 5534206842.7397\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 6902892951.0532 - val_loss: 5534934962.8493\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7058697122.9091 - val_loss: 5535098978.1918\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6966235455.6707 - val_loss: 5536033434.3014\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7067155891.5952 - val_loss: 5534071723.8356\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 6913239750.0377 - val_loss: 5534846327.2329\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7061491960.3156 - val_loss: 5535456732.9315\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7034985076.8027 - val_loss: 5536267944.3288\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6915976520.4528 - val_loss: 5535829244.4932\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 6894084591.7530 - val_loss: 5535028048.6575\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7031378475.0326 - val_loss: 5535293447.0137\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6964916831.7256 - val_loss: 5534410573.1507\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6881741867.0326 - val_loss: 5533707088.6575\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6913507459.7324 - val_loss: 5534342059.8356\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6878157326.9297 - val_loss: 5533879092.6027\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 6919214385.6192 - val_loss: 5533497344.0000\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7148202905.2487 - val_loss: 5534801253.6986\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7009719056.0274 - val_loss: 5534599027.7260\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 6869374677.4065 - val_loss: 5535251754.0822\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7101223555.7324 - val_loss: 5536090574.9041\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6847889724.1578 - val_loss: 5535307744.4384\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7212853330.5523 - val_loss: 5534647236.3836\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7033867346.5523 - val_loss: 5535012043.3973\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 6870039961.2487 - val_loss: 5535062520.9863\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7021545621.2967 - val_loss: 5535397586.4110\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 6872209931.4168 - val_loss: 5535174038.7945\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7047658493.3654 - val_loss: 5536077680.2192\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7018339059.2659 - val_loss: 5536560738.1918\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6997168507.8285 - val_loss: 5536307838.2466\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6947291625.1664 - val_loss: 5534975466.9589\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6707022277.1595 - val_loss: 5534605199.7808\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7014276803.8422 - val_loss: 5535319348.6027\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6953978604.2401 - val_loss: 5535530306.6301\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7099708616.2333 - val_loss: 5535296371.7260\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6917694383.2041 - val_loss: 5535509360.2192\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 6928792772.7204 - val_loss: 5534884744.7671\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 6981339215.9177 - val_loss: 5534805335.6712\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6979701666.9091 - val_loss: 5534708216.9863\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7018510619.6638 - val_loss: 5534526716.4932\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7196209964.3499 - val_loss: 5535713998.9041\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6915203921.6741 - val_loss: 5534898684.4932\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7079513621.0772 - val_loss: 5534345219.5068\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7136573510.2573 - val_loss: 5535390456.9863\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7217550524.8165 - val_loss: 5536272285.8082\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7189189881.4134 - val_loss: 5535525684.6027\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7063698108.8165 - val_loss: 5536176450.6301\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7065720828.4871 - val_loss: 5536565072.6575\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6940314616.9743 - val_loss: 5535820957.8082\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 6983944829.1458 - val_loss: 5534874602.9589\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7173321661.2556 - val_loss: 5535144192.0000\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 6933393377.2624 - val_loss: 5534467384.1096\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 6958702080.4391 - val_loss: 5534818083.0685\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7169564910.8748 - val_loss: 5534942060.7123\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7194112827.2796 - val_loss: 5535321957.6986\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7080653502.5729 - val_loss: 5535905322.0822\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7066622988.2950 - val_loss: 5535726241.3151\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7139527401.3859 - val_loss: 5536808928.4384\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7032994152.9468 - val_loss: 5536820069.6986\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7056712756.6930 - val_loss: 5536393626.3014\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 6954541946.5111 - val_loss: 5535173849.4247\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7043890289.7290 - val_loss: 5535436028.4932\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 150us/step - loss: 7090543745.9760 - val_loss: 5535373694.2466\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7109866408.6175 - val_loss: 5535882744.9863\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7192609352.8919 - val_loss: 5535768379.6164\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 6943330556.0480 - val_loss: 5535765945.8630\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 6923268882.8816 - val_loss: 5536091062.3562\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7056098739.5952 - val_loss: 5535799804.4932\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7119089678.0515 - val_loss: 5536480957.3699\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7119271163.1698 - val_loss: 5535763939.9452\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7046971967.6707 - val_loss: 5537238535.0137\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 6935845260.0755 - val_loss: 5536616391.8904\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7176479517.4202 - val_loss: 5536162928.2192\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7035622385.9485 - val_loss: 5536684382.6849\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 6790892260.3362 - val_loss: 5536381955.5068\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7199997045.2419 - val_loss: 5537015730.8493\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7215671755.7461 - val_loss: 5538216910.9041\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7042640362.9228 - val_loss: 5537740382.6849\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 6949317841.0154 - val_loss: 5538105792.8767\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 6924844088.2058 - val_loss: 5538553414.1370\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7022897745.6741 - val_loss: 5538369437.8082\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 6820377093.2693 - val_loss: 5538332601.8630\n",
      "neurons used (16, 32)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 558us/step - loss: 39208881905.5094 - val_loss: 38414480987.1781\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 39203289274.1818 - val_loss: 38406840095.5616\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39194209917.5849 - val_loss: 38394895542.3562\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 39181834039.7667 - val_loss: 38383293089.3151\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39166714776.3705 - val_loss: 38367037468.0548\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 39147412720.6312 - val_loss: 38344700913.9726\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39125624389.3791 - val_loss: 38324731511.2329\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 39101796179.8696 - val_loss: 38300672757.4795\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 39072316723.3756 - val_loss: 38273794440.7671\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 39041564721.1801 - val_loss: 38235360494.4658\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 39007018052.5009 - val_loss: 38206380060.0548\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38970764012.2401 - val_loss: 38158519590.5753\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38928517573.1595 - val_loss: 38110181151.5616\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38888753197.6672 - val_loss: 38059820130.1918\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 38840172101.3791 - val_loss: 38020108259.9452\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 38786196530.9365 - val_loss: 37980953501.8082\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38736436763.2247 - val_loss: 37924463545.8630\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 38686822171.6638 - val_loss: 37877242024.3288\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 38632115746.2504 - val_loss: 37820269890.6301\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38561658433.8662 - val_loss: 37750926490.3014\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 38497179370.4837 - val_loss: 37683036945.5342\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 38430886460.5969 - val_loss: 37608848510.2466\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 38365268631.9314 - val_loss: 37537563970.6301\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38294478679.3825 - val_loss: 37460367107.5069\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38212625669.7084 - val_loss: 37378609039.7808\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38129778526.4082 - val_loss: 37306121230.0274\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 38053384420.3362 - val_loss: 37220576550.5753\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 37972353431.4923 - val_loss: 37137074063.7808\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 37881224653.9417 - val_loss: 37048952018.4110\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 37787486232.5900 - val_loss: 36951200305.0959\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 37681941179.0600 - val_loss: 36851312471.6712\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 37603778145.4820 - val_loss: 36746959829.9178\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 37494475963.9382 - val_loss: 36653685100.7123\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 37405230966.9983 - val_loss: 36557245061.2603\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 37284035230.9571 - val_loss: 36450812465.0959\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 37178103558.5866 - val_loss: 36342122748.4931\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 37070466401.0429 - val_loss: 36229643306.0822\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 36982348636.6518 - val_loss: 36107231400.3288\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 36844743246.1612 - val_loss: 35981700334.4658\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 36728772882.0034 - val_loss: 35866708669.3699\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 36622163188.1441 - val_loss: 35744133232.2192\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 36520695839.6158 - val_loss: 35614054820.8219\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 36341361035.1973 - val_loss: 35490123271.0137\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 36217682246.6964 - val_loss: 35345395010.6301\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 36106537321.8250 - val_loss: 35221662958.4658\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 35918808234.3739 - val_loss: 35098470820.8219\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 35817610034.4974 - val_loss: 34980350288.6575\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 35698666128.9057 - val_loss: 34833008892.4931\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 35559208780.8439 - val_loss: 34697280469.9178\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 35380163852.7341 - val_loss: 34558402419.7260\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 35269334210.9640 - val_loss: 34375110375.4521\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 35093458996.6930 - val_loss: 34221849165.1507\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 34981272802.5798 - val_loss: 34076705862.1370\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 34818944138.7581 - val_loss: 33892260513.3151\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 34653459134.5729 - val_loss: 33757729553.5342\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 34521300837.4340 - val_loss: 33573777548.2740\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 34376375743.8902 - val_loss: 33415874503.8904\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 34131657065.8250 - val_loss: 33254194133.9178\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 34019345617.0154 - val_loss: 33100102613.9178\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 33849682137.7976 - val_loss: 32922468436.1644\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 33670393620.6381 - val_loss: 32739898606.4658\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 33467025587.1561 - val_loss: 32563608842.5205\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 33309463715.3482 - val_loss: 32416031954.4110\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 33118121176.0412 - val_loss: 32242525871.3425\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 32952490099.9245 - val_loss: 32040537354.5205\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 32799473776.4117 - val_loss: 31871322168.1096\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 32617698660.5557 - val_loss: 31682812240.6575\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 32400275867.0051 - val_loss: 31511277932.7123\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 32242745459.9245 - val_loss: 31329804933.2603\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 32000353594.4014 - val_loss: 31131658744.9863\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 31870818616.6449 - val_loss: 30923479629.1507\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 31729400809.1664 - val_loss: 30725388119.6712\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 31398619153.5643 - val_loss: 30543829216.4384\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 31265005055.1218 - val_loss: 30315864288.4384\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 31118131814.7513 - val_loss: 30100814104.5479\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 30901516481.2075 - val_loss: 29922119371.3973\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 30697055437.5026 - val_loss: 29736025522.8493\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 30564341760.0000 - val_loss: 29539165169.9726\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 30239401864.5626 - val_loss: 29348844922.7397\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 30031238244.1166 - val_loss: 29142277077.9178\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 29960206824.2882 - val_loss: 28915187599.7808\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 29671921667.5129 - val_loss: 28713853236.6027\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 29493378495.8902 - val_loss: 28488506999.2329\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 29196960762.7307 - val_loss: 28262911298.6301\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 29152117048.6449 - val_loss: 28040135553.7534\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 28889403597.5026 - val_loss: 27860687886.0274\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 28590568871.3002 - val_loss: 27622976021.0411\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 28333585855.8902 - val_loss: 27404556372.1644\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 28180678325.7907 - val_loss: 27186374459.6164\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 27963745334.4494 - val_loss: 26937749644.2740\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 27654137761.1527 - val_loss: 26735042083.0685\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 27617995491.4580 - val_loss: 26531986586.3014\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 27340924938.5386 - val_loss: 26306936607.5616\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 27064217600.0000 - val_loss: 26061474773.9178\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 26902677124.6106 - val_loss: 25840892717.5890\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 26713209372.9811 - val_loss: 25588932131.0685\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 26431664099.8971 - val_loss: 25368102547.2877\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 26092671724.2401 - val_loss: 25151610992.2192\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 25951564619.0875 - val_loss: 24909054176.4384\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 25740828071.3002 - val_loss: 24681958919.0137\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 25340869718.0652 - val_loss: 24432335914.0822\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25137868016.6312 - val_loss: 24208382485.0411\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25031076925.4751 - val_loss: 23967375331.9452\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 24843175563.6364 - val_loss: 23732011849.6438\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 24521268703.5060 - val_loss: 23506620191.5616\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 24132195965.5849 - val_loss: 23249715648.8767\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 24107365616.6312 - val_loss: 23004574958.4658\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 23936944728.6998 - val_loss: 22774083920.6575\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 158us/step - loss: 23453685103.0943 - val_loss: 22522650020.8219\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 23222990164.7479 - val_loss: 22310650192.6575\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 23023976275.8696 - val_loss: 22074155204.3836\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 22762673083.4991 - val_loss: 21833113066.9589\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 22629689698.7993 - val_loss: 21601020282.7397\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 22567905998.3808 - val_loss: 21347811159.6712\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 22246822472.8919 - val_loss: 21100503208.3288\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 21897741354.1544 - val_loss: 20831003451.6164\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 21731343238.8062 - val_loss: 20609135868.4931\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 21492219675.6638 - val_loss: 20358195087.7808\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 21111959541.4614 - val_loss: 20097789587.2877\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 20943735922.1681 - val_loss: 19871525354.9589\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 20780761070.4357 - val_loss: 19622851064.9863\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 20466855946.5386 - val_loss: 19367384877.5890\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 20306613464.0412 - val_loss: 19131477959.8904\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 20015541706.4288 - val_loss: 18901724258.1918\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 19732324032.3293 - val_loss: 18648071294.2466\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 19546298016.7136 - val_loss: 18409576910.9041\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 19343832889.5232 - val_loss: 18177794833.5342\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 19133350197.1321 - val_loss: 17932965817.8630\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 18889927244.4048 - val_loss: 17703390208.0000\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 18651668743.4648 - val_loss: 17456262536.7671\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 18272635884.6792 - val_loss: 17220231055.7808\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 18162238595.7324 - val_loss: 17004548194.1918\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 17849700559.2590 - val_loss: 16781009457.0959\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 17749438852.1715 - val_loss: 16546090180.3836\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 17379107279.6981 - val_loss: 16311639446.7945\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 17278218178.5249 - val_loss: 16071120208.6575\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 17079486319.9726 - val_loss: 15810653099.8356\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 16984982009.8525 - val_loss: 15585011487.5616\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 16751061914.1269 - val_loss: 15356383919.3425\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 16285259867.3345 - val_loss: 15119779012.3836\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 16106900662.6690 - val_loss: 14882400732.9315\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 15878152153.3585 - val_loss: 14654955141.2603\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 15757451592.4528 - val_loss: 14434157231.3425\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 15470614605.2830 - val_loss: 14225019356.9315\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 15199105332.2539 - val_loss: 14011471268.8219\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 14826720217.3585 - val_loss: 13796505487.7808\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 14833139206.1475 - val_loss: 13564416967.8904\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 14704007025.7290 - val_loss: 13343871929.8630\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 14330641232.3568 - val_loss: 13139183096.9863\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 14208673887.7256 - val_loss: 12918606286.9041\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 14000307983.3688 - val_loss: 12699900871.8904\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 13882066355.5952 - val_loss: 12485234000.6575\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 13440625764.1166 - val_loss: 12288971565.5890\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 13587711978.9228 - val_loss: 12097346440.7671\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 13116541684.1441 - val_loss: 11912809843.7260\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 13017325808.6312 - val_loss: 11691661816.9863\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 12807221862.7513 - val_loss: 11495227960.1096\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 12648889674.2093 - val_loss: 11303867861.9178\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 12529925502.4631 - val_loss: 11097332518.5753\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 12263556896.9331 - val_loss: 10899236162.6301\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 12162577236.7479 - val_loss: 10720886194.8493\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11958482701.6123 - val_loss: 10539000284.9315\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 11787756785.5094 - val_loss: 10357378637.1507\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 11619234919.6295 - val_loss: 10181113386.0822\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 11604552232.3979 - val_loss: 10023161533.3699\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 11174157167.9726 - val_loss: 9845107031.6712\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11101522747.2796 - val_loss: 9659385315.9452\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10863967702.7238 - val_loss: 9480776465.5342\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10856643325.8045 - val_loss: 9315685495.2329\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10511171584.0000 - val_loss: 9162732396.7123\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10348855905.4820 - val_loss: 9003564039.0137\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10570841636.0069 - val_loss: 8845536263.0137\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 171us/step - loss: 10257104164.4460 - val_loss: 8700572861.3699\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9811889906.3877 - val_loss: 8565289528.1096\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9987324612.7204 - val_loss: 8414780240.6575\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9647600207.0395 - val_loss: 8269279112.7671\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9687754100.8027 - val_loss: 8126128527.7808\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9529048806.0926 - val_loss: 7985271513.4247\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9348690018.7993 - val_loss: 7861981927.4521\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9282716450.6895 - val_loss: 7730115142.1370\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9180779112.5077 - val_loss: 7602827656.7671\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9095916262.9708 - val_loss: 7486326517.4795\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8935546129.1252 - val_loss: 7354565554.8493\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8841560994.9091 - val_loss: 7237182811.1781\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8571634320.0274 - val_loss: 7133888596.1644\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8660549140.1990 - val_loss: 7046599928.9863\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 8645504052.2539 - val_loss: 6946059046.5753\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 8425395793.6741 - val_loss: 6860325418.0822\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8605595121.0703 - val_loss: 6764331884.7123\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8429302750.6278 - val_loss: 6673358939.1781\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8459989334.0652 - val_loss: 6596063603.7260\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 8040397441.0978 - val_loss: 6511828550.1370\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7981708858.8405 - val_loss: 6437333623.2329\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8085814560.4940 - val_loss: 6353812827.1781\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8120216062.2436 - val_loss: 6276128718.9041\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7885633629.0909 - val_loss: 6225448163.9452\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8000679118.3808 - val_loss: 6162235188.6027\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8120760832.0000 - val_loss: 6113593933.1507\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7809675890.1681 - val_loss: 6063130995.7260\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7911850801.1801 - val_loss: 6021181064.7671\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7694114765.0635 - val_loss: 5980919229.3699\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7899551883.6364 - val_loss: 5936711655.4521\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7628986300.3774 - val_loss: 5897446277.2603\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7831616354.7993 - val_loss: 5865215740.4932\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 7734989399.3825 - val_loss: 5836127982.4658\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 7536166834.7170 - val_loss: 5808275154.4110\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7677901810.8268 - val_loss: 5780645127.0137\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 7754246893.9966 - val_loss: 5762876935.0137\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 7653634488.8645 - val_loss: 5743218554.7397\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 326us/step - loss: 7429543530.2642 - val_loss: 5722690819.5068\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 7474616888.2058 - val_loss: 5704776107.8356\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7381746391.1630 - val_loss: 5686048154.3014\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7478364371.6501 - val_loss: 5679449165.1507\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7642281065.3859 - val_loss: 5669370318.9041\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 7388089125.3242 - val_loss: 5661304670.6849\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 7499220697.7976 - val_loss: 5649865216.0000\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 270us/step - loss: 7429758643.1561 - val_loss: 5637468377.4247\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7591191161.1938 - val_loss: 5629625344.0000\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7626509031.8491 - val_loss: 5622901170.8493\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7734285193.4408 - val_loss: 5620465860.3836\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7439237947.2796 - val_loss: 5614354540.7123\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7575688772.5009 - val_loss: 5611098497.7534\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7643986141.7496 - val_loss: 5605303699.2877\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7468314407.5197 - val_loss: 5600848257.7534\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7567608049.5094 - val_loss: 5599753924.3836\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7606295131.3345 - val_loss: 5595786264.5479\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7370406277.9280 - val_loss: 5592154767.7808\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7319404573.8593 - val_loss: 5587645411.9452\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7404785125.6535 - val_loss: 5584201664.8767\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7531813456.3568 - val_loss: 5582583811.5068\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7665528416.6038 - val_loss: 5581655429.2603\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7539241403.4991 - val_loss: 5577975513.4247\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7663513959.1904 - val_loss: 5578614468.3836\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7337001309.5300 - val_loss: 5578030416.6575\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7406611570.1681 - val_loss: 5576297429.9178\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 279us/step - loss: 7307024971.5266 - val_loss: 5574090969.4247\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 363us/step - loss: 7191617129.3859 - val_loss: 5571894005.4795\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 415us/step - loss: 7498427924.1990 - val_loss: 5571802883.5068\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 1s 460us/step - loss: 7665433602.6346 - val_loss: 5571275123.7260\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 1s 448us/step - loss: 7258816580.5009 - val_loss: 5569702301.8082\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 1s 473us/step - loss: 7650701055.5609 - val_loss: 5571374690.1918\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 388us/step - loss: 7315204304.5763 - val_loss: 5566647127.6712\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 391us/step - loss: 7449074975.1767 - val_loss: 5566262468.3836\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 366us/step - loss: 7681337425.2350 - val_loss: 5566305676.2740\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 342us/step - loss: 7383149226.3739 - val_loss: 5564083943.4521\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 376us/step - loss: 7585179320.4254 - val_loss: 5562031216.2192\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 419us/step - loss: 7728005781.2967 - val_loss: 5563686954.0822\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7477433429.33 - 0s 360us/step - loss: 7619363511.5472 - val_loss: 5562795148.2740\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 342us/step - loss: 7634909732.0069 - val_loss: 5564326855.8904\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 304us/step - loss: 7471429896.3431 - val_loss: 5563679561.6438\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 417us/step - loss: 7607408855.1630 - val_loss: 5562589485.5890\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 324us/step - loss: 7525935846.0926 - val_loss: 5563246241.3151\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 304us/step - loss: 7740890899.7599 - val_loss: 5563984668.0548\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 365us/step - loss: 7537308164.3911 - val_loss: 5563883193.8630\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 289us/step - loss: 7697189715.8696 - val_loss: 5563971485.8082\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 265us/step - loss: 7484046735.5883 - val_loss: 5565480896.8767\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 7664657281.0978 - val_loss: 5564910395.6164\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 7546106119.4648 - val_loss: 5564647921.9726\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 7323297544.3431 - val_loss: 5562475881.2055\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 279us/step - loss: 7552258160.8508 - val_loss: 5562088679.4521\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 7339523149.7221 - val_loss: 5561875294.6849\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 241us/step - loss: 7625225691.1149 - val_loss: 5563516044.2740\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 7317436791.8765 - val_loss: 5561773932.7123\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 7694338305.3173 - val_loss: 5563341953.7534\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 7667061969.0154 - val_loss: 5563870176.4384\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 7745171723.8559 - val_loss: 5564090609.9726\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 7327694405.3791 - val_loss: 5564997730.1918\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 7358804196.3362 - val_loss: 5564339466.5205\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 7722871507.6501 - val_loss: 5564241695.5616\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 7642082314.5386 - val_loss: 5563612931.5068\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 7701397046.4494 - val_loss: 5564532546.6301\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 7295507313.7290 - val_loss: 5564181973.9178\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 7526268812.9537 - val_loss: 5564948501.0411\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7436951227.0600 - val_loss: 5563978622.2466\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7468376612.8851 - val_loss: 5565619803.1781\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7452664063.5609 - val_loss: 5563226245.2603\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7866478224.4666 - val_loss: 5564393885.8082\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7381639362.9640 - val_loss: 5564514444.2740\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7707327156.9125 - val_loss: 5564994139.1781\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7420106755.5129 - val_loss: 5563914415.3425\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7603893274.3465 - val_loss: 5563689735.0137\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7382495284.6930 - val_loss: 5563612296.7671\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7566167906.7993 - val_loss: 5565053110.3562\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 7315803957.5712 - val_loss: 5564063056.6575\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 7482370757.5986 - val_loss: 5564317418.9589\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7102593467.4991 - val_loss: 5562787594.5205\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 7638425961.8250 - val_loss: 5563142421.0411\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7443286037.0772 - val_loss: 5564064270.0274\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 7430469379.7324 - val_loss: 5563298437.2603\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 7480012673.9760 - val_loss: 5560907470.9041\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7374213408.9331 - val_loss: 5559591879.8904\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 7274759514.0172 - val_loss: 5558384163.0685\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7526118982.2573 - val_loss: 5559120373.4795\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7356860212.2539 - val_loss: 5558167110.1370\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 7578771022.1612 - val_loss: 5559612801.7534\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 7734936427.5815 - val_loss: 5561688526.9041\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7476414672.1372 - val_loss: 5563005825.7534\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7236921171.8696 - val_loss: 5561509383.0137\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7626412880.3568 - val_loss: 5562310813.8082\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7813689811.2110 - val_loss: 5560185747.2877\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7611188455.8491 - val_loss: 5559840796.0548\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7461407362.8542 - val_loss: 5560495784.3288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7803876665.5232 - val_loss: 5561549883.6164\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7498684574.0789 - val_loss: 5561560828.4932\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7567359564.4048 - val_loss: 5561410293.4795\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7355464923.7736 - val_loss: 5561924464.2192\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7348822004.5832 - val_loss: 5561955054.4658\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7571752164.7753 - val_loss: 5562160422.5753\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7756920048.6312 - val_loss: 5563762884.3836\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7439007270.6415 - val_loss: 5562345408.8767\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7410666237.8045 - val_loss: 5562190770.8493\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7554213990.7513 - val_loss: 5561071724.7123\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7411290202.4563 - val_loss: 5562750015.1233\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7393507500.1304 - val_loss: 5559960414.6849\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7659629779.2110 - val_loss: 5559927983.3425\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7463587699.4854 - val_loss: 5560945628.9315\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7483642614.7787 - val_loss: 5561424124.4932\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7667130290.7170 - val_loss: 5561876704.4384\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7552331700.4734 - val_loss: 5561279214.4658\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7238622986.0995 - val_loss: 5560870056.3288\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7432049995.0875 - val_loss: 5558710685.8082\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7263505868.1852 - val_loss: 5560330008.5479\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7580963702.1201 - val_loss: 5561455756.2740\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7484349375.4511 - val_loss: 5561675768.9863\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7168075912.1235 - val_loss: 5562246557.8082\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7423629324.7341 - val_loss: 5562633868.2740\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7389496663.3825 - val_loss: 5561470940.9315\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7589455989.6810 - val_loss: 5561841621.9178\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7430730467.4580 - val_loss: 5562003456.0000\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7380622140.1578 - val_loss: 5561381912.5479\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7639302899.7050 - val_loss: 5561573565.3699\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7544839964.9811 - val_loss: 5560569358.0274\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7396479220.1441 - val_loss: 5561980661.4795\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7385289854.4631 - val_loss: 5563593293.1507\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7405137187.5678 - val_loss: 5563602698.5205\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7375380992.8782 - val_loss: 5560807438.0274\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7563799875.1835 - val_loss: 5561684427.3973\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7507890141.7496 - val_loss: 5562487653.6986\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7398621093.1046 - val_loss: 5563495858.8493\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7522216153.7976 - val_loss: 5563146366.2466\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7480344360.1784 - val_loss: 5562483540.1644\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7470502536.1235 - val_loss: 5563841490.4110\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7534657921.5369 - val_loss: 5564655040.8767\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7379596231.3551 - val_loss: 5563041669.2603\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7288046336.0000 - val_loss: 5561328983.6712\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7552300791.6569 - val_loss: 5559091413.9178\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7592859061.7907 - val_loss: 5558642765.1507\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7778316533.0223 - val_loss: 5559684671.1233\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7528716510.1887 - val_loss: 5560001002.9589\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7498862487.4923 - val_loss: 5560270648.1096\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7689355108.9949 - val_loss: 5561495243.3973\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7559629381.3791 - val_loss: 5562856051.7260\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7461136189.0360 - val_loss: 5564045873.0959\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7438409399.1081 - val_loss: 5565946599.4521\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7389540283.0600 - val_loss: 5564865283.5068\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7745555651.8422 - val_loss: 5565532868.3836\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7500095722.9228 - val_loss: 5565527040.0000\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 7379502552.4803 - val_loss: 5563770410.0822\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7364068825.7976 - val_loss: 5563916484.3836\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7399535974.3122 - val_loss: 5562173103.3425\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7529326267.0600 - val_loss: 5560665550.9041\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7212781448.5626 - val_loss: 5561734908.4932\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7499149405.0909 - val_loss: 5564617854.2466\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7504153664.9880 - val_loss: 5564493515.3973\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7197324934.3671 - val_loss: 5563046298.3014\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 7365631206.5317 - val_loss: 5561857223.8904\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7415890373.1595 - val_loss: 5562518030.0274\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 176us/step - loss: 7565965258.6484 - val_loss: 5563325601.3151\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7489451808.9331 - val_loss: 5562597256.7671\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7503567169.4271 - val_loss: 5561403707.6164\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7534820836.7753 - val_loss: 5559516633.4247\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7348704151.4923 - val_loss: 5559505846.3562\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7338599350.6690 - val_loss: 5559095481.8630\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7832764876.1852 - val_loss: 5561707790.0274\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7497025063.7393 - val_loss: 5561821860.8219\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7307889545.4408 - val_loss: 5561388109.1507\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7606955863.3825 - val_loss: 5562126602.5205\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7456712219.2247 - val_loss: 5563378631.8904\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7448135602.7170 - val_loss: 5562992012.2740\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7265586815.3413 - val_loss: 5562260977.9726\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7329280804.4460 - val_loss: 5561485192.7671\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7486355102.9571 - val_loss: 5560485235.7260\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 7650686042.8954 - val_loss: 5559806292.1644\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7431655838.5180 - val_loss: 5558397808.2192\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 7555285854.4082 - val_loss: 5558774545.5342\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7397442707.5403 - val_loss: 5559865305.4247\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7642089399.9863 - val_loss: 5560361016.1096\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7684316239.9177 - val_loss: 5563003062.3562\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7619503414.8885 - val_loss: 5562595356.0548\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7506025359.1492 - val_loss: 5563590894.4658\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7423618201.6878 - val_loss: 5563750168.5479\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7535853473.1527 - val_loss: 5562750372.8219\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7517548204.1304 - val_loss: 5563737172.1644\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7446054421.9554 - val_loss: 5563417624.5479\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7562256823.1081 - val_loss: 5562397148.9315\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7413159785.8250 - val_loss: 5561835800.5479\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7339589948.5969 - val_loss: 5561550883.0685\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7464332226.0858 - val_loss: 5561919067.1781\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7646237298.6072 - val_loss: 5561672328.7671\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7548898379.5266 - val_loss: 5561858181.2603\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7435128326.1475 - val_loss: 5561590012.4932\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7506294351.0395 - val_loss: 5562468906.0822\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7514407281.7290 - val_loss: 5562310179.0685\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7593853125.5986 - val_loss: 5563355051.8356\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7666379165.6398 - val_loss: 5565558696.3288\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7506732641.9211 - val_loss: 5564668451.0685\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7457169101.5026 - val_loss: 5563685712.6575\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7529611140.1715 - val_loss: 5563318489.4247\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7588688288.2744 - val_loss: 5564005242.7397\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7507127511.1630 - val_loss: 5563056640.0000\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7651879333.5437 - val_loss: 5564677803.8356\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7680236522.9228 - val_loss: 5563891024.6575\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7314877232.7410 - val_loss: 5563579195.6164\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7423764465.9485 - val_loss: 5562166377.2055\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7336457509.7633 - val_loss: 5561804112.6575\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7367198056.0686 - val_loss: 5560757802.0822\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7450483282.5523 - val_loss: 5560094558.6849\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7541772412.7067 - val_loss: 5560074730.9589\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7318523240.9468 - val_loss: 5559263323.1781\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7595748135.0806 - val_loss: 5560853009.5342\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7258277353.1664 - val_loss: 5563524099.5068\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7500755625.4957 - val_loss: 5563543296.0000\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7489677667.6775 - val_loss: 5562846621.8082\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7518917380.3911 - val_loss: 5565223893.9178\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7430345205.9005 - val_loss: 5564071332.8219\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7243900251.7736 - val_loss: 5564515166.6849\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7531907565.9966 - val_loss: 5564959316.1644\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7458093162.2642 - val_loss: 5565209291.3973\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7448513323.4717 - val_loss: 5565569129.2055\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7351642644.1990 - val_loss: 5564382825.2055\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7613190443.9108 - val_loss: 5564869312.8767\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7513355662.7101 - val_loss: 5563768702.2466\n",
      "Epoch 433/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 164us/step - loss: 7632435520.5489 - val_loss: 5562615839.5616\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7430964363.6364 - val_loss: 5564386135.6712\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 7369784346.3465 - val_loss: 5563269617.9726\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7344117098.7033 - val_loss: 5561681478.1370\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7347269118.2436 - val_loss: 5561681197.5890\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7465545825.4820 - val_loss: 5561440298.0822\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 7415805296.8508 - val_loss: 5561836438.7945\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7758791434.0995 - val_loss: 5561708589.5890\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7515944769.8662 - val_loss: 5562370160.2192\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7407913681.8937 - val_loss: 5562292262.5753\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7592461427.9245 - val_loss: 5562430337.7534\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7362881609.7702 - val_loss: 5561667727.7808\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7469462497.4820 - val_loss: 5564052329.2055\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7566040035.0189 - val_loss: 5563442084.8219\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7493762704.9057 - val_loss: 5562801713.0959\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7377342969.8525 - val_loss: 5562444645.6986\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7696089604.3911 - val_loss: 5563712764.4932\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7459033995.1973 - val_loss: 5562232558.4658\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7602595984.9057 - val_loss: 5562540438.7945\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7610360021.4065 - val_loss: 5563016686.4658\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 7642062865.1252 - val_loss: 5563586209.3151\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7511924577.9211 - val_loss: 5564642433.7534\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 7509705006.1063 - val_loss: 5564506834.4110\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7569337248.2744 - val_loss: 5564360760.1096\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7507970951.6844 - val_loss: 5563446608.6575\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7298699313.1801 - val_loss: 5564098472.3288\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7538308794.1818 - val_loss: 5562822501.6986\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7787632323.8422 - val_loss: 5561185069.5890\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7361707404.9537 - val_loss: 5560207942.1370\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7045942377.3859 - val_loss: 5558684465.0959\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7442627711.3413 - val_loss: 5559813866.9589\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7259768476.7616 - val_loss: 5557699022.9041\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7289456520.5626 - val_loss: 5556856702.2466\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7570937541.5986 - val_loss: 5556685950.2466\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7441456972.8439 - val_loss: 5557578204.9315\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7360230107.5540 - val_loss: 5558396272.2192\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7296053200.5763 - val_loss: 5559493842.4110\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7503520414.9571 - val_loss: 5558790284.2740\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7501513707.3619 - val_loss: 5559529051.1781\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7577060708.5557 - val_loss: 5558748777.2055\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7552122138.7856 - val_loss: 5559335809.7534\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7248741826.5249 - val_loss: 5558195066.7397\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7406535407.7530 - val_loss: 5558733252.3836\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7540293184.1098 - val_loss: 5556281750.7945\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7572839439.8079 - val_loss: 5556794087.4521\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7456331754.9228 - val_loss: 5556761922.6301\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7434883741.2007 - val_loss: 5557144653.1507\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7553646265.3036 - val_loss: 5557710216.7671\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7466075339.3070 - val_loss: 5557943920.2192\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7603781992.0686 - val_loss: 5558067073.7534\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7570458817.3173 - val_loss: 5559292177.5342\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7457207260.8714 - val_loss: 5559886062.4658\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7613891311.7530 - val_loss: 5560112871.4521\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7759207820.9537 - val_loss: 5560383053.1507\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7429782097.6741 - val_loss: 5560316289.7534\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7552409317.6535 - val_loss: 5559839196.9315\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7409241474.4151 - val_loss: 5560148781.5890\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7626985849.6329 - val_loss: 5559438995.2877\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7568390048.2744 - val_loss: 5560607288.1096\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7479212010.0446 - val_loss: 5561626774.7945\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7816507658.5386 - val_loss: 5562986467.9452\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7404057329.5094 - val_loss: 5562919823.7808\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7547056542.5180 - val_loss: 5562838461.3699\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7418549817.0840 - val_loss: 5561930885.2603\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7406728865.5918 - val_loss: 5561808934.5753\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 154us/step - loss: 7719465302.5043 - val_loss: 5562802652.9315\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7425391022.7650 - val_loss: 5563934881.3151\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7288852056.6998 - val_loss: 5564024719.7808\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7645875015.5746 - val_loss: 5563048286.6849\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7385116559.5883 - val_loss: 5562079200.4384\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7314855452.9811 - val_loss: 5562609607.8904\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7634517883.8285 - val_loss: 5562482849.3151\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7490391797.0223 - val_loss: 5563708766.6849\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7382629170.9365 - val_loss: 5563613261.1507\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7288418471.7393 - val_loss: 5563572472.9863\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7482105901.6672 - val_loss: 5561949162.9589\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 140us/step - loss: 7748311408.8508 - val_loss: 5561770629.2603\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7126013906.7719 - val_loss: 5561093817.8630\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7493552358.0926 - val_loss: 5560135427.5068\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7425284974.2161 - val_loss: 5560557126.1370\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7769092848.6312 - val_loss: 5561222431.5616\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7644404878.2710 - val_loss: 5562115359.5616\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7365966941.9691 - val_loss: 5561228961.3151\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7801154507.7461 - val_loss: 5561534898.8493\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7877223765.6261 - val_loss: 5564051417.4247\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7259993509.5437 - val_loss: 5562478195.7260\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7479696440.2058 - val_loss: 5562394273.3151\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7589916883.6501 - val_loss: 5560855352.1096\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7852178827.6364 - val_loss: 5561634465.3151\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7755510237.3105 - val_loss: 5561877034.0822\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7423669669.5437 - val_loss: 5560499501.5890\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7365122940.2676 - val_loss: 5559694139.6164\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7168062197.76 - 0s 149us/step - loss: 7379693932.4597 - val_loss: 5559487943.8904\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7317630361.2487 - val_loss: 5560549740.7123\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7616219436.3499 - val_loss: 5559519224.9863\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7410214173.4202 - val_loss: 5559648161.3151\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7494878801.6741 - val_loss: 5559297984.8767\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7239663506.2230 - val_loss: 5559937122.1918\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7739760023.4923 - val_loss: 5560993097.6438\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7440257075.8148 - val_loss: 5560975132.0548\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7434712712.5626 - val_loss: 5560796612.3836\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 141us/step - loss: 7335478126.2161 - val_loss: 5559589207.6712\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7770480224.6038 - val_loss: 5559543117.1507\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7602752354.7993 - val_loss: 5559920408.5479\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7500267548.9811 - val_loss: 5560482100.6027\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7386456948.3636 - val_loss: 5559472668.0548\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7378317221.5437 - val_loss: 5557727302.1370\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7579251360.7136 - val_loss: 5558374336.8767\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7428411781.9280 - val_loss: 5558180702.6849\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7792304238.6552 - val_loss: 5561263840.4384\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7414487806.6827 - val_loss: 5560942763.8356\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7480989849.6878 - val_loss: 5563292426.5205\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7529826066.8816 - val_loss: 5562233273.8630\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7554668612.9400 - val_loss: 5562359327.5616\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7621225904.0823 - val_loss: 5562064036.8219\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 7615462408.7822 - val_loss: 5564197810.8493\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7351558155.4168 - val_loss: 5563635298.1918\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7533105740.4048 - val_loss: 5563132822.7945\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7639101579.6364 - val_loss: 5563418371.5068\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7464848405.0772 - val_loss: 5563046764.7123\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7766173539.6775 - val_loss: 5564069151.5616\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7266071058.4425 - val_loss: 5563218526.6849\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7386542370.6895 - val_loss: 5563531435.8356\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 7744483979.6364 - val_loss: 5564561983.1233\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7584348363.7461 - val_loss: 5564087552.0000\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7573390055.8491 - val_loss: 5563061658.3014\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7285450755.5129 - val_loss: 5564134445.5890\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7586426645.5163 - val_loss: 5564292702.6849\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7490755701.2419 - val_loss: 5564655868.4932\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7227762139.5540 - val_loss: 5566105126.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7278510036.0892 - val_loss: 5565678094.0274\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7381658976.1647 - val_loss: 5565862743.6712\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7639758020.7204 - val_loss: 5564844586.0822\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7460827247.0943 - val_loss: 5564701559.2329\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7266226163.7050 - val_loss: 5564046672.6575\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7475745228.1852 - val_loss: 5562001190.5753\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7538633262.9846 - val_loss: 5561326171.1781\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7866820727.4374 - val_loss: 5564017299.2877\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7421468110.8199 - val_loss: 5563492380.0548\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7327578307.8422 - val_loss: 5562622453.4795\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7608603807.3962 - val_loss: 5563182563.9452\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7510035857.5643 - val_loss: 5562807190.7945\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7462098264.2607 - val_loss: 5562160012.2740\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7386245559.9863 - val_loss: 5561066460.9315\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7392836883.7599 - val_loss: 5560931380.6027\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7583601447.0806 - val_loss: 5562245817.8630\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7483137442.9091 - val_loss: 5562409528.1096\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7494856348.3225 - val_loss: 5560884550.1370\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7565195489.7015 - val_loss: 5560460919.2329\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7745056137.8799 - val_loss: 5559971875.0685\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7577938166.7787 - val_loss: 5561547057.0959\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7669729873.6741 - val_loss: 5562855059.2877\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7292496698.4014 - val_loss: 5561660942.0274\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7538072874.5935 - val_loss: 5563211414.7945\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7495988112.4666 - val_loss: 5565027419.1781\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7407738618.7307 - val_loss: 5566008344.5479\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7604086731.3070 - val_loss: 5565272842.5205\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7343082055.1355 - val_loss: 5564070091.3973\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7460017873.8937 - val_loss: 5564853307.6164\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7555802185.7702 - val_loss: 5563538800.2192\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7258845965.6124 - val_loss: 5562899918.9041\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7607538303.3413 - val_loss: 5563138724.8219\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7225485412.5557 - val_loss: 5562449415.0137\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7450828747.3070 - val_loss: 5561596349.3699\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7526239069.5300 - val_loss: 5561498168.1096\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7822911451.1149 - val_loss: 5563342833.9726\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7673465879.7118 - val_loss: 5562199453.8082\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7479690592.1647 - val_loss: 5562350094.0274\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7439616043.9108 - val_loss: 5561066457.4247\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7462964197.6535 - val_loss: 5561854681.4247\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7241209718.9983 - val_loss: 5560078504.3288\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7580192879.5334 - val_loss: 5559618591.5616\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7318137507.3482 - val_loss: 5559706890.5205\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7548428721.8388 - val_loss: 5558211524.3836\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7838857347.2933 - val_loss: 5558962723.0685\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7841264816.5214 - val_loss: 5561580228.3836\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7604573436.7067 - val_loss: 5562648035.9452\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7648803312.4117 - val_loss: 5563078119.4521\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7429983166.7925 - val_loss: 5562241269.4795\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7719561605.9280 - val_loss: 5563144819.7260\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7715930386.8816 - val_loss: 5563529342.2466\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7594032476.6518 - val_loss: 5562999457.3151\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7386229356.8988 - val_loss: 5563391512.5479\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7598403138.7444 - val_loss: 5564497730.6301\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7387194486.9983 - val_loss: 5563917420.7123\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7642894015.4511 - val_loss: 5564402330.3014\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7491529643.6913 - val_loss: 5563750414.0274\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7513447829.7358 - val_loss: 5563471068.9315\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7603148592.7410 - val_loss: 5564544904.7671\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7358845940.5832 - val_loss: 5562496112.2192\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7621401077.6810 - val_loss: 5562355445.4795\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7355965055.3413 - val_loss: 5562761208.9863\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7486170357.0223 - val_loss: 5563353838.4658\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7331426639.4786 - val_loss: 5561726232.5479\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7419666939.1698 - val_loss: 5562085368.9863\n",
      "Epoch 628/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 7597134974.4631 - val_loss: 5562622288.6575\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7463860418.9640 - val_loss: 5562036195.9452\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7186904613.3242 - val_loss: 5562941026.1918\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7574092017.0703 - val_loss: 5564142942.6849\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7500617687.6021 - val_loss: 5564325144.5479\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7746500442.8954 - val_loss: 5564114228.6027\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7414372879.8079 - val_loss: 5564113148.4932\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7655425424.4666 - val_loss: 5564610314.5205\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7291389151.9451 - val_loss: 5564606814.6849\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7418621747.3756 - val_loss: 5565264233.2055\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7752583215.4237 - val_loss: 5565305294.9041\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7482308636.9811 - val_loss: 5565080618.0822\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7385842744.2058 - val_loss: 5565548263.4521\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7425915480.6998 - val_loss: 5563723635.7260\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7354209678.7101 - val_loss: 5564207493.2603\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7563689033.7702 - val_loss: 5564172785.9726\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7239259456.5489 - val_loss: 5562923190.3562\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7293097298.5523 - val_loss: 5563247784.3288\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7578048464.5763 - val_loss: 5562728788.1644\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7494499409.6741 - val_loss: 5563949196.2740\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7293516151.8765 - val_loss: 5561874719.5616\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7543983603.2659 - val_loss: 5562413248.8767\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7163158859.9657 - val_loss: 5561295258.3014\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7456513793.3173 - val_loss: 5561786501.2603\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7289428563.4305 - val_loss: 5563259339.3973\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7420154228.5832 - val_loss: 5563297388.7123\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7652051164.4322 - val_loss: 5563510454.3562\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7680916821.6261 - val_loss: 5564216071.0137\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7525564085.3516 - val_loss: 5563819477.9178\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7499724541.8045 - val_loss: 5563734941.8082\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7590011542.1750 - val_loss: 5563093833.6438\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7652321845.5712 - val_loss: 5564171681.3151\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7510435169.9211 - val_loss: 5563543930.7397\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7347623312.4666 - val_loss: 5562813152.4384\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7443803496.5077 - val_loss: 5563034939.6164\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7668348145.9485 - val_loss: 5564800385.7534\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 7493668758.6141 - val_loss: 5563797938.8493\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7816977090.9640 - val_loss: 5564873756.0548\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7498770231.7667 - val_loss: 5565734231.6712\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7226851935.7256 - val_loss: 5563962655.5616\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7423751088.0823 - val_loss: 5563710506.0822\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7475710665.1115 - val_loss: 5563192909.1507\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7465059352.1509 - val_loss: 5563934881.3151\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7727007004.5420 - val_loss: 5563600545.3151\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7611001344.8782 - val_loss: 5563318980.3836\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7177719907.6775 - val_loss: 5562701827.5068\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7462203840.7684 - val_loss: 5560948714.9589\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7419499855.4786 - val_loss: 5560665158.1370\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7485184979.6501 - val_loss: 5560117002.5205\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7545413106.8268 - val_loss: 5559235352.5479\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7453625442.3602 - val_loss: 5558490880.0000\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7799082950.9160 - val_loss: 5558486198.3562\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7631789969.3448 - val_loss: 5558744898.6301\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7567932262.3122 - val_loss: 5559775179.3973\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7609559256.9194 - val_loss: 5560662436.8219\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7673239067.2247 - val_loss: 5563094636.7123\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7357906806.9983 - val_loss: 5562193169.5342\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7370141948.0480 - val_loss: 5561106740.6027\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7442626659.6775 - val_loss: 5561338487.2329\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7674294900.8027 - val_loss: 5562341993.2055\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7303427017.9897 - val_loss: 5564743357.3699\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7273993175.6021 - val_loss: 5563304202.5205\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7185368708.6106 - val_loss: 5560759811.5068\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7618839501.0635 - val_loss: 5560267320.1096\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7469768760.6449 - val_loss: 5559271420.4932\n",
      "Epoch 693/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 146us/step - loss: 7478585032.2333 - val_loss: 5558539123.7260\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7229849355.8559 - val_loss: 5558038233.4247\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7736849869.0635 - val_loss: 5560080706.6301\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7367753672.6724 - val_loss: 5561445565.3699\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7309771031.2727 - val_loss: 5560119727.3425\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7458564317.3105 - val_loss: 5560221685.4795\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7887159920.4117 - val_loss: 5561969888.4384\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7491806093.8319 - val_loss: 5564496485.6986\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7701913650.9365 - val_loss: 5565117899.3973\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7666786867.8148 - val_loss: 5563478983.8904\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7494832906.9777 - val_loss: 5563681216.8767\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7573104330.8679 - val_loss: 5562644897.3151\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7325403296.7136 - val_loss: 5560369306.3014\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7633201457.6192 - val_loss: 5561202617.8630\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7486168683.1424 - val_loss: 5562706270.6849\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7461282028.2401 - val_loss: 5562136884.6027\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7569040456.0137 - val_loss: 5562252680.7671\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7650970353.5094 - val_loss: 5560662023.0137\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7480433447.0806 - val_loss: 5563013926.5753\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7383289271.1081 - val_loss: 5562817479.8904\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7476126535.5746 - val_loss: 5562019668.1644\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7495912509.4751 - val_loss: 5561803642.7397\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 7165225602.4151 - val_loss: 5560099156.1644\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7678214350.3808 - val_loss: 5560783647.5616\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7444079673.9623 - val_loss: 5561601230.9041\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7601475707.8285 - val_loss: 5562014590.2466\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7441764695.3825 - val_loss: 5562628383.5616\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7340941204.4185 - val_loss: 5561500566.7945\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7524802381.2830 - val_loss: 5561553856.8767\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7681639970.2504 - val_loss: 5562814449.9726\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7724854272.0000 - val_loss: 5563508083.7260\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7561455579.1149 - val_loss: 5564887853.5890\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7454657955.7873 - val_loss: 5567402446.9041\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7428455628.6244 - val_loss: 5567067918.0274\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7418616702.9022 - val_loss: 5566099989.0411\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7430981916.5420 - val_loss: 5565884906.9589\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 7458035524.9400 - val_loss: 5564691873.3151\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7464416511.5609 - val_loss: 5563743491.5068\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7551756817.5643 - val_loss: 5564182275.5068\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7714474224.6312 - val_loss: 5562893213.8082\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7619898852.7753 - val_loss: 5563447162.7397\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 305us/step - loss: 7558693296.0823 - val_loss: 5562724513.3151\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 1s 471us/step - loss: 7402740679.7942 - val_loss: 5563317767.0137\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 1s 708us/step - loss: 7523077160.3979 - val_loss: 5563012520.3288\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 1s 747us/step - loss: 7411815812.6106 - val_loss: 5563565245.3699\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 1s 747us/step - loss: 7583113439.9451 - val_loss: 5563203163.1781\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 1s 641us/step - loss: 7461338792.6175 - val_loss: 5563605041.0959\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 1s 529us/step - loss: 7378589198.9297 - val_loss: 5563921450.0822\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 1s 462us/step - loss: 7385882581.8456 - val_loss: 5562719056.6575\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 419us/step - loss: 7495905272.9743 - val_loss: 5564268123.1781\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 411us/step - loss: 7365954863.8628 - val_loss: 5563513617.5342\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 358us/step - loss: 7667764002.6895 - val_loss: 5563763957.4795\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 378us/step - loss: 7398904522.8679 - val_loss: 5565089749.9178\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 352us/step - loss: 7803361594.4014 - val_loss: 5565407652.8219\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 403us/step - loss: 7337884066.0309 - val_loss: 5564249501.8082\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 365us/step - loss: 7477486777.3036 - val_loss: 5563974017.7534\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 328us/step - loss: 7219966237.4202 - val_loss: 5564091830.3562\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 316us/step - loss: 7730829759.8902 - val_loss: 5565724103.8904\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 305us/step - loss: 7309699428.5557 - val_loss: 5563097529.8630\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 331us/step - loss: 7480607253.9554 - val_loss: 5562675606.7945\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 294us/step - loss: 7563029123.7324 - val_loss: 5563768039.4521\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 275us/step - loss: 7501720215.9314 - val_loss: 5563187477.0411\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 7720639923.5952 - val_loss: 5563896207.7808\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 263us/step - loss: 7200683557.3242 - val_loss: 5564104402.4110\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 255us/step - loss: 7615613726.2985 - val_loss: 5564076158.2466\n",
      "Epoch 758/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 266us/step - loss: 7610230065.1801 - val_loss: 5564656226.1918\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 7445012817.2350 - val_loss: 5564661528.5479\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 240us/step - loss: 7409584037.5437 - val_loss: 5563842921.2055\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 7487401242.7856 - val_loss: 5562989911.6712\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 7572316569.2487 - val_loss: 5562230243.9452\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 7441416444.0480 - val_loss: 5563832740.8219\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 7266971203.6226 - val_loss: 5563374988.2740\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 7700502133.6810 - val_loss: 5564271710.6849\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 7493599876.6106 - val_loss: 5563337068.7123\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 7317600250.7307 - val_loss: 5561896686.4658\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 7513855802.4014 - val_loss: 5563195006.2466\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 7382197515.4168 - val_loss: 5562965454.9041\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 7587379445.0223 - val_loss: 5562477420.7123\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7751541125.0497 - val_loss: 5563335802.7397\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 7488966287.1492 - val_loss: 5563490837.0411\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 7532008771.6226 - val_loss: 5563353701.6986\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7378613287.5197 - val_loss: 5562153973.4795\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7650143408.5214 - val_loss: 5561541460.1644\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 7479725618.9365 - val_loss: 5562410818.6301\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 7522962005.1870 - val_loss: 5560178225.0959\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7381037531.9931 - val_loss: 5559126727.8904\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 7536301462.6141 - val_loss: 5559762403.9452\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 7621443387.2796 - val_loss: 5559858060.2740\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 7398178760.6724 - val_loss: 5558937368.5479\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 7523332543.4511 - val_loss: 5559802964.1644\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 7679451904.4391 - val_loss: 5561037753.8630\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 7680523180.5695 - val_loss: 5561423738.7397\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 7408172393.8250 - val_loss: 5560281031.8904\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7522278772.3636 - val_loss: 5560212150.3562\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7534997898.3190 - val_loss: 5560062779.6164\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7568671078.3122 - val_loss: 5558587749.6986\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7459192397.2830 - val_loss: 5559996188.0548\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 7541791180.1852 - val_loss: 5557531192.1096\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7581756697.0292 - val_loss: 5558055536.2192\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 7508392836.6106 - val_loss: 5557695828.1644\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 7522784961.2075 - val_loss: 5559317006.0274\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 7630421831.5746 - val_loss: 5559616743.4521\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7623892157.6947 - val_loss: 5560025845.4795\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 7599614710.7787 - val_loss: 5560990779.6164\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 7604421430.0103 - val_loss: 5562402717.8082\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7639329366.0652 - val_loss: 5564485505.7534\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7485934815.0669 - val_loss: 5563320193.7534\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7374878921.9897 - val_loss: 5563134555.1781\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7607827213.6123 - val_loss: 5562893988.8219\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7452288135.4648 - val_loss: 5564151885.1507\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7571926455.1081 - val_loss: 5563004282.7397\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7824415096.7547 - val_loss: 5564041461.4795\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 7559940312.9194 - val_loss: 5563401763.0685\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7408854611.4305 - val_loss: 5561256988.0548\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7553831750.6964 - val_loss: 5560792400.6575\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7657983844.5557 - val_loss: 5561602163.7260\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7434208018.6621 - val_loss: 5562146644.1644\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7486840276.9674 - val_loss: 5561340142.4658\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7350173316.6106 - val_loss: 5560089880.5479\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7441810153.6055 - val_loss: 5560425938.4110\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 7207833271.5472 - val_loss: 5560144264.7671\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7517877723.9931 - val_loss: 5559440510.2466\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7576734409.1115 - val_loss: 5560054433.3151\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7458119629.0635 - val_loss: 5559624784.6575\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7539868820.4185 - val_loss: 5561061859.9452\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7615644053.7358 - val_loss: 5562599567.7808\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7736346154.1544 - val_loss: 5565247540.6027\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 7500471652.5557 - val_loss: 5565232499.7260\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7573900828.5420 - val_loss: 5567025948.0548\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 7600962529.2624 - val_loss: 5568039452.0548\n",
      "Epoch 823/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 172us/step - loss: 7738794214.0926 - val_loss: 5567848700.4932\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7734641337.3036 - val_loss: 5568089726.2466\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7415877739.1424 - val_loss: 5568906243.5068\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7571398305.5918 - val_loss: 5568315549.8082\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7514128792.3705 - val_loss: 5568067654.1370\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7609076133.5437 - val_loss: 5569242851.9452\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7222925651.8696 - val_loss: 5569205710.9041\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7374334254.1063 - val_loss: 5569674029.5890\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7477907542.9434 - val_loss: 5568093815.2329\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7744497291.6364 - val_loss: 5567307502.4658\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7339930266.5660 - val_loss: 5565809579.8356\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 7589232091.5540 - val_loss: 5565209207.2329\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7651218225.6192 - val_loss: 5564499273.6438\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7530294439.7393 - val_loss: 5563700076.7123\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7571495114.8679 - val_loss: 5563257982.2466\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 7338829804.6792 - val_loss: 5562876949.0411\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7540287699.2110 - val_loss: 5563624132.3836\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7687150928.3568 - val_loss: 5564152926.6849\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7272632768.7684 - val_loss: 5562753402.7397\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7660049022.4631 - val_loss: 5564300452.8219\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7400343908.5557 - val_loss: 5565422833.9726\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7298789630.6827 - val_loss: 5565211669.0411\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7411405281.2624 - val_loss: 5565320227.0685\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7127460202.7033 - val_loss: 5564478800.6575\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7779173537.5918 - val_loss: 5564130030.4658\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7768147234.6895 - val_loss: 5565626094.4658\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7551062576.7410 - val_loss: 5563367964.0548\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7464153723.8285 - val_loss: 5562665573.6986\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7239297261.1184 - val_loss: 5563223902.6849\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7713401322.0446 - val_loss: 5563649360.6575\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7362097303.9314 - val_loss: 5562027372.7123\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7561251254.2298 - val_loss: 5563844793.8630\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7610827145.4408 - val_loss: 5564146800.2192\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7580505843.2659 - val_loss: 5562491560.3288\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7306616856.5901 - val_loss: 5560814606.0274\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7581583240.5626 - val_loss: 5561189586.4110\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7734916167.1355 - val_loss: 5560642987.8356\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7513258872.7547 - val_loss: 5561594697.6438\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7343098912.4940 - val_loss: 5560794353.9726\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7627568860.8714 - val_loss: 5560945986.6301\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7576007789.7770 - val_loss: 5560562032.2192\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7477759448.9194 - val_loss: 5562206456.9863\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7529215253.9554 - val_loss: 5562066740.6027\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7337830534.3671 - val_loss: 5561009958.5753\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7581090272.3842 - val_loss: 5561007391.5616\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7740926375.3002 - val_loss: 5562732459.8356\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7454220012.2401 - val_loss: 5563512740.8219\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7757955252.9125 - val_loss: 5564478583.2329\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7330715563.2521 - val_loss: 5565568000.0000\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7592867983.1492 - val_loss: 5566920220.0548\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7567060929.6467 - val_loss: 5565894733.1507\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7309359724.4597 - val_loss: 5564125092.8219\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7592712390.4768 - val_loss: 5563685712.6575\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7651592656.5763 - val_loss: 5562770502.1370\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7267825483.9657 - val_loss: 5562516402.8493\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7572304095.0669 - val_loss: 5563121215.1233\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7444791088.7410 - val_loss: 5560341346.1918\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7556122978.3602 - val_loss: 5562659506.8493\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7163769490.6621 - val_loss: 5561634325.0411\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7426413575.0257 - val_loss: 5559770059.3973\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7406934418.2230 - val_loss: 5557822923.3973\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7496705607.1355 - val_loss: 5559074202.3014\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7378017092.9400 - val_loss: 5560821353.2055\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7467883639.4374 - val_loss: 5560612050.4110\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 7381581128.4528 - val_loss: 5559696566.3562\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 159us/step - loss: 7431808326.2573 - val_loss: 5560637671.4521\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7468286664.0137 - val_loss: 5560209204.6027\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7632190579.9245 - val_loss: 5559303490.6301\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7838405031.3002 - val_loss: 5561047285.4795\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7386147019.7461 - val_loss: 5560973697.7534\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7460701584.9057 - val_loss: 5560304527.7808\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7510522605.1184 - val_loss: 5560478404.3836\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7446475494.5317 - val_loss: 5560646817.3151\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7384228054.7238 - val_loss: 5558871618.6301\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7382019750.8611 - val_loss: 5560013564.4932\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7282875800.3705 - val_loss: 5559954193.5342\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7697648402.8816 - val_loss: 5560264177.9726\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7631821535.9451 - val_loss: 5559757448.7671\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7483897315.0189 - val_loss: 5559674865.9726\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7495347040.6038 - val_loss: 5560072528.6575\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7601121998.3808 - val_loss: 5560113390.4658\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7354883358.2985 - val_loss: 5559369861.2603\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7573103428.0618 - val_loss: 5559309908.1644\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7326973616.5214 - val_loss: 5559762810.7397\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7497480893.6947 - val_loss: 5558925788.9315\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7311524977.2899 - val_loss: 5559215258.3014\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7516847090.8268 - val_loss: 5559639075.0685\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7588434244.0618 - val_loss: 5558768296.3288\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7756376629.5712 - val_loss: 5558986780.0548\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7566239506.0034 - val_loss: 5560040114.8493\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7458576162.6895 - val_loss: 5560496198.1370\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7469731713.0978 - val_loss: 5561752078.0274\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7686457280.7684 - val_loss: 5562233519.3425\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7434288207.0395 - val_loss: 5561506710.7945\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7487246461.5849 - val_loss: 5561696161.3151\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7442964049.6741 - val_loss: 5561608612.8219\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7687450526.5180 - val_loss: 5561797996.7123\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7270616602.7856 - val_loss: 5561379349.0411\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7559784559.5334 - val_loss: 5560430809.4247\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7692994246.9160 - val_loss: 5560665880.5479\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7346861515.7461 - val_loss: 5560796230.1370\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7537568932.6655 - val_loss: 5561567856.2192\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7630332713.7153 - val_loss: 5563383071.5616\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7354043589.5986 - val_loss: 5563266451.2877\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7590683303.7393 - val_loss: 5563289172.1644\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7399420977.1801 - val_loss: 5562981670.5753\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7646732442.5660 - val_loss: 5565018504.7671\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7569212690.8816 - val_loss: 5564100131.0685\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7640801372.6518 - val_loss: 5565388196.8219\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7486897689.4683 - val_loss: 5565199963.1781\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7497893393.5643 - val_loss: 5564146281.2055\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7459953487.4786 - val_loss: 5562776372.6027\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7505293991.7393 - val_loss: 5562029638.1370\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7436530020.5557 - val_loss: 5561971817.2055\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7634904289.7015 - val_loss: 5563801298.4110\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7357932812.7341 - val_loss: 5562258004.1644\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7433749269.5163 - val_loss: 5563995535.7808\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7254031502.2710 - val_loss: 5563495171.5068\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7235032084.6381 - val_loss: 5565272681.2055\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7478171208.8919 - val_loss: 5565144007.8904\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7307070019.6226 - val_loss: 5564991410.8493\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7294020803.8422 - val_loss: 5562764323.0685\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7559300896.9331 - val_loss: 5561692440.5479\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7268562585.6878 - val_loss: 5559973137.5342\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7784142066.3877 - val_loss: 5561855070.6849\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7646551218.2779 - val_loss: 5562601198.4658\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7792919010.1407 - val_loss: 5562080908.2740\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7274485444.7204 - val_loss: 5561988846.4658\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7389871666.0583 - val_loss: 5562156621.1507\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7505983564.4048 - val_loss: 5562136169.2055\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 147us/step - loss: 7495216071.7942 - val_loss: 5560151783.4521\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7605335092.6930 - val_loss: 5559938602.0822\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7442245952.9880 - val_loss: 5561378858.0822\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7462129869.5026 - val_loss: 5561496372.6027\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7752705279.1218 - val_loss: 5561250675.7260\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 7898441088.00 - 0s 148us/step - loss: 7876266162.2779 - val_loss: 5561662821.6986\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 7495620903.0806 - val_loss: 5562694768.2192\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7587215602.3877 - val_loss: 5563024292.8219\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7541047238.9160 - val_loss: 5563675837.3699\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7519440275.1012 - val_loss: 5564265065.2055\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7634556473.9623 - val_loss: 5564490005.0411\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7436709192.8919 - val_loss: 5563778630.1370\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7744870187.4717 - val_loss: 5563538414.4658\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7315196337.8388 - val_loss: 5562230959.3425\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 7730172177.1252 - val_loss: 5563302848.8767\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7240100670.7925 - val_loss: 5562208662.7945\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 7610030352.2470 - val_loss: 5561491743.5616\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 7425441962.3739 - val_loss: 5560808679.4521\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7538234059.7461 - val_loss: 5561311375.7808\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7566216514.7444 - val_loss: 5560934414.0274\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 7456871979.0326 - val_loss: 5559925637.2603\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7504479092.3636 - val_loss: 5560344625.0959\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7593394403.8971 - val_loss: 5560914523.1781\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7713007181.2830 - val_loss: 5560804986.7397\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7740999332.2264 - val_loss: 5561417980.4932\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7643308979.5952 - val_loss: 5561969390.4658\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7335749197.2830 - val_loss: 5561560035.9452\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7332126562.7993 - val_loss: 5562037465.4247\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7498877626.8405 - val_loss: 5561683953.9726\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7507058535.1904 - val_loss: 5561426712.5479\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7552982558.7376 - val_loss: 5562988203.8356\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7360410863.3139 - val_loss: 5563464725.0411\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7434889006.1063 - val_loss: 5563100945.5342\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7573617807.1492 - val_loss: 5562323992.5479\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7605346969.6878 - val_loss: 5562427609.4247\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7736916723.2659 - val_loss: 5563588636.0548\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7698079129.6878 - val_loss: 5563786106.7397\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7309316905.7153 - val_loss: 5561238633.2055\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 7524567568.2470 - val_loss: 5561852808.7671\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7328791650.3602 - val_loss: 5560621750.3562\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7472153346.1955 - val_loss: 5560356555.3973\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 7809919325.5300 - val_loss: 5561535396.8219\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7614737379.4580 - val_loss: 5563128109.5890\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7401524267.0326 - val_loss: 5562090937.8630\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 7272442206.4082 - val_loss: 5562464241.9726\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7683512740.2264 - val_loss: 5562757239.2329\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 7549805568.0000 - val_loss: 5563118570.9589\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7380269415.6295 - val_loss: 5563405873.0959\n",
      "neurons used (32, 16)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 563us/step - loss: 39209600795.6638 - val_loss: 38415339772.4931\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 39206761414.0377 - val_loss: 38412268417.7534\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39202049334.8885 - val_loss: 38407780239.7808\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 39195902240.0549 - val_loss: 38400830057.2055\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39188193736.6724 - val_loss: 38392471327.5616\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39178895778.0309 - val_loss: 38379456876.7123\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 39168023957.7359 - val_loss: 38368815244.2740\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39154578208.9331 - val_loss: 38353581827.5069\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 39141312389.0497 - val_loss: 38341614101.0411\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 39125279095.8765 - val_loss: 38336073952.4384\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 39107995096.4803 - val_loss: 38316340771.0685\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39088788797.9142 - val_loss: 38295611981.1507\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 39066346111.3413 - val_loss: 38273853524.1644\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39047185571.3482 - val_loss: 38244155448.1096\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39021905688.1509 - val_loss: 38224976489.2055\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38999018206.1887 - val_loss: 38197492357.2603\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 154us/step - loss: 38975066154.1544 - val_loss: 38172412998.1370\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38947746413.7770 - val_loss: 38148230578.8493\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38915379547.7736 - val_loss: 38110348919.2329\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 38882993476.9400 - val_loss: 38079841265.9726\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38849988070.5317 - val_loss: 38046923958.3562\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38820382140.3774 - val_loss: 37996932867.5069\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 38784270891.0326 - val_loss: 37964785467.6164\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 38749848156.2127 - val_loss: 37917630744.5479\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38701507993.2487 - val_loss: 37886925473.3151\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38671768904.4528 - val_loss: 37843744768.0000\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 38631818543.8628 - val_loss: 37801613115.6164\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38581300973.9966 - val_loss: 37744521019.6164\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38537759868.7067 - val_loss: 37707872059.6164\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 38504536959.7804 - val_loss: 37653914750.2466\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38454213570.5249 - val_loss: 37617872727.6712\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38404035136.1098 - val_loss: 37562439623.8904\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 38355273120.2744 - val_loss: 37522897877.9178\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38297528625.6192 - val_loss: 37471805664.4384\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38237427986.0034 - val_loss: 37419694781.3699\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38189275722.6484 - val_loss: 37376934729.6438\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 38141437063.2453 - val_loss: 37319273654.3562\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38092692376.3705 - val_loss: 37254252544.0000\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38016791564.2950 - val_loss: 37199282176.0000\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 37954710266.2916 - val_loss: 37146770754.6301\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 37878554378.0995 - val_loss: 37081729865.6438\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 37838331032.8096 - val_loss: 37019363889.0959\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 37769328608.3842 - val_loss: 36937728112.2192\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 37698242992.0823 - val_loss: 36871036114.4110\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 37631377439.6158 - val_loss: 36790211738.3014\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 37577415625.5506 - val_loss: 36726028400.2192\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 37510142419.2110 - val_loss: 36660264062.2466\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 37422296013.0635 - val_loss: 36596636573.8082\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 37365712629.0223 - val_loss: 36525863809.7534\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 37291328211.6501 - val_loss: 36451007473.9726\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 37204532422.4768 - val_loss: 36371188862.2466\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 37122372602.7307 - val_loss: 36289692433.5342\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 37049078487.1629 - val_loss: 36218465013.4795\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 36962983957.0772 - val_loss: 36136513059.0685\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 36869991063.9314 - val_loss: 36067181722.3014\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 36801357669.4340 - val_loss: 35978984574.2466\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 36721357488.5214 - val_loss: 35869553257.2055\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 36616899606.8336 - val_loss: 35819529314.1918\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 36564036251.4443 - val_loss: 35705197610.0822\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 36460493692.2676 - val_loss: 35602048855.6712\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 36346106379.4168 - val_loss: 35509662032.6575\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 36268724097.5369 - val_loss: 35415592931.9452\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 36182973371.4991 - val_loss: 35340467943.4521\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 275us/step - loss: 36091153511.6295 - val_loss: 35232266885.2603\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 1s 548us/step - loss: 35952088873.7153 - val_loss: 35143937711.3425\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 35906674526.4082 - val_loss: 35035278237.8082\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 35837281274.7307 - val_loss: 34933352896.8767\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 35732149193.5506 - val_loss: 34847383327.5616\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 35614671726.2161 - val_loss: 34745904366.4658\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 35484626719.1767 - val_loss: 34634145904.2192\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 35430080304.7410 - val_loss: 34551586198.7945\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 35347379883.2521 - val_loss: 34456002419.7260\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 35182675079.2453 - val_loss: 34342348098.6301\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 35131607703.9314 - val_loss: 34228340820.1644\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 34989768689.9485 - val_loss: 34104628771.0685\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 34900493668.5557 - val_loss: 33996557662.6849\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 34780151312.6861 - val_loss: 33893105607.8904\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 34720864428.1304 - val_loss: 33798995911.8904\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 34525415926.3396 - val_loss: 33693036095.1233\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 34412940563.7599 - val_loss: 33593045973.9178\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 34307071223.6569 - val_loss: 33452078234.3014\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 34210108842.8130 - val_loss: 33351007638.7945\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 34064527374.0515 - val_loss: 33229279793.0959\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 34012587986.3328 - val_loss: 33124379942.5753\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 33820852094.0240 - val_loss: 32999650542.4658\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 33773488279.0532 - val_loss: 32847491072.0000\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 33629566719.5609 - val_loss: 32764171698.8493\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 33574768977.2350 - val_loss: 32650768720.6575\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 33317621275.2247 - val_loss: 32511985299.2877\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 33297777707.9108 - val_loss: 32399595267.5069\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 33142153353.0017 - val_loss: 32258859793.5342\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 33008976395.4168 - val_loss: 32105417124.8219\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 32906598877.7496 - val_loss: 31976319565.1507\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 32792986105.8525 - val_loss: 31856512490.9589\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 32640714987.3619 - val_loss: 31720014777.8630\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 32453396722.3877 - val_loss: 31580000424.3288\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 32358279452.5420 - val_loss: 31471736467.2877\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 32296738949.4888 - val_loss: 31323570793.2055\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 32053990306.9091 - val_loss: 31181438386.8493\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 32044140125.9691 - val_loss: 31023147316.6027\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 31897279029.5712 - val_loss: 30888521166.9041\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 31626821800.6175 - val_loss: 30744328500.6027\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 31665790027.5266 - val_loss: 30597698574.0274\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 31485428284.5969 - val_loss: 30480566664.7671\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 31362926043.9931 - val_loss: 30341199451.1781\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 31037270838.0103 - val_loss: 30192091472.6575\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 30974690376.0137 - val_loss: 30051323735.6712\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 30923172869.2693 - val_loss: 29915342539.3973\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 30826192098.5798 - val_loss: 29798407182.0274\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 30483369537.8662 - val_loss: 29652874618.7397\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 30358940852.9125 - val_loss: 29527892388.8219\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 30190680397.7221 - val_loss: 29368910749.8082\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 30105944436.3636 - val_loss: 29222569675.3973\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 30036774673.1252 - val_loss: 29078700228.3836\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 29847140018.2779 - val_loss: 28930069097.2055\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 29699785002.5935 - val_loss: 28779061191.8904\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 29380777355.1973 - val_loss: 28634562840.5479\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 29392008460.7341 - val_loss: 28479788915.7260\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 29428237489.3997 - val_loss: 28325269784.5479\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 29230147587.5129 - val_loss: 28183182181.6986\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 29001562396.5420 - val_loss: 28033833745.5342\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 28740826408.8371 - val_loss: 27859492723.7260\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 28737390409.3310 - val_loss: 27710137498.3014\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 28397447364.7204 - val_loss: 27550223710.6849\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 28443827273.7702 - val_loss: 27387170282.9589\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 28324779989.8456 - val_loss: 27235389243.6164\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 27965469279.7256 - val_loss: 27072609658.7397\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 27959248555.2521 - val_loss: 26924636777.2055\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 27806503386.2367 - val_loss: 26767901681.9726\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 27586046289.2350 - val_loss: 26604810913.3151\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 27548960219.9931 - val_loss: 26455902151.8904\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 27339737966.2161 - val_loss: 26296980634.3014\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 27121208005.5986 - val_loss: 26150176515.5069\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26971234484.9125 - val_loss: 25995245371.6164\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 26827001768.1784 - val_loss: 25805339942.5753\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 26602608977.2350 - val_loss: 25639551817.6438\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 26406065620.9674 - val_loss: 25472689867.3973\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 26298490827.3070 - val_loss: 25306290793.2055\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 26039682148.1166 - val_loss: 25131814126.4658\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 25994571336.8919 - val_loss: 24982284400.2192\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 25831129836.2401 - val_loss: 24798871159.2329\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 25807988981.9005 - val_loss: 24648576098.1918\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25518676686.3808 - val_loss: 24482220901.6986\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 25427343331.8971 - val_loss: 24306750870.7945\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 179us/step - loss: 25022551315.7599 - val_loss: 24123583670.3562\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 25032848761.6329 - val_loss: 23942776074.5205\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 24868264965.2693 - val_loss: 23774449664.0000\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 24693257885.2007 - val_loss: 23621451944.3288\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 24534616169.3859 - val_loss: 23441469888.8767\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 24426230564.4460 - val_loss: 23278477059.5069\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 24277686823.5197 - val_loss: 23123962304.8767\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 24013905818.1269 - val_loss: 22966207698.4110\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 23864283979.0875 - val_loss: 22793091492.8219\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 23619003709.9142 - val_loss: 22641274613.4795\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 23485566283.9657 - val_loss: 22480576540.0548\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 23457280270.4906 - val_loss: 22290698394.3014\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 23110162579.5403 - val_loss: 22120832462.9041\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 23007624738.2504 - val_loss: 21927753082.7397\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 22769114356.1441 - val_loss: 21766977451.8356\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 22958106571.3070 - val_loss: 21604141673.2055\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 22518978802.3876 - val_loss: 21457018094.4658\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 22449081391.4237 - val_loss: 21283303971.0685\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 22312422563.3482 - val_loss: 21102827772.4931\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 22014364062.5180 - val_loss: 20908703701.9178\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 22038650114.1955 - val_loss: 20751247893.0411\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 21576270438.7513 - val_loss: 20574454279.0137\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 21817440930.4700 - val_loss: 20399650100.6027\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 21612962736.9605 - val_loss: 20220091363.9452\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 21476348564.4185 - val_loss: 20083856369.9726\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 21106044330.666 - 0s 153us/step - loss: 21054588401.0703 - val_loss: 19915940387.0685\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 21032029684.5832 - val_loss: 19733293771.3973\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 20921785985.0978 - val_loss: 19538864113.9726\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 20898286811.5540 - val_loss: 19389448584.7671\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 20466703307.3070 - val_loss: 19243109376.0000\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 20097584477.5300 - val_loss: 19062827793.5342\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 20075207980.3499 - val_loss: 18847620138.0822\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 20008980527.4237 - val_loss: 18720768336.6575\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 20040506910.7376 - val_loss: 18557732050.4110\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 19348349955.5129 - val_loss: 18377642012.0548\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 19370097920.4391 - val_loss: 18208980094.2466\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 19258868295.1355 - val_loss: 18035859203.5069\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 19110147874.6895 - val_loss: 17887003283.2877\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 19114901641.0017 - val_loss: 17724259636.6027\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 19015119329.2624 - val_loss: 17552823043.5069\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 18832265024.5489 - val_loss: 17379196731.6164\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 18520387891.3756 - val_loss: 17187190615.6712\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 18165042588.7616 - val_loss: 17012475918.0274\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 18516953506.0309 - val_loss: 16852525238.3562\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 17785039965.0909 - val_loss: 16688169885.8082\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 17768639296.5489 - val_loss: 16522079736.9863\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 17679348549.8182 - val_loss: 16360407222.3562\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 17594179592.7822 - val_loss: 16198816389.2603\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 17401507165.5300 - val_loss: 16039726851.5068\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 17519534810.6758 - val_loss: 15889874986.0822\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 17267064266.4288 - val_loss: 15717433905.0959\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 16877499428.8851 - val_loss: 15553543153.9726\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 16586749580.5146 - val_loss: 15378983290.7397\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 16587244099.6226 - val_loss: 15240877855.5616\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 16750848472.4803 - val_loss: 15082172303.7808\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 16327288565.0223 - val_loss: 14918905898.0822\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 16016408620.7890 - val_loss: 14762688455.8904\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 16260790208.7684 - val_loss: 14593673622.7945\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 16013632938.8130 - val_loss: 14438566084.3836\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 15967777368.6998 - val_loss: 14293766705.0959\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 15542270396.3774 - val_loss: 14116990723.5068\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 15519652849.0703 - val_loss: 13970673649.9726\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 15487554705.7839 - val_loss: 13847101397.9178\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 15374381089.3722 - val_loss: 13679446226.4110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 15030443801.0292 - val_loss: 13539719476.6027\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 14538244337.5094 - val_loss: 13386553442.1918\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 14760189650.7719 - val_loss: 13238333468.0548\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 14546033602.5249 - val_loss: 13063525937.0959\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 14598386547.4854 - val_loss: 12889076441.4247\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 14058255570.7719 - val_loss: 12737482660.8219\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 14608135528.0686 - val_loss: 12592994865.0959\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 13870379006.2436 - val_loss: 12450311967.5616\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 13492150610.9914 - val_loss: 12308698813.3699\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 13694593884.6518 - val_loss: 12162786311.0137\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 13562293583.9177 - val_loss: 11999387584.8767\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 13688195481.2487 - val_loss: 11861441809.5342\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 13200051246.5455 - val_loss: 11737344469.9178\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 13414617052.8714 - val_loss: 11604512227.9452\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 13215567422.3533 - val_loss: 11466139984.6575\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 13169590398.4631 - val_loss: 11318959952.6575\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 13266981159.0806 - val_loss: 11208724241.5342\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 12765393240.2607 - val_loss: 11083405732.8219\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 12695868672.4391 - val_loss: 10922096001.7534\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 12688107604.3087 - val_loss: 10777012146.8493\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 12546719480.5352 - val_loss: 10648831298.6301\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 12182806601.7702 - val_loss: 10524088291.9452\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 12365799209.7153 - val_loss: 10398937501.8082\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 11973811869.2007 - val_loss: 10269703203.0685\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 12011573286.6415 - val_loss: 10137449521.0959\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11925470812.2127 - val_loss: 10010098070.7945\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11499637461.4065 - val_loss: 9898647061.0411\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 11722295108.0618 - val_loss: 9777805578.5205\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11867763876.2264 - val_loss: 9654042736.2192\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 11391081363.9794 - val_loss: 9548307210.5205\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 11316456179.2659 - val_loss: 9439148053.0411\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 11392607456.8233 - val_loss: 9322252386.1918\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10924115646.5729 - val_loss: 9216427681.3151\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10851938888.0137 - val_loss: 9110275401.6438\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10274112330.2093 - val_loss: 8999037643.3973\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10545770882.4151 - val_loss: 8886196280.1096\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10785160374.6690 - val_loss: 8762756460.7123\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10555303604.0343 - val_loss: 8651418694.1370\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10498170577.8937 - val_loss: 8561205928.3288\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10575142005.2419 - val_loss: 8449189775.7808\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10550324809.3310 - val_loss: 8344162226.8493\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10170012055.4923 - val_loss: 8255284027.6164\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 10276865568.4940 - val_loss: 8159707199.1233\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10136743208.8370 - val_loss: 8064421614.4658\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9887862887.1904 - val_loss: 7970732789.4795\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9880689519.0943 - val_loss: 7866271982.4658\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10173488782.2710 - val_loss: 7782798784.8767\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 9778620137.1664 - val_loss: 7694291512.1096\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 9734527154.2779 - val_loss: 7608262824.3288\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 9267854181.4340 - val_loss: 7529101634.6301\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 9691943623.3551 - val_loss: 7441440508.4932\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 9464589686.1201 - val_loss: 7364764693.0411\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 9634978145.0429 - val_loss: 7280673265.9726\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 9339810756.2813 - val_loss: 7220415526.5753\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 9474712393.3310 - val_loss: 7139836563.2877\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 9371862488.4803 - val_loss: 7082426294.3562\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 9041915022.2710 - val_loss: 7015038842.7397\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 9273069833.2213 - val_loss: 6952240005.2603\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 9407822531.8422 - val_loss: 6884691813.6986\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 9070597794.0309 - val_loss: 6828952856.5479\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 9254162293.2419 - val_loss: 6765480377.8630\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 9352047823.2590 - val_loss: 6707796953.4247\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8996458997.4614 - val_loss: 6659885680.2192\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8615396748.9537 - val_loss: 6603233630.6849\n",
      "Epoch 273/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 186us/step - loss: 9136609652.3636 - val_loss: 6559576228.8219\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8855588112.6861 - val_loss: 6513171880.3288\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8995126098.1132 - val_loss: 6458678335.1233\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8878022082.9640 - val_loss: 6416657341.3699\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8871177391.6432 - val_loss: 6375913093.2603\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8817903048.2333 - val_loss: 6332081109.9178\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8565499009.0978 - val_loss: 6291115071.1233\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8807950334.2436 - val_loss: 6251762358.3562\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8795689738.0995 - val_loss: 6215541444.3836\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8694232115.8148 - val_loss: 6185905706.0822\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8461675876.5557 - val_loss: 6150019910.1370\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8659882862.2161 - val_loss: 6125145512.3288\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8421350270.9022 - val_loss: 6102030742.7945\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8749399024.1921 - val_loss: 6073995607.6712\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8248430781.6947 - val_loss: 6051593587.7260\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8639696481.4820 - val_loss: 6026387189.4795\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8500280404.3087 - val_loss: 5995629006.9041\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8670913407.7804 - val_loss: 5974479289.8630\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8186459120.1921 - val_loss: 5948440884.6027\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8779820952.3705 - val_loss: 5935739325.3699\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8660777911.9863 - val_loss: 5925036593.0959\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8318961221.3791 - val_loss: 5905098906.3014\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8330662892.6792 - val_loss: 5891873813.0411\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8823463498.6484 - val_loss: 5881395263.1233\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8312539482.8954 - val_loss: 5862649526.3562\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8229931252.1441 - val_loss: 5847882702.9041\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8653146249.4408 - val_loss: 5837827675.1781\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8317350881.2624 - val_loss: 5830248981.0411\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8511343139.1286 - val_loss: 5820458180.3836\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8204344479.8353 - val_loss: 5810350269.3699\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8354874187.0875 - val_loss: 5795686031.7808\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8059098651.2247 - val_loss: 5785536540.0548\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8333593707.1424 - val_loss: 5774033997.1507\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8524825862.5866 - val_loss: 5769096816.2192\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8413334135.4374 - val_loss: 5763184184.1096\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8433364319.2864 - val_loss: 5757888557.5890\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8249326204.7067 - val_loss: 5749848246.3562\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8468360664.4803 - val_loss: 5744356685.1507\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8479165778.5523 - val_loss: 5738660888.5479\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8436614425.9074 - val_loss: 5733622657.7534\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8265897764.4460 - val_loss: 5730889398.3562\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8754317885.9142 - val_loss: 5730250268.0548\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9022959347.2659 - val_loss: 5726365173.4795\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8568956836.6655 - val_loss: 5724050958.0274\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8578148687.0395 - val_loss: 5721658869.4795\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8807933510.2573 - val_loss: 5716344418.1918\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8403454478.9297 - val_loss: 5715539035.1781\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8122486964.9125 - val_loss: 5712492628.1644\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8695716319.5060 - val_loss: 5710255047.8904\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8268559476.8027 - val_loss: 5703060886.7945\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8151756882.5523 - val_loss: 5698757267.2877\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8178862930.1132 - val_loss: 5692661079.6712\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8625609411.8422 - val_loss: 5690158409.6438\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7888668865.2075 - val_loss: 5688048015.7808\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8234773739.3619 - val_loss: 5685022246.5753\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8156805504.6587 - val_loss: 5680015886.0274\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8436975314.7719 - val_loss: 5682924067.0685\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8133645350.6415 - val_loss: 5683012979.7260\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8414594754.0858 - val_loss: 5680321655.2329\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8631397604.3362 - val_loss: 5677486507.8356\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8826413850.7856 - val_loss: 5677588725.4795\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8328230991.0395 - val_loss: 5673414610.4110\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8445944150.5043 - val_loss: 5669298568.7671\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8606056174.8748 - val_loss: 5669731075.5068\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8647565908.3087 - val_loss: 5669644715.8356\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 8669874532.1166 - val_loss: 5668427253.4795\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8674953509.3242 - val_loss: 5667560069.2603\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8530376456.3431 - val_loss: 5669121592.1096\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8882947842.1955 - val_loss: 5673598176.4384\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 9222105643.0326 - val_loss: 5679439338.9589\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8527498452.9674 - val_loss: 5677289801.6438\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8174674318.2710 - val_loss: 5670693407.5616\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8327816940.2401 - val_loss: 5667693266.4110\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8497451111.6295 - val_loss: 5665435213.1507\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8604653834.9777 - val_loss: 5666241858.6301\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8646341175.3276 - val_loss: 5664016194.6301\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8676675557.6535 - val_loss: 5664297976.9863\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8469139100.3225 - val_loss: 5660525308.4932\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8138560072.0137 - val_loss: 5659444532.6027\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8008794966.2847 - val_loss: 5656515226.3014\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8618031826.7719 - val_loss: 5659400374.3562\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8713222900.1441 - val_loss: 5659012145.0959\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8357297586.7170 - val_loss: 5656977920.0000\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 7964593011.4854 - val_loss: 5654953461.4795\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8956782523.4991 - val_loss: 5656870789.2603\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8504951932.7067 - val_loss: 5655949648.6575\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8554809414.2573 - val_loss: 5655520291.0685\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8085557774.9297 - val_loss: 5655214251.8356\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8435577379.1286 - val_loss: 5656234895.7808\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8711125141.2967 - val_loss: 5654406894.4658\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8387428069.6535 - val_loss: 5654658479.3425\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 7861332385.1527 - val_loss: 5654524773.6986\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8335370257.1252 - val_loss: 5655755172.8219\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8239325724.9811 - val_loss: 5655371565.5890\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8430169857.3173 - val_loss: 5655498787.0685\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8271737163.9657 - val_loss: 5654734055.4521\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8433005463.4923 - val_loss: 5654516693.9178\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8376644455.1904 - val_loss: 5654984718.0274\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8435723719.7942 - val_loss: 5655203931.1781\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8369920287.1767 - val_loss: 5654374042.3014\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8081235793.2350 - val_loss: 5653521800.7671\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8335781650.8816 - val_loss: 5653126112.4384\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8441931326.3533 - val_loss: 5654403233.3151\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8392074753.3173 - val_loss: 5652052760.5479\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8499136011.4168 - val_loss: 5651922179.5068\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8185610257.5643 - val_loss: 5649576062.2466\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8431203629.2281 - val_loss: 5649182495.5616\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8362945723.0600 - val_loss: 5650197616.2192\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7953199542.2298 - val_loss: 5650007096.1096\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8396655652.0069 - val_loss: 5647416116.6027\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8242358395.8285 - val_loss: 5644911784.3288\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8236842881.5369 - val_loss: 5643084035.5068\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8506082948.6106 - val_loss: 5644095663.3425\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8342828448.2744 - val_loss: 5643551018.0822\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8712354066.0034 - val_loss: 5640593934.0274\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8366078052.1166 - val_loss: 5642022224.6575\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8235136767.5609 - val_loss: 5643498271.5616\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8247610536.6175 - val_loss: 5642170865.9726\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8136898033.0703 - val_loss: 5645518483.2877\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8606714488.3156 - val_loss: 5647401443.9452\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8362879287.7667 - val_loss: 5647283985.5342\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8345442635.9657 - val_loss: 5648573425.9726\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8405829723.3345 - val_loss: 5649861386.5205\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8725663688.6724 - val_loss: 5651821119.1233\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8595150542.3808 - val_loss: 5652925071.7808\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8241285527.4923 - val_loss: 5650017385.2055\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8639186288.8508 - val_loss: 5652292727.2329\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8323638567.5197 - val_loss: 5652067124.6027\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8482223305.9897 - val_loss: 5652481009.9726\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8904167061.2967 - val_loss: 5655014806.7945\n",
      "Epoch 403/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 158us/step - loss: 8700800120.3156 - val_loss: 5655104869.6986\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8503731839.3413 - val_loss: 5655690408.3288\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8187530722.5798 - val_loss: 5651077344.4384\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7923596249.3585 - val_loss: 5649911783.4521\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8587630676.3087 - val_loss: 5653069220.8219\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8599328092.2127 - val_loss: 5653431520.4384\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8631857058.9091 - val_loss: 5654990844.4932\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8569940419.4031 - val_loss: 5655981217.3151\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8667206477.7221 - val_loss: 5658029441.7534\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8547567764.4185 - val_loss: 5657786894.0274\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8723975081.9348 - val_loss: 5657122693.2603\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8490075390.6827 - val_loss: 5655711242.5205\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8193908592.8508 - val_loss: 5655723463.8904\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8089504118.1201 - val_loss: 5657412183.6712\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8609898669.8868 - val_loss: 5656339757.5890\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8312809065.3859 - val_loss: 5657303790.4658\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8292695582.7376 - val_loss: 5656836418.6301\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8406876630.7238 - val_loss: 5655654424.5479\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8210873691.7736 - val_loss: 5653385447.4521\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7882511181.7221 - val_loss: 5650937799.8904\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8665019367.4100 - val_loss: 5653658936.1096\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8469898401.5918 - val_loss: 5654845671.4521\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8315914299.7187 - val_loss: 5654832724.1644\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8029571159.3825 - val_loss: 5652857084.4932\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8386634806.4494 - val_loss: 5651726213.2603\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8275918091.8559 - val_loss: 5653868901.6986\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8446121471.1218 - val_loss: 5655315834.7397\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8257718281.6604 - val_loss: 5658533116.4932\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8564195962.9503 - val_loss: 5659280138.5205\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8260166246.7513 - val_loss: 5660318832.2192\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8502286163.8696 - val_loss: 5660039746.6301\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8586180020.4734 - val_loss: 5658450838.7945\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8379997558.9983 - val_loss: 5656147371.8356\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8596337500.6518 - val_loss: 5657031665.9726\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8417610777.4683 - val_loss: 5658497322.0822\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8826468386.2504 - val_loss: 5660304201.6438\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8703700001.8113 - val_loss: 5659045456.6575\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8850610272.6038 - val_loss: 5660181384.7671\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8469250121.7702 - val_loss: 5658792405.9178\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8548924898.1407 - val_loss: 5658882686.2466\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8587653547.6913 - val_loss: 5660842804.6027\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8320311324.9811 - val_loss: 5662373786.3014\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8648790501.6535 - val_loss: 5661050213.6986\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8343841531.1698 - val_loss: 5662282702.9041\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8676746419.1561 - val_loss: 5662902496.4384\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8526257125.6535 - val_loss: 5661739470.9041\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8786855244.8439 - val_loss: 5659995023.7808\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8429629613.0086 - val_loss: 5660153252.8219\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8321019590.4768 - val_loss: 5662925126.1370\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8075938316.7341 - val_loss: 5660251563.8356\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8451144267.5266 - val_loss: 5661823971.9452\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7995714978.9091 - val_loss: 5659626250.5205\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8443674112.8782 - val_loss: 5659424143.7808\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8513476394.5935 - val_loss: 5657909774.0274\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8355292681.6604 - val_loss: 5656046065.9726\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8829192469.5163 - val_loss: 5656623082.9589\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 7919171815.4099 - val_loss: 5653534965.4795\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8649603816.7273 - val_loss: 5654054855.8904\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8559014905.8525 - val_loss: 5655834273.3151\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8363790671.4786 - val_loss: 5653241691.1781\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8628278882.3602 - val_loss: 5655069664.4384\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8615258974.4082 - val_loss: 5656412826.3014\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8315245366.0103 - val_loss: 5655715885.5890\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8757896381.6947 - val_loss: 5656848752.2192\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8588872768.9880 - val_loss: 5655975879.8904\n",
      "Epoch 468/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 153us/step - loss: 8609276531.0463 - val_loss: 5653446564.8219\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8255217560.3705 - val_loss: 5650642249.6438\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8344221139.2110 - val_loss: 5648479547.6164\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8674909166.4357 - val_loss: 5651228601.8630\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8118684938.9777 - val_loss: 5650696956.4932\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8497125023.8353 - val_loss: 5649721017.8630\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8427520989.7496 - val_loss: 5647645643.3973\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8578876280.7547 - val_loss: 5649412888.5479\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8660209672.7822 - val_loss: 5650870208.8767\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8246894658.7444 - val_loss: 5648212388.8219\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8551633004.0206 - val_loss: 5650553196.7123\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8688664318.6827 - val_loss: 5652767456.4384\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8915865072.1921 - val_loss: 5652378609.9726\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8138750240.9331 - val_loss: 5652377154.6301\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8512565190.0377 - val_loss: 5653512044.7123\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8726528091.3345 - val_loss: 5653554091.8356\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8645668389.7633 - val_loss: 5653212949.0411\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9000172117.1870 - val_loss: 5653035477.9178\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8367267660.8439 - val_loss: 5652602090.9589\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8233712262.3671 - val_loss: 5653860295.8904\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8596045284.3362 - val_loss: 5653419723.3973\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8514599914.4837 - val_loss: 5653901224.3288\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8760898285.1184 - val_loss: 5654359390.6849\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8303817280.9880 - val_loss: 5655702938.3014\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8483883562.1544 - val_loss: 5659774793.6438\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8991473482.2093 - val_loss: 5661697062.5753\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8890586424.6449 - val_loss: 5664501788.0548\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8451896251.0600 - val_loss: 5661587021.1507\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8562474937.7427 - val_loss: 5658685348.8219\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8982338660.9949 - val_loss: 5660313628.0548\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8074622809.1389 - val_loss: 5660683144.7671\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8511646877.2007 - val_loss: 5657688786.4110\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8177757220.0069 - val_loss: 5659465233.5342\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8486486871.3825 - val_loss: 5654736012.2740\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8235525671.5197 - val_loss: 5656313445.6986\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8297554179.9520 - val_loss: 5658160548.8219\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8850773376.6587 - val_loss: 5657140560.6575\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8292064213.8456 - val_loss: 5656864385.7534\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8633857483.3070 - val_loss: 5658598813.8082\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8615671557.7084 - val_loss: 5658638581.4795\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8709890509.5026 - val_loss: 5661633087.1233\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8608722236.1578 - val_loss: 5658326051.0685\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8856797110.2298 - val_loss: 5657205244.4932\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8209451624.5077 - val_loss: 5657162569.6438\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8189080813.1184 - val_loss: 5658949302.3562\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8071836751.9177 - val_loss: 5654378096.2192\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8576421716.7479 - val_loss: 5652083564.7123\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8688987956.2539 - val_loss: 5649350557.8082\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8294859633.7290 - val_loss: 5648063845.6986\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8391791448.2607 - val_loss: 5650193337.8630\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8420516205.3379 - val_loss: 5649464989.8082\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 8511285248.0000 - val_loss: 5648289301.0411\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8308367918.5455 - val_loss: 5644442147.0685\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 8304390561.1527 - val_loss: 5642752974.9041\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8800235390.0240 - val_loss: 5644398171.1781\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 8725600319.2316 - val_loss: 5645697655.2329\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 315us/step - loss: 8717862443.0326 - val_loss: 5645171999.5616\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 414us/step - loss: 7910380976.9605 - val_loss: 5643035700.6027\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 1s 547us/step - loss: 8530834385.4545 - val_loss: 5644737455.3425\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 1s 634us/step - loss: 8358007920.4117 - val_loss: 5641345781.4795\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 1s 595us/step - loss: 8382308452.5557 - val_loss: 5642272185.8630\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 1s 521us/step - loss: 8389383499.9657 - val_loss: 5644052076.7123\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 1s 451us/step - loss: 8556248847.3688 - val_loss: 5642319766.7945\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 1s 478us/step - loss: 8386770339.7873 - val_loss: 5643201820.0548\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 1s 439us/step - loss: 8309334405.0497 - val_loss: 5644897083.6164\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 1s 471us/step - loss: 8372954134.8336 - val_loss: 5640953568.4384\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 1s 435us/step - loss: 7947904873.8250 - val_loss: 5639565753.8630\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 1s 450us/step - loss: 8648134334.5729 - val_loss: 5639656083.2877\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 1s 451us/step - loss: 8766562329.9074 - val_loss: 5641165662.6849\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 1s 451us/step - loss: 8633011359.8353 - val_loss: 5639855924.6027\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 1s 449us/step - loss: 8456587093.6261 - val_loss: 5638972142.4658\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 1s 441us/step - loss: 8703113237.9554 - val_loss: 5642574483.2877\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 352us/step - loss: 8208649134.3259 - val_loss: 5640464187.6164\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 334us/step - loss: 7951663652.0069 - val_loss: 5641268462.4658\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 334us/step - loss: 8230162140.4322 - val_loss: 5639901341.8082\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 317us/step - loss: 8516961158.8062 - val_loss: 5638580974.4658\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 288us/step - loss: 8213381029.5437 - val_loss: 5638250902.7945\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 299us/step - loss: 8161613678.2161 - val_loss: 5638496382.2466\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 325us/step - loss: 8125893589.8456 - val_loss: 5639250958.0274\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 8130627229.2007 - val_loss: 5638585778.8493\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 280us/step - loss: 8762175575.8216 - val_loss: 5640457482.5205\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 271us/step - loss: 8340878934.0652 - val_loss: 5642209220.3836\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 244us/step - loss: 8462151986.4974 - val_loss: 5641604257.3151\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 8565111908.9949 - val_loss: 5642409717.4795\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 8522023833.2487 - val_loss: 5643011619.0685\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 8316445706.5386 - val_loss: 5644089154.6301\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8175731214.9297 - val_loss: 5643033799.8904\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 8429098694.4768 - val_loss: 5643767797.4795\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8575931801.2487 - val_loss: 5644702839.2329\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 8389864029.9691 - val_loss: 5643426191.7808\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8439652929.8662 - val_loss: 5644333462.7945\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 8375675637.0223 - val_loss: 5644455953.5342\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 8653973091.2384 - val_loss: 5646697044.1644\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8557610265.0292 - val_loss: 5648134971.6164\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8276619521.3173 - val_loss: 5646433272.9863\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8368108329.7153 - val_loss: 5650208575.1233\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 8448385192.1784 - val_loss: 5650631546.7397\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 8413714455.7118 - val_loss: 5648769318.5753\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 8363462826.3739 - val_loss: 5647674038.3562\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 8668010195.6501 - val_loss: 5648494805.9178\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 8729669447.5746 - val_loss: 5649913684.1644\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 8189421063.9039 - val_loss: 5649022316.7123\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8621333436.3774 - val_loss: 5651505541.2603\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 8487886227.1012 - val_loss: 5650242002.4110\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 8488445741.2281 - val_loss: 5648420881.5342\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 8278722650.8954 - val_loss: 5647260426.5205\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 8789228104.0137 - val_loss: 5649252958.6849\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 8407517882.1818 - val_loss: 5651079943.0137\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 8464915832.7547 - val_loss: 5652140200.3288\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 8395168809.7153 - val_loss: 5651848767.1233\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 8140857211.3894 - val_loss: 5649684571.1781\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8796245395.1012 - val_loss: 5653571173.6986\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8583492732.7067 - val_loss: 5656747691.8356\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8556761964.4597 - val_loss: 5655400644.3836\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 8032554596.9949 - val_loss: 5651984348.9315\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 7789078324.2539 - val_loss: 5648373816.1096\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8756835281.4545 - val_loss: 5646596558.9041\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8099671006.6278 - val_loss: 5646584509.3699\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8048581891.9520 - val_loss: 5645517564.4932\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8571046079.4511 - val_loss: 5645666163.7260\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8639322147.1286 - val_loss: 5645184603.1781\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 8420504935.1904 - val_loss: 5648306098.8493\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8468521710.8748 - val_loss: 5649747571.7260\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8322907336.2333 - val_loss: 5651027028.1644\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8493274089.1664 - val_loss: 5650425870.0274\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8401546141.6398 - val_loss: 5650652650.9589\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8248743409.9485 - val_loss: 5650811146.5205\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8445453382.2573 - val_loss: 5648541198.0274\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8232022761.6055 - val_loss: 5648089978.7397\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8320281228.5146 - val_loss: 5648968767.1233\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 175us/step - loss: 8236257354.2093 - val_loss: 5647022188.7123\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8074901013.9554 - val_loss: 5645275777.7534\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8153375728.1921 - val_loss: 5643470108.0548\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8468427049.2762 - val_loss: 5645940539.6164\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8605554543.0943 - val_loss: 5646443470.9041\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8429945267.5952 - val_loss: 5647100072.3288\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8398684217.9623 - val_loss: 5647712796.0548\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 8391596810.0995 - val_loss: 5649467420.0548\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8583697579.9108 - val_loss: 5652415761.5342\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 8495149921.0429 - val_loss: 5651636869.2603\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8050439845.9828 - val_loss: 5647869804.7123\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8437306327.6021 - val_loss: 5648798916.3836\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8200097760.3842 - val_loss: 5646013832.7671\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8223516023.8765 - val_loss: 5644693279.5616\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8404270442.7033 - val_loss: 5645586551.2329\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8421993593.6329 - val_loss: 5645494065.0959\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8821096892.3774 - val_loss: 5648459088.6575\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8385056906.7581 - val_loss: 5645968874.9589\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8296476113.0154 - val_loss: 5644847710.6849\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8798706730.1544 - val_loss: 5645533688.9863\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8462777284.2813 - val_loss: 5645600690.8493\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8612798789.8182 - val_loss: 5645708217.8630\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8199936831.8902 - val_loss: 5644602697.6438\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8171701468.8714 - val_loss: 5644133663.5616\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8355238825.0566 - val_loss: 5643927190.7945\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8672259764.0343 - val_loss: 5644919632.6575\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8368620691.5403 - val_loss: 5648050316.2740\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8938656190.5729 - val_loss: 5648927288.1096\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8461002836.3087 - val_loss: 5652561274.7397\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8603139334.5866 - val_loss: 5653001594.7397\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8088922336.8233 - val_loss: 5646242416.2192\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8612354695.2453 - val_loss: 5646628692.1644\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8153808924.1029 - val_loss: 5646897130.9589\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8586686358.6141 - val_loss: 5649198399.1233\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8640090082.5798 - val_loss: 5651400349.8082\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8565646743.4923 - val_loss: 5648235498.9589\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8483732651.2521 - val_loss: 5646764389.6986\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8128507445.5712 - val_loss: 5642376612.8219\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8541702223.9177 - val_loss: 5644289732.3836\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8633003871.2864 - val_loss: 5645347086.0274\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8434308900.4460 - val_loss: 5646013303.2329\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8646435133.9142 - val_loss: 5648204673.7534\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9088764003.2384 - val_loss: 5650567395.9452\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8667476570.4563 - val_loss: 5653286059.8356\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8399969683.9794 - val_loss: 5651455558.1370\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8333303501.9417 - val_loss: 5653790674.4110\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8616146989.6672 - val_loss: 5654951641.4247\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8612357733.8731 - val_loss: 5656379721.6438\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8422184875.2521 - val_loss: 5657503351.2329\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8700665968.4117 - val_loss: 5657099313.0959\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8465079016.2882 - val_loss: 5655931672.5479\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8423132274.1681 - val_loss: 5659015139.9452\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8606801975.3276 - val_loss: 5660088775.8904\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8156872083.1012 - val_loss: 5656786589.8082\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7959087221.6810 - val_loss: 5653430601.6438\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8589145875.7599 - val_loss: 5654522452.1644\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8218715950.1063 - val_loss: 5653248960.8767\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8254065379.4580 - val_loss: 5650989371.6164\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8525881228.0755 - val_loss: 5647802339.9452\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8154561766.9708 - val_loss: 5649686356.1644\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8570415197.0909 - val_loss: 5652645954.6301\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8190445034.9228 - val_loss: 5648598300.0548\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8551333472.6038 - val_loss: 5652482826.5205\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8702232048.4117 - val_loss: 5650795295.5616\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8453490867.1561 - val_loss: 5649493945.8630\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 165us/step - loss: 8323498669.0086 - val_loss: 5651486923.3973\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8503985089.2075 - val_loss: 5652845231.3425\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8605481342.0240 - val_loss: 5652134385.9726\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8636643461.4889 - val_loss: 5655540925.3699\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8531935403.2521 - val_loss: 5656022352.6575\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8371378994.9365 - val_loss: 5656956973.5890\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8553143629.2830 - val_loss: 5659620990.2466\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7990186937.7427 - val_loss: 5658154033.0959\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8621622067.8148 - val_loss: 5658491532.2740\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8226780529.7290 - val_loss: 5659226799.3425\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8688539150.9297 - val_loss: 5659738602.9589\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8213840367.3139 - val_loss: 5658915405.1507\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8697303645.9691 - val_loss: 5656125783.6712\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8103873049.9074 - val_loss: 5654971553.3151\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8494411056.7410 - val_loss: 5654957848.5479\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8566028888.2607 - val_loss: 5656294122.9589\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8577012576.6038 - val_loss: 5655626965.9178\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8370314582.5043 - val_loss: 5652792839.0137\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8426827679.3962 - val_loss: 5652530603.8356\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 143us/step - loss: 8549780599.4374 - val_loss: 5653017614.0274\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8751493172.6930 - val_loss: 5654336154.3014\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8596117050.4014 - val_loss: 5655655094.3562\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8574139865.7976 - val_loss: 5656708320.4384\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8621064132.2813 - val_loss: 5659591736.1096\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8149647460.5557 - val_loss: 5659981038.4658\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8387299394.7444 - val_loss: 5658833295.7808\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8264569671.1355 - val_loss: 5657664150.7945\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7916150803.3208 - val_loss: 5654221410.1918\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8755908647.5197 - val_loss: 5652026031.3425\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8333652358.8062 - val_loss: 5651639190.7945\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8714981648.2470 - val_loss: 5653412569.4247\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8425345920.6587 - val_loss: 5653964635.1781\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8702903489.2075 - val_loss: 5652216968.7671\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8406112688.0823 - val_loss: 5654164234.5205\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8555102347.6364 - val_loss: 5651694795.3973\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8234035993.0292 - val_loss: 5653206997.9178\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8399427164.2127 - val_loss: 5653825711.3425\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8511509781.0772 - val_loss: 5654581363.7260\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8369218013.7496 - val_loss: 5653405383.8904\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8475569821.2007 - val_loss: 5655007898.3014\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8577944266.4288 - val_loss: 5654174355.2877\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8225241552.5763 - val_loss: 5649931628.7123\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8382491514.5111 - val_loss: 5649795927.6712\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8173202878.1338 - val_loss: 5649397240.9863\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8118428867.8422 - val_loss: 5645983431.8904\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8530199229.2556 - val_loss: 5649955917.1507\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8514444237.9417 - val_loss: 5649274339.9452\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8369555018.6484 - val_loss: 5649010354.8493\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8958995050.2642 - val_loss: 5652825463.2329\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8587768135.5746 - val_loss: 5651345702.5753\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8505474222.7650 - val_loss: 5651005362.8493\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8222776595.7599 - val_loss: 5649165978.3014\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8665054819.2384 - val_loss: 5647449484.2740\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8636649402.6209 - val_loss: 5648284580.8219\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8237811843.2933 - val_loss: 5651323756.7123\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8315392732.4322 - val_loss: 5650674593.3151\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8866140118.2847 - val_loss: 5653544083.2877\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8686743577.9074 - val_loss: 5653575813.2603\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8402862404.0618 - val_loss: 5652281968.2192\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8819247183.0395 - val_loss: 5654842820.3836\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8176922962.9914 - val_loss: 5653067516.4932\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8768654302.6278 - val_loss: 5650632777.6438\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8697463093.1321 - val_loss: 5650508245.9178\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8310512168.8370 - val_loss: 5649128216.5479\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8570370810.2916 - val_loss: 5647093788.0548\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 160us/step - loss: 8567460288.7684 - val_loss: 5648021167.3425\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8402517549.6672 - val_loss: 5650774499.9452\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7934238128.7410 - val_loss: 5649553004.7123\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8409582184.5077 - val_loss: 5649379850.5205\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8398719358.0240 - val_loss: 5649035733.9178\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8419761213.9142 - val_loss: 5648150233.4247\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8311672384.1098 - val_loss: 5648184747.8356\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8225499491.6775 - val_loss: 5645942356.1644\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8041270284.7341 - val_loss: 5641275441.0959\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8449153448.6175 - val_loss: 5640826809.8630\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8628755140.7204 - val_loss: 5640949963.3973\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8164122300.8165 - val_loss: 5641804631.6712\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8577841495.3825 - val_loss: 5643652741.2603\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8408546344.3979 - val_loss: 5642991531.8356\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8454802624.7684 - val_loss: 5643550741.0411\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8417146597.2144 - val_loss: 5645103630.0274\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8218989888.5489 - val_loss: 5645560425.2055\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8293124721.2899 - val_loss: 5646323897.8630\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8404491563.4717 - val_loss: 5646813464.5479\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 144us/step - loss: 8844012076.7890 - val_loss: 5647880760.1096\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8551227010.8542 - val_loss: 5648746460.9315\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8523703676.7067 - val_loss: 5649044283.6164\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8405305200.8508 - val_loss: 5651527290.7397\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8346759847.7393 - val_loss: 5647023054.9041\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8119337504.4940 - val_loss: 5643931185.0959\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8641217228.6244 - val_loss: 5643150413.1507\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8499154359.9863 - val_loss: 5644030176.4384\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8377731429.4340 - val_loss: 5646294447.3425\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8292615280.4117 - val_loss: 5646732589.5890\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8335410488.6449 - val_loss: 5648488377.8630\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8239536237.7770 - val_loss: 5646744579.5068\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8651172150.8885 - val_loss: 5650071022.4658\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8390436275.1561 - val_loss: 5649374179.9452\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8713330854.8611 - val_loss: 5650225429.0411\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8375926449.3997 - val_loss: 5648868373.0411\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8369722222.2161 - val_loss: 5653562673.0959\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8822510712.7547 - val_loss: 5655596712.3288\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8427738240.2196 - val_loss: 5654022564.8219\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8506498957.8319 - val_loss: 5654625206.3562\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8602063616.4391 - val_loss: 5656732559.7808\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8540340837.8731 - val_loss: 5656852360.7671\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8292792843.8559 - val_loss: 5655483553.3151\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8528852975.3139 - val_loss: 5660256487.4521\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8246981788.3225 - val_loss: 5661230094.0274\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8755921818.1269 - val_loss: 5665121799.0137\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8416628266.1544 - val_loss: 5662733950.2466\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8502418677.0223 - val_loss: 5662910442.9589\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8679762694.5866 - val_loss: 5662915896.1096\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8729514255.3688 - val_loss: 5664046914.6301\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8454770552.7547 - val_loss: 5667126159.7808\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8567434864.4117 - val_loss: 5666575156.6027\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8413977234.2230 - val_loss: 5665505160.7671\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8417314174.4631 - val_loss: 5663534423.6712\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8598658066.8816 - val_loss: 5663156252.0548\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8115491166.8473 - val_loss: 5665150393.8630\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7875786044.1578 - val_loss: 5662282702.9041\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8584354533.2144 - val_loss: 5660065981.3699\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8387009630.8473 - val_loss: 5660132467.7260\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8357972093.5849 - val_loss: 5661186012.9315\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8454819176.0686 - val_loss: 5660910662.1370\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8727513384.8370 - val_loss: 5660674026.9589\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8494947936.6038 - val_loss: 5664114617.8630\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8134613478.5317 - val_loss: 5660475854.9041\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8267435290.7856 - val_loss: 5655673884.0548\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8196634869.9005 - val_loss: 5658474695.8904\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 8518317610.1544 - val_loss: 5659915369.2055\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8110307603.7599 - val_loss: 5657160332.2740\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8300516849.9485 - val_loss: 5654521224.7671\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8386649704.9468 - val_loss: 5652922360.9863\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8640361225.2213 - val_loss: 5653740347.6164\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8741167608.0961 - val_loss: 5657586880.8767\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8382306024.7273 - val_loss: 5658777109.0411\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8589036557.1732 - val_loss: 5657876830.6849\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8116654359.2727 - val_loss: 5655229685.4795\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8394528454.4768 - val_loss: 5653879050.5205\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8528104753.6192 - val_loss: 5656592797.8082\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8363994931.3756 - val_loss: 5655081464.9863\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8489176596.1990 - val_loss: 5656903006.6849\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8376332407.4374 - val_loss: 5658817746.4110\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8191370998.7787 - val_loss: 5656872297.2055\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8934618712.2607 - val_loss: 5656231122.4110\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8441500766.8473 - val_loss: 5655939696.2192\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8451583852.8988 - val_loss: 5657139666.4110\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8544047186.9914 - val_loss: 5657913771.8356\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8306671284.0343 - val_loss: 5657601536.0000\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8757981933.1184 - val_loss: 5658263404.7123\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8682888018.9914 - val_loss: 5658873203.7260\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8241598370.9091 - val_loss: 5660492049.5342\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8501209965.3379 - val_loss: 5660352476.9315\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8666477239.5472 - val_loss: 5661131860.1644\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8330777427.8696 - val_loss: 5659829195.3973\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8331152750.2161 - val_loss: 5657183431.8904\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7997680534.6141 - val_loss: 5656338947.5068\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8387928524.1852 - val_loss: 5656577139.7260\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8828976236.0206 - val_loss: 5660094569.2055\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8482050764.6244 - val_loss: 5663295319.6712\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8274506076.6518 - val_loss: 5660198112.4384\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8343408214.9434 - val_loss: 5659109923.0685\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8646778435.6226 - val_loss: 5659889888.4384\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8312013622.8885 - val_loss: 5663642269.8082\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8182519413.6810 - val_loss: 5662745080.9863\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8518192482.7993 - val_loss: 5659980757.9178\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8592026263.0532 - val_loss: 5660056390.1370\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8116644802.5249 - val_loss: 5653932144.2192\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8140247306.5386 - val_loss: 5652297089.7534\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8194547847.2453 - val_loss: 5649363473.5342\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8569432787.6501 - val_loss: 5647098985.2055\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8240354937.1938 - val_loss: 5648719822.9041\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8378458509.8319 - val_loss: 5650402507.3973\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8527874630.2573 - val_loss: 5651458749.3699\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8446205033.3859 - val_loss: 5649299550.6849\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8445203970.6346 - val_loss: 5647603441.9726\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8862302569.8250 - val_loss: 5645518848.0000\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8308890718.8473 - val_loss: 5645831364.3836\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8708290302.6827 - val_loss: 5646937933.1507\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8281759731.7050 - val_loss: 5644701608.3288\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8692887996.3774 - val_loss: 5645678374.5753\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8608053766.1475 - val_loss: 5644628458.9589\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8548027949.6672 - val_loss: 5644212792.1096\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8408805958.2573 - val_loss: 5649728448.8767\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8648298730.9228 - val_loss: 5649563065.8630\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8476147144.2333 - val_loss: 5646951964.0548\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8654335917.8868 - val_loss: 5650699944.3288\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8228260235.1973 - val_loss: 5649138281.2055\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8554250439.3551 - val_loss: 5647464097.3151\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8369524892.3225 - val_loss: 5648542485.0411\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8379009569.3722 - val_loss: 5650222998.7945\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8543444780.3499 - val_loss: 5649923440.2192\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8500654486.6141 - val_loss: 5651063730.8493\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8466757775.1492 - val_loss: 5651603911.8904\n",
      "Epoch 858/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 8653330219.4717 - val_loss: 5651451616.4384\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8384194013.7496 - val_loss: 5643067882.9589\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8085128749.6672 - val_loss: 5638931925.9178\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8383872853.6261 - val_loss: 5638431982.4658\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8336022187.2521 - val_loss: 5641005048.9863\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8723184039.3002 - val_loss: 5640126492.0548\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8620953376.9331 - val_loss: 5643869604.8219\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8005803345.2350 - val_loss: 5639684236.2740\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8552997529.2487 - val_loss: 5641351788.7123\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8608217696.1647 - val_loss: 5642232355.0685\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8727693872.3019 - val_loss: 5644003545.4247\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8636907433.9348 - val_loss: 5647003690.0822\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8641278744.1509 - val_loss: 5648887068.0548\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8458112671.8353 - val_loss: 5647915078.1370\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 7978432842.2093 - val_loss: 5646032110.4658\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8344320279.2727 - val_loss: 5645850925.5890\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8594152060.2676 - val_loss: 5649343740.4932\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8041201743.0395 - val_loss: 5648824295.4521\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8940770498.9640 - val_loss: 5649378037.4795\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8303305981.8045 - val_loss: 5650142748.0548\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8269934253.0086 - val_loss: 5648655065.4247\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8509508652.7890 - val_loss: 5651462799.7808\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8631969768.2882 - val_loss: 5652225185.3151\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7878631143.8491 - val_loss: 5652040626.8493\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8205619966.6827 - val_loss: 5650163459.5068\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8090050956.9537 - val_loss: 5648695113.6438\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8665679926.4494 - val_loss: 5650000250.7397\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8268351350.9983 - val_loss: 5648150759.4521\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 7905081045.4065 - val_loss: 5647399125.9178\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8592448935.3002 - val_loss: 5648868565.9178\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8525163806.2985 - val_loss: 5648645337.4247\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8104372458.4837 - val_loss: 5650347158.7945\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8406502332.8165 - val_loss: 5651081759.5616\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8126100714.4837 - val_loss: 5653974615.6712\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8233344038.6415 - val_loss: 5653677052.4932\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8365888917.7358 - val_loss: 5652756241.5342\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8586257061.9828 - val_loss: 5654261367.2329\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8303568274.2230 - val_loss: 5652392728.5479\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8611599240.5626 - val_loss: 5655754359.2329\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8490182333.6947 - val_loss: 5654582650.7397\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8559526067.1561 - val_loss: 5656547804.9315\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8471863959.9314 - val_loss: 5655632250.7397\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8937413142.8336 - val_loss: 5657544346.3014\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8382438040.8096 - val_loss: 5656430974.2466\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8570603439.2041 - val_loss: 5655581555.7260\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8394006886.3122 - val_loss: 5656173210.3014\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8516442127.8079 - val_loss: 5653740628.1644\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 7977344650.7581 - val_loss: 5651151198.6849\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8349687843.1286 - val_loss: 5648975247.7808\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8444990573.7770 - val_loss: 5648100316.9315\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8401131809.8113 - val_loss: 5649706650.3014\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8376657811.1012 - val_loss: 5649578103.2329\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8085352117.7907 - val_loss: 5645691591.8904\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8602607349.0223 - val_loss: 5644595515.6164\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8788200468.1990 - val_loss: 5645289191.4521\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8606839514.6758 - val_loss: 5648373816.1096\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8300315716.0618 - val_loss: 5647793762.1918\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8300690583.4923 - val_loss: 5647581923.9452\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 7886847663.6432 - val_loss: 5646941787.1781\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8354233741.8319 - val_loss: 5650359096.1096\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8321807585.9211 - val_loss: 5652667679.5616\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8732067478.1750 - val_loss: 5650813103.3425\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8483576912.3568 - val_loss: 5647223678.2466\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8571764616.5626 - val_loss: 5647144202.5205\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8465385793.4271 - val_loss: 5649394386.4110\n",
      "Epoch 923/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 152us/step - loss: 8104159570.1132 - val_loss: 5647860890.3014\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8106276333.5575 - val_loss: 5645560425.2055\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8582722085.7633 - val_loss: 5648351652.8219\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8366791030.1201 - val_loss: 5649774570.9589\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8470819678.4082 - val_loss: 5650364517.6986\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8296178830.2710 - val_loss: 5649490088.3288\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8560046928.3568 - val_loss: 5652041517.5890\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8566156107.9657 - val_loss: 5653770264.5479\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 142us/step - loss: 8363091713.3173 - val_loss: 5651079076.8219\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8442587443.3756 - val_loss: 5649193591.2329\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8540781817.4134 - val_loss: 5648679185.5342\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8483845069.0635 - val_loss: 5649695779.0685\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8349449859.7324 - val_loss: 5648371136.8767\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8462450183.9039 - val_loss: 5652687107.5068\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8581013472.3842 - val_loss: 5653331964.4932\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8656903997.0360 - val_loss: 5653833230.0274\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8163231907.3482 - val_loss: 5654354386.4110\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8109900945.7839 - val_loss: 5652120884.6027\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9172023745.6467 - val_loss: 5651898753.7534\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8621390893.6672 - val_loss: 5655800972.2740\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8391367459.1286 - val_loss: 5655350005.4795\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8384975525.9828 - val_loss: 5654042080.4384\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8346338878.3533 - val_loss: 5653109058.6301\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8694390049.8113 - val_loss: 5653573491.7260\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8332588450.0309 - val_loss: 5655711715.9452\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8155791496.1235 - val_loss: 5651611935.5616\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8776390670.0515 - val_loss: 5652634995.7260\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8490924856.2058 - val_loss: 5653128658.4110\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8719366256.4117 - val_loss: 5654297151.1233\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8260216092.5420 - val_loss: 5653157537.3151\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8125313021.3654 - val_loss: 5652554453.9178\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8529012407.5472 - val_loss: 5651717547.8356\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8189175124.7479 - val_loss: 5653079958.7945\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8313357187.2933 - val_loss: 5654827414.7945\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8405729131.5815 - val_loss: 5654867119.3425\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8244631584.4940 - val_loss: 5655365414.5753\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8296650123.1973 - val_loss: 5655767222.3562\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8133460124.3225 - val_loss: 5654398393.8630\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8255262512.7410 - val_loss: 5654326903.2329\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8376971013.7084 - val_loss: 5657466550.3562\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8484106696.6724 - val_loss: 5657961373.8082\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8360391018.2642 - val_loss: 5658509739.8356\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8402431340.4597 - val_loss: 5658212313.4247\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8388765838.2710 - val_loss: 5657029849.4247\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8208803639.7667 - val_loss: 5654649729.7534\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8530569122.0309 - val_loss: 5655826670.4658\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8381982196.5832 - val_loss: 5654265365.0411\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8149033176.0412 - val_loss: 5652100615.0137\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8180598606.6003 - val_loss: 5652872430.4658\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8532410549.7907 - val_loss: 5653775857.9726\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8497346958.2710 - val_loss: 5654054855.8904\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8415448062.2436 - val_loss: 5657021208.5479\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8260717204.4185 - val_loss: 5655570481.0959\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8476515723.1973 - val_loss: 5655865424.6575\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8580585091.7324 - val_loss: 5659628684.2740\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8130289874.7719 - val_loss: 5660427888.2192\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8222229858.7993 - val_loss: 5658805942.3562\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8341842309.9280 - val_loss: 5657431397.6986\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8501786771.5403 - val_loss: 5657809516.7123\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8602865646.4357 - val_loss: 5657356898.1918\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8482260446.6278 - val_loss: 5656223849.2055\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8545469916.8714 - val_loss: 5654631132.9315\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8450691648.1098 - val_loss: 5651816202.5205\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8549659488.1647 - val_loss: 5650571895.2329\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8396182513.9485 - val_loss: 5649896605.8082\n",
      "Epoch 988/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 150us/step - loss: 8122375991.7667 - val_loss: 5647975192.5479\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 8291403918.22 - 0s 153us/step - loss: 8299889586.7170 - val_loss: 5647161414.1370\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8177671974.2024 - val_loss: 5647907783.8904\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8598988397.7770 - val_loss: 5649707264.0000\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8076184749.8868 - val_loss: 5647192940.7123\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8359820339.8148 - val_loss: 5647675265.7534\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 8138522953.3310 - val_loss: 5647176784.6575\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8442871573.5163 - val_loss: 5647233739.3973\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8303749824.3293 - val_loss: 5644499231.5616\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8628128718.8199 - val_loss: 5645781598.6849\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8017950712.0961 - val_loss: 5646050465.3151\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8495342389.1321 - val_loss: 5647446384.2192\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8617531142.5866 - val_loss: 5647661904.6575\n",
      "neurons used (64, 16)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 557us/step - loss: 39209392047.2041 - val_loss: 38414785802.5205\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 39206457196.4597 - val_loss: 38409072247.2329\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39201799854.7650 - val_loss: 38404704957.3699\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 39195431375.6981 - val_loss: 38401150583.2329\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 39187887681.8662 - val_loss: 38390737400.9863\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 39177944561.0703 - val_loss: 38378531433.2055\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39166864480.6038 - val_loss: 38373252895.5616\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 39153478060.5695 - val_loss: 38359459727.7808\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 39139783077.5437 - val_loss: 38337983305.6438\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 39124144774.3671 - val_loss: 38324760912.6575\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39108225111.8216 - val_loss: 38305328899.5069\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39087300850.3876 - val_loss: 38289658809.8630\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 39068662957.8868 - val_loss: 38271588828.9315\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 39046316179.5403 - val_loss: 38249946294.3562\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 39021902375.5197 - val_loss: 38213811185.9726\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38997961185.2624 - val_loss: 38201853250.6301\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 38969226441.9897 - val_loss: 38170497276.4931\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 38944890198.5043 - val_loss: 38140409631.5616\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38913876498.4425 - val_loss: 38122008996.8219\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 38876512628.3636 - val_loss: 38084353458.8493\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38848890662.2024 - val_loss: 38049719590.5753\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 38823660767.0669 - val_loss: 38014145129.2055\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38781840603.5540 - val_loss: 37981902314.9589\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 38749932233.1115 - val_loss: 37938554234.7397\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 38710137787.4991 - val_loss: 37895811969.7534\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 38662303399.7393 - val_loss: 37850479601.9726\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38625525570.3053 - val_loss: 37808612309.9178\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38575486519.3276 - val_loss: 37770790378.9589\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 38537373534.4082 - val_loss: 37735154028.7123\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 38498977296.6861 - val_loss: 37673824789.0411\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 38435834579.6501 - val_loss: 37632994121.6438\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 38399509182.5729 - val_loss: 37602057819.1781\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 38352703895.4923 - val_loss: 37541683845.2603\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 38293791190.7238 - val_loss: 37482947878.5753\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 38242770353.8388 - val_loss: 37428238027.3973\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 38176432015.5883 - val_loss: 37365793469.3699\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38139062359.8216 - val_loss: 37316304839.8904\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 38067141538.9091 - val_loss: 37249933788.9315\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 38004236098.3053 - val_loss: 37180881793.7534\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 37953879494.9159 - val_loss: 37121720263.8904\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 37882517149.2007 - val_loss: 37060279394.1918\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 37842464051.3756 - val_loss: 37007359466.9589\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 37757374309.4340 - val_loss: 36940996243.2877\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 37689040818.7170 - val_loss: 36870629684.6027\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 37656071742.3533 - val_loss: 36806541929.2055\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 37553142683.8834 - val_loss: 36726548508.0548\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 37485037943.8765 - val_loss: 36647190415.7808\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 37425798317.8868 - val_loss: 36578248956.4931\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 257us/step - loss: 37376708544.7684 - val_loss: 36503225891.0685\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 269us/step - loss: 37256075130.5111 - val_loss: 36433977091.5069\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 264us/step - loss: 37192700824.3705 - val_loss: 36361199503.7808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 37112673207.9863 - val_loss: 36287008038.5753\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 37037755727.4786 - val_loss: 36219494680.5479\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 36976345811.6501 - val_loss: 36139858228.6027\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 36881362733.2281 - val_loss: 36063956599.2329\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 36789420193.5918 - val_loss: 35973128023.6712\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 36722849106.9914 - val_loss: 35890070233.4247\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 36619939411.4305 - val_loss: 35789966434.1918\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 225us/step - loss: 36548664971.6364 - val_loss: 35687638955.8356\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 36442754541.5575 - val_loss: 35605931947.8356\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 36387513282.5249 - val_loss: 35513010540.7123\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 36293619950.8748 - val_loss: 35416316212.6027\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 36159106362.4014 - val_loss: 35343082706.4110\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 36083797211.5540 - val_loss: 35237606245.6986\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 35948169651.5952 - val_loss: 35137523936.4384\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 35891387822.3259 - val_loss: 35024126765.5890\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 35796252211.8148 - val_loss: 34934856914.4110\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 35674223417.5232 - val_loss: 34842315369.2055\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 35614251759.7530 - val_loss: 34741850168.1096\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 35519213413.4340 - val_loss: 34640016874.9589\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 35407984278.1750 - val_loss: 34530654488.5479\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 35266403354.3465 - val_loss: 34427422888.3288\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 35196171300.8851 - val_loss: 34333606954.0822\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 35104761023.4511 - val_loss: 34243470097.5342\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 35014265070.8748 - val_loss: 34139355837.3699\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 230us/step - loss: 34816185444.1166 - val_loss: 34031015346.8493\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 34787910397.8045 - val_loss: 33914875707.6164\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 240us/step - loss: 34633479629.9417 - val_loss: 33788581803.8356\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 34589115994.4563 - val_loss: 33684473715.7260\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 34375325165.5575 - val_loss: 33556840560.2192\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 34351188456.2882 - val_loss: 33444262084.3836\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 34190169595.6089 - val_loss: 33321298677.4795\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 34060510020.0618 - val_loss: 33197366061.5890\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 33965880483.3482 - val_loss: 33063097778.8493\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 33840213475.0189 - val_loss: 32935667010.6301\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 33730600534.9434 - val_loss: 32835860788.6027\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 33657790288.3568 - val_loss: 32715649164.2740\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 33541135598.8748 - val_loss: 32604476850.8493\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 33327481555.6501 - val_loss: 32481652539.6164\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 33233922511.6981 - val_loss: 32356803962.7397\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 33058444549.7084 - val_loss: 32237135030.3562\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 33042507913.0017 - val_loss: 32110182512.2192\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 32886248962.6346 - val_loss: 31981782843.6164\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 32707589624.0961 - val_loss: 31841183744.0000\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 252us/step - loss: 32633628724.6930 - val_loss: 31713944674.1918\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 212us/step - loss: 32501534477.6123 - val_loss: 31565400148.1644\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 32354660850.8268 - val_loss: 31433936166.5753\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 32285253849.7976 - val_loss: 31324183958.7945\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 32059894529.3173 - val_loss: 31195096218.3014\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 31940017512.0686 - val_loss: 31071987291.1781\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 31811028819.8696 - val_loss: 30913300283.6164\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 31673919589.8731 - val_loss: 30762548855.2329\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 31598785889.0429 - val_loss: 30631461986.1918\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 31427654288.9057 - val_loss: 30479127762.4110\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 31244899983.1492 - val_loss: 30321137860.3836\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 31191957395.1012 - val_loss: 30205728768.0000\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 30955758091.4168 - val_loss: 30071022213.2603\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 30951876766.0789 - val_loss: 29919043780.3836\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 30733738085.8731 - val_loss: 29797946690.6301\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 30658572612.9400 - val_loss: 29646059576.1096\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 30391155478.3945 - val_loss: 29497754553.8630\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 30230494761.2762 - val_loss: 29352227068.4931\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 30174101089.4820 - val_loss: 29192791643.1781\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 30010511068.4323 - val_loss: 29038972310.7945\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 29772637122.5249 - val_loss: 28878376062.2466\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 217us/step - loss: 29724744610.9091 - val_loss: 28740849215.1233\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 29556592510.0240 - val_loss: 28599098129.5342\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 29504901021.6398 - val_loss: 28452107951.3425\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 328us/step - loss: 29262082118.2573 - val_loss: 28302628330.9589\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 29016733843.5403 - val_loss: 28157929247.5616\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 278us/step - loss: 29052357250.8542 - val_loss: 28005763408.6575\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 28784557517.9417 - val_loss: 27834559333.6986\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 28662948834.1407 - val_loss: 27684300687.7808\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 28554883342.4906 - val_loss: 27510522809.8630\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 28390677618.1681 - val_loss: 27334268114.4110\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 28061135792.9605 - val_loss: 27183926510.4658\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 28073503689.5506 - val_loss: 27027955768.1096\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 27750203929.4683 - val_loss: 26881786052.3836\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 27640907213.9417 - val_loss: 26729525668.8219\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 27464673494.2847 - val_loss: 26583101916.9315\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 258us/step - loss: 27521091471.5883 - val_loss: 26421118106.3014\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 27211382805.0772 - val_loss: 26266269667.9452\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 275us/step - loss: 27222976828.1578 - val_loss: 26095079704.5479\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 259us/step - loss: 26957514622.0240 - val_loss: 25923328084.1644\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 26779555492.2264 - val_loss: 25780407253.9178\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 26731394639.9177 - val_loss: 25620866062.0274\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 26358605595.6638 - val_loss: 25444028247.6712\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 26343950416.7959 - val_loss: 25285377907.7260\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 26163306889.4408 - val_loss: 25119408773.2603\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 26018116778.3739 - val_loss: 24947341452.2740\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 25810115185.2899 - val_loss: 24799557155.0685\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 25670957835.8559 - val_loss: 24630053930.0822\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 25652391245.7221 - val_loss: 24465080853.0411\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 25311255378.1132 - val_loss: 24296793803.3973\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 25200636733.0360 - val_loss: 24126312391.8904\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 25088916636.3225 - val_loss: 23947235103.5616\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 24869420885.6261 - val_loss: 23782539207.8904\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 24639402589.9691 - val_loss: 23609434252.2740\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 24420273993.3310 - val_loss: 23451716088.9863\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 24431260143.3139 - val_loss: 23284857561.4247\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 24295448813.1184 - val_loss: 23117988232.7671\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 24066892603.2796 - val_loss: 22949171733.0411\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 23942656407.4923 - val_loss: 22780386570.5205\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 23668509437.8045 - val_loss: 22612364358.1370\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 23458223716.9949 - val_loss: 22470629291.8356\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 23244813169.7290 - val_loss: 22268826455.6712\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 23245829869.9966 - val_loss: 22106921212.4931\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 22971800356.4460 - val_loss: 21935519589.6986\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 22916449134.2161 - val_loss: 21765783720.3288\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 22696378262.6141 - val_loss: 21611355739.1781\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 22473507320.0961 - val_loss: 21437103777.3151\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 22468602418.0583 - val_loss: 21227024664.5479\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 22535192407.3825 - val_loss: 21054217566.6849\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 22029488468.7479 - val_loss: 20898080305.0959\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 21981254309.9828 - val_loss: 20715371786.5205\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 246us/step - loss: 21696915087.1492 - val_loss: 20499754026.0822\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 21563664744.0686 - val_loss: 20372538606.4658\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 21287462982.2573 - val_loss: 20191468361.6438\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 21353056182.2298 - val_loss: 20004611913.6438\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 21247014005.6810 - val_loss: 19872946821.2603\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 20879714750.1338 - val_loss: 19698609432.5479\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 20867074100.6930 - val_loss: 19534947650.6301\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 20458067434.0446 - val_loss: 19370132171.3973\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 20166666782.7376 - val_loss: 19206151518.6849\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 19961279461.6535 - val_loss: 19024616027.1781\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 20144259305.6055 - val_loss: 18853745902.4658\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 19892255705.3585 - val_loss: 18682509185.7534\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 19797313395.4854 - val_loss: 18500073443.9452\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 19500180645.1046 - val_loss: 18337878773.4795\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 167us/step - loss: 19631721640.6175 - val_loss: 18186984405.9178\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 19419558548.4185 - val_loss: 18005406986.5205\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 19306926350.4906 - val_loss: 17835248457.6438\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 18833942958.3259 - val_loss: 17657107806.6849\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 18875578223.9726 - val_loss: 17475707272.7671\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 18614152590.7101 - val_loss: 17321332188.9315\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 18323107439.5334 - val_loss: 17144515864.5479\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 17939160064.0000 - val_loss: 16985286670.0274\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 18390525098.3739 - val_loss: 16841917804.7123\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 18346859289.9074 - val_loss: 16679991408.2192\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 18016510141.6947 - val_loss: 16497088483.9452\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 17654802876.3774 - val_loss: 16336766358.7945\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 17358053644.7341 - val_loss: 16200596676.3836\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 17383663155.8148 - val_loss: 16032882589.8082\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 17378114099.8148 - val_loss: 15860160301.5890\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 17027187463.4648 - val_loss: 15686086684.0548\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 16707851213.0635 - val_loss: 15552247513.4247\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 16741398078.3533 - val_loss: 15396316875.3973\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 16587277290.9228 - val_loss: 15233627164.0548\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 16438734043.5540 - val_loss: 15076339824.2192\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 16492563947.8010 - val_loss: 14914435731.2877\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 16131872924.3225 - val_loss: 14744092868.3836\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 15851025827.7873 - val_loss: 14609686177.3151\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 15499366329.7427 - val_loss: 14442614910.2466\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 15917344311.3276 - val_loss: 14272491646.2466\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 15271802679.7667 - val_loss: 14104591107.5068\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 15468923510.5592 - val_loss: 13975291258.7397\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 15297011402.8679 - val_loss: 13804015882.5205\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 15044130895.0394 - val_loss: 13641658760.7671\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 14909910277.7084 - val_loss: 13490747812.8219\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 14636549163.0326 - val_loss: 13311460871.0137\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 15042229249.7564 - val_loss: 13157590506.9589\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 14488765287.1904 - val_loss: 13020470243.9452\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 14485920875.1424 - val_loss: 12892771426.1918\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 13932254246.6415 - val_loss: 12755635375.3425\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 14249945551.6981 - val_loss: 12621253063.8904\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 14149153382.7513 - val_loss: 12493495927.2329\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 13859812146.4974 - val_loss: 12339670983.8904\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 13694079731.2659 - val_loss: 12185293915.1781\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 13506652925.8045 - val_loss: 12052389824.8767\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 13497073059.7873 - val_loss: 11896144348.9315\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 13673397073.6741 - val_loss: 11745660689.5342\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 12984265356.5146 - val_loss: 11618414921.6438\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 12912362610.1681 - val_loss: 11479376846.9041\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 13156769250.742 - 0s 154us/step - loss: 13128950285.1732 - val_loss: 11336903595.8356\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 13076704969.9897 - val_loss: 11202722437.2603\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 12710075783.6844 - val_loss: 11050621180.4932\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 12633546864.4117 - val_loss: 10924941403.1781\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 12532503624.0137 - val_loss: 10791703671.2329\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 12337568328.0137 - val_loss: 10657505728.8767\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11864018548.8027 - val_loss: 10513394884.3836\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 12215313643.3619 - val_loss: 10389184119.2329\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11924987607.1630 - val_loss: 10264851799.6712\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11840175386.7856 - val_loss: 10144491730.4110\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 11707724694.6141 - val_loss: 10011318762.9589\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 11818423463.7393 - val_loss: 9896142062.4658\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 11603857613.5026 - val_loss: 9773840243.7260\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 11347243996.8714 - val_loss: 9663919889.5342\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 11196151515.5540 - val_loss: 9533516435.2877\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 11591685084.8714 - val_loss: 9420090522.3014\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11111586503.3551 - val_loss: 9310669431.2329\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 11187858345.9348 - val_loss: 9190391296.0000\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 11135167795.3756 - val_loss: 9076924219.6164\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11062937758.9571 - val_loss: 8989928861.8082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10841515231.0669 - val_loss: 8874094746.3014\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10687270002.1681 - val_loss: 8778377461.4795\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10496734163.2110 - val_loss: 8666056339.2877\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10486065441.8113 - val_loss: 8551668644.8219\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10365124306.7719 - val_loss: 8452331562.0822\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10379839287.7667 - val_loss: 8357511055.7808\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10085257679.6981 - val_loss: 8267563064.1096\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10045463764.5283 - val_loss: 8174381154.1918\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10314917735.1904 - val_loss: 8081706411.8356\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9755051730.3328 - val_loss: 7992281256.3288\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9948557274.2367 - val_loss: 7901057851.6164\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9807576407.3825 - val_loss: 7807557533.8082\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9901058759.3551 - val_loss: 7718891442.8493\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9703233754.6758 - val_loss: 7628288652.2740\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9754409530.8405 - val_loss: 7548319295.1233\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9381649516.0206 - val_loss: 7468752292.8219\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9653378872.6449 - val_loss: 7386818966.7945\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9256245330.5523 - val_loss: 7304828138.9589\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9374317452.9537 - val_loss: 7225288465.5342\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9161403341.0635 - val_loss: 7159574549.0411\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9234699153.3448 - val_loss: 7097834068.1644\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9391784087.9314 - val_loss: 7018586048.8767\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9240517984.1647 - val_loss: 6958010908.0548\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9509545361.7839 - val_loss: 6885419214.9041\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8959103031.7667 - val_loss: 6824066482.8493\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8761786505.8799 - val_loss: 6764683183.3425\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9032673826.2504 - val_loss: 6700400489.2055\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9008240236.0206 - val_loss: 6645531209.6438\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9016081564.3225 - val_loss: 6595519403.8356\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9061674041.9623 - val_loss: 6540242011.1781\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8594953331.0463 - val_loss: 6492318902.3562\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8737483385.8525 - val_loss: 6452175773.8082\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8845573326.3808 - val_loss: 6407425753.4247\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 9205273879.2727 - val_loss: 6362703075.9452\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8697730073.4683 - val_loss: 6320030344.7671\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8160094999.2727 - val_loss: 6279097708.7123\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8620540293.9280 - val_loss: 6235886725.2603\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9073180150.3396 - val_loss: 6206978798.4658\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8314737969.6192 - val_loss: 6172126663.8904\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8665207127.3825 - val_loss: 6140304973.1507\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8724772990.4631 - val_loss: 6117489408.0000\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8365905672.3431 - val_loss: 6086796456.3288\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8734524493.2830 - val_loss: 6060753779.7260\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8662469919.1767 - val_loss: 6033696775.0137\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8522667837.0360 - val_loss: 6007336230.5753\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8478465994.4288 - val_loss: 5978473096.7671\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8669282551.6569 - val_loss: 5963055324.9315\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8099159900.2127 - val_loss: 5945626624.0000\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8552576881.7290 - val_loss: 5928440474.3014\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8291448594.8816 - val_loss: 5902625883.1781\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8155819864.2607 - val_loss: 5880631906.1918\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8477613610.1544 - val_loss: 5871312594.4110\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8650260554.6484 - val_loss: 5857618898.4110\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8554726445.6672 - val_loss: 5845505283.5068\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8706443630.2161 - val_loss: 5838775152.2192\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9201772529.9485 - val_loss: 5829159280.2192\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8695618161.2899 - val_loss: 5818487786.9589\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8587147701.3516 - val_loss: 5810401272.9863\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8299004722.4974 - val_loss: 5798149814.3562\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8739488393.8799 - val_loss: 5787737943.6712\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8843848226.2504 - val_loss: 5778679246.9041\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8357784549.2144 - val_loss: 5770793345.7534\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8549117158.0926 - val_loss: 5765846373.6986\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8747956467.7050 - val_loss: 5755383727.3425\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8574077192.3431 - val_loss: 5751328059.6164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8293653279.1767 - val_loss: 5744181191.8904\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8364232336.0274 - val_loss: 5739708430.0274\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8263171126.4494 - val_loss: 5737055274.0822\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8424147893.3516 - val_loss: 5731261475.0685\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8414091042.6895 - val_loss: 5725731555.9452\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8497819676.1029 - val_loss: 5721270864.6575\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8756380856.4254 - val_loss: 5718914517.9178\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8087559973.7633 - val_loss: 5714502410.5205\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8384404277.1321 - val_loss: 5709021899.3973\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8364557186.8542 - val_loss: 5702411225.4247\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8591454925.5026 - val_loss: 5701106516.1644\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8218802471.0806 - val_loss: 5698596204.7123\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8107484850.2779 - val_loss: 5695413349.6986\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8542956839.0806 - val_loss: 5692937244.0548\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8184452514.0309 - val_loss: 5689644389.6986\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8223464225.8113 - val_loss: 5690419645.3699\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8142013098.3739 - val_loss: 5688918513.9726\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8345095589.1046 - val_loss: 5682624336.6575\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8257802277.7633 - val_loss: 5676719854.4658\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8402700447.3962 - val_loss: 5675662700.7123\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8455594399.8353 - val_loss: 5676333764.3836\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8394766773.3516 - val_loss: 5674307934.6849\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8094488287.0669 - val_loss: 5673451583.1233\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8197064969.2213 - val_loss: 5673448760.1096\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8467639395.2384 - val_loss: 5672647027.7260\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8394310369.4820 - val_loss: 5668853388.2740\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8255736196.1715 - val_loss: 5667432363.8356\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8460275329.0978 - val_loss: 5664948616.7671\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8517574267.8285 - val_loss: 5665013973.9178\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 7986775846.2024 - val_loss: 5666836886.7945\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8689550784.7684 - val_loss: 5669471484.4932\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8600127219.2659 - val_loss: 5668198687.5616\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8860781593.9074 - val_loss: 5669879569.5342\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8080342451.5952 - val_loss: 5666817974.3562\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8669117507.1835 - val_loss: 5663714724.8219\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8614130628.2813 - val_loss: 5663383608.1096\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8349201149.8045 - val_loss: 5660032673.3151\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8507469764.2813 - val_loss: 5656610556.4932\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8533817320.2882 - val_loss: 5658330974.6849\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8738747583.8902 - val_loss: 5661289479.0137\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8622702989.8319 - val_loss: 5660936367.3425\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8613198602.9777 - val_loss: 5660431272.3288\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8312354666.2642 - val_loss: 5658475562.0822\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8582722557.3654 - val_loss: 5659509563.6164\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8241346093.2281 - val_loss: 5658248248.1096\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8581850793.4957 - val_loss: 5656780996.3836\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8435388982.4494 - val_loss: 5656812789.4795\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8751607675.8285 - val_loss: 5659317672.3288\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8659660172.9537 - val_loss: 5661280445.3699\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8496506022.4220 - val_loss: 5663821315.5068\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8693604733.1458 - val_loss: 5664582670.0274\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8368579591.0257 - val_loss: 5662276018.8493\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8207070330.0720 - val_loss: 5665113014.3562\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8414118015.3413 - val_loss: 5660697298.4110\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8498434936.7547 - val_loss: 5660385455.3425\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8658159844.3362 - val_loss: 5658689346.6301\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8219473605.5986 - val_loss: 5658872614.5753\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8724674565.2693 - val_loss: 5659227220.1644\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8379064818.8268 - val_loss: 5658984237.5890\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8352636504.6998 - val_loss: 5658923463.8904\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8402308780.1304 - val_loss: 5660458625.7534\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8711488092.2127 - val_loss: 5659553865.6438\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8931161957.4340 - val_loss: 5658660899.0685\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8710239702.7238 - val_loss: 5656229109.4795\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8300574957.9966 - val_loss: 5654249675.3973\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 152us/step - loss: 8374234148.0069 - val_loss: 5651265248.4384\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8482685578.7581 - val_loss: 5649322327.6712\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8260305601.2075 - val_loss: 5650831549.3699\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8481895509.1870 - val_loss: 5652073640.3288\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8477294860.7341 - val_loss: 5652412437.0411\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8241463442.6621 - val_loss: 5652143026.8493\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8362272755.7050 - val_loss: 5654527624.7671\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8112826334.6278 - val_loss: 5652696249.8630\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8286348572.5420 - val_loss: 5653733526.7945\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8483461996.0206 - val_loss: 5653800433.9726\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8682273662.9022 - val_loss: 5658969831.4521\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8618805755.6089 - val_loss: 5661060923.6164\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8794564355.8422 - val_loss: 5659686968.1096\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8563904999.8491 - val_loss: 5662804248.5479\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8574394144.9331 - val_loss: 5664838133.4795\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8940556144.8508 - val_loss: 5662891723.3973\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8247768345.0292 - val_loss: 5665064223.5616\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8837286464.9880 - val_loss: 5663259146.5205\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8585113788.8165 - val_loss: 5665084198.5753\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8790686852.1715 - val_loss: 5662178419.7260\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8315111532.0206 - val_loss: 5657901638.1370\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8706562517.4065 - val_loss: 5659500782.4658\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8658221266.7719 - val_loss: 5659847231.1233\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8127421494.4494 - val_loss: 5659713711.3425\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8275534634.5935 - val_loss: 5660205887.1233\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8371064719.5883 - val_loss: 5658807646.6849\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 7913603190.5592 - val_loss: 5660364673.7534\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8284292746.7581 - val_loss: 5660751451.1781\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8511824372.5832 - val_loss: 5662368666.3014\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8642633013.1321 - val_loss: 5663567879.0137\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8199379876.6655 - val_loss: 5663134127.3425\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8674120601.6878 - val_loss: 5660931584.0000\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8793491945.1664 - val_loss: 5660364673.7534\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8362719392.7136 - val_loss: 5659862675.2877\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8339708079.6432 - val_loss: 5659948985.8630\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8363665946.3465 - val_loss: 5657273898.0822\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8782649698.3602 - val_loss: 5659269512.7671\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8536254380.5695 - val_loss: 5660830972.4932\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8482477953.5369 - val_loss: 5660226083.0685\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8576379180.3499 - val_loss: 5658612546.6301\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8276969976.0961 - val_loss: 5658096057.8630\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8524269694.4631 - val_loss: 5657711889.5342\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8166413803.8010 - val_loss: 5656336124.4932\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8617321515.0326 - val_loss: 5659371316.6027\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8615579660.2950 - val_loss: 5657197778.4110\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8469903114.5386 - val_loss: 5658837826.6301\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8480865237.8456 - val_loss: 5657164582.5753\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8211484994.7444 - val_loss: 5651916617.6438\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8175417654.8885 - val_loss: 5652783721.2055\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8256956997.3791 - val_loss: 5651006758.5753\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8370017929.4408 - val_loss: 5649809737.6438\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8408738015.0669 - val_loss: 5646985580.7123\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8354700014.8748 - val_loss: 5646863205.6986\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8197744978.5523 - val_loss: 5644764864.8767\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8540728348.9811 - val_loss: 5643117473.3151\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8506885620.1441 - val_loss: 5641473914.7397\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8650435210.7581 - val_loss: 5641095890.4110\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8648139508.1441 - val_loss: 5644357295.3425\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8519971838.2436 - val_loss: 5646023585.3151\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8098025953.2624 - val_loss: 5644701608.3288\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8541502338.4151 - val_loss: 5646014646.3562\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8754144690.7170 - val_loss: 5647299079.0137\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8828685127.1355 - val_loss: 5646145476.3836\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8170451261.0360 - val_loss: 5645892586.9589\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8665914027.2521 - val_loss: 5648154147.0685\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 159us/step - loss: 8135153711.4237 - val_loss: 5646232576.0000\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8558389567.6707 - val_loss: 5647855132.0548\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8147624928.3842 - val_loss: 5648290391.6712\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8853179192.6449 - val_loss: 5651796771.0685\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8479113363.1012 - val_loss: 5651386595.9452\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8329141202.3328 - val_loss: 5651802308.3836\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8345525649.3448 - val_loss: 5654906711.6712\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8406887970.2504 - val_loss: 5653878047.5616\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8117865365.7358 - val_loss: 5651376057.8630\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8622338574.9297 - val_loss: 5655190373.6986\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8381284279.9863 - val_loss: 5652288252.4932\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8454565965.2830 - val_loss: 5652349145.4247\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8339881558.0652 - val_loss: 5651146752.0000\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8696920871.9588 - val_loss: 5651141831.8904\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8594308227.7324 - val_loss: 5653869771.3973\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8305648442.8405 - val_loss: 5653543160.9863\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8382141834.3190 - val_loss: 5652442627.5068\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8393076714.9228 - val_loss: 5653338785.3151\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8848787619.3482 - val_loss: 5653965080.5479\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8586477172.8027 - val_loss: 5654463375.7808\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8565490850.4700 - val_loss: 5654632781.1507\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8126826625.0978 - val_loss: 5656510306.1918\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8261681554.2230 - val_loss: 5658879831.6712\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8342111545.5232 - val_loss: 5659744224.4384\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8620808000.1098 - val_loss: 5658237089.3151\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8359047525.4340 - val_loss: 5657183431.8904\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8035076368.2470 - val_loss: 5655209472.0000\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8403035239.6295 - val_loss: 5654001481.6438\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8367470019.4031 - val_loss: 5654644918.3562\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8501625033.9897 - val_loss: 5654057289.6438\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8372209563.8834 - val_loss: 5650549255.0137\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8538331795.5403 - val_loss: 5652727250.4110\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8327619181.7770 - val_loss: 5655047574.7945\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8279743010.2504 - val_loss: 5654448583.8904\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8550531940.5557 - val_loss: 5652876428.2740\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8759755960.4254 - val_loss: 5654628337.9726\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8264802858.1544 - val_loss: 5653852826.3014\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8912429408.6038 - val_loss: 5653796295.8904\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8521640614.4220 - val_loss: 5653804456.3288\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8787021596.5420 - val_loss: 5655925240.9863\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8125381673.7153 - val_loss: 5655393651.7260\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8387737862.5866 - val_loss: 5657047860.6027\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8396501339.3345 - val_loss: 5655777651.7260\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8464902713.9623 - val_loss: 5658508870.1370\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8410230387.0463 - val_loss: 5657022495.5616\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8761397073.2350 - val_loss: 5658272108.7123\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8401269273.4683 - val_loss: 5658307678.6849\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8564093798.3122 - val_loss: 5658358075.6164\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8513683569.7290 - val_loss: 5661282265.4247\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8331495476.6930 - val_loss: 5660547713.7534\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8217934699.5815 - val_loss: 5661547239.4521\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8552830485.9554 - val_loss: 5662525850.3014\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8467885351.9588 - val_loss: 5662637469.8082\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8871955131.0600 - val_loss: 5661821092.8219\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8744039563.6364 - val_loss: 5663212344.1096\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8559174354.3328 - val_loss: 5664793059.9452\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8477591544.5352 - val_loss: 5662612515.0685\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8833356744.6724 - val_loss: 5662306759.8904\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8584821788.1029 - val_loss: 5664904493.5890\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8202525232.3019 - val_loss: 5663209910.3562\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7948493434.9503 - val_loss: 5662504956.4932\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8473105108.0892 - val_loss: 5665331887.3425\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8503115315.8148 - val_loss: 5666496925.8082\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8580279418.0720 - val_loss: 5668239794.8493\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8361210749.1458 - val_loss: 5665712120.9863\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 154us/step - loss: 8224283354.6758 - val_loss: 5666474650.3014\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8579883428.6655 - val_loss: 5661452361.6438\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8720594998.4494 - val_loss: 5662071646.6849\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8104943769.2487 - val_loss: 5660064220.9315\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8829827523.4031 - val_loss: 5660807616.8767\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8466244177.6741 - val_loss: 5657749945.8630\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8440904844.5146 - val_loss: 5659265202.8493\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8467437043.7050 - val_loss: 5661213562.7397\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8375824640.0000 - val_loss: 5662464280.5479\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8550111527.0806 - val_loss: 5662141159.4521\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8233079077.3242 - val_loss: 5660124075.8356\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8642843552.2744 - val_loss: 5659038660.3836\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8256730269.2007 - val_loss: 5659816216.5479\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8772182796.7341 - val_loss: 5660866076.0548\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8501040452.9400 - val_loss: 5658194133.9178\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8786044585.4957 - val_loss: 5658939819.8356\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8267581276.2127 - val_loss: 5660755112.3288\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8882046853.9280 - val_loss: 5661675884.7123\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8487103482.7307 - val_loss: 5660793435.1781\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8087210519.7118 - val_loss: 5658680733.8082\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8380547026.3328 - val_loss: 5656181598.6849\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8498588586.8130 - val_loss: 5655751869.3699\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8376664787.6501 - val_loss: 5658313749.0411\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8542781814.9983 - val_loss: 5657510175.5616\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8102684475.2796 - val_loss: 5657636688.6575\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8491674713.5780 - val_loss: 5655310076.4932\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8654956696.8096 - val_loss: 5654495161.8630\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8445705880.8096 - val_loss: 5653279824.6575\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8465021815.8765 - val_loss: 5652277994.9589\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8319251872.7136 - val_loss: 5650112448.8767\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8335078721.4271 - val_loss: 5649064349.8082\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8920343378.1132 - val_loss: 5647334063.3425\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8735153865.1115 - val_loss: 5648073742.0274\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 7856950144.6587 - val_loss: 5649125172.6027\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8175580620.1852 - val_loss: 5648094642.8493\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8746937692.6518 - val_loss: 5648869880.9863\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8449556439.6021 - val_loss: 5649742763.8356\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8014536506.4014 - val_loss: 5651264105.2055\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8607133253.3791 - val_loss: 5650407760.6575\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8432390588.3774 - val_loss: 5654012752.6575\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8392707645.9142 - val_loss: 5650972798.2466\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8552552866.4700 - val_loss: 5651681346.6301\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8225844850.1681 - val_loss: 5651946692.3836\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8465722437.3791 - val_loss: 5653707330.6301\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8891053533.7496 - val_loss: 5653642047.1233\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8593765934.5455 - val_loss: 5650013611.8356\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8539088552.6175 - val_loss: 5645531704.1096\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8242907385.4134 - val_loss: 5647465303.6712\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8411176923.1149 - val_loss: 5648898889.6438\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8318190680.6998 - val_loss: 5649470579.7260\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8612203393.5369 - val_loss: 5648037852.9315\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8210432948.4734 - val_loss: 5646452890.3014\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8644051247.8628 - val_loss: 5648275719.0137\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8110895473.7290 - val_loss: 5646562991.3425\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8787677885.6947 - val_loss: 5650223805.3699\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8803285610.2642 - val_loss: 5653891548.9315\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8483377527.8765 - val_loss: 5652843327.1233\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8297378536.7273 - val_loss: 5652049685.0411\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8159582395.0600 - val_loss: 5654846204.4932\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8699376246.5592 - val_loss: 5656457009.0959\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8597136852.0892 - val_loss: 5655096312.9863\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8289985607.1355 - val_loss: 5653824504.9863\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8433370110.2436 - val_loss: 5652453698.6301\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8645541738.7033 - val_loss: 5655040890.7397\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8529499947.0326 - val_loss: 5655076488.7671\n",
      "Epoch 569/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 8155314572.9537 - val_loss: 5655544172.7123\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8513154622.3533 - val_loss: 5653434206.6849\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8601786174.7925 - val_loss: 5655393150.2466\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8535734349.2830 - val_loss: 5651324177.5342\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8354889626.1269 - val_loss: 5651258676.6027\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8105480240.3019 - val_loss: 5652335082.9589\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8778417005.3379 - val_loss: 5652823923.7260\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8296309227.8010 - val_loss: 5655088846.9041\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8129069423.9726 - val_loss: 5652314140.0548\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 7976831490.6346 - val_loss: 5651449045.9178\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 7827025782.9983 - val_loss: 5649131264.0000\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8116964531.1561 - val_loss: 5648187988.1644\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8475997066.3190 - val_loss: 5648638435.9452\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8438831577.3585 - val_loss: 5649091352.5479\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8489907038.4082 - val_loss: 5649009769.2055\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8530360201.8799 - val_loss: 5648484267.8356\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8442791164.9262 - val_loss: 5648744917.9178\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8369338776.3705 - val_loss: 5649687306.5205\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8206743606.4494 - val_loss: 5650752666.3014\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8421611534.0515 - val_loss: 5651550464.0000\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8632418649.1389 - val_loss: 5650772795.6164\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8493270902.5592 - val_loss: 5650574188.7123\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8231264972.1852 - val_loss: 5649582493.8082\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8305327461.4340 - val_loss: 5649872903.0137\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8485321746.4425 - val_loss: 5651544733.8082\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8527231875.2933 - val_loss: 5649151498.5205\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8383486283.0875 - val_loss: 5649010631.8904\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8133876537.5232 - val_loss: 5648097329.0959\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8489330622.5729 - val_loss: 5648600421.6986\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8153152119.6569 - val_loss: 5649696112.2192\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8203380426.8679 - val_loss: 5648731311.3425\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8412742747.3345 - val_loss: 5647738343.4521\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8006491397.7084 - val_loss: 5645744710.1370\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8544922174.3533 - val_loss: 5650556913.9726\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8548676867.9520 - val_loss: 5650323652.3836\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8463854523.4991 - val_loss: 5651376899.5068\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8125652631.9314 - val_loss: 5649165978.3014\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8485286557.2007 - val_loss: 5647562639.7808\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8274410656.2744 - val_loss: 5646860859.6164\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8626308448.1647 - val_loss: 5643905171.2877\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8460149320.0137 - val_loss: 5645042603.8356\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8308909441.5369 - val_loss: 5645998521.8630\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8510167995.4991 - val_loss: 5648240924.0548\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8601463709.6398 - val_loss: 5646386158.4658\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8111158402.8542 - val_loss: 5642025654.3562\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8225375129.2487 - val_loss: 5642827677.8082\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8772449597.0360 - val_loss: 5643110182.5753\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8565224658.7719 - val_loss: 5644454498.1918\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8366429751.3276 - val_loss: 5644576150.7945\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8300172427.6364 - val_loss: 5644284619.3973\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8354636195.7873 - val_loss: 5643184913.5342\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8498489393.1801 - val_loss: 5643017819.1781\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8203083224.0412 - val_loss: 5642079989.4795\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8268969204.1441 - val_loss: 5639173176.1096\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8346453422.3259 - val_loss: 5637395880.3288\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8422481087.4511 - val_loss: 5636049029.2603\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8415807336.9468 - val_loss: 5638896822.3562\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8461864538.4563 - val_loss: 5640391034.7397\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9069292698.1269 - val_loss: 5640608122.7397\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8409203343.1492 - val_loss: 5642215143.4521\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8373281372.2127 - val_loss: 5646478686.6849\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8854615211.2521 - val_loss: 5648426587.1781\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8115552185.7427 - val_loss: 5652466474.0822\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8731825340.8165 - val_loss: 5651015680.0000\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9031951077.2144 - val_loss: 5655840483.9452\n",
      "Epoch 634/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 8004505916.1578 - val_loss: 5657848474.3014\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8212921808.5763 - val_loss: 5657339781.2603\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8332863776.9331 - val_loss: 5655283932.9315\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8315124552.4528 - val_loss: 5654728325.2603\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8707934395.9382 - val_loss: 5654679338.0822\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8588399946.2093 - val_loss: 5653151807.1233\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8563128091.6638 - val_loss: 5651589828.3836\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8409737268.6930 - val_loss: 5651434678.3562\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8392380647.8491 - val_loss: 5654007131.1781\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8380683607.3825 - val_loss: 5655196188.0548\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8777395967.5609 - val_loss: 5656129700.8219\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8135337471.1218 - val_loss: 5658180629.0411\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8359245293.1184 - val_loss: 5655222419.2877\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8410182490.8954 - val_loss: 5654465609.6438\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8502491071.4511 - val_loss: 5653620378.3014\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 240us/step - loss: 8332741014.6141 - val_loss: 5653736405.9178\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 275us/step - loss: 8412780096.5489 - val_loss: 5655312706.6301\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 362us/step - loss: 8166675170.5798 - val_loss: 5658309274.3014\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 356us/step - loss: 8536370277.8731 - val_loss: 5657122942.2466\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 335us/step - loss: 8332004671.2316 - val_loss: 5655350952.3288\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 336us/step - loss: 8114316685.8319 - val_loss: 5654219092.1644\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 337us/step - loss: 8220830219.8559 - val_loss: 5650545036.2740\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 338us/step - loss: 8376900190.8473 - val_loss: 5652262035.2877\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 331us/step - loss: 8300445966.4906 - val_loss: 5650733490.8493\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 340us/step - loss: 8703384458.3190 - val_loss: 5649233113.4247\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 328us/step - loss: 8571217219.1835 - val_loss: 5649955917.1507\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 322us/step - loss: 8503112069.0497 - val_loss: 5646700231.8904\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 422us/step - loss: 8239179490.5798 - val_loss: 5645495825.5342\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 335us/step - loss: 8417877033.7153 - val_loss: 5644941010.4110\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 298us/step - loss: 8856755805.0909 - val_loss: 5645479869.3699\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 299us/step - loss: 8128297444.7753 - val_loss: 5643378274.1918\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 289us/step - loss: 8222856870.8611 - val_loss: 5642287468.7123\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 272us/step - loss: 8334323669.8456 - val_loss: 5645008573.3699\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 293us/step - loss: 8795289192.5077 - val_loss: 5647314558.2466\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 274us/step - loss: 8313805569.7564 - val_loss: 5646797873.0959\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 293us/step - loss: 8821397200.1372 - val_loss: 5649187194.7397\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 270us/step - loss: 8391122499.6226 - val_loss: 5648544301.5890\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 8328152461.8319 - val_loss: 5645092618.5205\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 8617261781.4065 - val_loss: 5646424137.6438\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 8481621353.8250 - val_loss: 5645231209.2055\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 8485458099.1561 - val_loss: 5645015944.7671\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 8237322240.0000 - val_loss: 5643431248.6575\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 8857106576.0274 - val_loss: 5644163110.5753\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 8275137567.6158 - val_loss: 5646997290.0822\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 225us/step - loss: 8628030771.3756 - val_loss: 5649852973.5890\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8555986529.4820 - val_loss: 5649166479.7808\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8543378386.3328 - val_loss: 5649396707.9452\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 8508234502.5866 - val_loss: 5651999586.1918\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 8340768293.7633 - val_loss: 5652499911.8904\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8289604701.0909 - val_loss: 5652685708.2740\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8460277951.4511 - val_loss: 5653439659.8356\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8553532991.2316 - val_loss: 5653182502.5753\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8416409944.2607 - val_loss: 5654444305.5342\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 8367586318.0515 - val_loss: 5655357138.4110\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 8323859131.0600 - val_loss: 5655021378.6301\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8153947791.1492 - val_loss: 5651279086.4658\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 8449392556.1304 - val_loss: 5653797105.9726\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 8292112215.3825 - val_loss: 5654147598.0274\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 8127310714.5111 - val_loss: 5654499468.2740\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 8455075949.7770 - val_loss: 5651951363.5068\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 8372707892.6930 - val_loss: 5652207293.3699\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 233us/step - loss: 8512981979.5540 - val_loss: 5651711424.8767\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8446950408.7822 - val_loss: 5652473547.3973\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8676986067.2110 - val_loss: 5651477784.5479\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 8384638034.5523 - val_loss: 5651505541.2603\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 210us/step - loss: 7771555804.8714 - val_loss: 5648027483.1781\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8536625267.0463 - val_loss: 5647862791.0137\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8263616043.9108 - val_loss: 5648964183.6712\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8300997069.9417 - val_loss: 5650399933.3699\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8525230076.4871 - val_loss: 5651270613.9178\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8410465617.6741 - val_loss: 5651050927.3425\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8616233747.7599 - val_loss: 5651897077.4795\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8622792540.6518 - val_loss: 5653014815.5616\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8755543847.5197 - val_loss: 5655974813.8082\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8553800049.7290 - val_loss: 5657299231.5616\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8813215519.6158 - val_loss: 5658772550.1370\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 7826946333.4202 - val_loss: 5653456264.7671\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8531646500.0069 - val_loss: 5654119613.3699\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8664055707.8834 - val_loss: 5655334259.7260\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8441233626.6758 - val_loss: 5653085913.4247\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8294831451.3345 - val_loss: 5652134975.1233\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8089804035.9520 - val_loss: 5648823513.4247\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8308369869.5026 - val_loss: 5649929671.8904\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8845425271.4374 - val_loss: 5651076334.4658\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8408984479.8353 - val_loss: 5649339967.1233\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8189318086.9160 - val_loss: 5646935194.3014\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 7889236252.5420 - val_loss: 5648656124.4932\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8743972529.3997 - val_loss: 5648344779.3973\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8230469389.6123 - val_loss: 5649090318.0274\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8196659472.2470 - val_loss: 5648958365.8082\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8459061450.4288 - val_loss: 5645668790.3562\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8497631643.0051 - val_loss: 5645001415.8904\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8835047161.4134 - val_loss: 5647066062.9041\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 8144473289.1115 - val_loss: 5648082151.4521\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8199698375.7942 - val_loss: 5648086538.5205\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8872634420.6930 - val_loss: 5649684122.3014\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 8493368358.6415 - val_loss: 5650641499.1781\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 8828176593.0154 - val_loss: 5654017143.2329\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8563382454.6690 - val_loss: 5653736854.7945\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8655550764.3499 - val_loss: 5654458620.4932\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 8516527448.2607 - val_loss: 5655774351.7808\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8283603617.5918 - val_loss: 5652215513.4247\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 8329471513.4683 - val_loss: 5653451986.4110\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8393372088.8645 - val_loss: 5652487722.0822\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 8252017284.6106 - val_loss: 5650790876.9315\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8497999454.8473 - val_loss: 5652650846.6849\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8498650983.1904 - val_loss: 5651573777.5342\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8508228967.1904 - val_loss: 5651074714.3014\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8518733027.4580 - val_loss: 5652191470.4658\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 8420488861.2007 - val_loss: 5652947470.0274\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 8603412010.1544 - val_loss: 5654815224.9863\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8306489592.5352 - val_loss: 5655285777.5342\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8319841841.1801 - val_loss: 5656263448.5479\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 8433774204.7067 - val_loss: 5655419406.0274\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 8288062644.9125 - val_loss: 5655389120.8767\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8425844664.8645 - val_loss: 5654045015.6712\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 8729526140.2676 - val_loss: 5655986922.9589\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8492341060.9400 - val_loss: 5656008563.7260\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8211500786.3877 - val_loss: 5654828978.8493\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8272689694.7376 - val_loss: 5657043357.8082\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8263952375.2178 - val_loss: 5657339644.4932\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8501795985.7839 - val_loss: 5653724945.5342\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8591692179.9794 - val_loss: 5656017344.8767\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8404265140.0343 - val_loss: 5654969035.3973\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8431792426.5935 - val_loss: 5654647993.8630\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7855187487.6158 - val_loss: 5651757189.2603\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8578366389.3516 - val_loss: 5653226033.0959\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8720483616.0549 - val_loss: 5653882350.4658\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8204245868.4597 - val_loss: 5651568103.4521\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8162430714.2916 - val_loss: 5649947002.7397\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 162us/step - loss: 8708576985.7976 - val_loss: 5651579202.6301\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8539914655.3962 - val_loss: 5649215586.1918\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8330409099.6364 - val_loss: 5651984966.1370\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8428434987.0326 - val_loss: 5649249378.1918\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8394819492.6655 - val_loss: 5648962672.2192\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8238444724.9125 - val_loss: 5647782526.2466\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8491299754.8130 - val_loss: 5646193818.3014\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8449405198.4906 - val_loss: 5647747619.0685\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8414946421.6810 - val_loss: 5645854474.5205\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8361909038.9846 - val_loss: 5644771320.9863\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8467964474.8405 - val_loss: 5645833040.6575\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8168360011.5266 - val_loss: 5641991546.7397\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8469477876.1441 - val_loss: 5645133778.4110\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8586852203.5815 - val_loss: 5646210616.1096\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8075591528.9468 - val_loss: 5645253505.7534\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8505837534.6278 - val_loss: 5646723005.3699\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8524373482.9228 - val_loss: 5649094985.6438\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8129627663.8079 - val_loss: 5649934427.1781\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8428823984.9605 - val_loss: 5649285435.6164\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8360542215.0257 - val_loss: 5648645337.4247\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8577153847.7667 - val_loss: 5646783950.9041\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8437281463.5472 - val_loss: 5647298882.6301\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8331409932.2950 - val_loss: 5649505237.9178\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8352634102.7787 - val_loss: 5649216736.4384\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8404023668.3636 - val_loss: 5649209719.2329\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8477231854.8748 - val_loss: 5649613157.6986\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8627132497.2350 - val_loss: 5650121587.7260\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8221539928.6998 - val_loss: 5651053778.4110\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8275136127.3413 - val_loss: 5649675625.2055\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8287335907.0189 - val_loss: 5648606965.4795\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8519517649.4545 - val_loss: 5649931207.8904\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8504242238.3533 - val_loss: 5650165640.7671\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8651508458.9228 - val_loss: 5652482826.5205\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8676903881.5506 - val_loss: 5654248335.7808\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8574744720.9057 - val_loss: 5655605602.1918\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8540259590.3671 - val_loss: 5656059514.7397\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8615439451.3345 - val_loss: 5656213475.9452\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8470298269.2007 - val_loss: 5654589527.6712\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8578890997.0223 - val_loss: 5657170260.1644\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8510613246.6827 - val_loss: 5656847352.9863\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8427010115.6226 - val_loss: 5656194517.9178\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8837120764.0480 - val_loss: 5656725209.4247\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8298445618.4974 - val_loss: 5655019867.1781\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8311619078.1475 - val_loss: 5654196806.1370\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8346337153.5369 - val_loss: 5652940035.5068\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8429571642.8405 - val_loss: 5653480391.8904\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8395481360.2470 - val_loss: 5650929274.7397\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8242430557.5300 - val_loss: 5650336704.8767\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8276987735.3825 - val_loss: 5649075417.4247\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8470536110.3259 - val_loss: 5649924138.0822\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8585640804.5557 - val_loss: 5652165028.8219\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8426531215.5883 - val_loss: 5650840940.7123\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8346088637.6947 - val_loss: 5651075387.6164\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8250077602.0309 - val_loss: 5652807879.8904\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8519021373.0360 - val_loss: 5654199937.7534\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8353356024.9743 - val_loss: 5654106273.3151\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8511344760.3156 - val_loss: 5654176676.8219\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8247440133.7084 - val_loss: 5654846204.4932\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8677034811.2796 - val_loss: 5656472583.0137\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8588243218.8816 - val_loss: 5658519864.1096\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8180060038.8062 - val_loss: 5658974474.5205\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8253019701.5712 - val_loss: 5659037625.8630\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8574648101.3242 - val_loss: 5661398513.9726\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8756828203.0326 - val_loss: 5661497761.3151\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8073335074.6895 - val_loss: 5661025230.9041\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 164us/step - loss: 8507487365.4889 - val_loss: 5659705119.5616\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8595674726.7513 - val_loss: 5657955664.6575\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8810274318.9297 - val_loss: 5655552280.5479\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8046822619.5540 - val_loss: 5652688671.5616\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8666932798.3533 - val_loss: 5653995863.6712\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8182442550.4494 - val_loss: 5654672485.6986\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8590837504.4391 - val_loss: 5655953590.3562\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8482900296.0137 - val_loss: 5657897945.4247\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8566467616.4940 - val_loss: 5658086378.9589\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8710366167.6021 - val_loss: 5657996217.8630\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8717789506.3053 - val_loss: 5658797133.1507\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8257761580.3499 - val_loss: 5657211756.7123\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 9118774351.9177 - val_loss: 5660622058.9589\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8187754524.1029 - val_loss: 5663115074.6301\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8324933089.2624 - val_loss: 5661122882.6301\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8164301300.5832 - val_loss: 5660952421.6986\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8435057657.4134 - val_loss: 5662560564.6027\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8633645717.2967 - val_loss: 5662181130.5205\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8642405953.8662 - val_loss: 5662150333.3699\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8391747771.0600 - val_loss: 5661716781.5890\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8712619307.4717 - val_loss: 5664283567.3425\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8463190368.1647 - val_loss: 5665467918.0274\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8759765287.5197 - val_loss: 5665643989.9178\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8405731623.0806 - val_loss: 5663937220.3836\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8776688814.7650 - val_loss: 5664751935.1233\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8506159407.8628 - val_loss: 5663842493.3699\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8461473099.9657 - val_loss: 5661183018.0822\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8264940824.1509 - val_loss: 5658216370.8493\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8213281680.9057 - val_loss: 5659424620.7123\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8072386006.7238 - val_loss: 5657638645.4795\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8164820622.2710 - val_loss: 5658302954.9589\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8368823335.5197 - val_loss: 5656301476.8219\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8360649678.8199 - val_loss: 5656652361.6438\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8277841650.8268 - val_loss: 5656493168.2192\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8527690582.5043 - val_loss: 5654559807.1233\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8456720409.4683 - val_loss: 5656505442.1918\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8223558834.2779 - val_loss: 5654123050.0822\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8395151611.1698 - val_loss: 5655791272.3288\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8315302948.4460 - val_loss: 5655358365.8082\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8417436286.4631 - val_loss: 5654060561.5342\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8458863381.5163 - val_loss: 5653333809.0959\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8315942985.7702 - val_loss: 5654424870.5753\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8319579803.4443 - val_loss: 5657382259.7260\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8512846350.9297 - val_loss: 5655861454.9041\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8453873946.7856 - val_loss: 5660087997.3699\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8813890366.7925 - val_loss: 5660545336.1096\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8226202238.4631 - val_loss: 5659047778.1918\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8433477105.5094 - val_loss: 5656828423.0137\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8538855299.2933 - val_loss: 5657987801.4247\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8469313859.1835 - val_loss: 5657348341.4795\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8661249406.9022 - val_loss: 5657617955.0685\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8361512619.2521 - val_loss: 5655946769.5342\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8339677299.9245 - val_loss: 5653486823.4521\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8606110547.8696 - val_loss: 5653563739.1781\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8159383230.5729 - val_loss: 5649073881.4247\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8446085532.7616 - val_loss: 5647763438.4658\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8410868353.9760 - val_loss: 5648599723.8356\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8231238912.4391 - val_loss: 5648879216.2192\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8449970783.7256 - val_loss: 5651770297.8630\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8264060440.5901 - val_loss: 5652008419.9452\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8707920505.1938 - val_loss: 5651370885.2603\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8776323863.2727 - val_loss: 5652702846.2466\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8285990519.8765 - val_loss: 5651848546.1918\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8429196573.4202 - val_loss: 5651581464.5479\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8265391826.7719 - val_loss: 5653286059.8356\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 8103294192.6312 - val_loss: 5651775607.2329\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8405962978.5798 - val_loss: 5651908930.6301\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8404787470.9297 - val_loss: 5654663988.6027\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8662377163.7461 - val_loss: 5655401815.6712\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 8644793876.1990 - val_loss: 5653387264.0000\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8228088716.0755 - val_loss: 5652175731.7260\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8270467252.9125 - val_loss: 5651595025.5342\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8348211704.9743 - val_loss: 5649990887.4521\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8360274880.7684 - val_loss: 5650737011.7260\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8297879714.4700 - val_loss: 5651758304.4384\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8395523455.7804 - val_loss: 5650998236.9315\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8182068510.2985 - val_loss: 5650431968.4384\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8122728391.7942 - val_loss: 5646817686.7945\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8141401630.7376 - val_loss: 5643294011.6164\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8089036573.4202 - val_loss: 5643930069.9178\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8358427920.2470 - val_loss: 5644763633.9726\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 8791101221.3242 - val_loss: 5645824848.6575\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8807425345.4271 - val_loss: 5648256659.2877\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8354608329.9897 - val_loss: 5648766442.9589\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8289703717.3242 - val_loss: 5648522895.7808\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8448384265.2213 - val_loss: 5647775929.8630\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8162212498.6621 - val_loss: 5645344739.9452\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8441509433.0840 - val_loss: 5645681306.3014\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 7957472368.4117 - val_loss: 5644490541.5890\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8201392606.6278 - val_loss: 5642888721.5342\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8336451821.1184 - val_loss: 5643383246.9041\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8349173621.2419 - val_loss: 5644245475.9452\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8600770362.6209 - val_loss: 5644626081.3151\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8648625586.2779 - val_loss: 5644783391.5616\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8239553666.8542 - val_loss: 5643816160.4384\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8416436954.6758 - val_loss: 5644535162.7397\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8506782922.8679 - val_loss: 5645713078.3562\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8562896493.7770 - val_loss: 5648412805.2603\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8216803943.1904 - val_loss: 5644840644.3836\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8356526942.4082 - val_loss: 5644943942.1370\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8469036790.7787 - val_loss: 5645620588.7123\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8532735039.2316 - val_loss: 5645590131.7260\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8242764274.8268 - val_loss: 5646918564.8219\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8759494259.9245 - val_loss: 5647943921.9726\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8270932252.5420 - val_loss: 5644117595.1781\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8416302619.2247 - val_loss: 5644663078.5753\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8448485961.7702 - val_loss: 5642944736.4384\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8390965333.6261 - val_loss: 5643131136.0000\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8284009851.3894 - val_loss: 5642402121.6438\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8600760222.5180 - val_loss: 5645292263.4521\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8566707805.9691 - val_loss: 5646971662.0274\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8713886928.1372 - val_loss: 5649392931.0685\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8189378387.8696 - val_loss: 5646958725.2603\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8261863481.9623 - val_loss: 5648239721.2055\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8897302693.9828 - val_loss: 5647859547.1781\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8531591163.6089 - val_loss: 5647161414.1370\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8433602266.6758 - val_loss: 5646137315.9452\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8472789366.1201 - val_loss: 5647958622.6849\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8042642993.1801 - val_loss: 5647057148.4932\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8106094918.6964 - val_loss: 5645404896.4384\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8004019813.8731 - val_loss: 5641591576.5479\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8472980116.4185 - val_loss: 5642681119.5616\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8116077947.3894 - val_loss: 5644503734.3562\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8309514350.6552 - val_loss: 5645347086.0274\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8526430247.9588 - val_loss: 5645951992.9863\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8410005253.7084 - val_loss: 5648915185.9726\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8302208718.3808 - val_loss: 5648266299.6164\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8100607595.1424 - val_loss: 5646709030.5753\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8535082323.8696 - val_loss: 5648581723.1781\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8330099360.7136 - val_loss: 5647351590.5753\n",
      "Epoch 959/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 155us/step - loss: 8685833558.0652 - val_loss: 5647843731.2877\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8711950439.6295 - val_loss: 5646865835.8356\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 7995434956.1852 - val_loss: 5643366287.7808\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 7932158022.2573 - val_loss: 5643968732.9315\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 7975707742.8473 - val_loss: 5643204944.6575\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8380118856.4528 - val_loss: 5644098542.4658\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8584481209.7427 - val_loss: 5643752819.7260\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8488498389.4065 - val_loss: 5647239722.0822\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8145540858.2916 - val_loss: 5648703470.4658\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8783511241.1115 - val_loss: 5649079141.6986\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8372862294.5043 - val_loss: 5649537325.5890\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8436062795.5266 - val_loss: 5650696675.9452\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8358810613.4614 - val_loss: 5650238874.3014\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8639757137.2350 - val_loss: 5651259293.8082\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8755429101.1184 - val_loss: 5653309934.4658\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8448948746.5386 - val_loss: 5653448156.9315\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8851707008.2196 - val_loss: 5655640807.4521\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8237564263.1904 - val_loss: 5653058651.1781\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8196375191.0532 - val_loss: 5654501930.0822\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8372828801.0978 - val_loss: 5657567779.0685\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8907079611.4991 - val_loss: 5658065239.6712\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8517782403.2933 - val_loss: 5655778072.5479\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8602357084.6518 - val_loss: 5656577781.4795\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8125252442.8954 - val_loss: 5653736405.9178\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8349044918.6690 - val_loss: 5653914757.2603\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8166246972.5969 - val_loss: 5650378299.6164\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8140449075.3756 - val_loss: 5650775643.1781\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8702341365.9005 - val_loss: 5651748323.9452\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8163735834.7856 - val_loss: 5650303025.0959\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8344702515.8148 - val_loss: 5651065912.1096\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8742036561.2350 - val_loss: 5652156472.1096\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8473604146.4974 - val_loss: 5651662392.1096\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8428631740.8165 - val_loss: 5649940013.5890\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8827913850.9503 - val_loss: 5652541734.5753\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8406733362.4974 - val_loss: 5649850599.4521\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8458821417.7153 - val_loss: 5649052587.8356\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8488560311.5472 - val_loss: 5648506992.2192\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8299274607.9726 - val_loss: 5649041713.0959\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8488065939.1012 - val_loss: 5647162613.4795\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8427990153.0017 - val_loss: 5649522877.3699\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8238603825.1801 - val_loss: 5648132488.7671\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8600644477.1458 - val_loss: 5647696675.0685\n",
      "neurons used (32, 8)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 559us/step - loss: 39209810538.2641 - val_loss: 38416807262.6849\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 39208126776.6449 - val_loss: 38413628626.4110\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 39205513711.3139 - val_loss: 38415058130.4110\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 39202239644.3225 - val_loss: 38412177716.6027\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39198099276.8439 - val_loss: 38403364330.9589\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 39193110524.4871 - val_loss: 38400214310.5753\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 39186946037.4614 - val_loss: 38394706424.9863\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 39181013547.0326 - val_loss: 38389324701.8082\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39174227978.5386 - val_loss: 38379898290.8493\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 39165256463.3688 - val_loss: 38370080431.3425\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39156720536.3705 - val_loss: 38359675918.0274\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 39147144225.3722 - val_loss: 38353325659.1781\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 39137065616.9057 - val_loss: 38344880071.8904\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 39124225478.9159 - val_loss: 38330710436.8219\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39113310626.0309 - val_loss: 38318395616.4384\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 39099915114.7033 - val_loss: 38306569286.1370\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 39086814041.1389 - val_loss: 38292172575.5616\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 39074987547.2247 - val_loss: 38278296646.1370\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 39062560578.3053 - val_loss: 38259985983.1233\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 244us/step - loss: 39042774734.3808 - val_loss: 38243496244.6027\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 304us/step - loss: 39027769800.6724 - val_loss: 38229617397.4795\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 339us/step - loss: 39011884796.0480 - val_loss: 38214123491.9452\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 363us/step - loss: 38989637431.7667 - val_loss: 38187578241.7534\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 370us/step - loss: 38973357215.8353 - val_loss: 38169669155.0685\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 374us/step - loss: 38948062722.6346 - val_loss: 38147949610.0822\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 369us/step - loss: 38936408169.3859 - val_loss: 38128230371.9452\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 354us/step - loss: 38907656869.9828 - val_loss: 38110706898.4110\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 345us/step - loss: 38887296180.9125 - val_loss: 38087739672.5479\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 326us/step - loss: 38874792023.8216 - val_loss: 38065422364.0548\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 321us/step - loss: 38840346353.5094 - val_loss: 38043768270.9041\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 293us/step - loss: 38819847777.4820 - val_loss: 38016801637.6986\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 294us/step - loss: 38794450371.4031 - val_loss: 37990130281.2055\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 302us/step - loss: 38771499338.2093 - val_loss: 37964995036.9315\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 279us/step - loss: 38732009760.0549 - val_loss: 37934219264.0000\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 283us/step - loss: 38712744838.8062 - val_loss: 37905644501.9178\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 38681273310.6278 - val_loss: 37876986781.8082\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 270us/step - loss: 38661914676.6930 - val_loss: 37852749936.2192\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 253us/step - loss: 38635140744.1235 - val_loss: 37824032711.8904\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 274us/step - loss: 38586308235.6364 - val_loss: 37789910787.5069\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 38569008519.6844 - val_loss: 37760307087.7808\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 38542394503.2453 - val_loss: 37727671843.0685\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 262us/step - loss: 38518844867.4031 - val_loss: 37694709760.0000\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 38474155817.7153 - val_loss: 37662164739.5069\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 38433275464.8919 - val_loss: 37629182485.0411\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 253us/step - loss: 38376030622.5180 - val_loss: 37596807560.7671\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 38372370990.5454 - val_loss: 37555857351.8904\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 38323829631.7804 - val_loss: 37523970524.9315\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 38313883855.2590 - val_loss: 37484796549.2603\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 38260331318.0103 - val_loss: 37446239947.3973\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 38219559993.9623 - val_loss: 37406468937.6438\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 38189141201.0154 - val_loss: 37363116957.8082\n",
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 38127355914.5386 - val_loss: 37326086817.3151\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 38104122187.0875 - val_loss: 37282399442.4110\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 38059867654.1475 - val_loss: 37245781426.8493\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 38019618264.4803 - val_loss: 37203706389.0411\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 37988096860.6518 - val_loss: 37160517575.8904\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 37941366488.9194 - val_loss: 37115148456.3288\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 37897046363.7736 - val_loss: 37071897922.6301\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 37870255843.4580 - val_loss: 37024890992.2192\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 37827317408.7136 - val_loss: 36980601505.3151\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 37777835596.4048 - val_loss: 36930295779.9452\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 37719735793.0703 - val_loss: 36876373118.2466\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 37656706165.6810 - val_loss: 36832004657.0959\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 37658840701.5849 - val_loss: 36791642140.0548\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 37577195263.5609 - val_loss: 36740006280.7671\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 37542699352.2607 - val_loss: 36692642072.5479\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 37515770368.8782 - val_loss: 36645780886.7945\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 37419732050.5523 - val_loss: 36590201252.8219\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 37383144161.7015 - val_loss: 36542977907.7260\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 37318710582.8885 - val_loss: 36476901460.1644\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 37280979565.7770 - val_loss: 36424175503.7808\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 37222768766.4631 - val_loss: 36372127800.1096\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 37150561323.9108 - val_loss: 36313760192.8767\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 225us/step - loss: 37065112047.3139 - val_loss: 36255326937.4247\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 36998248325.0497 - val_loss: 36203265571.0685\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 36980744237.6672 - val_loss: 36148513749.9178\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 36952500733.3654 - val_loss: 36080943019.8356\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 36899666998.4494 - val_loss: 36032111545.8630\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 36830993838.3259 - val_loss: 35967093549.5890\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 36771781124.3911 - val_loss: 35916446481.5342\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 36725812418.9640 - val_loss: 35859843352.5479\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 36647900491.9657 - val_loss: 35796579145.6438\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 36588615989.1321 - val_loss: 35728113607.8904\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 36548142773.7907 - val_loss: 35670223324.9315\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 36385953510.9708 - val_loss: 35605822169.4247\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 36418764146.6072 - val_loss: 35553601451.8356\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 188us/step - loss: 36324391189.5163 - val_loss: 35486548332.7123\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 36260356896.9331 - val_loss: 35420959393.3151\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 36186134113.4820 - val_loss: 35345765053.3699\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 36161780393.4957 - val_loss: 35286678205.3699\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 36039421607.7393 - val_loss: 35215772152.9863\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 36050211926.0652 - val_loss: 35143674080.4384\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 36019099258.0720 - val_loss: 35075200939.8356\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 35936266900.4185 - val_loss: 35013683340.2740\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 35841067938.9091 - val_loss: 34945401701.6986\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 35671757910.0652 - val_loss: 34872379840.8767\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 35558067113.9348 - val_loss: 34799822427.1781\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 35620797522.5523 - val_loss: 34727185506.1918\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 35553772556.2950 - val_loss: 34653457955.0685\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 35377684873.4408 - val_loss: 34579303914.9589\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 35368626811.8285 - val_loss: 34508453859.9452\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 35303672911.0395 - val_loss: 34430468600.9863\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 35235202379.9657 - val_loss: 34363832460.2740\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 35168380706.6895 - val_loss: 34293210434.6301\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 35088957036.0206 - val_loss: 34208075888.2192\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 35067739527.6844 - val_loss: 34135793523.7260\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 34906984813.3379 - val_loss: 34065012062.6849\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 34838452654.3259 - val_loss: 33978584162.1918\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 34735253918.5180 - val_loss: 33897576784.6575\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 34639638183.7393 - val_loss: 33817695554.6301\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 34693162639.1492 - val_loss: 33738911519.5616\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 34522322076.3225 - val_loss: 33661373173.4795\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 34473506492.8165 - val_loss: 33587285398.7945\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 34355881636.2264 - val_loss: 33516169973.4795\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 34276643876.8851 - val_loss: 33437826679.2329\n",
      "Epoch 116/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 34217314570.9777 - val_loss: 33351202170.7397\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 34191739031.0532 - val_loss: 33264785828.8219\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 34088777654.2298 - val_loss: 33186802982.5753\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 34037303896.6998 - val_loss: 33105000812.7123\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 33818071124.3087 - val_loss: 33012082491.6164\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 33863555142.2573 - val_loss: 32922210247.8904\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 33655026359.5472 - val_loss: 32832110171.1781\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 33756450046.6827 - val_loss: 32746782776.1096\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 33518590995.3208 - val_loss: 32670667930.3014\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 33556090033.3997 - val_loss: 32582988280.9863\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 33388458219.3619 - val_loss: 32490463540.6027\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 33373167510.6141 - val_loss: 32403525127.0137\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 33111485353.9348 - val_loss: 32308651414.7945\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 33192434222.5455 - val_loss: 32221851760.2192\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 32976421823.0120 - val_loss: 32139809048.5479\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 33007206280.5626 - val_loss: 32038393238.7945\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 32736634995.9245 - val_loss: 31948968833.7534\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 32787092790.8885 - val_loss: 31864561327.3425\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 32652306927.3139 - val_loss: 31781079460.8219\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 32662420977.0703 - val_loss: 31675705736.7671\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 32396767337.3859 - val_loss: 31565606098.4110\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 32397765784.8096 - val_loss: 31471250305.7534\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 32256011743.5060 - val_loss: 31385316029.3699\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 32204598129.7290 - val_loss: 31299396902.5753\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 32291541705.1115 - val_loss: 31223558480.6575\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 32059507039.2864 - val_loss: 31121761434.3014\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 31784684250.6758 - val_loss: 31021163926.7945\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 31709696323.1835 - val_loss: 30928615732.6027\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 31775772872.2333 - val_loss: 30826499843.5069\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 31574645421.0086 - val_loss: 30721260165.2603\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 31681739949.8868 - val_loss: 30635501483.8356\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 31435338961.0154 - val_loss: 30532415712.4384\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 31357811176.2882 - val_loss: 30431876250.3014\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 31245158825.0566 - val_loss: 30315992021.9178\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 31093984658.2230 - val_loss: 30226081174.7945\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 167us/step - loss: 31078037616.4117 - val_loss: 30121621195.3973\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 31008828610.9640 - val_loss: 30024785443.0685\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 30952804759.4923 - val_loss: 29919776487.4521\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 30825430667.6364 - val_loss: 29819426142.6849\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 30762055592.1784 - val_loss: 29721424152.5479\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 30472535284.1441 - val_loss: 29644092626.4110\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 30397311783.9588 - val_loss: 29534610081.3151\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 30196119492.2813 - val_loss: 29446250299.6164\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 30240542337.0978 - val_loss: 29332896922.3014\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 29993476062.6278 - val_loss: 29229106218.0822\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 29978912399.1492 - val_loss: 29117214355.2877\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 30108548564.9674 - val_loss: 29008801960.3288\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 30041633495.1629 - val_loss: 28912851757.5890\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 29716583067.4443 - val_loss: 28811685298.8493\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 29678638394.4014 - val_loss: 28714319815.8904\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 29747194179.1835 - val_loss: 28594602264.5479\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 29522100610.4151 - val_loss: 28487405483.8356\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 29415214380.3499 - val_loss: 28390124501.9178\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 29179430655.5609 - val_loss: 28281207793.9726\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 29164922286.3259 - val_loss: 28171300807.8904\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 29056492584.3979 - val_loss: 28063075847.0137\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 28791512294.0926 - val_loss: 27955992267.3973\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 28799777442.4700 - val_loss: 27838069044.6027\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 28720949469.3105 - val_loss: 27718545183.5616\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 28772097918.0240 - val_loss: 27609917860.8219\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 28647872912.4666 - val_loss: 27508460726.3562\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 28420674997.3516 - val_loss: 27389998206.2466\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 28312916874.3190 - val_loss: 27279493260.2740\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 28226462897.3997 - val_loss: 27161019995.1781\n",
      "Epoch 180/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 28027651249.3997 - val_loss: 27060459800.5479\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27931748243.1012 - val_loss: 26941514204.9315\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 27917355454.1338 - val_loss: 26830129348.3836\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 27784911792.9605 - val_loss: 26709676621.1507\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 27720185364.1990 - val_loss: 26601209743.7808\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 27528548892.9811 - val_loss: 26494775492.3836\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 27481711333.2144 - val_loss: 26377917454.0274\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 27391191563.4168 - val_loss: 26257305375.5616\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27275447933.5849 - val_loss: 26147392806.5753\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26971696972.8439 - val_loss: 26033954254.9041\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 26918283221.8456 - val_loss: 25923163739.1781\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 26864179821.7770 - val_loss: 25798842732.7123\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26678467106.2504 - val_loss: 25687314347.8356\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 26600598607.0395 - val_loss: 25559027431.4521\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 26398889804.8439 - val_loss: 25454495042.6301\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26495326555.7736 - val_loss: 25343109568.8767\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 26522002742.8885 - val_loss: 25242701795.9452\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 25957282420.8027 - val_loss: 25134224173.5890\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 26028540919.2178 - val_loss: 25013444355.5069\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 25837923270.0377 - val_loss: 24892017229.1507\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 25839767548.4871 - val_loss: 24761768665.4247\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 25474302087.2453 - val_loss: 24663151770.3014\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25572734484.1990 - val_loss: 24540736385.7534\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 25653559886.1612 - val_loss: 24417681744.6575\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 25636400730.4563 - val_loss: 24304009861.2603\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 25377371474.9914 - val_loss: 24175838951.4521\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 25347846421.5163 - val_loss: 24050777550.9041\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 25264608825.0840 - val_loss: 23926303701.9178\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 25228902670.4906 - val_loss: 23812924654.4658\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 25087339065.0840 - val_loss: 23685370641.5342\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 24882757349.2144 - val_loss: 23568229866.9589\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 24755556991.3413 - val_loss: 23453430236.9315\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 24293365875.9245 - val_loss: 23335236762.3014\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 24469548792.5352 - val_loss: 23219556885.0411\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 24537750132.8027 - val_loss: 23121327959.6712\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 24239558339.8422 - val_loss: 23001190708.6027\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 23972973864.8371 - val_loss: 22883041756.9315\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 23948733162.4837 - val_loss: 22764917914.3014\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 23974663173.2693 - val_loss: 22644840363.8356\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 23823040606.8473 - val_loss: 22516776749.5890\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 23500126348.5146 - val_loss: 22394993818.3014\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 23567664231.6295 - val_loss: 22282542416.6575\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 23590543809.6467 - val_loss: 22164299411.2877\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 23119973743.0943 - val_loss: 22046463172.3836\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 23211283949.5575 - val_loss: 21937152070.1370\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 23263368564.3636 - val_loss: 21816603157.0411\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 22919044015.2041 - val_loss: 21707291858.4110\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 22866392943.9726 - val_loss: 21587062475.3973\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 22694529937.3448 - val_loss: 21473056739.9452\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 22765259465.1115 - val_loss: 21362641948.0548\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 22624168044.8988 - val_loss: 21238007078.5753\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 22442498844.5420 - val_loss: 21099869576.7671\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 22339852783.3139 - val_loss: 20967951879.0137\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 146us/step - loss: 22422563553.7015 - val_loss: 20834324423.8904\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 21945406367.3962 - val_loss: 20700839795.7260\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 21971794106.1818 - val_loss: 20601790407.8904\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 21890126326.3396 - val_loss: 20474982876.9315\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 21499486309.8731 - val_loss: 20355392988.9315\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 21353260897.9211 - val_loss: 20233603380.6027\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 21510257233.6741 - val_loss: 20121259386.7397\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 21579304004.5009 - val_loss: 20001121041.5342\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 21288020997.2693 - val_loss: 19878489536.8767\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 21639825204.2539 - val_loss: 19752380808.7671\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 20922348570.3465 - val_loss: 19625373850.3014\n",
      "Epoch 244/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 20812869375.5609 - val_loss: 19498928015.7808\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 20612007593.4957 - val_loss: 19377998371.0685\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 20972497897.1664 - val_loss: 19254986681.8630\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 20487378733.2281 - val_loss: 19141928104.3288\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 20907592920.0412 - val_loss: 19032243676.9315\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 20440028804.6106 - val_loss: 18899550488.5479\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 20739947795.7599 - val_loss: 18800402403.9452\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 20256638649.3036 - val_loss: 18690046218.5205\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 20106562653.0909 - val_loss: 18564720583.8904\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 20073052453.3242 - val_loss: 18431612928.0000\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 270us/step - loss: 20098570977.7015 - val_loss: 18298360860.0548\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 294us/step - loss: 19518735607.6569 - val_loss: 18175798131.7260\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 315us/step - loss: 19807508982.3396 - val_loss: 18068983723.8356\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 305us/step - loss: 19433317609.6055 - val_loss: 17962268138.9589\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 313us/step - loss: 19408244360.1235 - val_loss: 17847289575.4521\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 316us/step - loss: 19101734497.4820 - val_loss: 17742166745.4247\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 268us/step - loss: 18940221726.2985 - val_loss: 17621303155.7260\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 279us/step - loss: 19313421573.7084 - val_loss: 17495834848.4384\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 281us/step - loss: 18894818346.1544 - val_loss: 17369838381.5890\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 19460218440.8919 - val_loss: 17241081771.8356\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 263us/step - loss: 18924476538.9503 - val_loss: 17135361641.2055\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 18685689669.8182 - val_loss: 17029186055.0137\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 18633449247.1767 - val_loss: 16910582405.2603\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 246us/step - loss: 18201609395.1561 - val_loss: 16792823667.7260\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 18317473001.6055 - val_loss: 16674120802.1918\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 18386142761.2762 - val_loss: 16552581484.7123\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 17870458535.7393 - val_loss: 16447789098.0822\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 230us/step - loss: 17579866259.5403 - val_loss: 16332385953.3151\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 17522686446.4357 - val_loss: 16216815770.3014\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 17748438657.0978 - val_loss: 16099210562.6301\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 17618594599.9588 - val_loss: 15983669177.8630\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 17553973209.3585 - val_loss: 15861373769.6438\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 17188515188.3636 - val_loss: 15750504097.3151\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 17652731998.8473 - val_loss: 15632775350.3562\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 17077957493.2419 - val_loss: 15525968755.7260\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 220us/step - loss: 17308718839.6569 - val_loss: 15413703764.1644\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 17019641408.1098 - val_loss: 15298843802.3014\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 16837145211.8285 - val_loss: 15187391544.1096\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 16960993712.0823 - val_loss: 15071671099.6164\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 16699219953.9485 - val_loss: 14964038698.0822\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 16584057369.4683 - val_loss: 14843435737.4247\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 16215384487.3002 - val_loss: 14731446636.7123\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 16642294634.7033 - val_loss: 14612659943.4521\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 16316715526.1475 - val_loss: 14496436658.8493\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 16573095145.6055 - val_loss: 14387035332.3836\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 209us/step - loss: 15844354120.0137 - val_loss: 14279869608.3288\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 16367037162.4837 - val_loss: 14169284229.2603\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 16172132858.7307 - val_loss: 14068606316.7123\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 16297843445.0223 - val_loss: 13956028710.5753\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 15526844709.3242 - val_loss: 13858449408.0000\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 16137064964.3911 - val_loss: 13750111666.8493\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 15694474951.3551 - val_loss: 13624145835.8356\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 15727640711.2453 - val_loss: 13514930204.0548\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 15347599388.1029 - val_loss: 13422090646.7945\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 15718061181.5849 - val_loss: 13314705001.2055\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 15481490799.0943 - val_loss: 13204674728.3288\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 14876472719.5883 - val_loss: 13099049773.5890\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 15496278639.5334 - val_loss: 12992183632.6575\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 14840514689.0978 - val_loss: 12881691844.3836\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 15164831657.9348 - val_loss: 12778962558.2466\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 15101021391.2590 - val_loss: 12677686678.7945\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 14668803145.7702 - val_loss: 12566951304.7671\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 14634916900.8851 - val_loss: 12468873868.2740\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 14342358804.6381 - val_loss: 12368747253.4795\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 14261864471.7118 - val_loss: 12265923261.3699\n",
      "Epoch 309/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 14638787796.5283 - val_loss: 12152097118.6849\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 14396772072.7273 - val_loss: 12074016270.0274\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 14075251186.8268 - val_loss: 11979887475.7260\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 14183362906.0172 - val_loss: 11874383058.4110\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 13714032715.5266 - val_loss: 11787599114.5205\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 14378462968.5352 - val_loss: 11687186677.4795\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 13577456915.7599 - val_loss: 11584488216.5479\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 13641133217.5918 - val_loss: 11486373677.5890\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 13370192231.1904 - val_loss: 11381362288.2192\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 13444304401.1252 - val_loss: 11287094229.9178\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 13558364750.1612 - val_loss: 11184189825.7534\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 13456812861.9142 - val_loss: 11083249811.2877\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 13281840197.3791 - val_loss: 10997598046.6849\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 12818786077.4202 - val_loss: 10902038163.2877\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 13130438218.6484 - val_loss: 10814753216.8767\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 13030899365.9828 - val_loss: 10720697554.4110\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 13248475691.0326 - val_loss: 10624909943.2329\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 12673743283.5952 - val_loss: 10542570145.3151\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 12709799338.8130 - val_loss: 10447573714.4110\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 12805325307.6089 - val_loss: 10348469177.8630\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 12762264662.0652 - val_loss: 10255958654.2466\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 12687068539.3894 - val_loss: 10170543917.5890\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 12868848369.5094 - val_loss: 10088258412.7123\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 12860050136.9194 - val_loss: 10015326341.2603\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 12404623625.2213 - val_loss: 9935117340.0548\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 12436347744.1647 - val_loss: 9848363604.1644\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 12348665260.5695 - val_loss: 9773309895.8904\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 12629280782.0515 - val_loss: 9687592448.0000\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 12540700751.0395 - val_loss: 9600412643.9452\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 12492875127.8765 - val_loss: 9526435236.8219\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 12200618533.7633 - val_loss: 9446746827.3973\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 11515141204.3087 - val_loss: 9367640505.8630\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 12204688867.8971 - val_loss: 9290825096.7671\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 11651131230.4082 - val_loss: 9202107882.9589\n",
      "Epoch 343/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 169us/step - loss: 12282446668.8439 - val_loss: 9126789414.5753\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 12214808595.3208 - val_loss: 9049327132.0548\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11727360461.9417 - val_loss: 8977939869.8082\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11776471526.5317 - val_loss: 8899618556.4932\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11667725377.8662 - val_loss: 8826231232.8767\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 12121271162.5111 - val_loss: 8752742273.7534\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11235324723.3756 - val_loss: 8683686189.5890\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 11984480863.7256 - val_loss: 8621406222.0274\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 11348501297.6192 - val_loss: 8551226830.9041\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 11740666774.6141 - val_loss: 8481175411.7260\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11556935081.0566 - val_loss: 8413822744.5479\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11914535447.7118 - val_loss: 8355477398.7945\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 11281448167.8491 - val_loss: 8285484656.2192\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11299012121.0292 - val_loss: 8220344937.2055\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11262795386.0720 - val_loss: 8155550229.0411\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 11559179372.8988 - val_loss: 8093040457.6438\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11096479485.8045 - val_loss: 8027433359.7808\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 11229129815.8216 - val_loss: 7968200107.8356\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 11037700269.8868 - val_loss: 7909688004.3836\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10915186197.9554 - val_loss: 7851456301.5890\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10725610993.0703 - val_loss: 7791686375.4521\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 11086020254.9571 - val_loss: 7739063597.5890\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 11443030780.0480 - val_loss: 7683957682.8493\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11446314372.1715 - val_loss: 7626776428.7123\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10945348105.6604 - val_loss: 7573278362.3014\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 11011325613.0086 - val_loss: 7523045102.4658\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 11085280080.3568 - val_loss: 7470875458.6301\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10939028134.8611 - val_loss: 7423879434.5205\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10536641889.0429 - val_loss: 7371183545.8630\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10618960018.6621 - val_loss: 7319255306.5205\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10809839559.3551 - val_loss: 7271424540.0548\n",
      "Epoch 374/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10890820485.0497 - val_loss: 7232145369.4247\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10593946266.5660 - val_loss: 7188527756.2740\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10629872873.6055 - val_loss: 7149312490.9589\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11010684120.0412 - val_loss: 7107278700.7123\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10336315525.4889 - val_loss: 7062034884.3836\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10652499177.6055 - val_loss: 7023631114.5205\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10031826407.4100 - val_loss: 6990927226.7397\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10169977272.8645 - val_loss: 6950382707.7260\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10746061936.4117 - val_loss: 6912022086.1370\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10649749337.1389 - val_loss: 6872296875.8356\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10391538734.5455 - val_loss: 6838758466.6301\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10299633024.6587 - val_loss: 6799675742.6849\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9816753520.8508 - val_loss: 6771010033.9726\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10237026678.1201 - val_loss: 6737434413.5890\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10257420477.6947 - val_loss: 6707155129.8630\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10086794793.2762 - val_loss: 6681061120.0000\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10140487096.8645 - val_loss: 6652138159.3425\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10583301982.4082 - val_loss: 6633149026.1918\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10415111947.8559 - val_loss: 6606600781.1507\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10166624999.8491 - val_loss: 6583884968.3288\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10621635716.6106 - val_loss: 6561571503.3425\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10740770916.9949 - val_loss: 6541016007.8904\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10562357251.5129 - val_loss: 6521591288.9863\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9682509032.7273 - val_loss: 6498907363.9452\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10041525482.4837 - val_loss: 6476352336.6575\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9938727133.3105 - val_loss: 6450154636.2740\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10444798673.8937 - val_loss: 6432432170.0822\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10292377137.1801 - val_loss: 6417307648.0000\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10342338287.7530 - val_loss: 6393760627.7260\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9851763511.7667 - val_loss: 6375418673.0959\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10144403070.4631 - val_loss: 6358204913.9726\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10333542375.4100 - val_loss: 6344400976.6575\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10467857632.8233 - val_loss: 6329450601.2055\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 159us/step - loss: 9747879104.3293 - val_loss: 6314464526.0274\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10476252327.7393 - val_loss: 6297224269.1507\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10242886636.6792 - val_loss: 6284512157.8082\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10695559015.1904 - val_loss: 6270723857.5342\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10216228584.7273 - val_loss: 6255458398.6849\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 145us/step - loss: 10296759108.0618 - val_loss: 6245932624.6575\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9971577329.9485 - val_loss: 6239554735.3425\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10265831980.7890 - val_loss: 6227227542.7945\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10639542825.2762 - val_loss: 6221277485.5890\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10845263772.7616 - val_loss: 6219323349.9178\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10088922657.3722 - val_loss: 6215694914.6301\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9852749516.6244 - val_loss: 6201878654.2466\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10343981438.0240 - val_loss: 6193385920.8767\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9892385184.2744 - val_loss: 6186092228.3836\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10678357367.8765 - val_loss: 6180211838.2466\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10457917918.6278 - val_loss: 6180834903.6712\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10520644327.8491 - val_loss: 6171387511.2329\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10171085391.9177 - val_loss: 6162704485.6986\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10420662338.7444 - val_loss: 6152502580.6027\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10214235067.9382 - val_loss: 6146808453.2603\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9540580162.3053 - val_loss: 6137433578.9589\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9594992729.5780 - val_loss: 6125699682.1918\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9993148524.0206 - val_loss: 6121600441.8630\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10536249711.0943 - val_loss: 6118761514.0822\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10433714490.4014 - val_loss: 6115087202.1918\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10605684786.9365 - val_loss: 6111573977.4247\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10813066062.6003 - val_loss: 6107593685.9178\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10495146535.5197 - val_loss: 6105330733.5890\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10066899069.5849 - val_loss: 6099600703.1233\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9907985027.7324 - val_loss: 6098903997.3699\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10565467128.9743 - val_loss: 6094600479.5616\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9870381470.5180 - val_loss: 6090801376.4384\n",
      "Epoch 439/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9705780347.8285 - val_loss: 6084526840.9863\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10208004218.9503 - val_loss: 6080993227.3973\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10158128315.9382 - val_loss: 6073640998.5753\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 10129296867.4580 - val_loss: 6067071182.9041\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9997976251.0600 - val_loss: 6064848678.5753\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9999625349.4889 - val_loss: 6062112848.6575\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9907852841.2762 - val_loss: 6054262917.2603\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 10144511293.9142 - val_loss: 6056091248.2192\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10025174917.0497 - val_loss: 6049025080.1096\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9479517312.2196 - val_loss: 6048727113.6438\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 9695095283.7050 - val_loss: 6045178887.0137\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10335437716.8576 - val_loss: 6039357937.9726\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10035676498.5523 - val_loss: 6039296350.6849\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10360629803.9108 - val_loss: 6035733994.9589\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9997451645.1458 - val_loss: 6035715022.9041\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10378110142.5729 - val_loss: 6035710646.3562\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10612594788.1166 - val_loss: 6032339690.9589\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10155094570.1544 - val_loss: 6024627487.5616\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10787391445.8456 - val_loss: 6027697544.7671\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10546185201.0703 - val_loss: 6025649127.4521\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10693119083.1424 - val_loss: 6030433216.8767\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10137740303.8079 - val_loss: 6023840768.0000\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10037208793.7976 - val_loss: 6026483052.7123\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10300166252.8988 - val_loss: 6029320177.9726\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9984848179.3756 - val_loss: 6023475508.6027\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10261466800.5214 - val_loss: 6022222244.8219\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9877567289.5232 - val_loss: 6015030335.1233\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10185237324.8439 - val_loss: 6015570677.4795\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9776324453.4340 - val_loss: 6012597276.0548\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10127932500.3087 - val_loss: 6007252448.4384\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10587972910.1063 - val_loss: 6006958479.7808\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10203198754.6895 - val_loss: 6009689417.6438\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9730049967.2041 - val_loss: 6009506149.6986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9736267271.9039 - val_loss: 6005060103.0137\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10273125404.1029 - val_loss: 6005218307.5068\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10032388735.3413 - val_loss: 6001289307.1781\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10127911718.2024 - val_loss: 6006858741.4795\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10557824659.5403 - val_loss: 6004814486.7945\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10364106612.3636 - val_loss: 6002475414.7945\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10059831068.9811 - val_loss: 6002161583.3425\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9928565323.5266 - val_loss: 6007343700.1644\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9972809259.9108 - val_loss: 6002993867.3973\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10317907845.0497 - val_loss: 6005341268.1644\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10365645297.0703 - val_loss: 6006234609.9726\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10092283212.8439 - val_loss: 6005069045.4795\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10002568243.8148 - val_loss: 5999793902.4658\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10288081050.5660 - val_loss: 5993325624.1096\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10510500434.5523 - val_loss: 5997182029.1507\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10272095534.1063 - val_loss: 5995463378.4110\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10247411906.0858 - val_loss: 5993758572.7123\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10000594283.5815 - val_loss: 5993812662.3562\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10261127422.6827 - val_loss: 5988164211.7260\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9946173552.4117 - val_loss: 5984631141.6986\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 10353480429.9966 - val_loss: 5989734031.7808\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9812496521.8799 - val_loss: 5989023133.8082\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10483363111.0806 - val_loss: 5987352874.0822\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10521343702.2847 - val_loss: 5989689358.0274\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10126083298.5798 - val_loss: 5988743532.7123\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10456174421.6261 - val_loss: 5985448798.6849\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10464330121.4408 - val_loss: 5984324015.3425\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10163052334.1063 - val_loss: 5982002232.1096\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10242447634.8816 - val_loss: 5978969340.4932\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10702009702.3122 - val_loss: 5982188414.2466\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9510569729.3173 - val_loss: 5983439633.5342\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9608641711.6432 - val_loss: 5976861573.2603\n",
      "Epoch 504/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10268644110.4906 - val_loss: 5980468918.3562\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9957644546.1955 - val_loss: 5977913929.6438\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10519361701.1046 - val_loss: 5977791309.1507\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10153396829.9691 - val_loss: 5978587097.4247\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10195744123.3894 - val_loss: 5969376396.2740\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9893511800.3156 - val_loss: 5966540922.7397\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9638526413.9417 - val_loss: 5967049307.1781\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10362556672.4391 - val_loss: 5967334617.4247\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10484877554.3877 - val_loss: 5965355439.3425\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9663523157.1870 - val_loss: 5960505189.6986\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10237811458.1955 - val_loss: 5962126693.6986\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9857453814.7787 - val_loss: 5963262320.2192\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10063813173.5712 - val_loss: 5964227959.2329\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10052406609.2350 - val_loss: 5962860978.8493\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10305911052.7341 - val_loss: 5963558666.5205\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10265569775.3139 - val_loss: 5961882308.3836\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10091354205.0909 - val_loss: 5964242417.9726\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10253636755.5403 - val_loss: 5966724762.3014\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10403793811.9794 - val_loss: 5967297588.6027\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10215521727.0120 - val_loss: 5965351690.5205\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10461056346.0172 - val_loss: 5964492866.6301\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9698043561.4957 - val_loss: 5961099453.3699\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10339469894.2573 - val_loss: 5962732603.6164\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10249929146.6209 - val_loss: 5963485857.3151\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9836147351.9314 - val_loss: 5965747631.3425\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10355735591.5197 - val_loss: 5964750188.7123\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11281618464.4940 - val_loss: 5963990696.3288\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10162444382.4082 - val_loss: 5965771158.7945\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 9717678609.5643 - val_loss: 5965224854.7945\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 306us/step - loss: 10689117930.4837 - val_loss: 5967314638.9041\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 411us/step - loss: 9790371959.4374 - val_loss: 5965657172.1644\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 1s 541us/step - loss: 10416702376.1784 - val_loss: 5967865715.7260\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 1s 600us/step - loss: 9668724156.3774 - val_loss: 5965547390.2466\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 1s 601us/step - loss: 10339055960.2607 - val_loss: 5962721641.2055\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 1s 543us/step - loss: 10133933529.3585 - val_loss: 5957832988.0548\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 1s 496us/step - loss: 9705211658.0995 - val_loss: 5957493181.3699\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 1s 449us/step - loss: 9741851990.5043 - val_loss: 5955820084.6027\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 405us/step - loss: 10150830326.7787 - val_loss: 5959415843.0685\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 1s 445us/step - loss: 10001626547.5952 - val_loss: 5960956279.2329\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 422us/step - loss: 10250743642.8954 - val_loss: 5961799462.5753\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 381us/step - loss: 9996686668.4048 - val_loss: 5960377968.2192\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 389us/step - loss: 10101127654.5317 - val_loss: 5956360048.2192\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 367us/step - loss: 9732727110.6964 - val_loss: 5950882605.5890\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 335us/step - loss: 9784831048.0137 - val_loss: 5952595873.3151\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 306us/step - loss: 10836422116.7753 - val_loss: 5957771109.6986\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 305us/step - loss: 10164800367.9726 - val_loss: 5958256194.6301\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 333us/step - loss: 10175563749.6535 - val_loss: 5957698160.2192\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 302us/step - loss: 9724998568.1784 - val_loss: 5955327319.6712\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 292us/step - loss: 10605312003.5129 - val_loss: 5956643580.4932\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 308us/step - loss: 10533639257.5780 - val_loss: 5959584389.2603\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 10335688417.7015 - val_loss: 5961889129.2055\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 263us/step - loss: 10406446924.8439 - val_loss: 5957498420.6027\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 10028315026.2230 - val_loss: 5954611799.6712\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 254us/step - loss: 10140083094.6141 - val_loss: 5956421919.5616\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 269us/step - loss: 10800475849.1115 - val_loss: 5959505386.9589\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 275us/step - loss: 9861839263.3962 - val_loss: 5956152895.1233\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 269us/step - loss: 9783120833.6467 - val_loss: 5956845890.6301\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 9275853151.2864 - val_loss: 5958556107.3973\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 9637938517.6261 - val_loss: 5957879815.0137\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 246us/step - loss: 10039761464.2058 - val_loss: 5958953061.6986\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 257us/step - loss: 10345475435.1424 - val_loss: 5957559506.4110\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 278us/step - loss: 9749363498.1544 - val_loss: 5958969912.1096\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 10476391089.3997 - val_loss: 5960738640.6575\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 247us/step - loss: 9888299701.7907 - val_loss: 5957038441.2055\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 240us/step - loss: 10253133691.3894 - val_loss: 5953133192.7671\n",
      "Epoch 569/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 10122251270.5866 - val_loss: 5956316489.6438\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 258us/step - loss: 10243412231.4648 - val_loss: 5955356479.1233\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 280us/step - loss: 9861322056.4528 - val_loss: 5954023918.4658\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 313us/step - loss: 10241021578.7581 - val_loss: 5955159250.4110\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 304us/step - loss: 10152139055.8628 - val_loss: 5957010323.2877\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 306us/step - loss: 10310006566.2024 - val_loss: 5956388814.9041\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 10286790828.1304 - val_loss: 5958729847.2329\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 9944428765.3105 - val_loss: 5957641615.7808\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 10170940704.0549 - val_loss: 5962809810.4110\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 10054181389.1732 - val_loss: 5962056640.8767\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 10170823281.2899 - val_loss: 5959022662.1370\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 10893726226.4425 - val_loss: 5965790239.5616\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 10582035326.0240 - val_loss: 5967433868.2740\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 252us/step - loss: 10383196953.9074 - val_loss: 5970614969.8630\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 241us/step - loss: 10069380538.6209 - val_loss: 5967534690.1918\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 10188116854.9983 - val_loss: 5967835648.0000\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 9519546318.8199 - val_loss: 5969288956.4932\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 9779980771.8971 - val_loss: 5968857691.1781\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 208us/step - loss: 10336214430.5180 - val_loss: 5968587842.6301\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 10066155178.3739 - val_loss: 5970509911.6712\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 10568730068.0892 - val_loss: 5974152328.7671\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 10340939412.4185 - val_loss: 5974490027.8356\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 238us/step - loss: 10288813008.5763 - val_loss: 5975633211.6164\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 9727007480.5352 - val_loss: 5974637361.0959\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 10914723489.5918 - val_loss: 5974200155.1781\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 10269407562.2093 - val_loss: 5973073811.2877\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 9767842965.2967 - val_loss: 5972413503.1233\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 9794863162.4014 - val_loss: 5970143572.1644\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 10558923375.5334 - val_loss: 5969249869.1507\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 210us/step - loss: 10263892143.6432 - val_loss: 5970714669.5890\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 10263230167.1630 - val_loss: 5966035673.4247\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 9939101620.4734 - val_loss: 5966275475.2877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 9884339930.6758 - val_loss: 5968125895.8904\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 10564982981.1595 - val_loss: 5968257690.3014\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 10025228124.6518 - val_loss: 5969024543.5616\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 9741082696.0137 - val_loss: 5966406989.1507\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 9636308992.8782 - val_loss: 5966504967.0137\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10363034465.9211 - val_loss: 5970858082.1918\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10248731714.7444 - val_loss: 5972173515.3973\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9964031929.7427 - val_loss: 5966396394.9589\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10095021064.7822 - val_loss: 5966711576.5479\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 10504183843.1286 - val_loss: 5969051623.4521\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9789777600.3293 - val_loss: 5967508227.5068\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 10538418031.9726 - val_loss: 5973432386.6301\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 10151795269.3791 - val_loss: 5976124928.0000\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10513254515.9245 - val_loss: 5976004081.9726\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9813823470.4357 - val_loss: 5977660963.0685\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 9624640310.0103 - val_loss: 5977438744.5479\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9682528195.4031 - val_loss: 5975824398.0274\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10618478312.7273 - val_loss: 5978593381.6986\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10097790609.7839 - val_loss: 5981265912.9863\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10373485642.6484 - val_loss: 5982732498.4110\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 9826220750.3808 - val_loss: 5981152585.6438\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10130107723.9657 - val_loss: 5980790093.1507\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10257999021.8868 - val_loss: 5979763494.5753\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10319776094.4082 - val_loss: 5980458432.8767\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 9744561750.9434 - val_loss: 5974046933.9178\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 9965200863.0669 - val_loss: 5974997882.7397\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10452822250.4837 - val_loss: 5974293661.8082\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9673010188.2950 - val_loss: 5971310122.0822\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9871166290.1132 - val_loss: 5967677587.2877\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10049984751.7530 - val_loss: 5970317778.4110\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10218314227.7050 - val_loss: 5964941073.5342\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10192465371.1149 - val_loss: 5965337796.3836\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10187606687.8353 - val_loss: 5968610500.3836\n",
      "Epoch 634/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10316581295.2041 - val_loss: 5964180788.6027\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9455077856.3842 - val_loss: 5964257041.5342\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9696537055.5060 - val_loss: 5960418353.0959\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9638753866.6484 - val_loss: 5959389296.2192\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 9713138496.5489 - val_loss: 5956019063.2329\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 10309096973.1732 - val_loss: 5951725354.0822\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10117466098.8268 - val_loss: 5952690284.7123\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10446551891.8696 - val_loss: 5951610743.2329\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10181545017.0840 - val_loss: 5951381318.1370\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10326225912.0961 - val_loss: 5954632928.4384\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9783733448.6724 - val_loss: 5952403690.9589\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10285923784.6724 - val_loss: 5955520182.3562\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10902810978.7993 - val_loss: 5959966698.9589\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 10284632621.6672 - val_loss: 5959804170.5205\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10851577235.9794 - val_loss: 5960910157.1507\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9674952845.3928 - val_loss: 5959200000.0000\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9835478337.4271 - val_loss: 5954844219.6164\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 10279058030.6552 - val_loss: 5954140707.0685\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10173756273.7290 - val_loss: 5955808645.2603\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10033070363.6638 - val_loss: 5957646851.5068\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9768959783.9588 - val_loss: 5952400334.9041\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9943038951.4100 - val_loss: 5946344321.7534\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9346776367.8628 - val_loss: 5941667980.2740\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10012988113.0154 - val_loss: 5942629810.8493\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10087979223.1630 - val_loss: 5944539812.8219\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10696320732.4322 - val_loss: 5944475132.4932\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10183710265.9623 - val_loss: 5947492849.9726\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 10299739125.4614 - val_loss: 5948050488.1096\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 9996185448.9468 - val_loss: 5950217044.1644\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9846215003.7736 - val_loss: 5949149566.2466\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10201166418.5523 - val_loss: 5950850794.9589\n",
      "Epoch 665/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 164us/step - loss: 9690945673.0017 - val_loss: 5948538620.4932\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10133544284.6518 - val_loss: 5947599486.2466\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9867259601.4545 - val_loss: 5945110643.7260\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10112838478.6003 - val_loss: 5943995469.1507\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10454566154.9777 - val_loss: 5945815292.4932\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10538721380.9949 - val_loss: 5947242618.7397\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10275496185.4134 - val_loss: 5949196077.5890\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10318810287.2041 - val_loss: 5950839355.6164\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10328336592.1372 - val_loss: 5955460422.1370\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9895510035.3208 - val_loss: 5952016145.5342\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10225935042.0858 - val_loss: 5955346249.6438\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10678354803.4854 - val_loss: 5956315416.5479\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10325204227.9520 - val_loss: 5956214741.9178\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10161213092.2264 - val_loss: 5951643791.7808\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10131591882.4288 - val_loss: 5951006656.8767\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10159558088.6724 - val_loss: 5948050488.1096\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10230462826.2642 - val_loss: 5948026624.0000\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9841076194.1407 - val_loss: 5943187161.4247\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10305956323.0189 - val_loss: 5945736241.0959\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9906422239.5060 - val_loss: 5945181184.0000\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10228428592.7410 - val_loss: 5949025574.5753\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10373888999.8491 - val_loss: 5948735270.5753\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10231703664.4117 - val_loss: 5944349625.8630\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10284298211.8971 - val_loss: 5946548858.7397\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10041355470.3808 - val_loss: 5946338293.4795\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9855568598.7238 - val_loss: 5947807744.0000\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 9707926491.9931 - val_loss: 5948097816.5479\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10579114498.6346 - val_loss: 5951352018.4110\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10023028950.2847 - val_loss: 5944897886.6849\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10501793356.4048 - val_loss: 5944228565.9178\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10817741326.9297 - val_loss: 5944643885.5890\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9808841996.7341 - val_loss: 5945160199.0137\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9835139009.6467 - val_loss: 5948400173.5890\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10242445073.1252 - val_loss: 5946352941.5890\n",
      "Epoch 699/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9916759251.6501 - val_loss: 5948789332.1644\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9977335593.7153 - val_loss: 5948078830.4658\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9640831819.9657 - val_loss: 5942942039.6712\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10181638502.3122 - val_loss: 5947650875.6164\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10438794476.6792 - val_loss: 5947477893.2603\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10790443954.7170 - val_loss: 5947085606.5753\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9913560618.1544 - val_loss: 5950398316.7123\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9677548175.1492 - val_loss: 5952003271.8904\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9445798379.8010 - val_loss: 5947020049.5342\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10405593419.9657 - val_loss: 5949116738.6301\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10228940744.6724 - val_loss: 5955108590.4658\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9937451722.8679 - val_loss: 5954032401.5342\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10428257014.7787 - val_loss: 5952879254.7945\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10584771053.5575 - val_loss: 5953717458.4110\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9655562449.0154 - val_loss: 5951870004.6027\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9768443921.5643 - val_loss: 5953821089.3151\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10168400728.2607 - val_loss: 5951907587.5068\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10460069043.1561 - val_loss: 5952696789.9178\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9885402313.1115 - val_loss: 5954598557.8082\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9906822467.1835 - val_loss: 5952034798.4658\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10077118339.2933 - val_loss: 5954065393.9726\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9847801358.9297 - val_loss: 5952221092.8219\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9835216139.8559 - val_loss: 5951974869.9178\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10171806198.3396 - val_loss: 5953171992.5479\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10130282003.3208 - val_loss: 5950693895.0137\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10003527276.0206 - val_loss: 5953646065.9726\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9960984397.7221 - val_loss: 5945165750.3562\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10442863580.8714 - val_loss: 5946094037.9178\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10270057115.4443 - val_loss: 5945266719.5616\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10054088426.4837 - val_loss: 5946224359.4521\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10046275483.8834 - val_loss: 5947393006.4658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10042570690.5249 - val_loss: 5949725268.1644\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10150630370.1407 - val_loss: 5947652734.2466\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10621165290.4837 - val_loss: 5951886883.0685\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10078603009.3173 - val_loss: 5953593042.4110\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10255122238.7925 - val_loss: 5952671323.1781\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9510887407.3139 - val_loss: 5954913728.8767\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9324805850.6758 - val_loss: 5949188218.7397\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10474362300.3774 - val_loss: 5949843287.6712\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10471101566.9022 - val_loss: 5952201763.0685\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9704266293.5712 - val_loss: 5948505207.2329\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10111835179.9108 - val_loss: 5946225772.7123\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10304782288.5763 - val_loss: 5948061583.7808\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10001622670.2710 - val_loss: 5945306894.0274\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10414304160.2744 - val_loss: 5947834396.0548\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9957243525.4889 - val_loss: 5945718352.6575\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10367096883.8148 - val_loss: 5946964778.0822\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10163205515.1973 - val_loss: 5950522003.2877\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10123872391.2453 - val_loss: 5952510386.8493\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10281191856.0823 - val_loss: 5956712644.3836\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9944090567.7942 - val_loss: 5956990011.6164\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10114418742.4494 - val_loss: 5957232212.1644\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10522490147.5678 - val_loss: 5956074625.7534\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10297831237.8182 - val_loss: 5958043858.4110\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10479671629.7221 - val_loss: 5958683016.7671\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10160373240.5352 - val_loss: 5955267503.3425\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10239518516.2539 - val_loss: 5956431896.5479\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10436572842.3739 - val_loss: 5955568050.8493\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10275622038.1750 - val_loss: 5955493695.1233\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9651619804.8714 - val_loss: 5950732014.4658\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9988968490.1544 - val_loss: 5950936754.8493\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9810924675.7324 - val_loss: 5954238022.1370\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10217316799.0120 - val_loss: 5950682175.1233\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10140533240.0961 - val_loss: 5948860815.7808\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10220003711.7804 - val_loss: 5946203290.3014\n",
      "Epoch 764/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9946323510.4494 - val_loss: 5949378959.7808\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9910999886.6003 - val_loss: 5947619545.4247\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10365894549.7358 - val_loss: 5946666338.1918\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10459670702.7650 - val_loss: 5949149085.8082\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10559526627.4580 - val_loss: 5948166620.9315\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10295801834.9228 - val_loss: 5950870349.1507\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 10393817643.0326 - val_loss: 5953688274.4110\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9973006278.0377 - val_loss: 5954444105.6438\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10467773375.8902 - val_loss: 5958011595.3973\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10641624360.8370 - val_loss: 5958587272.7671\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 10592105961.1664 - val_loss: 5961438397.3699\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 9981821846.6141 - val_loss: 5960448526.0274\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9632481248.3842 - val_loss: 5960526862.0274\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 10062640928.9331 - val_loss: 5961006269.3699\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9770390848.5489 - val_loss: 5962399456.4384\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10204774257.7290 - val_loss: 5961872643.5068\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10208822133.2419 - val_loss: 5961609861.2603\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11046400021.9554 - val_loss: 5965027436.7123\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9815968789.0772 - val_loss: 5962527579.1781\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9801716935.3551 - val_loss: 5958529395.7260\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9996808740.0069 - val_loss: 5956017600.8767\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9921800631.1081 - val_loss: 5956719714.1918\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10007923095.4923 - val_loss: 5958812181.0411\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9746211641.5232 - val_loss: 5959810735.3425\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10413571730.6621 - val_loss: 5960655345.9726\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10575317239.6569 - val_loss: 5962739985.5342\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9973554836.4185 - val_loss: 5960388453.6986\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9823970852.0069 - val_loss: 5954444105.6438\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9776705907.4854 - val_loss: 5952460659.7260\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10359819919.5883 - val_loss: 5953229750.3562\n",
      "Epoch 794/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 157us/step - loss: 10311734753.2624 - val_loss: 5952602406.5753\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10034481255.6295 - val_loss: 5952641795.5068\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10227772762.0172 - val_loss: 5953933171.7260\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10566423924.3636 - val_loss: 5954897558.7945\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10557357874.4974 - val_loss: 5957363007.1233\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9948971940.6655 - val_loss: 5957474921.2055\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10038073097.2213 - val_loss: 5958814600.7671\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9885578654.5180 - val_loss: 5959483630.4658\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10296983775.9451 - val_loss: 5959215587.9452\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9788402749.4751 - val_loss: 5955506488.1096\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9729296392.7822 - val_loss: 5949539405.1507\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9889847677.1458 - val_loss: 5951964503.6712\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10469306189.7221 - val_loss: 5959807470.4658\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10231186422.3396 - val_loss: 5958906627.5068\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10075149245.2556 - val_loss: 5957837634.6301\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10354902511.3139 - val_loss: 5959406146.6301\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9997441350.2573 - val_loss: 5957802275.0685\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10198986999.6569 - val_loss: 5959272363.8356\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10081105679.3688 - val_loss: 5958243994.3014\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10271303140.7753 - val_loss: 5960645035.8356\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9626503105.6467 - val_loss: 5959877323.3973\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10061104027.0051 - val_loss: 5957600585.6438\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10270557645.9417 - val_loss: 5959783322.3014\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10128621566.2436 - val_loss: 5961071587.9452\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10292886565.7633 - val_loss: 5959613696.0000\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9895303247.0395 - val_loss: 5957403861.9178\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10450973602.9091 - val_loss: 5963630858.5205\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10459540906.8130 - val_loss: 5963625535.1233\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9987130594.5798 - val_loss: 5964225423.7808\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9786963973.2693 - val_loss: 5965961903.3425\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9383675313.8388 - val_loss: 5960800571.6164\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10275926353.2350 - val_loss: 5959907271.8904\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10281503977.6055 - val_loss: 5958537061.6986\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10050162435.9520 - val_loss: 5957959217.0959\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10055279927.7667 - val_loss: 5958402265.4247\n",
      "Epoch 829/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10067585106.5523 - val_loss: 5959436691.2877\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10091607589.7633 - val_loss: 5959042861.5890\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 9561186056.3431 - val_loss: 5960173631.1233\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9780497371.9931 - val_loss: 5956299835.6164\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10194097579.9108 - val_loss: 5954715935.5616\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10594729759.1767 - val_loss: 5955064214.7945\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9764861036.0206 - val_loss: 5955624742.5753\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9777735218.0583 - val_loss: 5955699547.1781\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10041685921.1527 - val_loss: 5953919249.5342\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10358153961.6055 - val_loss: 5956050140.9315\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 10463768410.8954 - val_loss: 5953998872.5479\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10375856920.1509 - val_loss: 5952645516.2740\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9826545333.7907 - val_loss: 5950488081.5342\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10067445255.0257 - val_loss: 5950112943.3425\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9982919059.9794 - val_loss: 5948468550.1370\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9993789290.2642 - val_loss: 5950502084.3836\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 9796802184.1235 - val_loss: 5945452712.3288\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9525448870.8611 - val_loss: 5946724772.8219\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 9189229473.1527 - val_loss: 5941791035.6164\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9743244866.7444 - val_loss: 5944392924.9315\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9897628817.7839 - val_loss: 5946254511.3425\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 9932896194.5249 - val_loss: 5944736876.7123\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10204257177.2487 - val_loss: 5948123486.6849\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9742230189.0086 - val_loss: 5944195268.3836\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10029249961.0566 - val_loss: 5942957308.4932\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10030071633.6741 - val_loss: 5943132707.0685\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10186867522.3053 - val_loss: 5942424046.4658\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10417451267.9520 - val_loss: 5944676534.3562\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9909104128.8782 - val_loss: 5945391661.5890\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9891320664.2607 - val_loss: 5946510770.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9817889806.0515 - val_loss: 5948751331.9452\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10151600281.6878 - val_loss: 5945400028.9315\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 10607082971.1149 - val_loss: 5948237981.8082\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9947542930.2230 - val_loss: 5945516270.4658\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9899636411.9382 - val_loss: 5949915128.9863\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 10181709890.7444 - val_loss: 5951869355.8356\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10546614579.3756 - val_loss: 5955114369.7534\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10533557787.2247 - val_loss: 5955259777.7534\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10324205718.1750 - val_loss: 5950764582.5753\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10298615584.9331 - val_loss: 5955172295.8904\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10495402471.4100 - val_loss: 5955862405.2603\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10001038572.2401 - val_loss: 5955538859.8356\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10489950592.6587 - val_loss: 5957418541.5890\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10489050596.7753 - val_loss: 5958093532.9315\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10130014333.5849 - val_loss: 5957063094.3562\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10304103149.1184 - val_loss: 5954264568.9863\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10194531049.6055 - val_loss: 5959075548.9315\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10182655873.5369 - val_loss: 5960289269.4795\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9876766413.5026 - val_loss: 5956569649.0959\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9617013306.8405 - val_loss: 5953923335.0137\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9817666731.2521 - val_loss: 5954468807.8904\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10208865649.7290 - val_loss: 5955923434.9589\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10097304785.8937 - val_loss: 5960235481.4247\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10106380817.5643 - val_loss: 5963359393.3151\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10233765322.4288 - val_loss: 5965265095.8904\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10654935708.3225 - val_loss: 5964300771.9452\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10516809427.6501 - val_loss: 5966212920.1096\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9486274934.5592 - val_loss: 5963269112.9863\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9940616729.0292 - val_loss: 5959705754.3014\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10193379615.1767 - val_loss: 5960057315.9452\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10067091473.5643 - val_loss: 5960372055.6712\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9880347410.8816 - val_loss: 5961443671.6712\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10143086827.3619 - val_loss: 5960447144.3288\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9639857180.1029 - val_loss: 5957663168.8767\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9991494891.3619 - val_loss: 5959694988.2740\n",
      "Epoch 894/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9927795991.2727 - val_loss: 5955663030.3562\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9764728435.0463 - val_loss: 5956976001.7534\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9964771294.6278 - val_loss: 5956433081.8630\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9612473126.2024 - val_loss: 5954066295.2329\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10526345170.3328 - val_loss: 5957801822.6849\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9162187406.2710 - val_loss: 5958000212.1644\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10087182974.4631 - val_loss: 5958124386.1918\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10671284935.3551 - val_loss: 5955966428.9315\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 9492526132.6930 - val_loss: 5952441978.7397\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10343008279.7118 - val_loss: 5952668840.3288\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9813052670.6827 - val_loss: 5954053958.1370\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10249490261.6261 - val_loss: 5958020418.6301\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10140399216.4117 - val_loss: 5961336453.2603\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10472972193.1527 - val_loss: 5960441315.9452\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10163696167.5197 - val_loss: 5962002176.0000\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10447294871.4923 - val_loss: 5966805581.1507\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 10116794907.2247 - val_loss: 5968723862.7945\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10262526260.2539 - val_loss: 5973445151.5616\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10032020386.9091 - val_loss: 5972457605.2603\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10220096012.2950 - val_loss: 5974638739.2877\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 10287041359.4786 - val_loss: 5976511870.2466\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 10453003545.9074 - val_loss: 5975217365.9178\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9744667833.7427 - val_loss: 5971289799.8904\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10425947808.7136 - val_loss: 5974631557.2603\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 9923090749.0360 - val_loss: 5973023480.9863\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10162985495.7118 - val_loss: 5974395819.8356\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9563974749.0909 - val_loss: 5974169522.8493\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 10762063511.0532 - val_loss: 5973372668.4932\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9852261873.0703 - val_loss: 5968905598.2466\n",
      "Epoch 923/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 172us/step - loss: 9996962832.6861 - val_loss: 5970340976.2192\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10582840460.5146 - val_loss: 5970998955.8356\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10422016551.5197 - val_loss: 5973332795.6164\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9936932791.9863 - val_loss: 5971303809.7534\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10777263686.2573 - val_loss: 5976229232.2192\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10195657706.4837 - val_loss: 5973651070.2466\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9836707629.2281 - val_loss: 5969538153.2055\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10294617943.8216 - val_loss: 5970448531.2877\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10614769158.1475 - val_loss: 5969439323.1781\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10146940541.5849 - val_loss: 5970182347.3973\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9939948197.5437 - val_loss: 5968468104.7671\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 9908052722.3877 - val_loss: 5965957958.1370\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10115231499.8559 - val_loss: 5969080565.4795\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10010512459.5266 - val_loss: 5967443108.8219\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 10096361071.5334 - val_loss: 5965214997.0411\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10585959601.3997 - val_loss: 5967984997.6986\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9722186885.4889 - val_loss: 5963420426.5205\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10488306600.1784 - val_loss: 5960892661.4795\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10425291027.7599 - val_loss: 5963459086.0274\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10227843115.9108 - val_loss: 5960888148.1644\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10157122475.6913 - val_loss: 5963128330.5205\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9980809920.3293 - val_loss: 5961482808.1096\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10091177389.8868 - val_loss: 5963589326.9041\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10042356340.8027 - val_loss: 5962150841.8630\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10713445240.7547 - val_loss: 5963128330.5205\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10595098481.7290 - val_loss: 5966546333.8082\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10233546080.6038 - val_loss: 5966253753.8630\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10467703539.2659 - val_loss: 5968184116.6027\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 10598078959.3139 - val_loss: 5971056275.2877\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10381628691.3208 - val_loss: 5968510772.6027\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 10494577171.7599 - val_loss: 5972324260.8219\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9916612903.0806 - val_loss: 5970967983.3425\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10416438674.2230 - val_loss: 5972738686.2466\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9767773135.2590 - val_loss: 5973717216.4384\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 10208952164.5557 - val_loss: 5973283987.2877\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10139257471.3413 - val_loss: 5970922923.8356\n",
      "Epoch 959/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 10179580534.5592 - val_loss: 5967187294.6849\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9650667644.7067 - val_loss: 5965377080.1096\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9947041092.9400 - val_loss: 5965793813.0411\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 10456423295.7804 - val_loss: 5967460074.9589\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9754746499.7324 - val_loss: 5967906097.0959\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9663500169.4408 - val_loss: 5965048965.2603\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10325680486.3122 - val_loss: 5963967000.5479\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10131847853.0086 - val_loss: 5963778794.9589\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10073057768.2882 - val_loss: 5960097806.0274\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 10253519650.6895 - val_loss: 5962201733.2603\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 9956049387.8010 - val_loss: 5962294012.4932\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10103860685.9417 - val_loss: 5964243175.4521\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 9610497898.7033 - val_loss: 5960916325.6986\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 9461796106.9777 - val_loss: 5956310654.2466\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9350503135.0669 - val_loss: 5956183495.8904\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 9992355730.6621 - val_loss: 5956501153.3151\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9929998459.8285 - val_loss: 5956791874.6301\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9995448839.9039 - val_loss: 5956853072.6575\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10200682295.7667 - val_loss: 5953047629.1507\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10069829841.8937 - val_loss: 5951746005.9178\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10074443252.5832 - val_loss: 5952525431.2329\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 10210621703.4648 - val_loss: 5950180871.0137\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9961815607.3276 - val_loss: 5951033084.4932\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10597044492.7341 - val_loss: 5954630228.1644\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 9937658096.6312 - val_loss: 5952861275.1781\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 9964453601.2624 - val_loss: 5951016265.6438\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 9664539064.8645 - val_loss: 5949474437.2603\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9543078462.3533 - val_loss: 5947839442.4110\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10469347005.6947 - val_loss: 5949068961.3151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 10017395262.3533 - val_loss: 5949861996.7123\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10205120493.5575 - val_loss: 5947811292.9315\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 9706216072.1235 - val_loss: 5943166709.4795\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 9917076399.2041 - val_loss: 5944837421.5890\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 10324552237.6672 - val_loss: 5945630990.0274\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 10120467042.7993 - val_loss: 5942845492.6027\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10565042455.2727 - val_loss: 5944437269.0411\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10992014168.2607 - val_loss: 5946757786.3014\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10592507103.9451 - val_loss: 5951168659.2877\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 9828882216.8370 - val_loss: 5950869644.2740\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9772745650.7170 - val_loss: 5949422963.7260\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 9676090232.7547 - val_loss: 5945226261.0411\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 147us/step - loss: 10432071992.6449 - val_loss: 5944074913.3151\n",
      "neurons used (8, 16)\n",
      "Train on 1166 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1166/1166 [==============================] - 1s 565us/step - loss: 39209590805.0772 - val_loss: 38416361528.1096\n",
      "Epoch 2/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 39206660686.1612 - val_loss: 38412733930.9589\n",
      "Epoch 3/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 39202024699.1698 - val_loss: 38407422232.5479\n",
      "Epoch 4/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 39195989274.7856 - val_loss: 38398454236.9315\n",
      "Epoch 5/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 39187637520.2470 - val_loss: 38391080651.3973\n",
      "Epoch 6/1000\n",
      "1166/1166 [==============================] - 0s 298us/step - loss: 39178205861.9828 - val_loss: 38380222183.4521\n",
      "Epoch 7/1000\n",
      "1166/1166 [==============================] - 0s 360us/step - loss: 39168077929.3859 - val_loss: 38367365484.7123\n",
      "Epoch 8/1000\n",
      "1166/1166 [==============================] - 1s 451us/step - loss: 39154975450.6758 - val_loss: 38352707808.4384\n",
      "Epoch 9/1000\n",
      "1166/1166 [==============================] - 1s 502us/step - loss: 39140849147.6089 - val_loss: 38338291768.1096\n",
      "Epoch 10/1000\n",
      "1166/1166 [==============================] - 1s 547us/step - loss: 39124472092.5420 - val_loss: 38321468345.8630\n",
      "Epoch 11/1000\n",
      "1166/1166 [==============================] - 1s 485us/step - loss: 39107230746.3465 - val_loss: 38302099540.1644\n",
      "Epoch 12/1000\n",
      "1166/1166 [==============================] - 1s 455us/step - loss: 39088727414.1201 - val_loss: 38283251038.6849\n",
      "Epoch 13/1000\n",
      "1166/1166 [==============================] - 1s 434us/step - loss: 39069292803.9520 - val_loss: 38265307921.5342\n",
      "Epoch 14/1000\n",
      "1166/1166 [==============================] - 0s 407us/step - loss: 39045384771.6226 - val_loss: 38237361727.1233\n",
      "Epoch 15/1000\n",
      "1166/1166 [==============================] - 0s 377us/step - loss: 39022510406.6964 - val_loss: 38209575557.2603\n",
      "Epoch 16/1000\n",
      "1166/1166 [==============================] - 0s 356us/step - loss: 38998582456.4254 - val_loss: 38188826792.3288\n",
      "Epoch 17/1000\n",
      "1166/1166 [==============================] - 0s 335us/step - loss: 38975593010.0583 - val_loss: 38165166051.9452\n",
      "Epoch 18/1000\n",
      "1166/1166 [==============================] - 0s 328us/step - loss: 38947146427.0600 - val_loss: 38140766067.7260\n",
      "Epoch 19/1000\n",
      "1166/1166 [==============================] - 0s 329us/step - loss: 38913688412.6518 - val_loss: 38107660344.1096\n",
      "Epoch 20/1000\n",
      "1166/1166 [==============================] - 0s 305us/step - loss: 38882869592.2607 - val_loss: 38076176804.8219\n",
      "Epoch 21/1000\n",
      "1166/1166 [==============================] - 0s 293us/step - loss: 38849755687.5197 - val_loss: 38047438343.0137\n",
      "Epoch 22/1000\n",
      "1166/1166 [==============================] - 0s 297us/step - loss: 38819401728.0000 - val_loss: 38004640333.1507\n",
      "Epoch 23/1000\n",
      "1166/1166 [==============================] - 0s 288us/step - loss: 38778409086.4631 - val_loss: 37975002855.4521\n",
      "Epoch 24/1000\n",
      "1166/1166 [==============================] - 0s 293us/step - loss: 38741576224.4940 - val_loss: 37930506015.5616\n",
      "Epoch 25/1000\n",
      "1166/1166 [==============================] - 0s 278us/step - loss: 38704718203.3894 - val_loss: 37902237415.4521\n",
      "Epoch 26/1000\n",
      "1166/1166 [==============================] - 0s 291us/step - loss: 38673203038.4082 - val_loss: 37858552789.9178\n",
      "Epoch 27/1000\n",
      "1166/1166 [==============================] - 0s 280us/step - loss: 38627513068.2401 - val_loss: 37818473934.9041\n",
      "Epoch 28/1000\n",
      "1166/1166 [==============================] - 0s 261us/step - loss: 38582383157.5712 - val_loss: 37770501947.6164\n",
      "Epoch 29/1000\n",
      "1166/1166 [==============================] - 0s 273us/step - loss: 38536437169.8388 - val_loss: 37727205880.9863\n",
      "Epoch 30/1000\n",
      "1166/1166 [==============================] - 0s 274us/step - loss: 38495494836.0343 - val_loss: 37674673053.8082\n",
      "Epoch 31/1000\n",
      "1166/1166 [==============================] - 0s 259us/step - loss: 38438476657.7290 - val_loss: 37625195982.9041\n",
      "Epoch 32/1000\n",
      "1166/1166 [==============================] - 0s 256us/step - loss: 38388955476.7479 - val_loss: 37578728490.0822\n",
      "Epoch 33/1000\n",
      "1166/1166 [==============================] - 0s 296us/step - loss: 38345143589.3242 - val_loss: 37521954787.9452\n",
      "Epoch 34/1000\n",
      "1166/1166 [==============================] - 0s 293us/step - loss: 38305652307.4305 - val_loss: 37481728869.6986\n",
      "Epoch 35/1000\n",
      "1166/1166 [==============================] - 0s 283us/step - loss: 38234443199.8902 - val_loss: 37422164725.4795\n",
      "Epoch 36/1000\n",
      "1166/1166 [==============================] - 0s 294us/step - loss: 38191477993.6055 - val_loss: 37359502658.6301\n",
      "Epoch 37/1000\n",
      "1166/1166 [==============================] - 0s 282us/step - loss: 38119316850.6072 - val_loss: 37298678629.6986\n",
      "Epoch 38/1000\n",
      "1166/1166 [==============================] - 0s 287us/step - loss: 38073335337.2762 - val_loss: 37252946228.6027\n",
      "Epoch 39/1000\n",
      "1166/1166 [==============================] - 0s 268us/step - loss: 38002955258.7307 - val_loss: 37187936592.6575\n",
      "Epoch 40/1000\n",
      "1166/1166 [==============================] - ETA: 0s - loss: 37868409992.533 - 0s 253us/step - loss: 37951889857.6467 - val_loss: 37125301402.3014\n",
      "Epoch 41/1000\n",
      "1166/1166 [==============================] - 0s 244us/step - loss: 37873299311.9726 - val_loss: 37076071858.8493\n",
      "Epoch 42/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 37834355769.9623 - val_loss: 37007772629.9178\n",
      "Epoch 43/1000\n",
      "1166/1166 [==============================] - 0s 232us/step - loss: 37763308320.9331 - val_loss: 36942872632.1096\n",
      "Epoch 44/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 37707585265.5094 - val_loss: 36850376030.6849\n",
      "Epoch 45/1000\n",
      "1166/1166 [==============================] - 0s 230us/step - loss: 37640680161.7015 - val_loss: 36778466205.8082\n",
      "Epoch 46/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 37579235566.8748 - val_loss: 36710251477.9178\n",
      "Epoch 47/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 37482733908.7479 - val_loss: 36651354813.3699\n",
      "Epoch 48/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 37434623132.3225 - val_loss: 36583054714.7397\n",
      "Epoch 49/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 37341853608.1784 - val_loss: 36501602135.6712\n",
      "Epoch 50/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 37294609234.1132 - val_loss: 36436863088.2192\n",
      "Epoch 51/1000\n",
      "1166/1166 [==============================] - 0s 214us/step - loss: 37205072395.4168 - val_loss: 36364689239.6712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 37113441763.0189 - val_loss: 36291391936.8767\n",
      "Epoch 53/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 37049351535.0943 - val_loss: 36207951535.3425\n",
      "Epoch 54/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 36973335940.1715 - val_loss: 36118974968.9863\n",
      "Epoch 55/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 36861545442.1406 - val_loss: 36037602149.6986\n",
      "Epoch 56/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 36803456075.5266 - val_loss: 35951726872.5479\n",
      "Epoch 57/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 36699587715.7324 - val_loss: 35867996973.5890\n",
      "Epoch 58/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 36619351898.8954 - val_loss: 35791164065.3151\n",
      "Epoch 59/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 36529214065.2899 - val_loss: 35699497240.5479\n",
      "Epoch 60/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 36418653280.6038 - val_loss: 35608653824.0000\n",
      "Epoch 61/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 36378366795.0875 - val_loss: 35515982413.1507\n",
      "Epoch 62/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 36303314311.6844 - val_loss: 35436180185.4247\n",
      "Epoch 63/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 36159248173.2281 - val_loss: 35338621629.3699\n",
      "Epoch 64/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 36035850001.1252 - val_loss: 35250502950.5753\n",
      "Epoch 65/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 35985646776.4254 - val_loss: 35167759261.8082\n",
      "Epoch 66/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 35906424533.4065 - val_loss: 35054288839.8904\n",
      "Epoch 67/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 35796385061.3242 - val_loss: 34944761210.7397\n",
      "Epoch 68/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 35651065539.8422 - val_loss: 34840727075.0685\n",
      "Epoch 69/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 35573932274.3876 - val_loss: 34750429773.1507\n",
      "Epoch 70/1000\n",
      "1166/1166 [==============================] - 0s 230us/step - loss: 35468075520.8782 - val_loss: 34649761539.5069\n",
      "Epoch 71/1000\n",
      "1166/1166 [==============================] - 0s 230us/step - loss: 35413411492.2264 - val_loss: 34534296141.1507\n",
      "Epoch 72/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 35379480776.2333 - val_loss: 34446144329.6438\n",
      "Epoch 73/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 35241137318.8611 - val_loss: 34339098708.1644\n",
      "Epoch 74/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 35075870361.6878 - val_loss: 34233190933.0411\n",
      "Epoch 75/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 35026433693.2007 - val_loss: 34121379980.2740\n",
      "Epoch 76/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 34859558293.7359 - val_loss: 34010459346.4110\n",
      "Epoch 77/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 34740262258.6072 - val_loss: 33918583934.2466\n",
      "Epoch 78/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 34687079151.7530 - val_loss: 33815917946.7397\n",
      "Epoch 79/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 34595122103.9863 - val_loss: 33706255598.4658\n",
      "Epoch 80/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 34478364387.4580 - val_loss: 33588163401.6438\n",
      "Epoch 81/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 34303053644.8439 - val_loss: 33470575882.5205\n",
      "Epoch 82/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 34284514390.0652 - val_loss: 33344991596.7123\n",
      "Epoch 83/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 34076908890.0172 - val_loss: 33228589308.4931\n",
      "Epoch 84/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 34011762586.1269 - val_loss: 33093532686.0274\n",
      "Epoch 85/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 33870672778.3190 - val_loss: 32982914735.3425\n",
      "Epoch 86/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 33737280074.6484 - val_loss: 32852881548.2740\n",
      "Epoch 87/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 33582653562.9503 - val_loss: 32741039342.4658\n",
      "Epoch 88/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 33483379365.9828 - val_loss: 32627119566.9041\n",
      "Epoch 89/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 33380696741.9828 - val_loss: 32502526990.0274\n",
      "Epoch 90/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 33223322309.5986 - val_loss: 32375897102.0274\n",
      "Epoch 91/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 33151191127.8216 - val_loss: 32245763899.6164\n",
      "Epoch 92/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 33059579043.3482 - val_loss: 32115017868.2740\n",
      "Epoch 93/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 32826367968.3842 - val_loss: 31984304969.6438\n",
      "Epoch 94/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 32767042361.5232 - val_loss: 31853814012.4931\n",
      "Epoch 95/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 32605910232.0412 - val_loss: 31743602996.6027\n",
      "Epoch 96/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 32424337576.6175 - val_loss: 31598149351.4521\n",
      "Epoch 97/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 32329518292.5283 - val_loss: 31485923945.2055\n",
      "Epoch 98/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 32305189707.0875 - val_loss: 31336341616.2192\n",
      "Epoch 99/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 32169068118.9434 - val_loss: 31188762287.3425\n",
      "Epoch 100/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 32032516893.4202 - val_loss: 31055821557.4795\n",
      "Epoch 101/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 31940790531.9520 - val_loss: 30906404835.9452\n",
      "Epoch 102/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 31699837275.7736 - val_loss: 30776779313.0959\n",
      "Epoch 103/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 31611174244.5557 - val_loss: 30639178064.6575\n",
      "Epoch 104/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 31413778143.9451 - val_loss: 30497391265.3151\n",
      "Epoch 105/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 31306164921.3036 - val_loss: 30328098226.8493\n",
      "Epoch 106/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 31098605989.5437 - val_loss: 30186141387.3973\n",
      "Epoch 107/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 31017633602.3053 - val_loss: 30052880552.3288\n",
      "Epoch 108/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 30949017617.5643 - val_loss: 29917456552.3288\n",
      "Epoch 109/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 30631030882.3602 - val_loss: 29778748149.4795\n",
      "Epoch 110/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 30540326458.8405 - val_loss: 29631505758.6849\n",
      "Epoch 111/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 30478596327.8491 - val_loss: 29484948886.7945\n",
      "Epoch 112/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 30353208897.8662 - val_loss: 29341033429.9178\n",
      "Epoch 113/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 30184736571.2796 - val_loss: 29195385393.0959\n",
      "Epoch 114/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 30142924178.2230 - val_loss: 29041683105.3151\n",
      "Epoch 115/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 29871628352.9880 - val_loss: 28904138583.6712\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 170us/step - loss: 29819789652.7479 - val_loss: 28748644436.1644\n",
      "Epoch 117/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 29522397921.7015 - val_loss: 28592433993.6438\n",
      "Epoch 118/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 29373000965.7084 - val_loss: 28446227189.4795\n",
      "Epoch 119/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 29162140698.3465 - val_loss: 28307797342.6849\n",
      "Epoch 120/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 29023365084.8714 - val_loss: 28149462394.7397\n",
      "Epoch 121/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 29075200403.9794 - val_loss: 28002764323.0685\n",
      "Epoch 122/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 28850754157.7770 - val_loss: 27857105877.9178\n",
      "Epoch 123/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 28777111706.5660 - val_loss: 27710582727.8904\n",
      "Epoch 124/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 28573875191.2178 - val_loss: 27569165634.6301\n",
      "Epoch 125/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 28399669223.4099 - val_loss: 27404483850.5205\n",
      "Epoch 126/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 28233299479.7118 - val_loss: 27226698317.1507\n",
      "Epoch 127/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27954051258.1818 - val_loss: 27075234381.1507\n",
      "Epoch 128/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27857170881.6467 - val_loss: 26925665742.9041\n",
      "Epoch 129/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 27838092939.6364 - val_loss: 26787376955.6164\n",
      "Epoch 130/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27541370110.6827 - val_loss: 26621397553.0959\n",
      "Epoch 131/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27415231426.5249 - val_loss: 26455080398.9041\n",
      "Epoch 132/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 27270414469.4888 - val_loss: 26290622155.3973\n",
      "Epoch 133/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 27076414757.3242 - val_loss: 26130800948.6027\n",
      "Epoch 134/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 26995210420.9125 - val_loss: 25980155651.5069\n",
      "Epoch 135/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 26744615379.2110 - val_loss: 25797358381.5890\n",
      "Epoch 136/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 26551583513.9074 - val_loss: 25634153570.1918\n",
      "Epoch 137/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 26581240134.6964 - val_loss: 25472340360.7671\n",
      "Epoch 138/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 26443533492.9125 - val_loss: 25314465371.1781\n",
      "Epoch 139/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 26271752367.6432 - val_loss: 25140171593.6438\n",
      "Epoch 140/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 25890825354.7581 - val_loss: 24975970247.8904\n",
      "Epoch 141/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 25793758357.2967 - val_loss: 24800572878.9041\n",
      "Epoch 142/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 25723702268.4871 - val_loss: 24637676558.0274\n",
      "Epoch 143/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 25361860024.8645 - val_loss: 24466006577.0959\n",
      "Epoch 144/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 25250978733.4477 - val_loss: 24314118059.8356\n",
      "Epoch 145/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 25278998225.8937 - val_loss: 24162124982.3562\n",
      "Epoch 146/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 25020946122.8679 - val_loss: 23999821683.7260\n",
      "Epoch 147/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 24940608868.5557 - val_loss: 23830954068.1644\n",
      "Epoch 148/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 24962093621.5712 - val_loss: 23661529200.2192\n",
      "Epoch 149/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 24648009085.1458 - val_loss: 23498924817.5342\n",
      "Epoch 150/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 24559915735.1629 - val_loss: 23317845819.6164\n",
      "Epoch 151/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 24075993952.1647 - val_loss: 23147402730.9589\n",
      "Epoch 152/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 24139752864.2744 - val_loss: 22972696716.2740\n",
      "Epoch 153/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 23614585782.2298 - val_loss: 22793830287.7808\n",
      "Epoch 154/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 23767156964.3362 - val_loss: 22616375899.1781\n",
      "Epoch 155/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 23624777322.2642 - val_loss: 22456784278.7945\n",
      "Epoch 156/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 23619395731.5403 - val_loss: 22288962279.4521\n",
      "Epoch 157/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 23293770226.8268 - val_loss: 22123207778.1918\n",
      "Epoch 158/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 23092811584.5489 - val_loss: 21954725284.8219\n",
      "Epoch 159/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 22715444605.1458 - val_loss: 21782448212.1644\n",
      "Epoch 160/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 22627349902.7101 - val_loss: 21603278314.9589\n",
      "Epoch 161/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 22742562650.8954 - val_loss: 21429843757.5890\n",
      "Epoch 162/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 22503824239.9726 - val_loss: 21267387939.0685\n",
      "Epoch 163/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 22347339449.3036 - val_loss: 21083557326.9041\n",
      "Epoch 164/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 22178546192.6861 - val_loss: 20931289831.4521\n",
      "Epoch 165/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 21887156743.9039 - val_loss: 20761727747.5069\n",
      "Epoch 166/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 21662283431.7393 - val_loss: 20595893262.0274\n",
      "Epoch 167/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 21695729003.5815 - val_loss: 20420487518.6849\n",
      "Epoch 168/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 21473267002.4014 - val_loss: 20250930512.6575\n",
      "Epoch 169/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 21156611193.1938 - val_loss: 20071238305.3151\n",
      "Epoch 170/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 20962978547.2659 - val_loss: 19905355158.7945\n",
      "Epoch 171/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 21151978954.4288 - val_loss: 19741458095.3425\n",
      "Epoch 172/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 20886609087.4511 - val_loss: 19583664983.6712\n",
      "Epoch 173/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 20652679210.1544 - val_loss: 19404628865.7534\n",
      "Epoch 174/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 20450378075.7736 - val_loss: 19225384230.5753\n",
      "Epoch 175/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 20570985670.4768 - val_loss: 19052735810.6301\n",
      "Epoch 176/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 19964439139.2384 - val_loss: 18874342568.3288\n",
      "Epoch 177/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 20068665214.0240 - val_loss: 18723934909.3699\n",
      "Epoch 178/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 19892163129.0840 - val_loss: 18538334348.2740\n",
      "Epoch 179/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 19791018315.9657 - val_loss: 18375517632.8767\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 19461376005.2693 - val_loss: 18212048980.1644\n",
      "Epoch 181/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 19128137378.4700 - val_loss: 18044613449.6438\n",
      "Epoch 182/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 19240396220.3774 - val_loss: 17865870560.4384\n",
      "Epoch 183/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 18991145026.7444 - val_loss: 17689779410.4110\n",
      "Epoch 184/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 18710422570.1544 - val_loss: 17534383875.5069\n",
      "Epoch 185/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 18755951010.0309 - val_loss: 17376832526.0274\n",
      "Epoch 186/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 18702904772.2813 - val_loss: 17206239863.2329\n",
      "Epoch 187/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 18578751477.4614 - val_loss: 17032193220.3836\n",
      "Epoch 188/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 18272651776.8782 - val_loss: 16860610363.6164\n",
      "Epoch 189/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 17743068005.4340 - val_loss: 16692732002.1918\n",
      "Epoch 190/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 17870265394.9365 - val_loss: 16520346427.6164\n",
      "Epoch 191/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 17439524347.6089 - val_loss: 16358062304.4384\n",
      "Epoch 192/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 17544918544.6861 - val_loss: 16201271899.1781\n",
      "Epoch 193/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 17331110411.4168 - val_loss: 16035656255.1233\n",
      "Epoch 194/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 17085400731.4443 - val_loss: 15874133763.5068\n",
      "Epoch 195/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 17004415845.4340 - val_loss: 15701444818.4110\n",
      "Epoch 196/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 16910474267.2247 - val_loss: 15550282261.0411\n",
      "Epoch 197/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 16833212547.7324 - val_loss: 15373647984.2192\n",
      "Epoch 198/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 16751345003.5815 - val_loss: 15217474097.0959\n",
      "Epoch 199/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 16426022478.1612 - val_loss: 15058246501.6986\n",
      "Epoch 200/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 16176077291.8010 - val_loss: 14891430617.4247\n",
      "Epoch 201/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 16501500751.4786 - val_loss: 14741368383.1233\n",
      "Epoch 202/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 16207277707.6364 - val_loss: 14577287448.5479\n",
      "Epoch 203/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 15847112489.7153 - val_loss: 14426137038.9041\n",
      "Epoch 204/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 16141433794.5249 - val_loss: 14265080495.3425\n",
      "Epoch 205/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 15503336009.7702 - val_loss: 14098414016.8767\n",
      "Epoch 206/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 15414237775.9177 - val_loss: 13930568353.3151\n",
      "Epoch 207/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 15396496303.2041 - val_loss: 13787909765.2603\n",
      "Epoch 208/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 14944981345.9211 - val_loss: 13636821356.7123\n",
      "Epoch 209/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 15028116323.6775 - val_loss: 13481529989.2603\n",
      "Epoch 210/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 14905442748.3774 - val_loss: 13326878762.0822\n",
      "Epoch 211/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 14826006972.3774 - val_loss: 13174877562.7397\n",
      "Epoch 212/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 14594819892.2539 - val_loss: 13016999557.2603\n",
      "Epoch 213/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 14609322101.6810 - val_loss: 12876961385.2055\n",
      "Epoch 214/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 14616157361.3997 - val_loss: 12728895649.3151\n",
      "Epoch 215/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 14232002873.5232 - val_loss: 12586167800.9863\n",
      "Epoch 216/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 14204089621.5163 - val_loss: 12450130635.3973\n",
      "Epoch 217/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 13848043498.9228 - val_loss: 12289946231.2329\n",
      "Epoch 218/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 13841185173.7358 - val_loss: 12143638892.7123\n",
      "Epoch 219/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 13669204772.4460 - val_loss: 12009691704.1096\n",
      "Epoch 220/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 13412016129.7564 - val_loss: 11866841130.0822\n",
      "Epoch 221/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 13497753146.8405 - val_loss: 11731874479.3425\n",
      "Epoch 222/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 13409590800.6861 - val_loss: 11605674923.8356\n",
      "Epoch 223/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 13346458539.6913 - val_loss: 11456474729.2055\n",
      "Epoch 224/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 12745080993.5918 - val_loss: 11309340244.1644\n",
      "Epoch 225/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 12841395526.6964 - val_loss: 11167641010.8493\n",
      "Epoch 226/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 12832823623.5746 - val_loss: 11041942205.3699\n",
      "Epoch 227/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 12525495889.6741 - val_loss: 10904041612.2740\n",
      "Epoch 228/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 12450575878.1475 - val_loss: 10770966044.0548\n",
      "Epoch 229/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 12469635792.1372 - val_loss: 10628728663.6712\n",
      "Epoch 230/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 12593554962.4425 - val_loss: 10505671771.1781\n",
      "Epoch 231/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 12224780400.4117 - val_loss: 10361148780.7123\n",
      "Epoch 232/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11937571895.3276 - val_loss: 10243182963.7260\n",
      "Epoch 233/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 11768067198.4631 - val_loss: 10112944997.6986\n",
      "Epoch 234/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 11914838162.6621 - val_loss: 9997682884.3836\n",
      "Epoch 235/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 11674262438.4220 - val_loss: 9873721799.8904\n",
      "Epoch 236/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 11405444837.2144 - val_loss: 9749734989.1507\n",
      "Epoch 237/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 11557486200.3156 - val_loss: 9630452764.0548\n",
      "Epoch 238/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 11241934170.0172 - val_loss: 9501460073.2055\n",
      "Epoch 239/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 11091033109.0772 - val_loss: 9384001395.7260\n",
      "Epoch 240/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 11274220447.3962 - val_loss: 9283392743.4521\n",
      "Epoch 241/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 11173437685.9005 - val_loss: 9197483414.7945\n",
      "Epoch 242/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 11019142847.4511 - val_loss: 9072149987.9452\n",
      "Epoch 243/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 10833876107.6364 - val_loss: 8967892550.1370\n",
      "Epoch 244/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 154us/step - loss: 10519641878.3945 - val_loss: 8851015855.3425\n",
      "Epoch 245/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 10729744197.8182 - val_loss: 8726745880.5479\n",
      "Epoch 246/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 10604614580.4734 - val_loss: 8626965588.1644\n",
      "Epoch 247/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10566412029.8045 - val_loss: 8519378439.0137\n",
      "Epoch 248/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 10120069286.8611 - val_loss: 8424871290.7397\n",
      "Epoch 249/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 10223498903.9314 - val_loss: 8322915559.4521\n",
      "Epoch 250/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 10201546813.4751 - val_loss: 8208555050.0822\n",
      "Epoch 251/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10052489651.5952 - val_loss: 8127639474.8493\n",
      "Epoch 252/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9862322466.6895 - val_loss: 8039944135.8904\n",
      "Epoch 253/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 10094150601.5506 - val_loss: 7956198933.0411\n",
      "Epoch 254/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 10346163853.3928 - val_loss: 7857824866.1918\n",
      "Epoch 255/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 10078231998.1338 - val_loss: 7762214806.7945\n",
      "Epoch 256/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 9902280055.8765 - val_loss: 7685972746.5205\n",
      "Epoch 257/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9858487079.5197 - val_loss: 7615471524.8219\n",
      "Epoch 258/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9666387121.3997 - val_loss: 7531019516.4932\n",
      "Epoch 259/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 9608953057.7015 - val_loss: 7443345912.9863\n",
      "Epoch 260/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9196341716.9674 - val_loss: 7353573628.4932\n",
      "Epoch 261/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 9520960123.8285 - val_loss: 7273400260.3836\n",
      "Epoch 262/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9136366726.3671 - val_loss: 7214834807.2329\n",
      "Epoch 263/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 9703961268.0343 - val_loss: 7135775214.4658\n",
      "Epoch 264/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 9598561503.0669 - val_loss: 7068498512.6575\n",
      "Epoch 265/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 9469403540.4185 - val_loss: 7003846214.1370\n",
      "Epoch 266/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 9198544430.9846 - val_loss: 6932773561.8630\n",
      "Epoch 267/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 9194678632.0686 - val_loss: 6868474557.3699\n",
      "Epoch 268/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 9251509183.0120 - val_loss: 6800639270.5753\n",
      "Epoch 269/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8832596556.4048 - val_loss: 6738826927.3425\n",
      "Epoch 270/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 9406196743.9039 - val_loss: 6686704657.5342\n",
      "Epoch 271/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8982943113.4408 - val_loss: 6639023230.2466\n",
      "Epoch 272/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8773059674.4563 - val_loss: 6584192007.0137\n",
      "Epoch 273/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8945373945.4134 - val_loss: 6534872803.9452\n",
      "Epoch 274/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8822325400.8096 - val_loss: 6490502014.2466\n",
      "Epoch 275/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8569028958.4082 - val_loss: 6439725824.0000\n",
      "Epoch 276/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8478600954.2916 - val_loss: 6407378000.6575\n",
      "Epoch 277/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9134836912.0823 - val_loss: 6364052241.5342\n",
      "Epoch 278/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8993548439.4923 - val_loss: 6314030283.3973\n",
      "Epoch 279/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8657233784.7547 - val_loss: 6283957949.3699\n",
      "Epoch 280/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 9204638121.9348 - val_loss: 6242071190.7945\n",
      "Epoch 281/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8964434364.3774 - val_loss: 6206434907.1781\n",
      "Epoch 282/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8555876725.2419 - val_loss: 6170548960.4384\n",
      "Epoch 283/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8465638529.0978 - val_loss: 6139385140.6027\n",
      "Epoch 284/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8572551521.0429 - val_loss: 6116163082.5205\n",
      "Epoch 285/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8567375708.6518 - val_loss: 6096628883.2877\n",
      "Epoch 286/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8647523128.6449 - val_loss: 6064258756.3836\n",
      "Epoch 287/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8470641389.5575 - val_loss: 6047507894.3562\n",
      "Epoch 288/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8535916251.5540 - val_loss: 6021279456.4384\n",
      "Epoch 289/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8779502189.7770 - val_loss: 5991827796.1644\n",
      "Epoch 290/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8492864979.2110 - val_loss: 5966723976.7671\n",
      "Epoch 291/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8972263023.5334 - val_loss: 5951028686.9041\n",
      "Epoch 292/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8991322471.1904 - val_loss: 5928697098.5205\n",
      "Epoch 293/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8249300805.8182 - val_loss: 5913327033.8630\n",
      "Epoch 294/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8603961589.9005 - val_loss: 5903831243.3973\n",
      "Epoch 295/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8451711246.4906 - val_loss: 5883697811.2877\n",
      "Epoch 296/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8331403889.2899 - val_loss: 5871902039.6712\n",
      "Epoch 297/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8480865617.6741 - val_loss: 5856061131.3973\n",
      "Epoch 298/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8465081522.2779 - val_loss: 5845711528.3288\n",
      "Epoch 299/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8250908306.4425 - val_loss: 5832916129.3151\n",
      "Epoch 300/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8620306891.3070 - val_loss: 5827351601.0959\n",
      "Epoch 301/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8406402968.3705 - val_loss: 5817896483.0685\n",
      "Epoch 302/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8492979315.0463 - val_loss: 5805044497.5342\n",
      "Epoch 303/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8132663910.7513 - val_loss: 5791047795.7260\n",
      "Epoch 304/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8359629225.0566 - val_loss: 5780453418.0822\n",
      "Epoch 305/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8497882013.6398 - val_loss: 5768006105.4247\n",
      "Epoch 306/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8481594652.5420 - val_loss: 5761172494.0274\n",
      "Epoch 307/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8493608599.9314 - val_loss: 5756594954.5205\n",
      "Epoch 308/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8392905027.1835 - val_loss: 5751763315.7260\n",
      "Epoch 309/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 156us/step - loss: 8673537533.3654 - val_loss: 5744033206.3562\n",
      "Epoch 310/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8471544436.3636 - val_loss: 5744690828.2740\n",
      "Epoch 311/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8473072445.9142 - val_loss: 5737452400.2192\n",
      "Epoch 312/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8256667160.1509 - val_loss: 5731380977.9726\n",
      "Epoch 313/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8838744981.7358 - val_loss: 5733981696.0000\n",
      "Epoch 314/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8395634126.8199 - val_loss: 5726549482.9589\n",
      "Epoch 315/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8287724373.6261 - val_loss: 5721190926.0274\n",
      "Epoch 316/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 9114411245.1184 - val_loss: 5719272924.9315\n",
      "Epoch 317/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8345358937.5780 - val_loss: 5714255896.5479\n",
      "Epoch 318/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8378679413.6810 - val_loss: 5713524069.6986\n",
      "Epoch 319/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8427571393.6467 - val_loss: 5710435640.1096\n",
      "Epoch 320/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8369308741.3791 - val_loss: 5705268851.7260\n",
      "Epoch 321/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8386647970.0309 - val_loss: 5701436598.3562\n",
      "Epoch 322/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 8302247898.2367 - val_loss: 5696544796.0548\n",
      "Epoch 323/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8350734196.8027 - val_loss: 5693088347.1781\n",
      "Epoch 324/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8471068840.6175 - val_loss: 5697970204.0548\n",
      "Epoch 325/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8138886695.5197 - val_loss: 5688900222.2466\n",
      "Epoch 326/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8372261903.8079 - val_loss: 5684409957.6986\n",
      "Epoch 327/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8590563669.6261 - val_loss: 5682725460.1644\n",
      "Epoch 328/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8535361466.6209 - val_loss: 5680781578.5205\n",
      "Epoch 329/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8094334891.2521 - val_loss: 5674056903.8904\n",
      "Epoch 330/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8512357539.3482 - val_loss: 5674773258.5205\n",
      "Epoch 331/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8372671952.5763 - val_loss: 5681456513.7534\n",
      "Epoch 332/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8467639076.4460 - val_loss: 5681489471.1233\n",
      "Epoch 333/1000\n",
      "1166/1166 [==============================] - 0s 258us/step - loss: 8018105811.2110 - val_loss: 5677209592.9863\n",
      "Epoch 334/1000\n",
      "1166/1166 [==============================] - 0s 322us/step - loss: 8418900732.4871 - val_loss: 5677505097.6438\n",
      "Epoch 335/1000\n",
      "1166/1166 [==============================] - 0s 303us/step - loss: 8387979448.4254 - val_loss: 5673609286.1370\n",
      "Epoch 336/1000\n",
      "1166/1166 [==============================] - 0s 260us/step - loss: 8366834056.5626 - val_loss: 5675589975.6712\n",
      "Epoch 337/1000\n",
      "1166/1166 [==============================] - 0s 342us/step - loss: 8181881718.9983 - val_loss: 5674813040.2192\n",
      "Epoch 338/1000\n",
      "1166/1166 [==============================] - 0s 277us/step - loss: 8659657635.7873 - val_loss: 5679416516.3836\n",
      "Epoch 339/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 8740734528.1098 - val_loss: 5676016415.5616\n",
      "Epoch 340/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 8202369918.9022 - val_loss: 5674233533.3699\n",
      "Epoch 341/1000\n",
      "1166/1166 [==============================] - 0s 235us/step - loss: 8094637951.7804 - val_loss: 5673854744.5479\n",
      "Epoch 342/1000\n",
      "1166/1166 [==============================] - 0s 275us/step - loss: 8327477236.5832 - val_loss: 5671196538.7397\n",
      "Epoch 343/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 8587718143.1218 - val_loss: 5670050647.6712\n",
      "Epoch 344/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 8369610637.8319 - val_loss: 5669239800.9863\n",
      "Epoch 345/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 8477117913.3585 - val_loss: 5666358198.3562\n",
      "Epoch 346/1000\n",
      "1166/1166 [==============================] - 0s 291us/step - loss: 8063958830.9846 - val_loss: 5664280632.1096\n",
      "Epoch 347/1000\n",
      "1166/1166 [==============================] - 0s 263us/step - loss: 8620664393.5506 - val_loss: 5666852225.7534\n",
      "Epoch 348/1000\n",
      "1166/1166 [==============================] - 0s 286us/step - loss: 8624946190.9297 - val_loss: 5666983143.4521\n",
      "Epoch 349/1000\n",
      "1166/1166 [==============================] - 0s 249us/step - loss: 8730182280.1235 - val_loss: 5670348302.0274\n",
      "Epoch 350/1000\n",
      "1166/1166 [==============================] - 0s 253us/step - loss: 8252060394.4837 - val_loss: 5667545852.4932\n",
      "Epoch 351/1000\n",
      "1166/1166 [==============================] - 0s 242us/step - loss: 8692242270.4082 - val_loss: 5667268110.0274\n",
      "Epoch 352/1000\n",
      "1166/1166 [==============================] - 0s 250us/step - loss: 8522682348.6792 - val_loss: 5666749980.0548\n",
      "Epoch 353/1000\n",
      "1166/1166 [==============================] - 0s 282us/step - loss: 8409423695.4786 - val_loss: 5665266533.6986\n",
      "Epoch 354/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 8507291392.4391 - val_loss: 5665732937.6438\n",
      "Epoch 355/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8294845959.9039 - val_loss: 5661296447.1233\n",
      "Epoch 356/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8330200388.5009 - val_loss: 5660402800.2192\n",
      "Epoch 357/1000\n",
      "1166/1166 [==============================] - 0s 263us/step - loss: 8479057891.0189 - val_loss: 5655194567.8904\n",
      "Epoch 358/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 8999140070.9708 - val_loss: 5654828754.4110\n",
      "Epoch 359/1000\n",
      "1166/1166 [==============================] - 0s 223us/step - loss: 8548305356.1852 - val_loss: 5655891708.4932\n",
      "Epoch 360/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 8180239065.7976 - val_loss: 5653509246.2466\n",
      "Epoch 361/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8482977836.7890 - val_loss: 5656478541.1507\n",
      "Epoch 362/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 8383216913.1252 - val_loss: 5658612546.6301\n",
      "Epoch 363/1000\n",
      "1166/1166 [==============================] - 0s 213us/step - loss: 8729635162.8954 - val_loss: 5659697653.4795\n",
      "Epoch 364/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 8281522930.3877 - val_loss: 5659127878.1370\n",
      "Epoch 365/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 8028864977.4545 - val_loss: 5658357121.7534\n",
      "Epoch 366/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 8307758160.7959 - val_loss: 5655724887.6712\n",
      "Epoch 367/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8708925056.2196 - val_loss: 5655423684.3836\n",
      "Epoch 368/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8435810697.4408 - val_loss: 5659459275.3973\n",
      "Epoch 369/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8036603241.8250 - val_loss: 5656984519.8904\n",
      "Epoch 370/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8426297763.7873 - val_loss: 5657840447.1233\n",
      "Epoch 371/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8680884213.4614 - val_loss: 5657788654.4658\n",
      "Epoch 372/1000\n",
      "1166/1166 [==============================] - 0s 236us/step - loss: 8388253340.3225 - val_loss: 5659622778.7397\n",
      "Epoch 373/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 8723935329.4820 - val_loss: 5659120885.4795\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 246us/step - loss: 8744403174.0926 - val_loss: 5660749438.2466\n",
      "Epoch 375/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8398859725.0635 - val_loss: 5660803899.6164\n",
      "Epoch 376/1000\n",
      "1166/1166 [==============================] - 0s 258us/step - loss: 8446672142.4906 - val_loss: 5660152856.5479\n",
      "Epoch 377/1000\n",
      "1166/1166 [==============================] - 0s 248us/step - loss: 8524934714.8405 - val_loss: 5661215772.0548\n",
      "Epoch 378/1000\n",
      "1166/1166 [==============================] - 0s 245us/step - loss: 8438570027.9108 - val_loss: 5661428893.8082\n",
      "Epoch 379/1000\n",
      "1166/1166 [==============================] - 0s 262us/step - loss: 8616836596.5832 - val_loss: 5660456163.9452\n",
      "Epoch 380/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 8243281438.7376 - val_loss: 5659478520.9863\n",
      "Epoch 381/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8678478807.6021 - val_loss: 5657983495.0137\n",
      "Epoch 382/1000\n",
      "1166/1166 [==============================] - 0s 241us/step - loss: 8320569612.7341 - val_loss: 5658727269.6986\n",
      "Epoch 383/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 8299498585.5780 - val_loss: 5655790655.1233\n",
      "Epoch 384/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8451436839.9588 - val_loss: 5655130676.6027\n",
      "Epoch 385/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8430012918.3396 - val_loss: 5654160545.3151\n",
      "Epoch 386/1000\n",
      "1166/1166 [==============================] - 0s 221us/step - loss: 8565231096.0961 - val_loss: 5654986036.6027\n",
      "Epoch 387/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8449882929.1801 - val_loss: 5653661085.8082\n",
      "Epoch 388/1000\n",
      "1166/1166 [==============================] - 0s 297us/step - loss: 8780446711.2178 - val_loss: 5654719740.4932\n",
      "Epoch 389/1000\n",
      "1166/1166 [==============================] - 0s 224us/step - loss: 8361078285.1732 - val_loss: 5654245091.9452\n",
      "Epoch 390/1000\n",
      "1166/1166 [==============================] - 0s 222us/step - loss: 8780380933.7084 - val_loss: 5652156668.4932\n",
      "Epoch 391/1000\n",
      "1166/1166 [==============================] - 0s 251us/step - loss: 8483064377.0840 - val_loss: 5652448557.5890\n",
      "Epoch 392/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 8087662024.6724 - val_loss: 5651362444.2740\n",
      "Epoch 393/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 8279395000.4254 - val_loss: 5650173520.6575\n",
      "Epoch 394/1000\n",
      "1166/1166 [==============================] - 0s 237us/step - loss: 8505293917.9691 - val_loss: 5650094613.0411\n",
      "Epoch 395/1000\n",
      "1166/1166 [==============================] - 0s 226us/step - loss: 8699500717.8868 - val_loss: 5651656079.7808\n",
      "Epoch 396/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 8211130764.9537 - val_loss: 5651367196.0548\n",
      "Epoch 397/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8895679190.2847 - val_loss: 5649626595.9452\n",
      "Epoch 398/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 8334904195.2933 - val_loss: 5650864534.7945\n",
      "Epoch 399/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 8207304043.5815 - val_loss: 5650304308.6027\n",
      "Epoch 400/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 7996526606.0515 - val_loss: 5651472555.8356\n",
      "Epoch 401/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8403873140.3636 - val_loss: 5652169163.3973\n",
      "Epoch 402/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8348515064.9743 - val_loss: 5649356238.9041\n",
      "Epoch 403/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8462911790.1063 - val_loss: 5649713218.6301\n",
      "Epoch 404/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8312390975.6707 - val_loss: 5648051603.2877\n",
      "Epoch 405/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8245776608.8233 - val_loss: 5648675496.3288\n",
      "Epoch 406/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 8354200623.8628 - val_loss: 5645818283.8356\n",
      "Epoch 407/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8362279634.3328 - val_loss: 5647516303.7808\n",
      "Epoch 408/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8373928055.8765 - val_loss: 5649578916.8219\n",
      "Epoch 409/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 8360381656.0412 - val_loss: 5650978107.6164\n",
      "Epoch 410/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8465422814.1887 - val_loss: 5651106893.1507\n",
      "Epoch 411/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 8431118862.0515 - val_loss: 5654541631.1233\n",
      "Epoch 412/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8187162005.7358 - val_loss: 5656174549.9178\n",
      "Epoch 413/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8664904637.2556 - val_loss: 5656025901.5890\n",
      "Epoch 414/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8542110433.7015 - val_loss: 5647849237.0411\n",
      "Epoch 415/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8286617671.5746 - val_loss: 5650519734.3562\n",
      "Epoch 416/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8149703257.5780 - val_loss: 5652161981.3699\n",
      "Epoch 417/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8471692373.1870 - val_loss: 5653683620.8219\n",
      "Epoch 418/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8564829916.4322 - val_loss: 5650307187.7260\n",
      "Epoch 419/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8478711665.7290 - val_loss: 5650321162.5205\n",
      "Epoch 420/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8935154875.0600 - val_loss: 5654452553.6438\n",
      "Epoch 421/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8512486860.1852 - val_loss: 5653363754.0822\n",
      "Epoch 422/1000\n",
      "1166/1166 [==============================] - 0s 206us/step - loss: 8241356652.4597 - val_loss: 5649047194.3014\n",
      "Epoch 423/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8436216410.4563 - val_loss: 5653886656.8767\n",
      "Epoch 424/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8190006316.7890 - val_loss: 5656588968.3288\n",
      "Epoch 425/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 8307540642.4700 - val_loss: 5656193735.8904\n",
      "Epoch 426/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8421728354.3602 - val_loss: 5655997131.3973\n",
      "Epoch 427/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8324773131.8559 - val_loss: 5655412276.6027\n",
      "Epoch 428/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8533815623.5746 - val_loss: 5655402517.0411\n",
      "Epoch 429/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8478726453.1321 - val_loss: 5657916542.2466\n",
      "Epoch 430/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8417549070.4906 - val_loss: 5657643512.9863\n",
      "Epoch 431/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8318050354.9365 - val_loss: 5657835050.0822\n",
      "Epoch 432/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8206296699.8285 - val_loss: 5657687334.5753\n",
      "Epoch 433/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8417613010.7719 - val_loss: 5656680802.1918\n",
      "Epoch 434/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8860543318.5043 - val_loss: 5659579598.9041\n",
      "Epoch 435/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8518272426.8130 - val_loss: 5663290897.5342\n",
      "Epoch 436/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8033890758.0377 - val_loss: 5664016194.6301\n",
      "Epoch 437/1000\n",
      "1166/1166 [==============================] - 0s 211us/step - loss: 8486055387.9931 - val_loss: 5660446011.6164\n",
      "Epoch 438/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8368186692.9400 - val_loss: 5658658051.5068\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 217us/step - loss: 8300091024.0274 - val_loss: 5660915501.5890\n",
      "Epoch 440/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 8652008325.0497 - val_loss: 5659043387.6164\n",
      "Epoch 441/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 8542231898.8954 - val_loss: 5657348341.4795\n",
      "Epoch 442/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8186169576.7273 - val_loss: 5655224681.2055\n",
      "Epoch 443/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 8666039761.4545 - val_loss: 5655837071.7808\n",
      "Epoch 444/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8620151877.3791 - val_loss: 5657740330.0822\n",
      "Epoch 445/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8714661373.3654 - val_loss: 5658165724.9315\n",
      "Epoch 446/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8335502869.9554 - val_loss: 5661139466.5205\n",
      "Epoch 447/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8369107127.5472 - val_loss: 5658210942.2466\n",
      "Epoch 448/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8290186117.9280 - val_loss: 5659087549.3699\n",
      "Epoch 449/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8423483467.5266 - val_loss: 5657398619.1781\n",
      "Epoch 450/1000\n",
      "1166/1166 [==============================] - 0s 239us/step - loss: 8723783328.7136 - val_loss: 5657694968.9863\n",
      "Epoch 451/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8626329561.3585 - val_loss: 5656216414.6849\n",
      "Epoch 452/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 8801719887.9177 - val_loss: 5657269451.3973\n",
      "Epoch 453/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8412498863.2041 - val_loss: 5656531336.7671\n",
      "Epoch 454/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 8321620524.7890 - val_loss: 5656467911.8904\n",
      "Epoch 455/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8432884177.4545 - val_loss: 5654658307.5068\n",
      "Epoch 456/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8234077204.6381 - val_loss: 5656093432.9863\n",
      "Epoch 457/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8727275030.8336 - val_loss: 5658788432.6575\n",
      "Epoch 458/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8257984487.4099 - val_loss: 5659493958.1370\n",
      "Epoch 459/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8223686476.4048 - val_loss: 5658191759.7808\n",
      "Epoch 460/1000\n",
      "1166/1166 [==============================] - 0s 220us/step - loss: 8244998439.9588 - val_loss: 5659830871.6712\n",
      "Epoch 461/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8610555017.0017 - val_loss: 5657617141.4795\n",
      "Epoch 462/1000\n",
      "1166/1166 [==============================] - 0s 243us/step - loss: 8394541903.4786 - val_loss: 5657472953.8630\n",
      "Epoch 463/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 8305608602.1269 - val_loss: 5656370351.3425\n",
      "Epoch 464/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8191472869.8731 - val_loss: 5656785330.8493\n",
      "Epoch 465/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8442519858.4974 - val_loss: 5654476596.6027\n",
      "Epoch 466/1000\n",
      "1166/1166 [==============================] - 0s 197us/step - loss: 8562114596.0069 - val_loss: 5652864659.2877\n",
      "Epoch 467/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8392341751.6569 - val_loss: 5653174005.4795\n",
      "Epoch 468/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8293675563.0326 - val_loss: 5655122432.0000\n",
      "Epoch 469/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8366594561.7564 - val_loss: 5653434206.6849\n",
      "Epoch 470/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8306314008.1509 - val_loss: 5653051721.6438\n",
      "Epoch 471/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8447765754.2916 - val_loss: 5652779891.7260\n",
      "Epoch 472/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8609672711.0257 - val_loss: 5651769014.3562\n",
      "Epoch 473/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8530200065.7564 - val_loss: 5652371757.5890\n",
      "Epoch 474/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8152706109.4751 - val_loss: 5654168064.0000\n",
      "Epoch 475/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8635342364.9811 - val_loss: 5657569181.8082\n",
      "Epoch 476/1000\n",
      "1166/1166 [==============================] - 0s 178us/step - loss: 8305621727.0669 - val_loss: 5650446974.2466\n",
      "Epoch 477/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8295183165.4751 - val_loss: 5648911528.3288\n",
      "Epoch 478/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8368133098.9228 - val_loss: 5648884357.2603\n",
      "Epoch 479/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8468432370.8268 - val_loss: 5646349024.4384\n",
      "Epoch 480/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8606356602.0720 - val_loss: 5648463893.0411\n",
      "Epoch 481/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8279084327.0806 - val_loss: 5649205665.3151\n",
      "Epoch 482/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8541941315.6226 - val_loss: 5648161914.7397\n",
      "Epoch 483/1000\n",
      "1166/1166 [==============================] - 0s 228us/step - loss: 7949783732.0343 - val_loss: 5646414385.0959\n",
      "Epoch 484/1000\n",
      "1166/1166 [==============================] - 0s 227us/step - loss: 8011389259.0875 - val_loss: 5643512516.3836\n",
      "Epoch 485/1000\n",
      "1166/1166 [==============================] - 0s 217us/step - loss: 8358630141.8045 - val_loss: 5646646826.0822\n",
      "Epoch 486/1000\n",
      "1166/1166 [==============================] - 0s 219us/step - loss: 8473583920.7410 - val_loss: 5644770177.7534\n",
      "Epoch 487/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 7942509427.4854 - val_loss: 5645732387.0685\n",
      "Epoch 488/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8368721436.9811 - val_loss: 5644815773.8082\n",
      "Epoch 489/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8502821203.4305 - val_loss: 5643195532.2740\n",
      "Epoch 490/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8637298018.7993 - val_loss: 5647273450.9589\n",
      "Epoch 491/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8533810825.8799 - val_loss: 5647856808.3288\n",
      "Epoch 492/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8800688415.1767 - val_loss: 5645344571.6164\n",
      "Epoch 493/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 8641870204.2676 - val_loss: 5645216985.4247\n",
      "Epoch 494/1000\n",
      "1166/1166 [==============================] - 0s 195us/step - loss: 8460429382.2573 - val_loss: 5647084729.8630\n",
      "Epoch 495/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8442130251.9657 - val_loss: 5644689450.0822\n",
      "Epoch 496/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8720739940.9949 - val_loss: 5646854599.8904\n",
      "Epoch 497/1000\n",
      "1166/1166 [==============================] - 0s 234us/step - loss: 8243741693.3654 - val_loss: 5647422709.4795\n",
      "Epoch 498/1000\n",
      "1166/1166 [==============================] - 0s 229us/step - loss: 8339939404.4048 - val_loss: 5649209470.2466\n",
      "Epoch 499/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8423409667.0738 - val_loss: 5644929858.6301\n",
      "Epoch 500/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 8215504484.9949 - val_loss: 5641477183.1233\n",
      "Epoch 501/1000\n",
      "1166/1166 [==============================] - 0s 202us/step - loss: 8255159161.1938 - val_loss: 5641565738.0822\n",
      "Epoch 502/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8394925558.3396 - val_loss: 5641653591.6712\n",
      "Epoch 503/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8502156621.7221 - val_loss: 5641857234.4110\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 163us/step - loss: 8113844675.4031 - val_loss: 5639226774.7945\n",
      "Epoch 505/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8315723879.6295 - val_loss: 5640303019.8356\n",
      "Epoch 506/1000\n",
      "1166/1166 [==============================] - 0s 215us/step - loss: 8647840244.5832 - val_loss: 5643734857.6438\n",
      "Epoch 507/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8183344816.5214 - val_loss: 5642915461.2603\n",
      "Epoch 508/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8540738402.7993 - val_loss: 5642807955.2877\n",
      "Epoch 509/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8655668007.9588 - val_loss: 5646855438.0274\n",
      "Epoch 510/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8451426306.6346 - val_loss: 5645889679.7808\n",
      "Epoch 511/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8354522691.6226 - val_loss: 5644357993.2055\n",
      "Epoch 512/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8468676550.9160 - val_loss: 5644220163.5068\n",
      "Epoch 513/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8816145903.7530 - val_loss: 5645320458.5205\n",
      "Epoch 514/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8278850660.1166 - val_loss: 5644291580.4932\n",
      "Epoch 515/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8415812117.9554 - val_loss: 5644098069.0411\n",
      "Epoch 516/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8285284864.0000 - val_loss: 5642289818.3014\n",
      "Epoch 517/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8766520765.2556 - val_loss: 5646391443.2877\n",
      "Epoch 518/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8549226917.5437 - val_loss: 5645322078.6849\n",
      "Epoch 519/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8402362961.6741 - val_loss: 5645409006.4658\n",
      "Epoch 520/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8302555656.7822 - val_loss: 5649335660.7123\n",
      "Epoch 521/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8428505541.5986 - val_loss: 5648073742.0274\n",
      "Epoch 522/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8254030219.1973 - val_loss: 5646051499.8356\n",
      "Epoch 523/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8493167978.7033 - val_loss: 5651329038.0274\n",
      "Epoch 524/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8269803009.7564 - val_loss: 5651465819.1781\n",
      "Epoch 525/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8429973316.0618 - val_loss: 5649784355.0685\n",
      "Epoch 526/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8143086829.1184 - val_loss: 5650938581.9178\n",
      "Epoch 527/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8369534747.6638 - val_loss: 5649812697.4247\n",
      "Epoch 528/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8236785906.3877 - val_loss: 5649667717.2603\n",
      "Epoch 529/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8495101415.4099 - val_loss: 5649527513.4247\n",
      "Epoch 530/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8137857640.5077 - val_loss: 5650570892.2740\n",
      "Epoch 531/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8334655096.3156 - val_loss: 5648319263.5616\n",
      "Epoch 532/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8626120260.5009 - val_loss: 5651415499.3973\n",
      "Epoch 533/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8782931477.9554 - val_loss: 5652368545.3151\n",
      "Epoch 534/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8264756844.8988 - val_loss: 5651864842.5205\n",
      "Epoch 535/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8807906610.4974 - val_loss: 5651193238.7945\n",
      "Epoch 536/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8012949148.3225 - val_loss: 5650876612.3836\n",
      "Epoch 537/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8540706486.6690 - val_loss: 5651790062.4658\n",
      "Epoch 538/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8325745247.7256 - val_loss: 5650210026.9589\n",
      "Epoch 539/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8123284602.9503 - val_loss: 5649125172.6027\n",
      "Epoch 540/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8197047396.1166 - val_loss: 5650538043.6164\n",
      "Epoch 541/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8364153218.4151 - val_loss: 5651788077.5890\n",
      "Epoch 542/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8631244177.3448 - val_loss: 5650735700.1644\n",
      "Epoch 543/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8459554290.8268 - val_loss: 5650315712.8767\n",
      "Epoch 544/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8246839434.7581 - val_loss: 5649821247.1233\n",
      "Epoch 545/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8280551270.3122 - val_loss: 5648855011.9452\n",
      "Epoch 546/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 7897042114.5249 - val_loss: 5647563116.7123\n",
      "Epoch 547/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8602894137.5232 - val_loss: 5646672538.3014\n",
      "Epoch 548/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8147875725.8319 - val_loss: 5646113820.0548\n",
      "Epoch 549/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8199474335.8353 - val_loss: 5645829070.9041\n",
      "Epoch 550/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8292010066.5523 - val_loss: 5645251050.9589\n",
      "Epoch 551/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8616036070.9708 - val_loss: 5645634700.2740\n",
      "Epoch 552/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8385634758.9160 - val_loss: 5647753321.2055\n",
      "Epoch 553/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8352451288.0412 - val_loss: 5643172092.4932\n",
      "Epoch 554/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8676565923.3482 - val_loss: 5641350056.3288\n",
      "Epoch 555/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8472452126.7376 - val_loss: 5644255203.9452\n",
      "Epoch 556/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8850219456.7684 - val_loss: 5648876642.1918\n",
      "Epoch 557/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8315530822.2573 - val_loss: 5646554778.3014\n",
      "Epoch 558/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8364550063.2041 - val_loss: 5645104468.1644\n",
      "Epoch 559/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8439891144.2333 - val_loss: 5646468373.0411\n",
      "Epoch 560/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 8068743632.1372 - val_loss: 5646199239.8904\n",
      "Epoch 561/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8607546692.9400 - val_loss: 5646525324.2740\n",
      "Epoch 562/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8391533712.0274 - val_loss: 5645604408.1096\n",
      "Epoch 563/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8606967258.2367 - val_loss: 5645849526.3562\n",
      "Epoch 564/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8357308598.6690 - val_loss: 5645481713.9726\n",
      "Epoch 565/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8315034116.3911 - val_loss: 5646262924.2740\n",
      "Epoch 566/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8715512247.1081 - val_loss: 5645518848.0000\n",
      "Epoch 567/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8262363606.7238 - val_loss: 5646210055.0137\n",
      "Epoch 568/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8488478427.5540 - val_loss: 5647721770.0822\n",
      "Epoch 569/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 179us/step - loss: 8719619224.8096 - val_loss: 5648110350.0274\n",
      "Epoch 570/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8153207597.2281 - val_loss: 5648693798.5753\n",
      "Epoch 571/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8315854856.7822 - val_loss: 5649001885.8082\n",
      "Epoch 572/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8158932029.4751 - val_loss: 5649138112.8767\n",
      "Epoch 573/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8689973876.8027 - val_loss: 5649922153.2055\n",
      "Epoch 574/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8738867985.1252 - val_loss: 5651413518.0274\n",
      "Epoch 575/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8395461361.5094 - val_loss: 5653079397.6986\n",
      "Epoch 576/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8536276893.2007 - val_loss: 5654469498.7397\n",
      "Epoch 577/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8789174939.4443 - val_loss: 5654175530.0822\n",
      "Epoch 578/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8469625628.5420 - val_loss: 5652682773.0411\n",
      "Epoch 579/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7956086858.2093 - val_loss: 5650973492.6027\n",
      "Epoch 580/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8527805115.9382 - val_loss: 5652082225.0959\n",
      "Epoch 581/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8191687975.0806 - val_loss: 5652323538.4110\n",
      "Epoch 582/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8042040764.3774 - val_loss: 5651045418.0822\n",
      "Epoch 583/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8392714440.2333 - val_loss: 5650399680.8767\n",
      "Epoch 584/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8401955158.5043 - val_loss: 5651511106.6301\n",
      "Epoch 585/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8154268987.2796 - val_loss: 5650337795.5068\n",
      "Epoch 586/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8758154629.9280 - val_loss: 5650500895.5616\n",
      "Epoch 587/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8365820348.3774 - val_loss: 5648366129.0959\n",
      "Epoch 588/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8533391251.9794 - val_loss: 5650351882.5205\n",
      "Epoch 589/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8641688404.7479 - val_loss: 5649710115.0685\n",
      "Epoch 590/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 9022415475.0463 - val_loss: 5652094997.0411\n",
      "Epoch 591/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8248549855.5060 - val_loss: 5646814222.0274\n",
      "Epoch 592/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8266463377.3448 - val_loss: 5647465773.5890\n",
      "Epoch 593/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8644788258.6895 - val_loss: 5648242014.6849\n",
      "Epoch 594/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8125878065.1801 - val_loss: 5647707683.0685\n",
      "Epoch 595/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8102923374.6552 - val_loss: 5648957559.2329\n",
      "Epoch 596/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8553829237.2419 - val_loss: 5649616426.0822\n",
      "Epoch 597/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8467946767.3688 - val_loss: 5648398188.7123\n",
      "Epoch 598/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8324163390.7925 - val_loss: 5647394682.7397\n",
      "Epoch 599/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8498299074.5249 - val_loss: 5647545424.6575\n",
      "Epoch 600/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8474941294.2161 - val_loss: 5647045302.3562\n",
      "Epoch 601/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8625403957.5712 - val_loss: 5646317469.8082\n",
      "Epoch 602/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8620698490.5111 - val_loss: 5648930111.1233\n",
      "Epoch 603/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8399156469.0223 - val_loss: 5650139504.2192\n",
      "Epoch 604/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8502620658.8268 - val_loss: 5651355595.3973\n",
      "Epoch 605/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8500332494.8199 - val_loss: 5651806755.0685\n",
      "Epoch 606/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8600359998.3533 - val_loss: 5653233579.8356\n",
      "Epoch 607/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8565374348.9537 - val_loss: 5655716078.4658\n",
      "Epoch 608/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8740041216.8782 - val_loss: 5659838029.1507\n",
      "Epoch 609/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8775735756.1852 - val_loss: 5661819272.7671\n",
      "Epoch 610/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8504675232.7136 - val_loss: 5662911726.4658\n",
      "Epoch 611/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8237021881.3036 - val_loss: 5659051078.1370\n",
      "Epoch 612/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8496500313.5780 - val_loss: 5657849003.8356\n",
      "Epoch 613/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8537696613.4340 - val_loss: 5655889976.1096\n",
      "Epoch 614/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8665201937.1252 - val_loss: 5657212850.8493\n",
      "Epoch 615/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8597884718.9846 - val_loss: 5656282908.0548\n",
      "Epoch 616/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8453991781.4340 - val_loss: 5655504773.2603\n",
      "Epoch 617/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8716067978.7581 - val_loss: 5655884217.8630\n",
      "Epoch 618/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8566034323.9794 - val_loss: 5657183877.2603\n",
      "Epoch 619/1000\n",
      "1166/1166 [==============================] - 0s 199us/step - loss: 8361675563.4717 - val_loss: 5654609211.6164\n",
      "Epoch 620/1000\n",
      "1166/1166 [==============================] - 0s 203us/step - loss: 8509071675.2796 - val_loss: 5651911189.0411\n",
      "Epoch 621/1000\n",
      "1166/1166 [==============================] - 0s 201us/step - loss: 8394482384.1372 - val_loss: 5654099789.1507\n",
      "Epoch 622/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8504795596.1852 - val_loss: 5656918328.1096\n",
      "Epoch 623/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8146143571.8696 - val_loss: 5657257899.8356\n",
      "Epoch 624/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8030054315.6913 - val_loss: 5655106798.4658\n",
      "Epoch 625/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 8492417703.7393 - val_loss: 5653042467.0685\n",
      "Epoch 626/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8129181125.1595 - val_loss: 5650208852.1644\n",
      "Epoch 627/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8635134228.6381 - val_loss: 5651488992.4384\n",
      "Epoch 628/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8587820684.5146 - val_loss: 5652853170.8493\n",
      "Epoch 629/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8440936474.3465 - val_loss: 5655013716.1644\n",
      "Epoch 630/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 8676332443.8834 - val_loss: 5657803726.9041\n",
      "Epoch 631/1000\n",
      "1166/1166 [==============================] - 0s 190us/step - loss: 8167048838.8062 - val_loss: 5655887430.1370\n",
      "Epoch 632/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8332635235.6775 - val_loss: 5655012036.3836\n",
      "Epoch 633/1000\n",
      "1166/1166 [==============================] - 0s 198us/step - loss: 8191015437.1732 - val_loss: 5650833450.0822\n",
      "Epoch 634/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 176us/step - loss: 8365660330.3739 - val_loss: 5650961534.2466\n",
      "Epoch 635/1000\n",
      "1166/1166 [==============================] - 0s 149us/step - loss: 8521978298.6209 - val_loss: 5650053246.2466\n",
      "Epoch 636/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8165709745.8388 - val_loss: 5648302044.9315\n",
      "Epoch 637/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8276867618.2504 - val_loss: 5650385565.8082\n",
      "Epoch 638/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8504666177.4271 - val_loss: 5652393422.9041\n",
      "Epoch 639/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8614696498.0583 - val_loss: 5652754509.1507\n",
      "Epoch 640/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8442732255.0669 - val_loss: 5651634663.4521\n",
      "Epoch 641/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8222370754.9640 - val_loss: 5651039435.3973\n",
      "Epoch 642/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8027753104.9057 - val_loss: 5650285666.1918\n",
      "Epoch 643/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8715881689.7976 - val_loss: 5652854678.7945\n",
      "Epoch 644/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8744375426.8542 - val_loss: 5652699100.9315\n",
      "Epoch 645/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8545499062.2298 - val_loss: 5653466918.5753\n",
      "Epoch 646/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8844573512.8919 - val_loss: 5654704976.6575\n",
      "Epoch 647/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8499693517.0635 - val_loss: 5656020199.4521\n",
      "Epoch 648/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8610973565.1458 - val_loss: 5658675164.9315\n",
      "Epoch 649/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8241500209.1801 - val_loss: 5655690408.3288\n",
      "Epoch 650/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8076225099.0875 - val_loss: 5655138198.7945\n",
      "Epoch 651/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8388627789.7221 - val_loss: 5657043357.8082\n",
      "Epoch 652/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8343611332.2813 - val_loss: 5656187360.4384\n",
      "Epoch 653/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8323256343.7118 - val_loss: 5654349466.3014\n",
      "Epoch 654/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8254855946.0995 - val_loss: 5654680148.1644\n",
      "Epoch 655/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8628576747.8010 - val_loss: 5656048440.1096\n",
      "Epoch 656/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8495974854.0377 - val_loss: 5654435468.2740\n",
      "Epoch 657/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8677813322.6484 - val_loss: 5652558090.5205\n",
      "Epoch 658/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8493929791.6707 - val_loss: 5652249368.5479\n",
      "Epoch 659/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8657911363.1835 - val_loss: 5653237132.2740\n",
      "Epoch 660/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8331191006.1887 - val_loss: 5650428107.3973\n",
      "Epoch 661/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8332253659.5540 - val_loss: 5649708635.1781\n",
      "Epoch 662/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8335076084.1441 - val_loss: 5647821568.0000\n",
      "Epoch 663/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8440834975.3962 - val_loss: 5648991431.8904\n",
      "Epoch 664/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8145886236.9811 - val_loss: 5646197900.2740\n",
      "Epoch 665/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8075635334.3671 - val_loss: 5645496102.5753\n",
      "Epoch 666/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8510105614.9297 - val_loss: 5646639338.9589\n",
      "Epoch 667/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8283635216.2470 - val_loss: 5645404089.8630\n",
      "Epoch 668/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8512971037.4202 - val_loss: 5642315628.7123\n",
      "Epoch 669/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8811081545.3310 - val_loss: 5645181944.9863\n",
      "Epoch 670/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8393705048.6998 - val_loss: 5644652319.5616\n",
      "Epoch 671/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8642571656.5626 - val_loss: 5646975880.7671\n",
      "Epoch 672/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8263362247.3551 - val_loss: 5646102780.4932\n",
      "Epoch 673/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8302695491.6226 - val_loss: 5646009505.3151\n",
      "Epoch 674/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 7956540819.9794 - val_loss: 5644941034.9589\n",
      "Epoch 675/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 8205749650.2230 - val_loss: 5643203745.3151\n",
      "Epoch 676/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8583123081.8799 - val_loss: 5644139586.6301\n",
      "Epoch 677/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8417375056.3568 - val_loss: 5644975626.5205\n",
      "Epoch 678/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8493335316.6381 - val_loss: 5643065845.4795\n",
      "Epoch 679/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8502659031.6021 - val_loss: 5645616510.2466\n",
      "Epoch 680/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8431221514.0995 - val_loss: 5643826302.2466\n",
      "Epoch 681/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8776834552.0961 - val_loss: 5644248968.7671\n",
      "Epoch 682/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8422744493.4477 - val_loss: 5644432650.5205\n",
      "Epoch 683/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8573173482.4837 - val_loss: 5645212377.4247\n",
      "Epoch 684/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8308107464.2333 - val_loss: 5648181395.2877\n",
      "Epoch 685/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8461953547.4168 - val_loss: 5647512782.9041\n",
      "Epoch 686/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8830779414.8336 - val_loss: 5647152527.7808\n",
      "Epoch 687/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8348454607.2590 - val_loss: 5647564067.0685\n",
      "Epoch 688/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8780446130.7170 - val_loss: 5651971240.3288\n",
      "Epoch 689/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8487409051.0051 - val_loss: 5652343383.6712\n",
      "Epoch 690/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8297927883.7461 - val_loss: 5651515493.6986\n",
      "Epoch 691/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8496259201.9760 - val_loss: 5655919980.7123\n",
      "Epoch 692/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8467900061.2007 - val_loss: 5656331790.0274\n",
      "Epoch 693/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8372064601.5780 - val_loss: 5657318024.7671\n",
      "Epoch 694/1000\n",
      "1166/1166 [==============================] - 0s 231us/step - loss: 8169514122.7581 - val_loss: 5652832480.4384\n",
      "Epoch 695/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8503235798.2847 - val_loss: 5651858972.0548\n",
      "Epoch 696/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8354398346.7581 - val_loss: 5652757111.2329\n",
      "Epoch 697/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8754211509.7907 - val_loss: 5654373368.9863\n",
      "Epoch 698/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8382776132.0618 - val_loss: 5653454083.5068\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 167us/step - loss: 8490522116.3911 - val_loss: 5654216910.9041\n",
      "Epoch 700/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8412374794.9777 - val_loss: 5655172755.2877\n",
      "Epoch 701/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8512187102.1887 - val_loss: 5656492466.8493\n",
      "Epoch 702/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8358512620.6792 - val_loss: 5655762133.9178\n",
      "Epoch 703/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8544574933.8456 - val_loss: 5654613349.6986\n",
      "Epoch 704/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8491067161.9074 - val_loss: 5656102743.6712\n",
      "Epoch 705/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8343191605.5712 - val_loss: 5657427340.2740\n",
      "Epoch 706/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8397737774.1063 - val_loss: 5654139125.4795\n",
      "Epoch 707/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8447901084.7616 - val_loss: 5654503834.3014\n",
      "Epoch 708/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8571281484.4048 - val_loss: 5653632371.7260\n",
      "Epoch 709/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8406785854.7925 - val_loss: 5652710617.4247\n",
      "Epoch 710/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8306827209.5506 - val_loss: 5652023015.4521\n",
      "Epoch 711/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8303584281.4683 - val_loss: 5648661493.4795\n",
      "Epoch 712/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8339231352.3156 - val_loss: 5648888607.5616\n",
      "Epoch 713/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8582797488.0823 - val_loss: 5650552193.7534\n",
      "Epoch 714/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8390930793.8250 - val_loss: 5650838591.1233\n",
      "Epoch 715/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8384436030.7925 - val_loss: 5652164495.7808\n",
      "Epoch 716/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8367207277.7770 - val_loss: 5649752099.0685\n",
      "Epoch 717/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8611215052.6244 - val_loss: 5650822519.2329\n",
      "Epoch 718/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8751894589.4751 - val_loss: 5652960522.5205\n",
      "Epoch 719/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8505059419.3345 - val_loss: 5652466281.2055\n",
      "Epoch 720/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8388154531.7873 - val_loss: 5650451589.2603\n",
      "Epoch 721/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8546234446.6003 - val_loss: 5652624173.5890\n",
      "Epoch 722/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8041753972.3636 - val_loss: 5654612150.3562\n",
      "Epoch 723/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8807338816.5489 - val_loss: 5654721500.9315\n",
      "Epoch 724/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8297656973.3928 - val_loss: 5657086898.8493\n",
      "Epoch 725/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8303433482.9777 - val_loss: 5653187955.7260\n",
      "Epoch 726/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8541629540.5557 - val_loss: 5654323880.3288\n",
      "Epoch 727/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8660610130.5523 - val_loss: 5655804521.2055\n",
      "Epoch 728/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8425725450.9777 - val_loss: 5655337591.2329\n",
      "Epoch 729/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8648370112.7684 - val_loss: 5653441476.3836\n",
      "Epoch 730/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8386562832.2470 - val_loss: 5655777202.8493\n",
      "Epoch 731/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8358407503.4786 - val_loss: 5652775672.9863\n",
      "Epoch 732/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8264916803.1835 - val_loss: 5652401867.3973\n",
      "Epoch 733/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8226092390.3122 - val_loss: 5651563828.6027\n",
      "Epoch 734/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8266220587.4717 - val_loss: 5653197655.6712\n",
      "Epoch 735/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8453498882.6346 - val_loss: 5654619079.8904\n",
      "Epoch 736/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8410020485.9280 - val_loss: 5656086668.2740\n",
      "Epoch 737/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8608091311.6432 - val_loss: 5655655094.3562\n",
      "Epoch 738/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8249082867.7050 - val_loss: 5654578680.9863\n",
      "Epoch 739/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8539769254.4220 - val_loss: 5653812034.6301\n",
      "Epoch 740/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8379695005.6398 - val_loss: 5651826933.4795\n",
      "Epoch 741/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8195981587.7599 - val_loss: 5651207385.4247\n",
      "Epoch 742/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8817043268.9400 - val_loss: 5652664881.0959\n",
      "Epoch 743/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8502943972.3362 - val_loss: 5650309646.0274\n",
      "Epoch 744/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8247324833.5918 - val_loss: 5652208692.6027\n",
      "Epoch 745/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8700115912.6724 - val_loss: 5655421671.4521\n",
      "Epoch 746/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8792310259.2659 - val_loss: 5656482458.3014\n",
      "Epoch 747/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8939971770.1818 - val_loss: 5658707382.3562\n",
      "Epoch 748/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8452262679.2727 - val_loss: 5655785454.4658\n",
      "Epoch 749/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8504569096.3431 - val_loss: 5654550135.2329\n",
      "Epoch 750/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8565953920.6587 - val_loss: 5655296371.7260\n",
      "Epoch 751/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8291941599.9451 - val_loss: 5658090881.7534\n",
      "Epoch 752/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8445884376.6998 - val_loss: 5658179619.0685\n",
      "Epoch 753/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8846696840.5626 - val_loss: 5661435072.8767\n",
      "Epoch 754/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8268554518.8336 - val_loss: 5661398513.9726\n",
      "Epoch 755/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7997403777.9760 - val_loss: 5659065792.8767\n",
      "Epoch 756/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8532847693.2830 - val_loss: 5661095943.0137\n",
      "Epoch 757/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8717408760.0961 - val_loss: 5662122587.1781\n",
      "Epoch 758/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8781615835.5540 - val_loss: 5663109702.1370\n",
      "Epoch 759/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8434379822.5455 - val_loss: 5662763491.9452\n",
      "Epoch 760/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8462214908.0480 - val_loss: 5662319153.0959\n",
      "Epoch 761/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8390615836.5420 - val_loss: 5660856817.9726\n",
      "Epoch 762/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8484679643.1149 - val_loss: 5657864609.3151\n",
      "Epoch 763/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8424164932.5009 - val_loss: 5655297855.1233\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 159us/step - loss: 8115505805.3928 - val_loss: 5652190074.7397\n",
      "Epoch 765/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8425299758.9846 - val_loss: 5654352738.1918\n",
      "Epoch 766/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8678500762.1269 - val_loss: 5653918334.2466\n",
      "Epoch 767/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8634702835.2659 - val_loss: 5652131927.6712\n",
      "Epoch 768/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9078731788.2950 - val_loss: 5653068330.0822\n",
      "Epoch 769/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8675692991.0120 - val_loss: 5652580702.6849\n",
      "Epoch 770/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8743728567.1081 - val_loss: 5654603481.4247\n",
      "Epoch 771/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8302296895.6707 - val_loss: 5655673189.6986\n",
      "Epoch 772/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8054454604.8439 - val_loss: 5652504021.9178\n",
      "Epoch 773/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8081208527.2590 - val_loss: 5651090901.9178\n",
      "Epoch 774/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8596975280.5214 - val_loss: 5650677276.0548\n",
      "Epoch 775/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8236803023.6981 - val_loss: 5653866134.7945\n",
      "Epoch 776/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8327868596.9125 - val_loss: 5654014008.1096\n",
      "Epoch 777/1000\n",
      "1166/1166 [==============================] - 0s 148us/step - loss: 8520445946.7307 - val_loss: 5651732725.4795\n",
      "Epoch 778/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8096058604.6792 - val_loss: 5649600049.0959\n",
      "Epoch 779/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8790077225.7153 - val_loss: 5650152672.4384\n",
      "Epoch 780/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8239839752.7822 - val_loss: 5648064827.6164\n",
      "Epoch 781/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8452613140.1990 - val_loss: 5648682341.6986\n",
      "Epoch 782/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8453036672.2196 - val_loss: 5648292239.7808\n",
      "Epoch 783/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8013256843.6364 - val_loss: 5648288711.8904\n",
      "Epoch 784/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8642288569.7427 - val_loss: 5651601288.7671\n",
      "Epoch 785/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8355509164.5695 - val_loss: 5651341536.4384\n",
      "Epoch 786/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8064435166.6278 - val_loss: 5650034631.8904\n",
      "Epoch 787/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8446826135.9314 - val_loss: 5650574525.3699\n",
      "Epoch 788/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8269210055.7942 - val_loss: 5650281889.3151\n",
      "Epoch 789/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8389492600.7547 - val_loss: 5648998028.2740\n",
      "Epoch 790/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8262189706.7581 - val_loss: 5649045069.1507\n",
      "Epoch 791/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8377032518.6964 - val_loss: 5649721715.7260\n",
      "Epoch 792/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8228594163.7050 - val_loss: 5650673194.0822\n",
      "Epoch 793/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8676758893.3379 - val_loss: 5648893275.1781\n",
      "Epoch 794/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8710668321.3722 - val_loss: 5647521336.1096\n",
      "Epoch 795/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8698237880.8645 - val_loss: 5645780255.5616\n",
      "Epoch 796/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8615537560.3705 - val_loss: 5645337866.5205\n",
      "Epoch 797/1000\n",
      "1166/1166 [==============================] - 0s 192us/step - loss: 9123907151.9177 - val_loss: 5645612151.2329\n",
      "Epoch 798/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8359727142.6415 - val_loss: 5643593121.3151\n",
      "Epoch 799/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8274386120.2333 - val_loss: 5642875595.3973\n",
      "Epoch 800/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8600250694.6964 - val_loss: 5643491959.2329\n",
      "Epoch 801/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8372421503.7804 - val_loss: 5642681400.1096\n",
      "Epoch 802/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8417102642.4974 - val_loss: 5642080494.4658\n",
      "Epoch 803/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8462747226.4563 - val_loss: 5643365758.2466\n",
      "Epoch 804/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8597082419.3756 - val_loss: 5647183296.8767\n",
      "Epoch 805/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8441559428.1715 - val_loss: 5646789344.4384\n",
      "Epoch 806/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8274205291.5815 - val_loss: 5646046053.6986\n",
      "Epoch 807/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8450463689.5506 - val_loss: 5647537797.2603\n",
      "Epoch 808/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8437233302.1750 - val_loss: 5648381054.2466\n",
      "Epoch 809/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8678590394.6209 - val_loss: 5649174668.2740\n",
      "Epoch 810/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8411827034.0172 - val_loss: 5650545930.5205\n",
      "Epoch 811/1000\n",
      "1166/1166 [==============================] - 0s 187us/step - loss: 8193761334.4494 - val_loss: 5647482346.9589\n",
      "Epoch 812/1000\n",
      "1166/1166 [==============================] - 0s 200us/step - loss: 8393761983.0120 - val_loss: 5648729631.5616\n",
      "Epoch 813/1000\n",
      "1166/1166 [==============================] - 0s 204us/step - loss: 8611772531.9245 - val_loss: 5649424292.8219\n",
      "Epoch 814/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8122837098.2642 - val_loss: 5647860413.3699\n",
      "Epoch 815/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8285441687.9314 - val_loss: 5647084172.2740\n",
      "Epoch 816/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8600485542.8611 - val_loss: 5649540060.9315\n",
      "Epoch 817/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8513891907.6226 - val_loss: 5650597025.3151\n",
      "Epoch 818/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8082392355.1286 - val_loss: 5650546400.4384\n",
      "Epoch 819/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8483880475.2247 - val_loss: 5650316161.7534\n",
      "Epoch 820/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8440025390.1063 - val_loss: 5648867952.2192\n",
      "Epoch 821/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8398526938.2367 - val_loss: 5650159349.4795\n",
      "Epoch 822/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8658185416.2333 - val_loss: 5649127434.5205\n",
      "Epoch 823/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8422481909.4614 - val_loss: 5649519075.9452\n",
      "Epoch 824/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8314397292.0206 - val_loss: 5649121146.7397\n",
      "Epoch 825/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8600882911.9451 - val_loss: 5650163459.5068\n",
      "Epoch 826/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8909896936.2882 - val_loss: 5653291818.0822\n",
      "Epoch 827/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8378215864.8645 - val_loss: 5652519059.2877\n",
      "Epoch 828/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8393451967.8902 - val_loss: 5652822331.6164\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 160us/step - loss: 8817462664.5626 - val_loss: 5653196733.3699\n",
      "Epoch 830/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8397921831.5197 - val_loss: 5651784051.7260\n",
      "Epoch 831/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8625363068.7067 - val_loss: 5653675653.2603\n",
      "Epoch 832/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8272686707.0463 - val_loss: 5654088381.3699\n",
      "Epoch 833/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8289206296.5901 - val_loss: 5651819667.2877\n",
      "Epoch 834/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8915047780.5557 - val_loss: 5654071411.7260\n",
      "Epoch 835/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8187159015.4099 - val_loss: 5652920099.0685\n",
      "Epoch 836/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8325362027.5815 - val_loss: 5652769911.2329\n",
      "Epoch 837/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8347812330.9228 - val_loss: 5656788543.1233\n",
      "Epoch 838/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8439337650.2779 - val_loss: 5655931444.6027\n",
      "Epoch 839/1000\n",
      "1166/1166 [==============================] - 0s 151us/step - loss: 8187792284.7616 - val_loss: 5658008186.7397\n",
      "Epoch 840/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 9008678658.1955 - val_loss: 5657948089.8630\n",
      "Epoch 841/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8984204927.3413 - val_loss: 5661247551.1233\n",
      "Epoch 842/1000\n",
      "1166/1166 [==============================] - 0s 156us/step - loss: 8656302132.6930 - val_loss: 5661491971.5068\n",
      "Epoch 843/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8556178769.2350 - val_loss: 5660769574.5753\n",
      "Epoch 844/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8445885434.7307 - val_loss: 5662616905.6438\n",
      "Epoch 845/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8167620142.5455 - val_loss: 5658173496.1096\n",
      "Epoch 846/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8074140008.0686 - val_loss: 5657857532.4932\n",
      "Epoch 847/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8132964949.1870 - val_loss: 5657461374.2466\n",
      "Epoch 848/1000\n",
      "1166/1166 [==============================] - 0s 167us/step - loss: 8450508689.3448 - val_loss: 5655481841.9726\n",
      "Epoch 849/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8394681426.5523 - val_loss: 5655658867.7260\n",
      "Epoch 850/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8161014930.6621 - val_loss: 5655143872.8767\n",
      "Epoch 851/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8431860367.5883 - val_loss: 5657614932.1644\n",
      "Epoch 852/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8519290447.9177 - val_loss: 5657342211.5068\n",
      "Epoch 853/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8615685662.7376 - val_loss: 5655397845.9178\n",
      "Epoch 854/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8223519331.2384 - val_loss: 5653961138.8493\n",
      "Epoch 855/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8251522713.2487 - val_loss: 5654784522.5205\n",
      "Epoch 856/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8210503786.7033 - val_loss: 5656328767.1233\n",
      "Epoch 857/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8383011573.0223 - val_loss: 5658034084.8219\n",
      "Epoch 858/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8446042660.8851 - val_loss: 5656156882.4110\n",
      "Epoch 859/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8816464684.3499 - val_loss: 5658439932.4932\n",
      "Epoch 860/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8593346154.2642 - val_loss: 5658012468.6027\n",
      "Epoch 861/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8383700377.2487 - val_loss: 5654556899.9452\n",
      "Epoch 862/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8009217217.2075 - val_loss: 5653613697.7534\n",
      "Epoch 863/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8351812329.6055 - val_loss: 5654999369.6438\n",
      "Epoch 864/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8189996295.4648 - val_loss: 5655516657.9726\n",
      "Epoch 865/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8436067883.0326 - val_loss: 5654003441.9726\n",
      "Epoch 866/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8498412891.7736 - val_loss: 5657416241.0959\n",
      "Epoch 867/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8752716261.6535 - val_loss: 5659353803.3973\n",
      "Epoch 868/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8198697185.2624 - val_loss: 5660893068.2740\n",
      "Epoch 869/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8694656220.4322 - val_loss: 5660410322.4110\n",
      "Epoch 870/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8485256518.2573 - val_loss: 5662367126.7945\n",
      "Epoch 871/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8279267746.0309 - val_loss: 5661952476.9315\n",
      "Epoch 872/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8632841453.9966 - val_loss: 5661505255.4521\n",
      "Epoch 873/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8075843212.5146 - val_loss: 5659727244.2740\n",
      "Epoch 874/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8488138762.5386 - val_loss: 5660990884.8219\n",
      "Epoch 875/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8710118221.7221 - val_loss: 5660678364.9315\n",
      "Epoch 876/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8618938285.4477 - val_loss: 5660879893.0411\n",
      "Epoch 877/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8438347033.0292 - val_loss: 5659022441.2055\n",
      "Epoch 878/1000\n",
      "1166/1166 [==============================] - 0s 193us/step - loss: 8494008939.1424 - val_loss: 5660248260.3836\n",
      "Epoch 879/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8211753498.3465 - val_loss: 5660186673.0959\n",
      "Epoch 880/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8997580623.4786 - val_loss: 5661673899.8356\n",
      "Epoch 881/1000\n",
      "1166/1166 [==============================] - 0s 196us/step - loss: 8483955671.6021 - val_loss: 5663359214.4658\n",
      "Epoch 882/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8167677464.5901 - val_loss: 5660460950.7945\n",
      "Epoch 883/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8290657597.9142 - val_loss: 5660611990.7945\n",
      "Epoch 884/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8503293942.3396 - val_loss: 5658138287.3425\n",
      "Epoch 885/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8581777075.5952 - val_loss: 5660137335.2329\n",
      "Epoch 886/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 7904638426.2367 - val_loss: 5660318078.2466\n",
      "Epoch 887/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8219587061.0223 - val_loss: 5658759125.9178\n",
      "Epoch 888/1000\n",
      "1166/1166 [==============================] - 0s 218us/step - loss: 8612861632.3293 - val_loss: 5657695361.7534\n",
      "Epoch 889/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8253244137.1664 - val_loss: 5656795146.5205\n",
      "Epoch 890/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8882869015.2727 - val_loss: 5655726037.9178\n",
      "Epoch 891/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8291346227.3756 - val_loss: 5653115406.0274\n",
      "Epoch 892/1000\n",
      "1166/1166 [==============================] - 0s 207us/step - loss: 8536339456.0000 - val_loss: 5653155524.3836\n",
      "Epoch 893/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8780300971.2521 - val_loss: 5657334187.8356\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 180us/step - loss: 8288508431.8079 - val_loss: 5655968803.0685\n",
      "Epoch 895/1000\n",
      "1166/1166 [==============================] - 0s 184us/step - loss: 8287649476.7204 - val_loss: 5653907515.6164\n",
      "Epoch 896/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8600566604.8439 - val_loss: 5654997637.2603\n",
      "Epoch 897/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8140849073.8388 - val_loss: 5653722988.7123\n",
      "Epoch 898/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8930004706.5798 - val_loss: 5656997158.5753\n",
      "Epoch 899/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8655270471.1355 - val_loss: 5658398712.9863\n",
      "Epoch 900/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8271352202.3190 - val_loss: 5662097969.0959\n",
      "Epoch 901/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8403091811.6775 - val_loss: 5660223396.8219\n",
      "Epoch 902/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8360001685.2967 - val_loss: 5659929631.5616\n",
      "Epoch 903/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8259665555.9794 - val_loss: 5658306419.7260\n",
      "Epoch 904/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8417124376.5901 - val_loss: 5658294703.3425\n",
      "Epoch 905/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8295655439.8079 - val_loss: 5657724584.3288\n",
      "Epoch 906/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8442663650.5798 - val_loss: 5657622847.1233\n",
      "Epoch 907/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8305907956.1441 - val_loss: 5655260167.0137\n",
      "Epoch 908/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8521306788.2264 - val_loss: 5657005715.2877\n",
      "Epoch 909/1000\n",
      "1166/1166 [==============================] - 0s 175us/step - loss: 8620457608.1235 - val_loss: 5657969173.0411\n",
      "Epoch 910/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8462678656.2196 - val_loss: 5656316465.0959\n",
      "Epoch 911/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8808543826.5523 - val_loss: 5657381617.9726\n",
      "Epoch 912/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8455304857.6878 - val_loss: 5657997557.4795\n",
      "Epoch 913/1000\n",
      "1166/1166 [==============================] - 0s 205us/step - loss: 8371442949.7084 - val_loss: 5658625581.5890\n",
      "Epoch 914/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 8704089965.3379 - val_loss: 5660789128.7671\n",
      "Epoch 915/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8219574749.7496 - val_loss: 5659881857.7534\n",
      "Epoch 916/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8582491251.9245 - val_loss: 5661047948.2740\n",
      "Epoch 917/1000\n",
      "1166/1166 [==============================] - 0s 216us/step - loss: 8202400426.3739 - val_loss: 5662965016.5479\n",
      "Epoch 918/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8439392840.8919 - val_loss: 5662127900.0548\n",
      "Epoch 919/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8344777224.3431 - val_loss: 5660882186.5205\n",
      "Epoch 920/1000\n",
      "1166/1166 [==============================] - 0s 153us/step - loss: 8228455996.5969 - val_loss: 5662257664.0000\n",
      "Epoch 921/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8484792269.9417 - val_loss: 5661797484.7123\n",
      "Epoch 922/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8469987657.7702 - val_loss: 5661916538.7397\n",
      "Epoch 923/1000\n",
      "1166/1166 [==============================] - 0s 152us/step - loss: 8189289560.6998 - val_loss: 5659495971.0685\n",
      "Epoch 924/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8532523379.0463 - val_loss: 5659775130.3014\n",
      "Epoch 925/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8383461101.9966 - val_loss: 5659825979.6164\n",
      "Epoch 926/1000\n",
      "1166/1166 [==============================] - 0s 194us/step - loss: 8373241674.2093 - val_loss: 5658925669.6986\n",
      "Epoch 927/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8330946949.0497 - val_loss: 5657314444.2740\n",
      "Epoch 928/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 8417077060.0618 - val_loss: 5655846161.5342\n",
      "Epoch 929/1000\n",
      "1166/1166 [==============================] - 0s 188us/step - loss: 8457661330.2230 - val_loss: 5653513805.1507\n",
      "Epoch 930/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 7918837078.5043 - val_loss: 5652020104.7671\n",
      "Epoch 931/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8519313263.0943 - val_loss: 5652358873.4247\n",
      "Epoch 932/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8589754575.6981 - val_loss: 5652341595.1781\n",
      "Epoch 933/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 7950059532.2950 - val_loss: 5648721246.6849\n",
      "Epoch 934/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8385419916.5146 - val_loss: 5648368955.6164\n",
      "Epoch 935/1000\n",
      "1166/1166 [==============================] - 0s 177us/step - loss: 8184388989.1458 - val_loss: 5646303779.0685\n",
      "Epoch 936/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8791425841.6192 - val_loss: 5648122508.2740\n",
      "Epoch 937/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8284347058.2779 - val_loss: 5648552293.6986\n",
      "Epoch 938/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8451164435.7599 - val_loss: 5652890602.9589\n",
      "Epoch 939/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8717950711.6569 - val_loss: 5652844000.4384\n",
      "Epoch 940/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8620304798.5180 - val_loss: 5653723602.4110\n",
      "Epoch 941/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8602106732.4597 - val_loss: 5655032393.6438\n",
      "Epoch 942/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8354839522.1407 - val_loss: 5655542801.5342\n",
      "Epoch 943/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8499075703.4374 - val_loss: 5654820337.9726\n",
      "Epoch 944/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8779685905.5643 - val_loss: 5655077495.2329\n",
      "Epoch 945/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8535069512.4528 - val_loss: 5655468088.1096\n",
      "Epoch 946/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8525312395.1973 - val_loss: 5655600036.8219\n",
      "Epoch 947/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8798968048.6312 - val_loss: 5655428716.7123\n",
      "Epoch 948/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8292332909.7770 - val_loss: 5656536204.2740\n",
      "Epoch 949/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8688522490.2916 - val_loss: 5656982983.8904\n",
      "Epoch 950/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8353118451.2659 - val_loss: 5656232995.0685\n",
      "Epoch 951/1000\n",
      "1166/1166 [==============================] - 0s 191us/step - loss: 8623340544.0000 - val_loss: 5654942695.4521\n",
      "Epoch 952/1000\n",
      "1166/1166 [==============================] - 0s 179us/step - loss: 8394584763.9382 - val_loss: 5655151254.7945\n",
      "Epoch 953/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8420138326.9434 - val_loss: 5656196169.6438\n",
      "Epoch 954/1000\n",
      "1166/1166 [==============================] - 0s 158us/step - loss: 8347559376.5763 - val_loss: 5655038909.3699\n",
      "Epoch 955/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8444599682.4151 - val_loss: 5654942109.8082\n",
      "Epoch 956/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8371727335.4099 - val_loss: 5653199391.5616\n",
      "Epoch 957/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8393531067.0600 - val_loss: 5654201477.2603\n",
      "Epoch 958/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8125176202.3190 - val_loss: 5651501210.3014\n",
      "Epoch 959/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 0s 167us/step - loss: 8617140437.4065 - val_loss: 5650042876.4932\n",
      "Epoch 960/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8559933960.7822 - val_loss: 5650668866.6301\n",
      "Epoch 961/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8317201500.6518 - val_loss: 5649446540.2740\n",
      "Epoch 962/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8337776636.4871 - val_loss: 5648384799.5616\n",
      "Epoch 963/1000\n",
      "1166/1166 [==============================] - 0s 174us/step - loss: 8501074998.0103 - val_loss: 5648636030.2466\n",
      "Epoch 964/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8448223657.0566 - val_loss: 5649322327.6712\n",
      "Epoch 965/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8683220131.3482 - val_loss: 5649019104.4384\n",
      "Epoch 966/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8261989714.9914 - val_loss: 5648822755.9452\n",
      "Epoch 967/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8245842925.5575 - val_loss: 5647333453.1507\n",
      "Epoch 968/1000\n",
      "1166/1166 [==============================] - 0s 169us/step - loss: 8093108874.7581 - val_loss: 5647393981.3699\n",
      "Epoch 969/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8202294960.5214 - val_loss: 5647311065.4247\n",
      "Epoch 970/1000\n",
      "1166/1166 [==============================] - 0s 155us/step - loss: 8635651557.6535 - val_loss: 5649382701.5890\n",
      "Epoch 971/1000\n",
      "1166/1166 [==============================] - 0s 181us/step - loss: 8755332323.4580 - val_loss: 5652574050.1918\n",
      "Epoch 972/1000\n",
      "1166/1166 [==============================] - 0s 186us/step - loss: 8507501135.9177 - val_loss: 5654005956.3836\n",
      "Epoch 973/1000\n",
      "1166/1166 [==============================] - 0s 172us/step - loss: 8744230126.8748 - val_loss: 5656346076.9315\n",
      "Epoch 974/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8264500768.4940 - val_loss: 5653636457.2055\n",
      "Epoch 975/1000\n",
      "1166/1166 [==============================] - 0s 185us/step - loss: 8838619030.6141 - val_loss: 5655161014.3562\n",
      "Epoch 976/1000\n",
      "1166/1166 [==============================] - 0s 160us/step - loss: 8484963052.2401 - val_loss: 5654860968.3288\n",
      "Epoch 977/1000\n",
      "1166/1166 [==============================] - 0s 176us/step - loss: 8387508384.7136 - val_loss: 5656722242.6301\n",
      "Epoch 978/1000\n",
      "1166/1166 [==============================] - 0s 171us/step - loss: 8184482918.3122 - val_loss: 5655998106.3014\n",
      "Epoch 979/1000\n",
      "1166/1166 [==============================] - 0s 170us/step - loss: 8481801027.1835 - val_loss: 5657566972.4932\n",
      "Epoch 980/1000\n",
      "1166/1166 [==============================] - 0s 150us/step - loss: 8354902983.7942 - val_loss: 5656303517.8082\n",
      "Epoch 981/1000\n",
      "1166/1166 [==============================] - 0s 189us/step - loss: 8154918569.4957 - val_loss: 5655542215.8904\n",
      "Epoch 982/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8395395195.8285 - val_loss: 5654299528.7671\n",
      "Epoch 983/1000\n",
      "1166/1166 [==============================] - 0s 154us/step - loss: 8337224361.4957 - val_loss: 5655109456.6575\n",
      "Epoch 984/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8334198988.8439 - val_loss: 5655555103.5616\n",
      "Epoch 985/1000\n",
      "1166/1166 [==============================] - 0s 165us/step - loss: 8573048094.2985 - val_loss: 5654946135.6712\n",
      "Epoch 986/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7902914079.6158 - val_loss: 5655014105.4247\n",
      "Epoch 987/1000\n",
      "1166/1166 [==============================] - 0s 168us/step - loss: 8522735995.3894 - val_loss: 5656758345.6438\n",
      "Epoch 988/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8559913622.1750 - val_loss: 5658241536.0000\n",
      "Epoch 989/1000\n",
      "1166/1166 [==============================] - 0s 183us/step - loss: 7965493936.5214 - val_loss: 5659169048.5479\n",
      "Epoch 990/1000\n",
      "1166/1166 [==============================] - 0s 173us/step - loss: 8603527127.6021 - val_loss: 5660291142.1370\n",
      "Epoch 991/1000\n",
      "1166/1166 [==============================] - 0s 180us/step - loss: 8486889560.6998 - val_loss: 5658221876.6027\n",
      "Epoch 992/1000\n",
      "1166/1166 [==============================] - 0s 182us/step - loss: 8338408238.9846 - val_loss: 5659138395.1781\n",
      "Epoch 993/1000\n",
      "1166/1166 [==============================] - 0s 161us/step - loss: 8684443648.8782 - val_loss: 5660484330.9589\n",
      "Epoch 994/1000\n",
      "1166/1166 [==============================] - 0s 166us/step - loss: 8169764900.8851 - val_loss: 5658242040.9863\n",
      "Epoch 995/1000\n",
      "1166/1166 [==============================] - 0s 159us/step - loss: 8511636018.9365 - val_loss: 5657534530.6301\n",
      "Epoch 996/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 8559749597.7496 - val_loss: 5661885653.9178\n",
      "Epoch 997/1000\n",
      "1166/1166 [==============================] - 0s 162us/step - loss: 8328824565.9005 - val_loss: 5657613115.6164\n",
      "Epoch 998/1000\n",
      "1166/1166 [==============================] - 0s 157us/step - loss: 8335129491.1012 - val_loss: 5657796457.2055\n",
      "Epoch 999/1000\n",
      "1166/1166 [==============================] - 0s 163us/step - loss: 8070054578.2779 - val_loss: 5657321661.3699\n",
      "Epoch 1000/1000\n",
      "1166/1166 [==============================] - 0s 164us/step - loss: 7949910132.8027 - val_loss: 5654340965.6986\n"
     ]
    }
   ],
   "source": [
    "def train_model(neurons):\n",
    "    print(\"neurons used\", neurons)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons[0], activation='relu', input_dim=287))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(neurons[1], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = tf.train.RMSPropOptimizer(0.01)\n",
    "    model.compile (loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "    hist = model.fit(train_X, train_y, epochs=1000, batch_size=32, validation_data = (val_X, val_y), callbacks=[tbCallBack])\n",
    "\n",
    "    return hist\n",
    "\n",
    "a = [8,16,32,64]\n",
    "perms = set(permutations(a, 2))\n",
    "\n",
    "for p in perms:\n",
    "    res = train_model(p)\n",
    "    history[p] = np.average([res.history['val_loss'][-1], res.history['val_loss'][-2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 16): 5655831313.534246,\n",
       " (8, 32): 5565689098.520548,\n",
       " (8, 64): 5538101851.178082,\n",
       " (16, 8): 5957681011.7260275,\n",
       " (16, 32): 5563262222.027397,\n",
       " (16, 64): 5538351019.835616,\n",
       " (32, 8): 5944650587.1780815,\n",
       " (32, 16): 5647554144.438356,\n",
       " (32, 64): 5535648775.013699,\n",
       " (64, 8): 5959677743.342465,\n",
       " (64, 16): 5647914581.917809,\n",
       " (64, 32): 5559387490.19178}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history\n",
    "\n",
    "# the key is the number of neurons in the first and second layer\n",
    "# the value is the average validation loss of the last two epochs\n",
    "# we should use the smallest network with 8 and 16 neurons in the two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_proj_res_2.csv', 'w') as f:\n",
    "    for k in history.keys():\n",
    "        f.write(str(k))\n",
    "        f.write(',')\n",
    "        f.write(str(history[k]))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
